{
    "actorCOMP": {
        "label": "actorCOMP",
        "members": [
            {
                "text": "Menu : The kinematic state defines the Actor COMPs ability to move from external forces. If an object is dynamic, then it is moveable in the simulation, but if it static then it is not.",
                "type": "Par",
                "name": "kinstate"
            },
            {
                "text": "Menu : The type of collision shape to make from the selected SOPs. Collision shapes can be viewed using a guide in the Actor COMP's viewer",
                "type": "Par",
                "name": "shape"
            },
            {
                "text": "The initial linear velocity of the actor in m/s. This parameter can also be used to modify an actor's linear velocity during a simulation. Additionally, it is used in conjunction with the \"Cue Velocity\" and \"Cue Velocity Pulse\" parameters.",
                "type": "Par",
                "name": "linvelx"
            },
            {
                "text": "The initial linear velocity of the actor in m/s. This parameter can also be used to modify an actor's linear velocity during a simulation. Additionally, it is used in conjunction with the \"Cue Velocity\" and \"Cue Velocity Pulse\" parameters.",
                "type": "Par",
                "name": "linvely"
            },
            {
                "text": "The initial linear velocity of the actor in m/s. This parameter can also be used to modify an actor's linear velocity during a simulation. Additionally, it is used in conjunction with the \"Cue Velocity\" and \"Cue Velocity Pulse\" parameters.",
                "type": "Par",
                "name": "linvelz"
            },
            {
                "text": "The initial angular velocity of the actor in degrees per second in m/s. This parameter can also be used to modify the actor's angular velocity during a simulation. Additionally, it is used in conjunction with the \"Cue Velocity\" and \"Cue Velocity Pulse\" parameters.",
                "type": "Par",
                "name": "angvelx"
            },
            {
                "text": "The initial angular velocity of the actor in degrees per second in m/s. This parameter can also be used to modify the actor's angular velocity during a simulation. Additionally, it is used in conjunction with the \"Cue Velocity\" and \"Cue Velocity Pulse\" parameters.",
                "type": "Par",
                "name": "angvely"
            },
            {
                "text": "The initial angular velocity of the actor in degrees per second in m/s. This parameter can also be used to modify the actor's angular velocity during a simulation. Additionally, it is used in conjunction with the \"Cue Velocity\" and \"Cue Velocity Pulse\" parameters.",
                "type": "Par",
                "name": "angvelz"
            },
            {
                "text": "Actor's local gravity in m/s^2. Will only be applied if the actor is not using the Bullet Solver COMP's global gravity ie. the \"Use Global Gravity\" parameter above is turned off.",
                "type": "Par",
                "name": "gravityx"
            },
            {
                "text": "Actor's local gravity in m/s^2. Will only be applied if the actor is not using the Bullet Solver COMP's global gravity ie. the \"Use Global Gravity\" parameter above is turned off.",
                "type": "Par",
                "name": "gravityy"
            },
            {
                "text": "Actor's local gravity in m/s^2. Will only be applied if the actor is not using the Bullet Solver COMP's global gravity ie. the \"Use Global Gravity\" parameter above is turned off.",
                "type": "Par",
                "name": "gravityz"
            },
            {
                "text": "Specifies the center of mass of the collision shape. The center of mass is the point around which the body will rotate. Center of mass can be viewed using a guide in the Actor COMP's viewer. It is shown as a red axis.",
                "type": "Par",
                "name": "comx"
            },
            {
                "text": "Specifies the center of mass of the collision shape. The center of mass is the point around which the body will rotate. Center of mass can be viewed using a guide in the Actor COMP's viewer. It is shown as a red axis.",
                "type": "Par",
                "name": "comy"
            },
            {
                "text": "Specifies the center of mass of the collision shape. The center of mass is the point around which the body will rotate. Center of mass can be viewed using a guide in the Actor COMP's viewer. It is shown as a red axis.",
                "type": "Par",
                "name": "comz"
            },
            {
                "text": "Menu : The type of dynamic Flex actor.",
                "type": "Par",
                "name": "flextype"
            },
            {
                "text": "The size of the 2D emission grid. The size represents the number of particles on each side of the emission grid. For example, a 2x5 emission size will emit a grid 2 particles wide and 5 particles high.",
                "type": "Par",
                "name": "emitsizex"
            },
            {
                "text": "The size of the 2D emission grid. The size represents the number of particles on each side of the emission grid. For example, a 2x5 emission size will emit a grid 2 particles wide and 5 particles high.",
                "type": "Par",
                "name": "emitsizey"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "actorCOMP",
        "opLabel": "Actor",
        "opClass": "actorCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "An Actor COMP is analogous to a body (or bodies) in a physics system.",
        "long": "An Actor COMP is analogous to a body (or bodies) in a physics system. An Actor COMP must be used in conjunction with a physics solver: either a [[Bullet Solver COMP]] or [[Nvidia Flex Solver COMP]], which in turn is analogous to the world/simulation that the actors/bodies operate in. An Actor COMP can either be static, meaning it is not affected by any forces in the simulation and cannot move (ie. has infinite mass), or it can be dynamic, meaning it is moved by forces and collides with other bodies (either static or dynamic) in the world.\n\nSee also: [[Flex]], [[Bullet Dynamics]], [[Bullet Solver COMP]], [[Force COMP]], [[Constraint COMP]], [[Bullet Solver CHOP]], [[Nvidia Flex Solver COMP]], [[Nvidia Flex TOP]].",
        "opCategories": ""
    },
    "ambientlightCOMP": {
        "label": "ambientlightCOMP",
        "members": [
            {
                "text": "You can modify the color of the light three ways: <span class=\"tipTextCOMP\">Color List</span>, <span class=\"tipTextCOMP\">Hue</span>, <span class=\"tipTextCOMP\">Saturation</span>, and <span class=\"tipTextCOMP\">Value</span>, or <span class=\"tipTextCOMP\">Red</span>, <span class=\"tipTextCOMP\">Green</span>, and <span class=\"tipTextCOMP\">Blue</span>. To choose one, click on the appropriate box and the color editing fields below change accordingly.",
                "type": "Par",
                "name": "cr"
            },
            {
                "text": "You can modify the color of the light three ways: <span class=\"tipTextCOMP\">Color List</span>, <span class=\"tipTextCOMP\">Hue</span>, <span class=\"tipTextCOMP\">Saturation</span>, and <span class=\"tipTextCOMP\">Value</span>, or <span class=\"tipTextCOMP\">Red</span>, <span class=\"tipTextCOMP\">Green</span>, and <span class=\"tipTextCOMP\">Blue</span>. To choose one, click on the appropriate box and the color editing fields below change accordingly.",
                "type": "Par",
                "name": "cg"
            },
            {
                "text": "You can modify the color of the light three ways: <span class=\"tipTextCOMP\">Color List</span>, <span class=\"tipTextCOMP\">Hue</span>, <span class=\"tipTextCOMP\">Saturation</span>, and <span class=\"tipTextCOMP\">Value</span>, or <span class=\"tipTextCOMP\">Red</span>, <span class=\"tipTextCOMP\">Green</span>, and <span class=\"tipTextCOMP\">Blue</span>. To choose one, click on the appropriate box and the color editing fields below change accordingly.",
                "type": "Par",
                "name": "cb"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Ambient Light",
        "opFamily": "COMP",
        "long": "The Ambient Light Component controls the color and intensity of the environmental light in a given scene. This light, unlike the [[Light COMP|Light Component]], has no particular source. The light it sheds comes from everywhere as opposed to a point light source or focused spotlight.",
        "opClass": "ambientlightCOMP_Class",
        "short": "The Ambient Light Component controls the color and intensity of the environmental light in a given scene.",
        "opType": "ambient",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "animationCOMP": {
        "label": "animationCOMP",
        "members": [
            {
                "text": "Menu : Specifies the method used to playback the animation or allows the output the entire animation curve.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "Menu : When <span class=\"tipTextCOMP\">Play Mode</span> is set to '''Use Input Index''' use this menu to choose the units for the index input channel. For example, choose between setting the index with frames or seconds. The Units X option sets the index to use the key information directly from the key DAT table inside the Animation COMP, disregarding any custom settings found in the attributes DAT table.",
                "type": "Par",
                "name": "inputindexunit"
            },
            {
                "text": "Menu : Adapts the range of the animation for cyclic or non-cyclic input indices. When using a cyclic input index the lookup value for index 0.0 and 1.0 result in the same value. To avoid this, set Cyclic Range to Yes and the lookup will cycle smoothly.",
                "type": "Par",
                "name": "cyclic"
            },
            {
                "text": "Menu : Set the working range for the Animation COMP.",
                "type": "Par",
                "name": "rangetype"
            },
            {
                "text": "Menu : Determines the output of the channels when past the 'End' position. Does not affect Play Mode = Output Full Range, to manipulate the [[Extend Conditions]] of that mode adjust the Extend parameters of the [[Keyframe CHOP]] inside the Animation COMP.",
                "type": "Par",
                "name": "tleft"
            },
            {
                "text": "Menu : Determines the output of the channels when before the 'Start' position. Does not affect Play Mode = Output Full Range, to manipulate the [[Extend Conditions]] of that mode adjust the Extend parameters of the [[Keyframe CHOP]] inside the Animation COMP.",
                "type": "Par",
                "name": "tright"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Animation Component is a special component used for creating keyframe animation channels. The component contains a pre-defined network utilizing a [[Keyframe CHOP]] and a number of [[Table DAT]]s to define the animated [[CHOP]] channels.\t\t\n\t\t\t\nThe [[Animation Editor]] is the user interface for creating and editing the animation of the Animation Component.\t\t\t\n\t\t\t\nThe Animation Component has both in and out CHOP connectors. \t\t\t\n\t\t\t\n'''Animation Component Inputs'''\t\t\t\n\t\t\t\nWith no input connected, the Animation Component's index loops over the time range of the channels. \t\t\t\nThe CHOP input can be used to manually control the index of the animated channels. For example, if the channels are keyed from frame 1 to 600, you can connect an input to the component and manually drive the animation output by feeding it a number between 1 and 600 (indexes outside the range will use the channel extend conditions). \t\t\t\n\t\t\t\nUsing the Keyframe CHOP's Index Units menu, you can drive the animation with numbers expressed in seconds, samples, or a fraction where 0 is the start and 1 is the end.\t\t\t\n\t\t\t\n'''Animation Component Outputs'''\t\t\t\nThe CHOP output gives access to the animation channel's current value. CHOPs can be directly connected or a [[Null CHOP]] may be appended for [[CHOP Export|exporting]] the channels to parameters. The current channel values can also be viewed by turning on the Animation Component's [[Node Viewer|node viewer]].\t\t\t\n\t\t\t\n[[image:AnimationCOMPTimesliced.png|right]]",
        "opLabel": "Animation",
        "opLicense": "Non-Commercial",
        "opFamily": "COMP",
        "short": "The Animation Component is a special component used for creating keyframe animation channels.",
        "opType": "animation",
        "opFilter": "False",
        "opClass": "animationCOMP_Class",
        "opCategories": ""
    },
    "annotateCOMP": {
        "label": "annotateCOMP",
        "members": [
            {
                "text": "Menu : Switch between Comment, Network Box, and Annotate Modes",
                "type": "Par",
                "name": "Mode"
            },
            {
                "text": "Menu : Alignment of title text",
                "type": "Par",
                "name": "Titlealign"
            },
            {
                "text": "Menu : Switch between Comment, Network Box, and Annotate modes. See also [[Network_Utilities:_Comments,_Network_Boxes,_Annotates]].",
                "type": "Par",
                "name": "Mode"
            },
            {
                "text": "Background color",
                "type": "Par",
                "name": "Backcolorr"
            },
            {
                "text": "Background color",
                "type": "Par",
                "name": "Backcolorg"
            },
            {
                "text": "Background color",
                "type": "Par",
                "name": "Backcolorb"
            },
            {
                "text": "Menu : Use the Size/Aspect Override to control viewer's size in the background.",
                "type": "Par",
                "name": "Opvieweroversize"
            },
            {
                "text": "Diplay viewer as-if it were being displayed at this resolution. This is particularly useful for zooming into operators that don't have a built-in resolution, like CHOPs, SOPs, and DATs.",
                "type": "Par",
                "name": "Opviewersizew"
            },
            {
                "text": "Diplay viewer as-if it were being displayed at this resolution. This is particularly useful for zooming into operators that don't have a built-in resolution, like CHOPs, SOPs, and DATs.",
                "type": "Par",
                "name": "Opviewersizeh"
            },
            {
                "text": "Offsets the displayed area within the viewer. Combined with OP Viewer Zoom, this lets you display a specific area of a viewer, such as a CHOP channel or table cell.",
                "type": "Par",
                "name": "Opvieweroffsetx"
            },
            {
                "text": "Offsets the displayed area within the viewer. Combined with OP Viewer Zoom, this lets you display a specific area of a viewer, such as a CHOP channel or table cell.",
                "type": "Par",
                "name": "Opvieweroffsety"
            },
            {
                "text": "Menu : Where this annotateCOMP is layered with regards to other items in the network.",
                "type": "Par",
                "name": "layerzone"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "annotateCOMP",
        "opLabel": "Annotate",
        "opClass": "annotateCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "",
        "long": "Annotates are displayed in the Network Editor as colored rectangles containing user-authored text and graphics. It is based on the [[Annotate COMP]] and allows you to document your networks with useful information like comments and node grouping.\n\nThere are three built-in forms of the Annotate COMP:  [[Network_Utilities:_Comments,_Network_Boxes,_Annotates|Comments, Network Boxes, and Annotates]] that can be easily created:\n* '''[[Network_Utilities:_Comments,_Network_Boxes,_Annotates|Comments]]''' are simple, text-only post-it notes. They can be created via the network RMB menu or with the shortcut Shift-C\n* '''[[Network_Utilities:_Comments,_Network_Boxes,_Annotates|Network Boxes]]''' group nodes together for labeling/dragging. They can be created via the network RMB menu or with the shortcut Shift-B\n* '''[[#Default_Setup|Annotates]]''' (Default Setup) do all of the above and incorporate a powerful node-viewing feature. They can be created via the network RMB menu, with the shortcut Shift-A, by holding Alt and left-dragging in the network, or by selecting Annotate from the COMP family in the [[OP Create Dialog]]."
    },
    "baseCOMP": {
        "label": "baseCOMP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLabel": "Base",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "short": "The Base Component has no panel parameters and no 3D object parameters.",
        "opFamily": "COMP",
        "long": "The Base Component has no panel parameters and no 3D object parameters. You would use it for a component that has no panel associated with it, nor any 3D, such as component that converted RGB channels to HSV channels.",
        "opType": "base",
        "opClass": "baseCOMP_Class",
        "opCategories": ""
    },
    "blendCOMP": {
        "label": "blendCOMP",
        "members": [
            {
                "text": "Menu : Method in which parent transforms (i.e. Translate, Rotate, Scale) are combined to produce a unique blended transform.",
                "type": "Par",
                "name": "parenttype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "opLabel": "Blend",
        "opFamily": "COMP",
        "long": "The Blend Component allows the blending of its attached 3D objects, allowing you to animate the parents of Components, sequencing (object A to object B to C, etc.), partial transformation inheritance, three-point orientation, and other effects. It gives you some extra flexibility in setting up parent-child relationships. It operates like the Switch and Sequence Blend SOPs insofar as it takes more than one input and blends or switches those into one output.\tIt affects the object transform only, not the contents of the blended components.\n\nSome potential uses of the Blend op are to animate parenting, such as when one character passes an item to another, or to pass on only part of a parents characteristics.\n\nNote that the effect of the Blend COMP is only visible through a [[Camera COMP]] or the [[Render TOP]] that is rendering that camera's view.\n\nSee also [[Camera Blend COMP]].",
        "opClass": "blendCOMP_Class",
        "short": "The Blend Component allows various effects such as blended inputs, animating the parents of Components, sequencing, partial transformation inheritance, three-point orientation, and other effects.",
        "opType": "blend",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "boneCOMP": {
        "label": "boneCOMP",
        "members": [
            {
                "text": "Defines the relative weighting of rotations about Rx, Ry, Rz, the bone's x,y,z axis for the Inverse Kinematics solver.",
                "type": "Par",
                "name": "restanglesx"
            },
            {
                "text": "Defines the relative weighting of rotations about Rx, Ry, Rz, the bone's x,y,z axis for the Inverse Kinematics solver.",
                "type": "Par",
                "name": "restanglesy"
            },
            {
                "text": "Defines the relative weighting of rotations about Rx, Ry, Rz, the bone's x,y,z axis for the Inverse Kinematics solver.",
                "type": "Par",
                "name": "restanglesz"
            },
            {
                "text": "Float : Specifies the maximum and minimum rotation angles.",
                "type": "Par",
                "name": "xrange"
            },
            {
                "text": "Float : Specifies the maximum and minimum rotation angles.",
                "type": "Par",
                "name": "yrange"
            },
            {
                "text": "Position of the center of the region.",
                "type": "Par",
                "name": "crcenterx"
            },
            {
                "text": "Position of the center of the region.",
                "type": "Par",
                "name": "crcentery"
            },
            {
                "text": "Position of the center of the region.",
                "type": "Par",
                "name": "crcenterz"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "crtopcapx"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "crtopcapy"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "crtopcapz"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "crbotcapx"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "crbotcapy"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "crbotcapz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Bone",
        "opFamily": "COMP",
        "long": "The Bone Component is the foundation of all of the [[Character Tools]]. It is a Component with most of the properties of a [[Geometry COMP|Geometry Component]]. It also has some extra features such as length, two types of geometry, end-to-end linking, and kinematic parameters.\t\t\n\t\t\t\nThe Bone Component is used to create hierarchies of limb-like objects that form part of a hierarchy or chain of Bone Components that are parented to one another. The movement of the chain of Bone Components is \"solved\" or computed based on several methods including Inverse Kinematics. The parenting attribute of bones is unique in that each bone attaches to the end, not the origin, of the parent bone.\t\t\t\n\t\t\t\nIt is recommended that you use the Bone Creation state, accessed through the state icons above the Viewport, to construct such a chain because placing individual Bone Components and establishing their parenting relationships from operator to operator is extremely time consuming and not at all intuitive. In addition, a chain created using the Bone state will produce a better behaved bone chain. \t\t\t\n\t\t\t\nBy default, bones do not render. They contain two types of display geometry: \"link geometry\" and \"capture region geometry\". The former consists of a narrow diamond shape which has been stretched to the length specified in ''Bone Length'', and placed along the Bone Component's negative Z-axis. The latter consists of two or more user-controllable ellipses that are used to define capture regions used in skeleton sops. You can specify whether either of the two types of geometry are displayed. \t\t\t\n\t\t\t\nThe actual movement of the Bone Components is controlled through an IK CHOP (when using the standard Capture/Deform model). This is effected through an expression in the '''Transform''' channels of the Bone Component. If you want to override this behaviour, then you need to delete the bone's translate channels such that they are no longer over-ridden by chop control. \t\t\t\n\t\t\t\nIf you make a bone the child of a non-bone Component, then it will attach to the origin of that Component. If you want to reposition the bone relative to its non-bone parent, you must remove the expression in the bone's translate parameters.",
        "opClass": "boneCOMP_Class",
        "short": "The Bone Component is the foundation of all of the [[Character Tools]].",
        "opType": "bone",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "bulletsolverCOMP": {
        "label": "bulletsolverCOMP",
        "members": [
            {
                "text": "Gravity applied to all actors in the simulation in m/s^2. Gravity is applied to actors irrespective of their mass.",
                "type": "Par",
                "name": "gravityx"
            },
            {
                "text": "Gravity applied to all actors in the simulation in m/s^2. Gravity is applied to actors irrespective of their mass.",
                "type": "Par",
                "name": "gravityy"
            },
            {
                "text": "Gravity applied to all actors in the simulation in m/s^2. Gravity is applied to actors irrespective of their mass.",
                "type": "Par",
                "name": "gravityz"
            },
            {
                "text": "dropmenu : The dimension of the simulation. The options in this menu can also be recreated using the linear/angular multiplier parameters.",
                "type": "Par",
                "name": "dimension"
            },
            {
                "text": "A multiplier for the linear velocities of the actors in the simulation. For example, if linmult is (0, 1, 1) then the actors can move linearly at normal speed on the Y and Z axes but cannot move in the X direction. These values are multiplied internally by the values from dimension. For example, if the dimension is 2D and linmult is (0, 1, 1) then the only direction the actors can move is along the Y axis because 2D is constraining on the Z and this parameter is constraining on the Y.",
                "type": "Par",
                "name": "linmultx"
            },
            {
                "text": "A multiplier for the linear velocities of the actors in the simulation. For example, if linmult is (0, 1, 1) then the actors can move linearly at normal speed on the Y and Z axes but cannot move in the X direction. These values are multiplied internally by the values from dimension. For example, if the dimension is 2D and linmult is (0, 1, 1) then the only direction the actors can move is along the Y axis because 2D is constraining on the Z and this parameter is constraining on the Y.",
                "type": "Par",
                "name": "linmulty"
            },
            {
                "text": "A multiplier for the linear velocities of the actors in the simulation. For example, if linmult is (0, 1, 1) then the actors can move linearly at normal speed on the Y and Z axes but cannot move in the X direction. These values are multiplied internally by the values from dimension. For example, if the dimension is 2D and linmult is (0, 1, 1) then the only direction the actors can move is along the Y axis because 2D is constraining on the Z and this parameter is constraining on the Y.",
                "type": "Par",
                "name": "linmultz"
            },
            {
                "text": "A multiplier for the angular velocities of the actors in the simulation. For example, if angmult is (1, 0, 0) then the actors can only rotate on the X axes. These values are multiplied internally by the values from dimension. So, if dimension is 2D and angmult is (1, 0, 0) then the actor will not be able to rotate in any direction because 2D constrains rotation only to the Z axis, and this parameter is constraining it only to the X axis.",
                "type": "Par",
                "name": "angmultx"
            },
            {
                "text": "A multiplier for the angular velocities of the actors in the simulation. For example, if angmult is (1, 0, 0) then the actors can only rotate on the X axes. These values are multiplied internally by the values from dimension. So, if dimension is 2D and angmult is (1, 0, 0) then the actor will not be able to rotate in any direction because 2D constrains rotation only to the Z axis, and this parameter is constraining it only to the X axis.",
                "type": "Par",
                "name": "angmulty"
            },
            {
                "text": "A multiplier for the angular velocities of the actors in the simulation. For example, if angmult is (1, 0, 0) then the actors can only rotate on the X axes. These values are multiplied internally by the values from dimension. So, if dimension is 2D and angmult is (1, 0, 0) then the actor will not be able to rotate in any direction because 2D constrains rotation only to the Z axis, and this parameter is constraining it only to the X axis.",
                "type": "Par",
                "name": "angmultz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "bulletsolverCOMP",
        "opLabel": "Bullet Solver",
        "opClass": "bulletsolverCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "In a [[Bullet Dynamics]] system, the Bullet Solver COMP is analogous to the world/simulation in which actors/bodies (ie. [[Actor COMP]]s) operate.",
        "long": "In a [[Bullet Dynamics]] system, the Bullet Solver COMP is analogous to the world/simulation in which actors/bodies (ie. [[Actor COMP]]s) operate. A Bullet Solver COMP contains any number of actors/bodies (Actor COMPs) or forces ([[Force COMP]]/[[Impulse Force COMP]]), and as the name suggests it also uses the [https://pybullet.org/wordpress/ Bullet Physics API] to step through the simulation. \n   \nThe Bullet Solver COMP runs a Bullet simulation based on some simulation parameters (eg. linear multiplier or angular multiplier) and updates the transformations of the Actor COMPs contained within it as the simulation progresses forward. The simulation can be paused, slowed down, sped up, or restarted using the parameters on the COMP. \n\nThe Bullet Solver COMP simulation operates in a vacuum, so there will be no air resistance applied to any actors in the simulation. The simulation is stepped at the given sample rate, and the Actor COMP transform is updated accordingly. These transformations are the same results displayed in the [[Bullet Solver CHOP]]. \n \nThe Actor COMPs referenced by the Bullet Solver COMP do not need to be inside its network. They can be anywhere as long as they are not already referenced by another Bullet Solver COMP.\n\nSee also: [[Bullet Dynamics]], [[Actor COMP]], [[Force COMP]], [[Impulse Force COMP]], [[Constraint COMP]], [[Bullet Solver CHOP]].",
        "opCategories": ""
    },
    "buttonCOMP": {
        "label": "buttonCOMP",
        "members": [
            {
                "text": "Menu : This menu determines the button's state behavior.",
                "type": "Par",
                "name": "buttontype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Button Component is used in panels to provide interactive on/off buttons, including toggle buttons, momentary buttons, and sets of radio buttons or exclusive buttons. Radio and exclusive buttons act as a group, which can be as simple as all Button components in a Container component. The group can be specified more tightly using the Button Group Label parameter or the Button Group DAT parameter. \t\t\n\t\t\t\n[[image:ButtonCOMP.png]]\n\t\t\t\nDefault Button Component",
        "1": "Default Button Component",
        "opLicense": "Non-Commercial",
        "opFamily": "COMP",
        "opLabel": "Button",
        "short": "The Button Component is used in panels to provide interactive on/off buttons, including toggle buttons, momentary buttons, and sets of radio buttons or exclusive buttons.",
        "opType": "button",
        "opFilter": "False",
        "opClass": "buttonCOMP_Class",
        "opCategories": ""
    },
    "camerablendCOMP": {
        "label": "camerablendCOMP",
        "members": [
            {
                "text": "Menu : Method in which parent transforms (i.e. Translate, Rotate, Scale) are combined to produce a unique blended transform.",
                "type": "Par",
                "name": "parenttype"
            },
            {
                "text": "Menu : A pop-up menu lets you choose from <span class=\"tipTextCOMP\">Perspective</span> and <span class=\"tipTextCOMP\">Orthographic</span> projection types. A third option <span class=\"tipTextCOMP\">Perpective to Ortho Blend</span> enables the <span class=\"tipTextCOMP\">Projection Blend</span> parameter below which can be used to blend between perspectives.",
                "type": "Par",
                "name": "projection"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "viewanglemethod"
            },
            {
                "text": "These parameters define the center of the window during the rendering process. The window parameter takes the view and expands it to fit the camera's field of vision. It is important to note that this action is independent of perspective. In other words, it acts as though you are panning the camera without actually moving the camera.",
                "type": "Par",
                "name": "winx"
            },
            {
                "text": "These parameters define the center of the window during the rendering process. The window parameter takes the view and expands it to fit the camera's field of vision. It is important to note that this action is independent of perspective. In other words, it acts as though you are panning the camera without actually moving the camera.",
                "type": "Par",
                "name": "winy"
            },
            {
                "text": "Sets the background color and alpha of the camera's view.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Sets the background color and alpha of the camera's view.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Sets the background color and alpha of the camera's view.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Sets the background color and alpha of the camera's view.",
                "type": "Par",
                "name": "bgcolora"
            },
            {
                "text": "Menu : This menu determines the type of fog rendered in the viewport: <blockquote><span class=\"tipTextCOMP\">'''Linear'''</span> fog uses the following equation: </blockquote>\t\n\t\t\t\n[[Image:Objects14.gif]]\t\t\t\n\t\t\t\n<blockquote><span class=\"tipTextCOMP\">'''Exponential'''</span> fog uses the following equation:</blockquote>\t\t\t\n\t\t\t\n[[Image:Objects18.gif]]\t\t\t\n\t\t\t\n<blockquote><span class=\"tipTextCOMP\">'''Squared Exponential'''</span> fog uses the following equation: </blockquote>\t\t\t\n\t\t\t\n[[Image:Objects20.gif]]\t\t\t\n\t\t\t\n<blockquote>Regardless of the fog mode, f is clamped to the range [0,1] after it is computed. Then, if GL is in RGBA color mode, the fragment's color Cr is replaced by:</blockquote>\t\t\t\n\t\t\t\n[[Image:Objects19.gif]]",
                "type": "Par",
                "name": "fog"
            },
            {
                "text": "The color of the fog.",
                "type": "Par",
                "name": "fogcolorr"
            },
            {
                "text": "The color of the fog.",
                "type": "Par",
                "name": "fogcolorg"
            },
            {
                "text": "The color of the fog.",
                "type": "Par",
                "name": "fogcolorb"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "opLabel": "Camera Blend",
        "opFamily": "COMP",
        "long": "The Camera Blend Component blends the 3D object transforms and viewing settings of multiple Camera Components together. It gives you some extra flexibility in setting up parent-child relationships. It operates like the [[Switch SOP]] and [[Sequence Blend SOP]]s insofar as it takes more than one input and blends or switches those into one output.\t\t\n\t\t\t\nThe Camera Blend COMP can animate camera parameters and positions between various cameras. \n\nTo set up, wire the bottom connector of a Camera COMP to the top input of the Camera Blend COMP. Then for another Camera COMP, wire its bottom connector to the top of the Camera Blend COMP. Then you can adjust the Weight parameters of the Camera Blend COMP.\n\t\t\t\nThe View and Background parameter pages are used as the camera parameters when non-Camera COMPs are connected to the Camera Blend COMP.\t\t\t\n\nSee also [[Blend COMP]].",
        "opClass": "camerablendCOMP_Class",
        "short": "The Camera Blend Component allows various effects by blending multiple Components together.",
        "opType": "camblend",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "cameraCOMP": {
        "label": "cameraCOMP",
        "members": [
            {
                "text": "Menu : A pop-up menu lets you choose from Perspective and Orthographic projection types. A third option Perpective to Ortho Blend enables the Projection Blend parameter below which can be used to blend between perspectives. A 4th option Custom Projection Matrix allows you to specify a custom 4x4 projection matrix using a tdu.Matrix, CHOP or a DAT.",
                "type": "Par",
                "name": "projection"
            },
            {
                "text": "Menu : This menu determines which method is used to define the camera's angle of view.",
                "type": "Par",
                "name": "viewanglemethod"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "winrollpivot"
            },
            {
                "text": "These parameters define the center of the window during the rendering process. The window parameter takes the view and expands it to fit the camera's field of vision. It is important to note that this action is independent of perspective. In other words, it acts as though you are panning the camera without actually moving the camera. The units for this parameter are normalized. That is a Window X of -0.5 will move the previous center of the image to the left edge of the render.",
                "type": "Par",
                "name": "winx"
            },
            {
                "text": "These parameters define the center of the window during the rendering process. The window parameter takes the view and expands it to fit the camera's field of vision. It is important to note that this action is independent of perspective. In other words, it acts as though you are panning the camera without actually moving the camera. The units for this parameter are normalized. That is a Window X of -0.5 will move the previous center of the image to the left edge of the render.",
                "type": "Par",
                "name": "winy"
            },
            {
                "text": "Specifies 4 point indices in the SOP referenced by Quad Reproject SOP that make up the quad that determines the region to be reprojected. The indices should be listed in bottom left, bottom right, top left, top right order, as viewed from the camera. The SOP that is referenced should be in the COMP that is being rendered, so the world transform that will be applied to is can be taken into account.",
                "type": "Par",
                "name": "quadreprojpts1"
            },
            {
                "text": "Specifies 4 point indices in the SOP referenced by Quad Reproject SOP that make up the quad that determines the region to be reprojected. The indices should be listed in bottom left, bottom right, top left, top right order, as viewed from the camera. The SOP that is referenced should be in the COMP that is being rendered, so the world transform that will be applied to is can be taken into account.",
                "type": "Par",
                "name": "quadreprojpts2"
            },
            {
                "text": "Specifies 4 point indices in the SOP referenced by Quad Reproject SOP that make up the quad that determines the region to be reprojected. The indices should be listed in bottom left, bottom right, top left, top right order, as viewed from the camera. The SOP that is referenced should be in the COMP that is being rendered, so the world transform that will be applied to is can be taken into account.",
                "type": "Par",
                "name": "quadreprojpts3"
            },
            {
                "text": "Specifies 4 point indices in the SOP referenced by Quad Reproject SOP that make up the quad that determines the region to be reprojected. The indices should be listed in bottom left, bottom right, top left, top right order, as viewed from the camera. The SOP that is referenced should be in the COMP that is being rendered, so the world transform that will be applied to is can be taken into account.",
                "type": "Par",
                "name": "quadreprojpts4"
            },
            {
                "text": "Sets the background color and alpha of the camera's view.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Sets the background color and alpha of the camera's view.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Sets the background color and alpha of the camera's view.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Sets the background color and alpha of the camera's view.",
                "type": "Par",
                "name": "bgcolora"
            },
            {
                "text": "Menu : This menu determines the type of fog rendered in the viewport: '''Linear''' fog uses the following equation:\t\n\t\t\t\n[[Image:Objects14.gif]]\t\t\t\n\t\t\t\n'''Exponential''' fog uses the following equation:\t\t\t\n\t\t\t\n[[Image:Objects18.gif]]\t\t\t\n\t\t\t\n'''Squared Exponential''' fog uses the following equation:\t\t\t\n\t\t\t\n[[Image:Objects20.gif]]",
                "type": "Par",
                "name": "fog"
            },
            {
                "text": "The color of the fog.",
                "type": "Par",
                "name": "fogcolorr"
            },
            {
                "text": "The color of the fog.",
                "type": "Par",
                "name": "fogcolorg"
            },
            {
                "text": "The color of the fog.",
                "type": "Par",
                "name": "fogcolorb"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Camera",
        "opFamily": "COMP",
        "long": "The Camera Component is a 3D object that behaves like a real-world camera. You view your scene through it and render from its point of view using a [[Render TOP]]. \n    \nSee [[Geometry Viewer]] to learn about how you can inspect a scene from a camera.\n\nSee [[Palette:camera|cameraViewport]] in the Palette - it's a powerful interactive camera that can be used in place of the basic Camera COMP.\n\nA Camera Component can be attached or linked to any other 3D Component in a [[3D Parenting|3D hierarchy]].",
        "opClass": "cameraCOMP_Class",
        "short": "The Camera Component is a 3D object that acts like real-world cameras.",
        "opType": "cam",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "": {
        "label": "NotSet",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": []
    },
    "constraintCOMP": {
        "label": "constraintCOMP",
        "members": [
            {
                "text": "dropmenu : The type of constraint to create: point to point, hinge, or slider.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "The pivot point for the constraint.",
                "type": "Par",
                "name": "pivot1x"
            },
            {
                "text": "The pivot point for the constraint.",
                "type": "Par",
                "name": "pivot1y"
            },
            {
                "text": "The pivot point for the constraint.",
                "type": "Par",
                "name": "pivot1z"
            },
            {
                "text": "The axis around which to create the hinge. Each value is typically a number between 0 and 1. For example, to spin around the Z axis set to 0, 0, 1.",
                "type": "Par",
                "name": "axis1x"
            },
            {
                "text": "The axis around which to create the hinge. Each value is typically a number between 0 and 1. For example, to spin around the Z axis set to 0, 0, 1.",
                "type": "Par",
                "name": "axis1y"
            },
            {
                "text": "The axis around which to create the hinge. Each value is typically a number between 0 and 1. For example, to spin around the Z axis set to 0, 0, 1.",
                "type": "Par",
                "name": "axis1z"
            },
            {
                "text": "The rotation of the slider constraint axis. By default the slider constraint is applied on the X axis.",
                "type": "Par",
                "name": "sliderrot1x"
            },
            {
                "text": "The rotation of the slider constraint axis. By default the slider constraint is applied on the X axis.",
                "type": "Par",
                "name": "sliderrot1y"
            },
            {
                "text": "The rotation of the slider constraint axis. By default the slider constraint is applied on the X axis.",
                "type": "Par",
                "name": "sliderrot1z"
            },
            {
                "text": "The pivot point for the constraint.",
                "type": "Par",
                "name": "pivot2x"
            },
            {
                "text": "The pivot point for the constraint.",
                "type": "Par",
                "name": "pivot2y"
            },
            {
                "text": "The pivot point for the constraint.",
                "type": "Par",
                "name": "pivot2z"
            },
            {
                "text": "The axis around which to create the hinge. Each value is typically a number between 0 and 1. For example, to spin around the Z axis set to 0, 0, 1.",
                "type": "Par",
                "name": "axis2x"
            },
            {
                "text": "The axis around which to create the hinge. Each value is typically a number between 0 and 1. For example, to spin around the Z axis set to 0, 0, 1.",
                "type": "Par",
                "name": "axis2y"
            },
            {
                "text": "The axis around which to create the hinge. Each value is typically a number between 0 and 1. For example, to spin around the Z axis set to 0, 0, 1.",
                "type": "Par",
                "name": "axis2z"
            },
            {
                "text": "The rotation of the slider constraint axis. By default the slider constraint is applied on the X axis.",
                "type": "Par",
                "name": "sliderrot2x"
            },
            {
                "text": "The rotation of the slider constraint axis. By default the slider constraint is applied on the X axis.",
                "type": "Par",
                "name": "sliderrot2y"
            },
            {
                "text": "The rotation of the slider constraint axis. By default the slider constraint is applied on the X axis.",
                "type": "Par",
                "name": "sliderrot2z"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "constraintCOMP",
        "opLabel": "Constraint",
        "opClass": "constraintCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "A Constraint COMP is used to restrict the movement of the bodies in a set of [[Actor COMP]]s.",
        "long": "A Constraint COMP is used to restrict the movement of the bodies in a set of [[Actor COMP]]s. Currently this can be done in a few ways: point to point, hinge or slider. Constraints can either be applied on a single body or between two bodies. Constraints can be used to create connectivity between bodies, or to create bodies that can move but need to have that movement restricted in some way. Some examples of constraints in the real world: a train, a door, an arm. \n\nIf a point to point constraint is applied to a single body, then that body will be restricted to 3 degrees of freedom (DOF). It will still have all 3 degrees of freedom for rotation (ie. All 3 axes), but the 3 degrees of freedom for translation will all be constrained. If a point to point constraint is applied between two bodies, then they will both be similarly constrained to 3 DOF. However, they will be able to move (translate) along all 3 axes but they will do it connected to each other at their pivot points. By using this constraint method, a chain of bodies can be created. For instance, point to point constraints can be used to simulate train cars connected to each other.\n\nIf a hinge constraint is applied to a single body, then that body will be restricted to 1 DOF relative to the other body. It will only be able to rotate around 1 axis, and that axis is defined using the Axis parameter on the Constraint COMP. Much like the point to point constraint, the hinge also as a pivot point around which it will rotate. If a hinge constraint is applied between two bodies, then they will both be able to move with 3 DOF but they will do it connected to each other at their pivot points. However, they will still only be able to rotate around their respective axis. The simplest example of a hinge constraint is a door.\n\nIf a slider constraint is applied to a single body, then that body's translation/rotation will be constrained to just that axis. In other words, the body can only move along that axis (either direction) and can only rotate along that axis (either direction).\n    \nSee also: [[Bullet Dynamics]], [[Bullet Solver COMP]], [[Actor COMP]], [[Force COMP]], [[Impulse Force COMP]], [[Bullet Solver CHOP]].",
        "opCategories": ""
    },
    "containerCOMP": {
        "label": "containerCOMP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Container",
        "opFamily": "COMP",
        "long": "The Container Component groups together any number of button, slider, field, container and other [[Panel Component]]s to build an interface. For example, the Container Component would be used to start creating your control panel, inside it you would place all the sliders, buttons, and viewer panels. It could also be used to group multiple sliders and buttons together into one panel that can be moved and scaled together, such as 3 RGB sliders for a color picker in your control panel.",
        "opClass": "containerCOMP_Class",
        "short": "The Container Component groups together any number of button, slider, field, container and other [[Panel Component]]s to build an interface.",
        "opType": "container",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "engineCOMP": {
        "label": "engineCOMP",
        "members": [
            {
                "text": "Menu : Specify the temporal connection to the TouchEngine instance.",
                "type": "Par",
                "name": "clock"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "engineCOMP",
        "opLabel": "Engine",
        "opClass": "engineCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Engine COMP will run a .tox file (component) in a separate process. It uses [[TouchEngine]] to manage these processes and pass data between the loaded component and the main project.",
        "long": "The Engine COMP will run a .tox file (component) in a separate process. It uses [[TouchEngine]] to manage these processes and pass data between the loaded component and the main project.\n\n'''Ins and Outs'''\n\nThe chosen component's top-level Ins and Outs are exposed as Ins and Outs on the Engine COMP. Only TOP, CHOP and DAT Ins and Outs are supported.\n\n'''Custom Parameters'''\n\nAny custom parameters on the top-level component are added to the Engine COMP's parameters.\n\nNote that parameters work in one direction only - you cannot set a parameter from within the loaded .tox.\n\n'''External File Paths'''\n\nRelative paths on OPs or in scripts '''inside''' the loaded component are relative to the .tox file's location. Relative paths as file or folder parameters '''of''' the component - those that show up on the Engine COMP - are relative to the main project.\n\n'''Component Lifetime'''\n\nUnder TouchEngine, components are loaded into an already-running instance. For this reason, an Execute DAT's onStart() and onExit() method will never be executed under TouchEngine. The onCreate() method will be executed when the component is loaded, and is a good place to do any setup you would normally do in onStart().\n\n'''TouchEngine Versions'''\n\nTouchEngine is installed as part of TouchDesigner, and the currently running version will be used to load the given .tox. If you wish to use a different version of TouchEngine you can either set the environment variable <code>TOUCHENGINE_APP_PATH</code> to the path to a TouchDesigner installation (an installation directory on Windows, or a TouchDesigner app on macOS) ''or'' install TouchDesigner into a folder named <code>TouchEngine</code> alongside the .tox (on macOS rename an application from TouchDesigner to TouchEngine) ''or'' create a link named <code>TouchEngine</code> alongside the .tox which points to an installation directory or TouchDesigner app.",
        "opCategories": ""
    },
    "environmentlightCOMP": {
        "label": "environmentlightCOMP",
        "members": [
            {
                "text": "You can modify the color of the light three ways: Color List, Hue, Saturation, and Value, or Red, Green, and Blue. To choose one, click on the appropriate box and the color editing fields below change accordingly.",
                "type": "Par",
                "name": "cr"
            },
            {
                "text": "You can modify the color of the light three ways: Color List, Hue, Saturation, and Value, or Red, Green, and Blue. To choose one, click on the appropriate box and the color editing fields below change accordingly.",
                "type": "Par",
                "name": "cg"
            },
            {
                "text": "You can modify the color of the light three ways: Color List, Hue, Saturation, and Value, or Red, Green, and Blue. To choose one, click on the appropriate box and the color editing fields below change accordingly.",
                "type": "Par",
                "name": "cb"
            },
            {
                "text": "Menu : Select the type of environment map to use (only equirectangular available for now).",
                "type": "Par",
                "name": "envlightmaptype2d"
            },
            {
                "text": "Rotate the texture specified by the Environment Map parameter above.",
                "type": "Par",
                "name": "envlightmaprotatex"
            },
            {
                "text": "Rotate the texture specified by the Environment Map parameter above.",
                "type": "Par",
                "name": "envlightmaprotatey"
            },
            {
                "text": "Rotate the texture specified by the Environment Map parameter above.",
                "type": "Par",
                "name": "envlightmaprotatez"
            },
            {
                "text": "Menu : Controls how the environment map is pre-filtered. A pre-filtered environment map is expensive to create, but results in much better rendering quality.",
                "type": "Par",
                "name": "envlightmapprefilter"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Environment Light",
        "opFamily": "COMP",
        "long": "The Environment Light Component controls the color and intensity of an environmental light in a given scene. This light, unlike the [[Light COMP|Light Component]], has no particular position. It comes from outside all of the objects in the scene and lights them. The orientation of the objects and the Environment Light Map will affect how each side of the objects is lit. However the position of the objects in space will have no effect on how the environment light hits them.",
        "opClass": "environmentlightCOMP_Class",
        "short": "The Environment Light Component controls the color and intensity of an environmental light in a given scene.",
        "opType": "environment",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "fbxCOMP": {
        "label": "fbxCOMP",
        "members": [
            {
                "text": "Menu : Determines what to do when clicking the 'Import' button below.",
                "type": "Par",
                "name": "importmethod"
            },
            {
                "text": "dropmenu : Select between using the 'File FPS' embedded in the FBX file or setting a 'Custom' sample rate.",
                "type": "Par",
                "name": "sampleratemode"
            },
            {
                "text": "dropmenu : A menu to specify the method used to play the animation.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "nolabel shortvalues dropmenu : Select what type of unit to specify the Cue Point with.",
                "type": "Par",
                "name": "cuepointunit"
            },
            {
                "text": "nolabel shortvalues dropmenu : ",
                "type": "Par",
                "name": "indexunit"
            },
            {
                "text": "nolabel shortvalues dropmenu : Specifies a unit type for Trim Start. Changing this will convert the previous unit to the selected unit.",
                "type": "Par",
                "name": "tstartunit"
            },
            {
                "text": "nolabel shortvalues dropmenu : Specifies a unit type for Trim End. Changing this will convert the previous unit to the selected unit.",
                "type": "Par",
                "name": "tendunit"
            },
            {
                "text": "dropmenu : Determines how the animation behaves before the start of the animation (or Trim Start position if it is used).",
                "type": "Par",
                "name": "textendleft"
            },
            {
                "text": "dropmenu : Determines how the animation behaves after the end of the animation (or Trim End position if it is used).",
                "type": "Par",
                "name": "textendright"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "fbxCOMP",
        "opLabel": "FBX",
        "opClass": "fbxCOMP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The FBX COMP imports geometry, animations and scenes using the FBX file format from Maya, 3DS Max, Cinema4D, Houdini and others.\nThe FBX COMP currently uses the 2019.0 version of the FBX SDK.",
        "long": "The FBX COMP imports geometry, animations and scenes using the FBX file format from Maya, 3DS Max, Cinema4D, Houdini and others.\nThe FBX COMP currently uses the 2019.0 version of the FBX SDK.\n\n[https://www.autodesk.com/products/fbx/overview FBX] is a file format and set of libraries from Autodesk that is used to exchange models, animations and image/texture data between applications. The FBX COMP reads FBX files and supports most of its features. You can drag-drop a <code>.fbx</code> into a TouchDesigner network or import it via the File > Import File... menu. The FBX COMP can also import meshes from .obj and .4ds files, see also [[File Types]].\n\nThe assets from the FBX file are saved into a \"<code>.tdc</code>\" file with the same name as the FBX file inside the <code>TDImportCache</code> folder, which is created next to your <code>.toe</code> file. Assets are read from the \"<code>.tdc</code>\" file using Import Select OPs ([[Import Select TOP]] / [[Import Select SOP]] / [[Import Select CHOP]]). Upon reloading a <code>.toe</code> file, the assets can be imported directly from the \"<code>.tdc</code>\" cache, and the FBX file will not need to be re-imported. However, if there is no existing \"<code>.tdc</code>\" (for instance, if the toe file changed computers) then the FBX file will be reopened to grab the assets and a new \"<code>.tdc</code>\" will be saved out.\n\nTo open an FBX file in an FBX COMP:\n\n1) Specify a valid file path in the \"FBX File\" parameter, including the name of the file with correct <code>.fbx</code> extension.\n\n2) This step is varied depending on whether the FBX COMP is just created and if any changes in the default values of parameters are required or not. If the file is being loaded for the first time in the network and the default parameter values are accepted then simply press the \"Import\" button to generate the FBX network and import the assets. Note that we recommend changing the \"Import Method\" to to other modes (less work) can significantly improve performance. Generally, any changes in the parameters above the \"Import\" button requires the network to be built again.\n\n3) With the \"Import Method\" menu set to \"Merge with Existing\", the \"Import\" pulse will reload the internal assets (e.g. meshes, etc.) and this is specifically useful if the file has moved to another location and when the <code>.toe</code> file is opened the assets were not found and reloaded properly.\n\n4) With the \"Import Method\" menu set to \"Import Assets (Import Selects)\", the \"Import\" button is used when some changes on FBX file are made and we want to merge those changes into the current network without fully rebuilding it.\n\n'''Animation channels''': When there is animation in the FBX file, use the controls on the Play page to initialize, start and guide the animation. Also create an [[Info CHOP]] and attach it to the FBX COMP to watch its animation timing. The Info CHOP channels are similar to those of the [[Timer CHOP]].\n\n'''Textures''': Textures can either be embedded within the FBX file or external and referenced by a path to a texture file. For example, Blender has an option during FBX export to embed, otherwise they'll be external. If they're external then they may be exported with an absolute path to the texture file, which means if you move the FBX file to a different machine or relocate the file, then the textures will fail to load. In this case, if you are unable to re-export to embed the textures, then you can instead specify a search directory using the Texture Directory parameter so that the FBX COMP knows where to locate the texture files at import.\n\nSee also: [[FBX]], [[Import Select CHOP]], [[Import Select TOP]], [[Import Select SOP]], [[USD COMP]]",
        "opCategories": ""
    },
    "fieldCOMP": {
        "label": "fieldCOMP",
        "members": [
            {
                "text": " : Specify what kind of data can be input into the field.",
                "type": "Par",
                "name": "fieldtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "'''Note''': Field COMP deprecated build 2022.24200, use [[Text COMP]].\n\nThe Field Component lets you enter text strings and renders text generated with the [[Text TOP]]. Internally it contains a Text TOP which points to one cell of a DAT that contains the text to render. The Field COMP modifies the DAT cell as text is entered.\t\n\t\t\t\n[[image:FieldCOMP.png]]",
        "opLicense": "Non-Commercial",
        "opFamily": "COMP",
        "opLabel": "Field",
        "short": "The Field Component lets you enter text strings and renders text generated with the [[Text TOP]].",
        "opType": "field",
        "opFilter": "False",
        "opClass": "fieldCOMP_Class"
    },
    "forceCOMP": {
        "label": "forceCOMP",
        "members": [
            {
                "text": "The linear force in Newtons that will be applied.",
                "type": "Par",
                "name": "forcex"
            },
            {
                "text": "The linear force in Newtons that will be applied.",
                "type": "Par",
                "name": "forcey"
            },
            {
                "text": "The linear force in Newtons that will be applied.",
                "type": "Par",
                "name": "forcez"
            },
            {
                "text": "The position at which to apply the linear force, relative to the center of the body (Note: the physical center of the object, not the center of mass). Having a nonzero relative position will also cause the body to rotate due to added torque.",
                "type": "Par",
                "name": "relposx"
            },
            {
                "text": "The position at which to apply the linear force, relative to the center of the body (Note: the physical center of the object, not the center of mass). Having a nonzero relative position will also cause the body to rotate due to added torque.",
                "type": "Par",
                "name": "relposy"
            },
            {
                "text": "The position at which to apply the linear force, relative to the center of the body (Note: the physical center of the object, not the center of mass). Having a nonzero relative position will also cause the body to rotate due to added torque.",
                "type": "Par",
                "name": "relposz"
            },
            {
                "text": "The rotational force in Newtons that will be applied.",
                "type": "Par",
                "name": "torquex"
            },
            {
                "text": "The rotational force in Newtons that will be applied.",
                "type": "Par",
                "name": "torquey"
            },
            {
                "text": "The rotational force in Newtons that will be applied.",
                "type": "Par",
                "name": "torquez"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "forceCOMP",
        "opLabel": "Force",
        "opClass": "forceCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "=Force COMPs are used to added forces to a physics solver's simulation. [[Bullet Dynamics|Bullet]] supports linear/rotational forces and impulse forces (see Force page) and [[Flex]] supports force fields.",
        "long": "Force COMPs are used to added forces to a physics solver's simulation. [[Bullet Dynamics|Bullet]] supports linear/rotational forces and impulse forces (see Force page) and [[Flex]] supports force fields (see Force Field page).\n\n===<div class=\"subSectionLineDialog\">Active Force</div>===\n\nActive forces are enabled using the Active toggle parameter on the Force page.\n\nAn active force will create a force in the simulation that is applied over time. An active force can either be applied globally by being referenced on the [[Bullet Solver COMP]], or it can be applied locally by being referenced on an individual [[Actor COMP]]. The active force applies its force each frame, and the force applied over 1 second is equivalent to an impulse force of the same value applied in a single frame. \n    \nThe units for the force and torque parameters are in Newtons (N), equivalent to kg*m/s^2. This means that if a force of 10N is applied to an actor with mass equal to 5kg and no initial velocity, then after 1 second the velocity of that actor will be 2m/s => 10N / 5kg * 1 sec = 2m/s. If all the parameters were the same, but instead it was an impulse force, then the velocity would still be 2m/s. However, the impulse force's velocity would change instantaneously and stop increasing (unless pulsed again) whereas with the active force the velocity will continue to increase after 1 second.\n\nThe center of mass is assumed to be center of the bounding box of the mass. By default, if a body is not constrained and not colliding, the force will not cause the body to rotate, unless the Relative Position parameter is set to a non-zero value.  If Relative Position is set to +1 in X and the force is +1 in Y, it will cause the body to rotate counter-clockwise around the Z-axis and translate in Y.\n\nIf the Torque is set to +1 in Z, it will cause the body to only rotate counter-clockwise in the Z-axis (a positive Z rotation), and not translate.\n\nTo apply force/torque to specific bodies use a Feedback CHOP (see [[Bullet Solver COMP]] or [[Actor COMP]]) and '''force[xyz]''' and '''torque[xyz]''' channels.\n\n===<div class=\"subSectionLineDialog\">Impulse Force</div>===\n\nImpulse forces are applied through the Impulse Force pulse parameter.\n\nAn impulse force pulse will create a force in the simulation that is applied for 1 frame. In the real world, impulse forces are forces applied over a very short duration, however in [[Bullet Dynamics|Bullet]] this is somewhat simplified, and they are instead applied instantly (for a single frame). Examples of impulse forces are kicking a ball or shooting a cannon. The velocities of the affected bodies are changed in an instant by the impulse force, and after that instant the force no longer has an effect unless applied again.  \n    \nThe resulting velocity of the bodies after the impulse force is applied is the same as an active force with the same values if the active force is applied for exactly 1 second. For example, if 10N of impulse force is applied to a body with mass 5kg then the resulting velocity will be 10N / 5kg * 1sec = 2m/s. \n\n===<div class=\"subSectionLineDialog\">Force Field</div>===\n\nForce fields are enabled through the Active parameter on the Force Field page.\n\nForce fields are spherical with a radius defined through the Radius parameter. Positive strength pushes bodies outward and negative strength pulls bodies inward.\n\n\nSee also: [[Flex]], [[Bullet Dynamics]], [[Bullet Solver COMP]], [[Actor COMP]], [[Constraint COMP]], [[Bullet Solver CHOP]], [[Nvidia Flex TOP]], [[Nvidia Flex Solver COMP]].",
        "opCategories": ""
    },
    "geotextCOMP": {
        "label": "geotextCOMP",
        "members": [
            {
                "text": "Menu : Controls where text is generated from. Either from the 'Text' parameter, or a table DAT provided via the 'Specification DAT' parameter.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "StrMenu : Select the font to be used from the dropdown menu. Available fonts are those that have been registered with the operating system. There may be a delay when selecting fonts that have not been used before as the system creates the necessary intermediate files required for rendering.",
                "type": "Par",
                "name": "font"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorr"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorg"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorb"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorg"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorb"
            },
            {
                "text": "Text is aligned and word-wrapped within a virtual layout box. This box is what is transformed by the various transform parameters, and then the text is aligned and laid out within that. The width and height units are the same units as the font size.",
                "type": "Par",
                "name": "layoutsizew"
            },
            {
                "text": "Text is aligned and word-wrapped within a virtual layout box. This box is what is transformed by the various transform parameters, and then the text is aligned and laid out within that. The width and height units are the same units as the font size.",
                "type": "Par",
                "name": "layoutsizeh"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingl"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingr"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingb"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingt"
            },
            {
                "text": "Menu : Controls the horizontal alignment of the text.",
                "type": "Par",
                "name": "alignx"
            },
            {
                "text": "Menu : Controls the vertical alignment of the text.",
                "type": "Par",
                "name": "aligny"
            },
            {
                "text": "Menu : Controls how the alignment is calculated for vertical alignment.",
                "type": "Par",
                "name": "alignymode"
            },
            {
                "text": "Extra padding to add to the sides of the layout box, pushing the text inwards for alignment.",
                "type": "Par",
                "name": "textpaddingl"
            },
            {
                "text": "Extra padding to add to the sides of the layout box, pushing the text inwards for alignment.",
                "type": "Par",
                "name": "textpaddingr"
            },
            {
                "text": "Extra padding to add to the sides of the layout box, pushing the text inwards for alignment.",
                "type": "Par",
                "name": "textpaddingb"
            },
            {
                "text": "Extra padding to add to the sides of the layout box, pushing the text inwards for alignment.",
                "type": "Par",
                "name": "textpaddingt"
            },
            {
                "text": "Menu : Controls where text is generated from. Either from the 'Text' parameter, or a table DAT provided via the 'Specification DAT' parameter.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "StrMenu : Select the font to be used from the dropdown menu. Available fonts are those that have been registered with the operating system. There may be a delay when selecting fonts that have not been used before as the system creates the necessary intermediate files required for rendering.",
                "type": "Par",
                "name": "font"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorr"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorg"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorb"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorg"
            },
            {
                "text": "The color for the font.",
                "type": "Par",
                "name": "fontcolorb"
            },
            {
                "text": "Text is aligned and word-wrapped within a virtual layout box. This box is what is transformed by the various transform parameters, and then the text is aligned and laid out within that. The width and height units are the same units as the font size.",
                "type": "Par",
                "name": "layoutsizew"
            },
            {
                "text": "Text is aligned and word-wrapped within a virtual layout box. This box is what is transformed by the various transform parameters, and then the text is aligned and laid out within that. The width and height units are the same units as the font size.",
                "type": "Par",
                "name": "layoutsizeh"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingl"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingr"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingb"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingt"
            },
            {
                "text": "Menu : Controls the horizontal alignment of the text.",
                "type": "Par",
                "name": "alignx"
            },
            {
                "text": "Menu : Controls the vertical alignment of the text.",
                "type": "Par",
                "name": "aligny"
            },
            {
                "text": "Menu : Controls how the alignment is calculated for vertical alignment.",
                "type": "Par",
                "name": "alignymode"
            },
            {
                "text": "Extra padding to add to the sides of the layout box, pushing the text inwards for alignment.",
                "type": "Par",
                "name": "textpaddingl"
            },
            {
                "text": "Extra padding to add to the sides of the layout box, pushing the text inwards for alignment.",
                "type": "Par",
                "name": "textpaddingr"
            },
            {
                "text": "Extra padding to add to the sides of the layout box, pushing the text inwards for alignment.",
                "type": "Par",
                "name": "textpaddingb"
            },
            {
                "text": "Extra padding to add to the sides of the layout box, pushing the text inwards for alignment.",
                "type": "Par",
                "name": "textpaddingt"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "geotextCOMP",
        "opLabel": "Geo Text",
        "opClass": "geotextCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "Renders text in 3D.",
        "long": "The Geo Text COMP renders text in 3D. It does not read or generate a SOP as it does direct rendering using the [[Slug Library]] and can be lit and textured with any [[MAT]] material, except the [[Line MAT]].\n\nYou can set fonts, colors, sizes, bold, italic, tracking, multi-lines like you can with the [[Text COMP]]. \n\nYou can also give the Geo Text COMP a Specification DAT which lets you separately 3D position, format and render a text string for each row of the DAT.\n\nBecause the Geo Text COMP doesn't have a boundary, width or height like the Text COMP, we substitute it with a layout box and the Layout Box parameters. The layout box has a width and height, and by default the bottom left of the layout box is placed at 0,0,0 in 3D space of the Geo Text COMP (\"object space\").  The Layout Box Anchor U and V let you put the center of the layout box at 0,0,0 by setting the anchors to .5, 5.\n\nThe dimensions of the layout box aren't visible by default, but are controlled by the Layout Box Size parameter. Using the align parameters, you can right-justify or top-justify text in the layout box, or clip to the layout box.  You can also padding space between the edge of the layout box and the text.\n\nSee also the 2D equivalent [[Text COMP]] and [[Text Formatting Codes]] for ways to override settings per-character.\n\n'''Render multiple strings transformed separately''': The Specification DAT and Specification CHOP allow for individual strings to be each positioned and styled independently in 3D. \n\nEvery row of the Spec DAT represents a \"block\" or \"text block\". Every Spec DAT contains a column named <code>text</code> which is the string that overrides the Text parameter.\n\nMost columns override a Geo Text COMP parameter, such as <code>text</code>, <code>tx</code> and <code>fontsize</code>. Some column names noted below have no corresponding parameter.\n\nThe Spec CHOP can also specify values per block. When including a Spec CHOP the number of Spec CHOP samples needs to be the same number of rows as the Spec DAT following the first column header. \n\nParameters that can be overrided include <code>fontsize</code>, <code>fontcolor</code>, tracking etc., plus all the layout box and alignment parameters. Font/bold/italic are not supported as columns as they are separate fonts. \n\n'''Transforming text blocks''': The column or channel names can include <code>tx</code>, <code>ty</code>, <code>tz</code> and all the rotate and scale channels (which use the Transform Order parameter). \n\nA special column/channel called <code>append</code> can be used with a value of <code>1</code> to position one block of text relative to the end of the previous block. Regular transforms are inherited by each appended text block. \n\nLocal transforms (<code>ltx</code>, <code>lrz</code>, etc), can be used to apply additional block transforms that do not affect transforms of following blocks. Furthermore, if the special column <code>localxform</code> is set to '<code>pre</code>', then the local transform is applied in world space before the inherited transforms are applied. If it is <code>post</code> (the default), it is transformed in the reference frame of the previous block.\n\nThe [[GeotextCOMP_Class|GeotextCOMP Class]] also has a member called <code>layoutText</code> that can be used to retrieve the 2D layout positions for all characters within a given piece of text. The positions include any applicable kerning, wrapping and alignment based on the current parameter settings of the Geo Text COMP. These values can be transformed or projected into 3D space and used to build a Spec DAT/CHOP to render the resulting text.\n\n'''Note''' - The Geo Text COMP uses '''blending/transparency''' to create the glyphs floating in space (each glyph is a partially transparent rectangle). So, to view properly without the enclosing polygons that surround them, you need to ensure they are drawn after other geometry that they are sitting in-front of. This is usually due using the [[#Parameters_-_Render_Page|Draw Priority]] parameter on the 'Render' parameter page and making the value more negative than the Draw Priority of other objects. All things with the highest draw priority are drawn first, then all things with the same second higher draw priority are drawn second. If the priority is the same between two objects, then the order they are drawn is arbitrary and will possibly change. '''Note''': Text within a Spec DAT should be setup so things in the back are earlier in the table than things in the front. It will draw row-by-row from the Spec DAT.\n\n'''Tip to render constant-size text facing the camera''': See [[OP Snippets]] for Geo Text COMP called \"better text beside 3D geo points\".\n\nSee OP Snippets for other transform examples.\n\nThe Geo Text COMP is similar to the [[Text COMP]] which is a 2D [[Panel]]."
    },
    "geometryCOMP": {
        "label": "geometryCOMP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Geometry Component is a 3D surface or [[Object|3D Object]] that you render in TouchDesigner with a [[Render TOP]]. [[Light COMP|Lights]], [[Camera COMP|Cameras]] and other Components affect the scene, but are not visible surfaces. \n    \nEach Geometry Component contains a [[Network]] containing [[SOP]]s (and any other node types), where SOPs are the operators that define its 3D shape. The 3D surfaces can be [[Polygon|polygons]], [[Particle|particles]], sprites, [[Mesh|meshes]], [[Spline|NURBS]] (with trim curves), [[Spline|Bezier]] patches or [[Metaball|metaballs]]. They can be shaded as solid-shaded surfaces or as wireframes.\t\t\n\t\t\t\t\nIn the Geometry COMP's network \n* the [[SOP]]s (Surface Operators) whose [[Render Flag]] is On are rendered by a [[Render TOP]]. More than one SOP can be turned on for rendering in a Geometry component.\n* The SOPs whose [[Display Flag]] is on are seen in the [[Geometry Viewer]] of the Geometry COMP and Camera COMPs in the same network.\t\t\n\nNOTE: Most often users turn on/off the Render and Display flags together so they are always in the same state.\n\nSee [[Geometry Viewer]] to learn about how you can inspect the SOPs that are turned on for display. \n\t\t\t\t\nSome SOPs, like the [[Texture SOP]] determine how texture images wrap and fit on the surface. \t\t\t\t\n\t\t\t\t\nEvery Geometry component needs a [[MAT|Material]] (MAT) operator to apply to the surface. This is assigned in the Material parameter of the Geometry component, or with a [[Material SOP]].\t\t\t\t\n\t\t\t\t\nTo get to the Geometry Component's network, use the roller wheel to zoom into it, or hit Enter or 'i' after selecting a Geometry Component.\t\t\t\t\n\t\t\t\t\nSee [[Geometry Viewer]], [[Render Flag]] and [[Display Flag]].\t\t\t\t\n\t\t\t\t\n[[image:Geometry Component.jpg]]",
        "opLabel": "Geometry",
        "opLicense": "Non-Commercial",
        "opFamily": "COMP",
        "short": "The Geometry Component is a 3D surface that you see and render in TouchDesigner with a [[Render TOP]].",
        "opType": "geo",
        "opFilter": "False",
        "opClass": "geometryCOMP_Class",
        "opCategories": ""
    },
    "glslCOMP": {
        "label": "glslCOMP",
        "members": [
            {
                "text": "TOP : This is the TOP that will be referenced by the above sampler name above it.\n\t\t\t\t\n'''Exposed by the + Button, texture sampling parameters''':\t\t\t\t\n\t\t\t\t\nRefer to the [[Texture Sampling Parameters]] article for more information on the parameters exposed by pressing the + button. The ''parameter'' prefix for each of the parameters is ''top[digit]''.",
                "type": "Par",
                "name": "top0extendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0filter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0anisotropy"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0x"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0y"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0z"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0w"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "glslCOMP",
        "opLabel": "GLSL",
        "opClass": "glslCOMP_Class",
        "opFilter": "False",
        "opLicense": "TouchDesigner Non-Commercial",
        "opCategories": "",
        "os": "",
        "hardware": "",
        "short": "The GLSL COMP uses shaders to render an image in a panel directly to the screen.",
        "long": "The GLSL COMP uses shaders to render an image in a panel directly to the screen. It is useful for rendering pixel accurate UIs as the resolution will automatically adapt to the DPI scaling of the screen it is displayed on. Panel variables can be accessed in the shader for responding to user events,\n    \nFor more information on writing a shader, see the [[:Category:GLSL|GLSL Category]]."
    },
    "handleCOMP": {
        "label": "handleCOMP",
        "members": [
            {
                "text": "Displacement tx,ty,tz relative to the origin of the bone where the handle is anchored.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Displacement tx,ty,tz relative to the origin of the bone where the handle is anchored.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Displacement tx,ty,tz relative to the origin of the bone where the handle is anchored.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Set the minimum and maximum rotation range in X axis.",
                "type": "Par",
                "name": "lrxmin"
            },
            {
                "text": "Set the minimum and maximum rotation range in X axis.",
                "type": "Par",
                "name": "lrxmax"
            },
            {
                "text": "Set the minimum and maximum rotation range in Y axis.",
                "type": "Par",
                "name": "lrymin"
            },
            {
                "text": "Set the minimum and maximum rotation range in Y axis.",
                "type": "Par",
                "name": "lrymax"
            },
            {
                "text": "Set the minimum and maximum rotation range in Z axis.",
                "type": "Par",
                "name": "lrzmin"
            },
            {
                "text": "Set the minimum and maximum rotation range in Z axis.",
                "type": "Par",
                "name": "lrzmax"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "opLabel": "Handle",
        "opFamily": "COMP",
        "long": "The Handle Component is a new IK tool designed for manipulating groups of bones. Whereas the previous IK tools only allowed for a single end-affector per bone chain, this new method allows for several end-affectors per bone. Furthermore, the bones need not be a chain. Any setup, including branches, are handled.\t\t\n\t\t\t\nOne typical example is the use of motion capture data. In higher-end systems, you could have a cloud of marker positions and a skeleton to be driven by it.\t\t\t\n\t\t\t\nThis Handle Component works in tandem with the [[Handle CHOP]]. The following setup is commonly used: Given a hierarchy of bones, attach one or more Handle Components to specific locations on each Bone Component. Assign each handle a target in space to follow. Create a Handle CHOP which collects this information and calculates the rotation channels for the bones. Export these values back to the bones.",
        "opClass": "handleCOMP_Class",
        "short": "The Handle Component is a new IK tool designed for manipulating groups of bones.",
        "opType": "handle",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "impulseforceCOMP": {
        "label": "impulseforceCOMP",
        "members": [
            {
                "text": "The linear force in Newtons to be applied when the node is pulsed.",
                "type": "Par",
                "name": "forcex"
            },
            {
                "text": "The linear force in Newtons to be applied when the node is pulsed.",
                "type": "Par",
                "name": "forcey"
            },
            {
                "text": "The linear force in Newtons to be applied when the node is pulsed.",
                "type": "Par",
                "name": "forcez"
            },
            {
                "text": "The position at which to apply the linear force, relative to the center of the body (Note: the physical center of the object, not the center of mass). Having a nonzero relative position will also cause the body to rotate due to added torque.",
                "type": "Par",
                "name": "relposx"
            },
            {
                "text": "The position at which to apply the linear force, relative to the center of the body (Note: the physical center of the object, not the center of mass). Having a nonzero relative position will also cause the body to rotate due to added torque.",
                "type": "Par",
                "name": "relposy"
            },
            {
                "text": "The position at which to apply the linear force, relative to the center of the body (Note: the physical center of the object, not the center of mass). Having a nonzero relative position will also cause the body to rotate due to added torque.",
                "type": "Par",
                "name": "relposz"
            },
            {
                "text": "The rotational force in Newtons that will be applied.",
                "type": "Par",
                "name": "torquex"
            },
            {
                "text": "The rotational force in Newtons that will be applied.",
                "type": "Par",
                "name": "torquey"
            },
            {
                "text": "The rotational force in Newtons that will be applied.",
                "type": "Par",
                "name": "torquez"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "impulseforceCOMP",
        "opLabel": "Impulse Force",
        "opClass": "impulseforceCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "An Impulse Force COMP will create a force in the simulation that can be applied for 1 frame using the Pulse Force parameter.",
        "long": "An Impulse Force COMP will create a force in the simulation that can be applied for 1 frame using the Pulse Force parameter. In the real world, impulse forces are forces applied over a very short duration, however in [[Bullet Dynamics|Bullet]] this is somewhat simplified, and they are instead applied instantly (for a single frame). Examples of impulse forces are kicking a ball or shooting a cannon. The velocities of the affected bodies are changed in an instant by the impulse force, and after that instant the force no longer has an effect unless applied again.  \n    \nThe resulting velocity of the bodies after the impulse force is applied is the same as the [[Force COMP]] with the same values if the Force COMP is applied for exactly 1 second. For example, if 10N of Impulse Force is applied to a body with mass 5kg then the resulting velocity will be 10N / 5kg * 1sec = 2m/s. \n\nSee also: [[Bullet Dynamics]], [[Bullet Solver COMP]], [[Actor COMP]], [[Force COMP]], [[Constraint COMP]], [[Bullet Solver CHOP]]."
    },
    "lightCOMP": {
        "label": "lightCOMP",
        "members": [
            {
                "text": "You can modify the color of a light here by adjusting the red, green, and blue parameters.  Alternatively, clicking on the color swatch will open a dialog with HSV and/or RGB sliders allowing interactive color picking with a preview of the selected color.",
                "type": "Par",
                "name": "cr"
            },
            {
                "text": "You can modify the color of a light here by adjusting the red, green, and blue parameters.  Alternatively, clicking on the color swatch will open a dialog with HSV and/or RGB sliders allowing interactive color picking with a preview of the selected color.",
                "type": "Par",
                "name": "cg"
            },
            {
                "text": "You can modify the color of a light here by adjusting the red, green, and blue parameters.  Alternatively, clicking on the color swatch will open a dialog with HSV and/or RGB sliders allowing interactive color picking with a preview of the selected color.",
                "type": "Par",
                "name": "cb"
            },
            {
                "text": "Menu : Specifies the type of light.",
                "type": "Par",
                "name": "lighttype"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "projmaptype"
            },
            {
                "text": "TOP : The path to a [[TOP]] used for the light's projector map.",
                "type": "Par",
                "name": "projmapextendu"
            },
            {
                "text": "Menu : Sets the extend conditions for the Projector Map texture.",
                "type": "Par",
                "name": "projmapextendu"
            },
            {
                "text": "Menu : Sets the extend conditions for the Projector Map texture.",
                "type": "Par",
                "name": "projmapextendv"
            },
            {
                "text": "Menu : Sets the extend conditions for the Projector Map texture.",
                "type": "Par",
                "name": "projmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "projmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "projmapanisotropy"
            },
            {
                "text": "Menu : Specify how the projection map is applied",
                "type": "Par",
                "name": "projmapmode"
            },
            {
                "text": "Menu : Controls how the polygon's normal is used to light the front face of the polygon. For more information refer to the [[Two-Sided Lighting]] article.",
                "type": "Par",
                "name": "frontfacelit"
            },
            {
                "text": "Menu : Controls how the polygon's normal is used to light the back face of the polygon. For more information refer to the [[Two-Sided Lighting]] article.",
                "type": "Par",
                "name": "backfacelit"
            },
            {
                "text": "Menu : Sets the type of shadows cast by the light.",
                "type": "Par",
                "name": "shadowtype"
            },
            {
                "text": "Controls the size of the source light when using Soft or Custom shadows.",
                "type": "Par",
                "name": "lightsize1"
            },
            {
                "text": "Controls the size of the source light when using Soft or Custom shadows.",
                "type": "Par",
                "name": "lightsize2"
            },
            {
                "text": "The resolution of the shadow's texture map used for the calculation.",
                "type": "Par",
                "name": "shadowresolution1"
            },
            {
                "text": "The resolution of the shadow's texture map used for the calculation.",
                "type": "Par",
                "name": "shadowresolution2"
            },
            {
                "text": "Menu : A pop-up menu lets you choose the projection type.",
                "type": "Par",
                "name": "projection"
            },
            {
                "text": "Menu : This menu determines which method is used to define the camera's angle of view.",
                "type": "Par",
                "name": "viewanglemethod"
            },
            {
                "text": "Set the background color of the view when using the light as a camera.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Set the background color of the view when using the light as a camera.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Set the background color of the view when using the light as a camera.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Set the background color of the view when using the light as a camera.",
                "type": "Par",
                "name": "bgcolora"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Light Components are objects which cast light into a 3D scene. With the light parameters you can control the color, brightness, and atmosphere of geometry lit by the light. A scene can also be viewed through a light's perspective, similar to a [[Camera COMP]]. \n    \n'''Tip''': To avoid a light from consuming compute time when it's off, make the Dimmer parameter less than .001.\n\nSee [[Geometry Viewer]] to learn about how you can inspect from a light.",
        "opLabel": "Light",
        "opLicense": "Non-Commercial",
        "opFamily": "COMP",
        "short": "The Light Components are objects which cast light into a 3D scene.",
        "opType": "light",
        "opFilter": "False",
        "opClass": "lightCOMP_Class",
        "opCategories": ""
    },
    "listCOMP": {
        "label": "listCOMP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "List",
        "opFamily": "COMP",
        "long": "The List Component lets you create large lists that are highly customizable via the List COMPs initialization and callback functions. Refer to the [[Build a List COMP]] article for more info on using this COMP.\t\t\n\nSee Also: [[Palette:lister|Lister Custom COMP]], a Python enhanced custom listCOMP.",
        "opClass": "listCOMP_Class",
        "short": "The List Component lets you create large lists that are highly customizable via the List COMPs initialization and callback functions.",
        "opType": "list",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "flexsolverCOMP": {
        "label": "flexsolverCOMP",
        "members": [
            {
                "text": "Gravity applied to all actors in the simulation in m/s^2. Gravity is applied to actors irrespective of their mass.",
                "type": "Par",
                "name": "gravityx"
            },
            {
                "text": "Gravity applied to all actors in the simulation in m/s^2. Gravity is applied to actors irrespective of their mass.",
                "type": "Par",
                "name": "gravityy"
            },
            {
                "text": "Gravity applied to all actors in the simulation in m/s^2. Gravity is applied to actors irrespective of their mass.",
                "type": "Par",
                "name": "gravityz"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "boundmode"
            },
            {
                "text": "Rotate the default plane. Default plane is a +Z XY plane (same as Grid SOP).",
                "type": "Par",
                "name": "planer0x"
            },
            {
                "text": "Rotate the default plane. Default plane is a +Z XY plane (same as Grid SOP).",
                "type": "Par",
                "name": "planer0y"
            },
            {
                "text": "Rotate the default plane. Default plane is a +Z XY plane (same as Grid SOP).",
                "type": "Par",
                "name": "planer0z"
            },
            {
                "text": "Translate the default plane. Default plane is a +Z XY plane (same as Grid SOP).",
                "type": "Par",
                "name": "planet0x"
            },
            {
                "text": "Translate the default plane. Default plane is a +Z XY plane (same as Grid SOP).",
                "type": "Par",
                "name": "planet0y"
            },
            {
                "text": "Translate the default plane. Default plane is a +Z XY plane (same as Grid SOP).",
                "type": "Par",
                "name": "planet0z"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "flexsolverCOMP",
        "opLabel": "Nvidia Flex Solver",
        "opClass": "flexsolverCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This feature is only available on systems with a Nvidia GPU.",
        "short": "The Nvidia Flex Solver COMP is a physics solver COMP similar to the [[Bullet Solver COMP]].",
        "long": "The Nvidia Flex Solver COMP is a physics solver COMP similar to the [[Bullet Solver COMP]].\n\nIn an Nvidia Flex simulation, the Nvidia Flex Solver COMP is analogous to the world/simulation in which actors/bodies (ie. Actor COMPs) operate. An Nvidia Flex Solver COMP contains any number of actors/bodies (Actor COMPs) or force fields (Force COMP), and as the name suggests it uses [https://developer.nvidia.com/flex Nvidia's FleX particle physics API].\n\nThe Nvidia Flex Solver COMP runs an Nvidia Flex simulation based on some simulation parameters (eg. particle radius and cohesion) and updates the transformations of the Actor COMPs contained within it as the simulation progresses forward.\n\nThe Actor COMPs referenced by the Nvidia Flex Solver COMP do not need to be inside its network. They can be anywhere as long as they are not already referenced by another Solver COMP (Nvidia Flex or Bullet). \n\nSee also: [[Flex]], [[Nvidia Flex TOP]], [[Actor COMP]], [[Force COMP]]",
        "opCategories": ""
    },
    "flowEmitterCOMP": {
        "label": "flowEmitterCOMP",
        "members": [
            {
                "text": "dropmenu : Select Emitter or Collider mode.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "dropmenu : Select the shape type used for the emitter.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Controls the dimensions of the emitter when using Box or Shape TOP types.",
                "type": "Par",
                "name": "sizex"
            },
            {
                "text": "Controls the dimensions of the emitter when using Box or Shape TOP types.",
                "type": "Par",
                "name": "sizey"
            },
            {
                "text": "Controls the dimensions of the emitter when using Box or Shape TOP types.",
                "type": "Par",
                "name": "sizez"
            },
            {
                "text": "Specifies the center of mass of the emitter.",
                "type": "Par",
                "name": "centerofmassx"
            },
            {
                "text": "Specifies the center of mass of the emitter.",
                "type": "Par",
                "name": "centerofmassy"
            },
            {
                "text": "Specifies the center of mass of the emitter.",
                "type": "Par",
                "name": "centerofmassz"
            },
            {
                "text": "Target linear velocity of the fuel added to the system.",
                "type": "Par",
                "name": "linearvelx"
            },
            {
                "text": "Target linear velocity of the fuel added to the system.",
                "type": "Par",
                "name": "linearvely"
            },
            {
                "text": "Target linear velocity of the fuel added to the system.",
                "type": "Par",
                "name": "linearvelz"
            },
            {
                "text": "Target angular velocity of the fuel added to the system. Think of this as 'rotational velocity.",
                "type": "Par",
                "name": "angularvelx"
            },
            {
                "text": "Target angular velocity of the fuel added to the system. Think of this as 'rotational velocity.",
                "type": "Par",
                "name": "angularvely"
            },
            {
                "text": "Target angular velocity of the fuel added to the system. Think of this as 'rotational velocity.",
                "type": "Par",
                "name": "angularvelz"
            },
            {
                "text": "Rate at which the the system gets to the target velocity. Each simulation block has its own velocity level, the emitter tries to change any blocks it overlaps with to match its emitter value. The correction rate is how strongly it tries to change the value to this target value, for example if 0 the emiitter won't do anything, when a small value like 0-1 the emitter will gently influence the simulation, when a high value like 10-100 it will force the value.",
                "type": "Par",
                "name": "velcorratex"
            },
            {
                "text": "Rate at which the the system gets to the target velocity. Each simulation block has its own velocity level, the emitter tries to change any blocks it overlaps with to match its emitter value. The correction rate is how strongly it tries to change the value to this target value, for example if 0 the emiitter won't do anything, when a small value like 0-1 the emitter will gently influence the simulation, when a high value like 10-100 it will force the value.",
                "type": "Par",
                "name": "velcorratey"
            },
            {
                "text": "Rate at which the the system gets to the target velocity. Each simulation block has its own velocity level, the emitter tries to change any blocks it overlaps with to match its emitter value. The correction rate is how strongly it tries to change the value to this target value, for example if 0 the emiitter won't do anything, when a small value like 0-1 the emitter will gently influence the simulation, when a high value like 10-100 it will force the value.",
                "type": "Par",
                "name": "velcorratez"
            },
            {
                "text": "The base color of the combustion.",
                "type": "Par",
                "name": "colorr"
            },
            {
                "text": "The base color of the combustion.",
                "type": "Par",
                "name": "colorg"
            },
            {
                "text": "The base color of the combustion.",
                "type": "Par",
                "name": "colorb"
            },
            {
                "text": "The base color of the combustion.",
                "type": "Par",
                "name": "colora"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "flowEmitterCOMP",
        "opLabel": "Nvidia Flow Emitter",
        "opClass": "flowEmitterCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This operator only works with '''Nvidia GPUs'''.",
        "short": "The Nvidia Flow COMP is the fuel emitter for the Flow simulation and can be placed anywhere in the 3D scene.",
        "long": "NVIDIA Flow is a volumetric fluid based simulation of a burning gas system. The user controls the 3 main factors of temperature, fuel, and smoke to create fire and smoke simulations. \n\nThe Nvidia Flow COMP is the fuel emitter for the Flow simulation and can be placed anywhere in the 3D scene.\n\nSee also [[Nvidia Flow TOP]], [[Nvidia Flow]].",
        "opCategories": ""
    },
    "opviewerCOMP": {
        "label": "opviewerCOMP",
        "members": [
            {
                "text": "Lets you pan across the target operator's viewer when the Scale is > 1. Center adjusts what part of the target operator's viewer is in the middle of the OP Viewer.",
                "type": "Par",
                "name": "opcenterx"
            },
            {
                "text": "Lets you pan across the target operator's viewer when the Scale is > 1. Center adjusts what part of the target operator's viewer is in the middle of the OP Viewer.",
                "type": "Par",
                "name": "opcentery"
            },
            {
                "text": "Menu : Center can be expressed in panel units or fraction of width, or display points.",
                "type": "Par",
                "name": "opcenterunit"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "OP Viewer",
        "opFamily": "COMP",
        "long": "The OP Viewer Component allows any operator viewer (CHOP Viewer, SOP Viewer, panels, etc.) to be part of a panel with optional full interactivity.",
        "opClass": "opviewerCOMP_Class",
        "short": "The OP Viewer Component allows any operator viewer (CHOP Viewer, SOP Viewer, panels, etc.) to be part of a panel with optional full interactivity.",
        "opType": "opviewer",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "Pallette:depthProjection Ext": {
        "label": "Pallette:depthProjection Ext",
        "members": [
            {
                "text": "Menu : Determines what kind of depth is stored in the source depth image i.e. whether the point cloud is projected in rays from a single camera point, or from the image plane.",
                "type": "Par",
                "name": "Depthtype"
            },
            {
                "text": "Used for scaling the point cloud depth. This parameter defines the range of depths in the source image. Depths outside this range are extrapolated.",
                "type": "Par",
                "name": "Fromrange1"
            },
            {
                "text": "Used for scaling the point cloud depth. This parameter defines the range of depths in the source image. Depths outside this range are extrapolated.",
                "type": "Par",
                "name": "Fromrange2"
            },
            {
                "text": "Determines the output range for the depth values. The range of input values is mapped linearly to the output range and values outside of the range are extrapolated.",
                "type": "Par",
                "name": "Torange1"
            },
            {
                "text": "Determines the output range for the depth values. The range of input values is mapped linearly to the output range and values outside of the range are extrapolated.",
                "type": "Par",
                "name": "Torange2"
            },
            {
                "text": "Menu : Determines how the field of view is defined for the projection.",
                "type": "Par",
                "name": "Viewanglemethod"
            },
            {
                "text": "The normalized focal length values when using the Focal Length view angle method.",
                "type": "Par",
                "name": "Focallengths1"
            },
            {
                "text": "The normalized focal length values when using the Focal Length view angle method.",
                "type": "Par",
                "name": "Focallengths2"
            },
            {
                "text": "The position of the camera relative to the image plane in normalized values i.e. (0.5, 0.5) assumes the camera point is directly in the center of the image plane.",
                "type": "Par",
                "name": "Center1"
            },
            {
                "text": "The position of the camera relative to the image plane in normalized values i.e. (0.5, 0.5) assumes the camera point is directly in the center of the image plane.",
                "type": "Par",
                "name": "Center2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "containerCOMP",
        "opLabel": "depthProjection",
        "opClass": "Pallette:depthProjection Ext",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "The depthProjection component converts a 2D depth map image into a 3D point cloud stored in a floating point texture.",
        "long": "The depthProjection component uses the given camera intrinsic properties to project a 2D depth map image into a 3D point cloud. The resulting point cloud is stored in a floating point texture which can be used as an instancing source for rendering point clouds."
    },
    "parameterCOMP": {
        "label": "parameterCOMP",
        "members": [
            {
                "text": "Menu : Specify the how to combine the scope parameters below to make the parameter selection.",
                "type": "Par",
                "name": "combinescopes"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Parameter",
        "opFamily": "COMP",
        "long": "The Parameter Component allows any operator's parameter dialog to be a panel with full interactivity. You specify which operator whose parameters you want to appear in the panel.\t\t\n\t\t\t\nYou can optionally have it display the header and the page names, and include built-in or [[Custom Parameters]].\t\t\t\n\t\t\t\nYou can specify a scope of pages and individual parameters to display, for example two entire pages plus four parameters on other pages.  When specifying parameters only, the order of the parameters is the order you specify them in.\t\t\t\n\t\t\t\nYou can shrink the UI so it fits into a smaller panel, using the Compress parameter.\n\nYou can control whether users can open the parameter for editing (via the + on the left of the parameter) using the Allow Expansion toggle. You can prevent users from going in and editing expressions.\n\t\t\t\nYou can specify page or parameter names using pattern matching: <code>scale*</code>  <code>^tx</code>, etc, with page names that contain spaces specified in quotes. <code>'Cue 1' 'Cue 2'</code>, or specified as a python list.",
        "opClass": "parameterCOMP_Class",
        "short": "The Parameter Component allows any operator's parameter dialog to be a panel with full interactivity.",
        "opType": "parameter",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "replicatorCOMP": {
        "label": "replicatorCOMP",
        "members": [
            {
                "text": "Menu : Choose between using a Template DAT Table where each row will create a replicant or using the Number of Replicants parameter below to set how many replications to make.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : How the node names will be generated.",
                "type": "Par",
                "name": "namefromtable"
            },
            {
                "text": "Menu : How to lay out the new nodes - all in one place (Off), horizontally, vertically, or in a grid.",
                "type": "Par",
                "name": "layout"
            },
            {
                "text": "Where to lay out the new nodes, giving the XY location of the top-left node's bottom-left corner.",
                "type": "Par",
                "name": "layoutorigin1"
            },
            {
                "text": "Where to lay out the new nodes, giving the XY location of the top-left node's bottom-left corner.",
                "type": "Par",
                "name": "layoutorigin2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Replicator",
        "opFamily": "COMP",
        "long": "The Replicator COMP creates copies of a component, one for every row in a table or using a Number of Replicants parameter - it is the \"for-loop\" of operators. Unlike [[Clone]], it automatically creates copies of a master component.\n    \nIt creates replicant nodes (\"[http://en.wikipedia.org/wiki/Replicant replicants]\") and deletes them as the table changes or the replicant count changes. The replicant master can be a full component and its contents or a single node. \t\t\n\t\t\t\nIt takes the node specified in the <span class=\"tipTextCOMP\">Master Node</span> parameter, and makes a copy of the master for every row in the <span class=\"tipTextCOMP\">Template Table</span> (or specified by the Number of Replicant parameter).\t\n\t\t\t\nThe nodes that are created can be named in two ways. Copies can be named/numbered sequentially using\t\t\t\nthe prefix specified by the <span class=\"tipTextCOMP\">Node Prefix</span> parameter: <code>item1</code>, <code>item2</code>, ... Alternately, copies can be named based on the string in a column of the table, specified with the <span class=\"tipTextCOMP\">Name from Table</span> parameter.\t\t\t\n\t\t\t\n[[Image:Replicator.1.png|700px]]\t\t\t\n\t\t\t\nIf you want to create a node for the first row of the table, un-set the <span class=\"tipTextCOMP\">Ignore First Row</span> parameter.\t\t\t\n\t\t\t\nThe replicants get laid out in a grid in the network, determined by the <span class=\"tipTextCOMP\">Layout</span> and <span class=\"tipTextCOMP\">Layout Origin</span> parameters.\t\t\t\n\t\t\t\nThe Replicator does not assume or require that the master and replicants are components \u2013 they can all be Movie File In TOPs if you want. It also does not assume or require that the replicants are [[Clone]]s.  However the <span class=\"tipTextCOMP\">Master Node</span> can be a component whose [[Clone]] parameter is set to itself, so that all nodes created are clones of the master.\t\t\t\n\t\t\t\nFor every replicant, you can run a script in the callback DAT where you can see some examples of typical cases that you can adapt. Here are some others:\t\t\t\n* change the expression of a [[Par Class|parameter]]: <code>c.par.display.expr = \"op('thing')[op.digits, 'display']\"</code>\t\t\t\n* Change the parameter expression mode:  <code>c.par.display.mode = ParMode.EXPRESSION</code>    The mode is one of: <code>ParMode.CONSTANT</code>, <code>ParMode.EXPRESSION</code>, or <code>ParMode.EXPORT</code>. \t\t\t\n\t\t\t\nIf only one line of a table changes, the other existing replicants are not changed or re-created. In the callback DAT, removing <code>onRemoveReplicant()</code> will keep the replicants around to be re-used when the table grows again.\t\t\t\n\t\t\t\nThis is an extremely powerful node type. Examples: (1) A button gadget for each row of the table. a geometry component, which is replicated at every point of a 3D particle system, each behaving separately. (2) You can feed the table of a [[Multi Touch In DAT]] directly to the Replicator to create something at each fingertip.",
        "opClass": "replicatorCOMP_Class",
        "short": "The Replicator Component creates a node for every row of a table, creating nodes (\"[http://en.wikipedia.org/wiki/Replicant replicants]\") and deleting them as the table changes.",
        "opType": "replicator",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "selectCOMP": {
        "label": "selectCOMP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Select",
        "opFamily": "COMP",
        "long": "The Select Component selects a [[Panel Component]] from any other location. This allows a panel to appear in multiple other panels.\t\t\n\t\t\t\nCan be used to select components recursively. If ''select1'' points to ''select2'', it will display whatever ''select2'' points to (recursively) using ''select2'''s parameters. \t\t\t\n\t\t\t\nThe Select component can re-size the component it refers to by setting its Width and Height parameters.",
        "opClass": "selectCOMP_Class",
        "short": "The Select Component selects a [[Panel Component]] from any other location.",
        "opType": "select",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "sharedmeminCOMP": {
        "label": "sharedmeminCOMP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Shared Mem In",
        "opFamily": "COMP",
        "long": "The Shared Mem In COMP is only available in TouchDesigner Commercial and Pro.\t\n\t\t\nThe Shared Mem In COMP will read transform data from a shared memory block. This memory block can be created by another Touch process using the [[Shared Mem Out COMP]].",
        "opClass": "sharedmeminCOMP_Class",
        "short": "The Shared Mem In COMP will read transform data from a shared memory block.",
        "opType": "sharedmemin",
        "opLicense": "Commercial",
        "opCategories": ""
    },
    "sharedmemoutCOMP": {
        "label": "sharedmemoutCOMP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "opLabel": "Shared Mem Out",
        "opFamily": "COMP",
        "long": "The Shared Mem In TOP is only available in TouchDesigner Commercial and Pro.\t\n\t\t\nThe Shared Mem Out COMP will write transform data to a shared memory block. This memory block can be read by another Touch process using the [[Shared Mem In COMP]].",
        "opClass": "sharedmemoutCOMP_Class",
        "short": "The Shared Mem Out COMP will write transform data to a shared memory block.",
        "opType": "sharedmemout",
        "opLicense": "Commercial",
        "opCategories": ""
    },
    "sliderCOMP": {
        "label": "sliderCOMP",
        "members": [
            {
                "text": "Menu : Sets the type of slider.",
                "type": "Par",
                "name": "slidertype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Slider Component lets you build sliders in X, Y and XY, and outputs 1 or 2 channels from a [[Panel CHOP]] placed in the Slider component. \t\t\n\t\t\t\n[[image:SliderCOMP.png]]\t\t\t\n\t\t\t\nDefault Slider Component\t\t\t\n\t\t\t\nSee [[Panel Value]].",
        "1": "Default Slider Component",
        "opLicense": "Non-Commercial",
        "opFamily": "COMP",
        "opLabel": "Slider",
        "short": "The Slider Component lets you build sliders in X, Y and XY, and outputs 1 or 2 channels from a [[Panel CHOP]] placed in the Slider component.",
        "opType": "slider",
        "opFilter": "False",
        "opClass": "sliderCOMP_Class",
        "opCategories": ""
    },
    "tableCOMP": {
        "label": "tableCOMP",
        "members": [
            {
                "text": "Menu : Specifies the order in which cells are arranged:",
                "type": "Par",
                "name": "tablealign"
            },
            {
                "text": "Menu : Lets you choose the unit of the specified font size.",
                "type": "Par",
                "name": "fontsizeunit"
            },
            {
                "text": "Menu : Determines how the state information in a connected [[Info DAT]] is displayed.",
                "type": "Par",
                "name": "infoformat"
            },
            {
                "text": "Offset the Table. This is not offsetting the Table COMP itself but the Table as it is drawn. So when selecting to Crop the Children, the Table will be potentially cut off at the borders of the Table COMP.",
                "type": "Par",
                "name": "tableoffsetx"
            },
            {
                "text": "Offset the Table. This is not offsetting the Table COMP itself but the Table as it is drawn. So when selecting to Crop the Children, the Table will be potentially cut off at the borders of the Table COMP.",
                "type": "Par",
                "name": "tableoffsety"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Table",
        "opFamily": "COMP",
        "long": "The Table Component creates a grid of user interface gadgets. These panels are laid out in a grid format where the contents of each cell are defined by DAT tables.",
        "opClass": "tableCOMP_Class",
        "short": "The Table Component creates a grid of user interface gadgets.",
        "opType": "table",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "textCOMP": {
        "label": "textCOMP",
        "members": [
            {
                "text": "Menu : Controls whether the contents are taken from the Text parameter or from a Specification DAT/CHOP.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : The Type parameter controls how the value is interpreted and as well as what formatting and editing options are available.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : This parameter controls how the source text is is formatted and displayed inside the panel. The options available will change depending on the selected mode. For example, in Float mode there are options for scientific notation or percentage, while in Integer mode there are options to treat the source value as a time code.",
                "type": "Par",
                "name": "formatting"
            },
            {
                "text": "Menu : Used in Float and Integer mode to add a separator between thousands to make it easier to read large numbers. For example 1,000,000",
                "type": "Par",
                "name": "thousandsseparator"
            },
            {
                "text": "Menu : Controls whether the text can be editing directly in the viewer.",
                "type": "Par",
                "name": "editmode"
            },
            {
                "text": "Menu : Use this parameter to control whether the text is displayed from left-to-right (LTR) or from right-to-left (RTL). Bidirectional layout is also supported when LTR characters are detected when using RTL mode.",
                "type": "Par",
                "name": "readingdirection"
            },
            {
                "text": "Menu : This parameter controls what happens when a user drags something onto an active panel.",
                "type": "Par",
                "name": "dragdropmode"
            },
            {
                "text": "Menu : This parameter controls what happens when a user drags something onto an active panel.",
                "type": "Par",
                "name": "dragdropmode"
            },
            {
                "text": "Menu : Select the font to be used from the dropdown menu. Available fonts are those that have been registered with the operating system. There may be a delay when selecting fonts that have not been used before as the system creates the necessary intermediate files required for rendering.",
                "type": "Par",
                "name": "font"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "typeface"
            },
            {
                "text": "Menu : Automatically adjust the font size to fit inside the panel.",
                "type": "Par",
                "name": "scaletofit"
            },
            {
                "text": "Menu : Determines how the font size is interpretted. The default is resolution-independent panel units.",
                "type": "Par",
                "name": "fontsizeunits"
            },
            {
                "text": "The default color of the text. Additional colors can be applied to separate parts of the text using formatting codes.",
                "type": "Par",
                "name": "fontcolorr"
            },
            {
                "text": "The default color of the text. Additional colors can be applied to separate parts of the text using formatting codes.",
                "type": "Par",
                "name": "fontcolorg"
            },
            {
                "text": "The default color of the text. Additional colors can be applied to separate parts of the text using formatting codes.",
                "type": "Par",
                "name": "fontcolorb"
            },
            {
                "text": "The color of the selection bar when Custom Select Color is enabled.",
                "type": "Par",
                "name": "selectcolorr"
            },
            {
                "text": "The color of the selection bar when Custom Select Color is enabled.",
                "type": "Par",
                "name": "selectcolorg"
            },
            {
                "text": "The color of the selection bar when Custom Select Color is enabled.",
                "type": "Par",
                "name": "selectcolorb"
            },
            {
                "text": "An offset applied to the text position after any other alignment operations. Positive values move the text up and to the right.",
                "type": "Par",
                "name": "textoffsetx"
            },
            {
                "text": "An offset applied to the text position after any other alignment operations. Positive values move the text up and to the right.",
                "type": "Par",
                "name": "textoffsety"
            },
            {
                "text": "Menu : Determine the units used by the Text Offset parameter.",
                "type": "Par",
                "name": "textoffsetunits"
            },
            {
                "text": "Menu : The units used by the text padding.",
                "type": "Par",
                "name": "textpaddingunits"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingl"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingr"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingb"
            },
            {
                "text": "",
                "type": "Par",
                "name": "textpaddingt"
            },
            {
                "text": "Menu : The units used by the text padding.",
                "type": "Par",
                "name": "textpaddingunits"
            },
            {
                "text": "Menu : Determines how the text is positioned horizontally in the panel. For example, with left alignment, the text will be positioned against the left side of the panel plus any defined padding.",
                "type": "Par",
                "name": "alignx"
            },
            {
                "text": "Menu : Determines how the text is measured for calculating the alignment. Only font metrics are available when using Multiline or Specification DAT mode.",
                "type": "Par",
                "name": "alignxmode"
            },
            {
                "text": "Menu : Determines how the text is positioned vertically inside the panel.",
                "type": "Par",
                "name": "aligny"
            },
            {
                "text": "Menu : Determines how the text is measured when doing the vertical alignment.",
                "type": "Par",
                "name": "alignymode"
            },
            {
                "text": "Set the amount of space between the edges of the panel and the text. Whether the padding has an effect on the position of the text depends on the current alignment mode and whether word wrapping is used. For example, if the text is left aligned, the text will be positioned away from the left edge based on the left padding. But the text may extend any distance from the right edge depending on the length of the text. However, if word wrap is enabled in multiline mode, then the text will be wrapped at a distance from the right edge based on the padding.",
                "type": "Par",
                "name": "textpaddingl"
            },
            {
                "text": "Set the amount of space between the edges of the panel and the text. Whether the padding has an effect on the position of the text depends on the current alignment mode and whether word wrapping is used. For example, if the text is left aligned, the text will be positioned away from the left edge based on the left padding. But the text may extend any distance from the right edge depending on the length of the text. However, if word wrap is enabled in multiline mode, then the text will be wrapped at a distance from the right edge based on the padding.",
                "type": "Par",
                "name": "textpaddingr"
            },
            {
                "text": "Set the amount of space between the edges of the panel and the text. Whether the padding has an effect on the position of the text depends on the current alignment mode and whether word wrapping is used. For example, if the text is left aligned, the text will be positioned away from the left edge based on the left padding. But the text may extend any distance from the right edge depending on the length of the text. However, if word wrap is enabled in multiline mode, then the text will be wrapped at a distance from the right edge based on the padding.",
                "type": "Par",
                "name": "textpaddingb"
            },
            {
                "text": "Set the amount of space between the edges of the panel and the text. Whether the padding has an effect on the position of the text depends on the current alignment mode and whether word wrapping is used. For example, if the text is left aligned, the text will be positioned away from the left edge based on the left padding. But the text may extend any distance from the right edge depending on the length of the text. However, if word wrap is enabled in multiline mode, then the text will be wrapped at a distance from the right edge based on the padding.",
                "type": "Par",
                "name": "textpaddingt"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "textCOMP",
        "opLabel": "Text",
        "opClass": "textCOMP_Class",
        "opFilter": "False",
        "opLicense": "TouchDesigner Non-Commercial",
        "opCategories": "",
        "short": "The Text COMP is a [[panel]] used to display read-only text or editable text.",
        "long": "The Text COMP is a [[panel]] used to display text for building user interfaces. The text can be view-only, view-only but copy/pasteable, or be fully editable directly in the panel. \n    \nThere are '''formatting''' modes for displaying single-line strings and multi-line text, floating point and integer numbers, password fields and more. The source of the text comes from the Text parameter and it is then formatted for display in the panel. Formatting examples include displaying a number as a currency, percent or scientific notation, or converting an integer timecode value to hours/minutes/seconds/frames. Other formatting options include support for Python syntax, Custom C++ Fmt and Custom Python F-String syntax.\n\nWhen a user clicks in the panel to edit the text, the contents are displayed in a raw format and then formatted again once the editing is completed.\n\nThe Text COMP supports '''[[Text Formatting Codes|inline formatting directives]]''' in the text for things like color, strikeouts, underlines, small caps, subscripts, gradients, etc. For example, the code <code>{#color(255, 0, 0);}</code> will turn all text that follows on that line red.\n\nIt has '''text-fitting''' options for wraparound, shrinking text if it doesn't fit, left-center-right alignment and language reading direction. View-only text can be selectable or not selectable.\n\nYou can draw '''multiple transformed/formatted strings using a \"Specification DAT\" table''': It draws one string per row of the table, each with its own position and formatting in your panel. Columns can be <code>x</code>, <code>y</code>, <code>text</code>, <code>fontsize</code>, <code>fontcolorr</code>, <code>fontcolorg</code>, <code>fontcolorb</code>, <code>fontalpha</code>, <code>skew</code>, <code>tracking</code> and <code>horzstretch</code>.\n\nIt has '''python callbacks''' that can be executed for every character or string that has changed, and a callback for change of focus.\n\n'''Resolution-independent text''' is drawn directly to the screen at the resolution required for the panel size, resulting in perfectly crisp text at all zoom levels. It is GPU-based using the [[Slug Library]].\n\nUnits for X, Y, Width and Height are in \"'''panel units'''\" whereas they were actual pixel units before. Default Font Size, Text Offsets and Padding are in panel units.\n\nSee [[Text Formatting Codes]]\n\nSee also [[Geo Text COMP]] for the 3D rendered equivalent of the Text COMP.\n\nNote: The Text COMP is a replacement for the [[Field COMP]], completely replacing it and adding many new features not previously available."
    },
    "timeCOMP": {
        "label": "timeCOMP",
        "members": [
            {
                "text": "Menu : This menu controls how the playback loops:",
                "type": "Par",
                "name": "rangelimit"
            },
            {
                "text": "Specifies the time signature. The first number is the number of beats per measure and the second number indicates the type of note that constitutes one beat. See [http://en.wikipedia.org/wiki/Time_signature Time Signature - Wikipedia] for additional information.",
                "type": "Par",
                "name": "signature1"
            },
            {
                "text": "Specifies the time signature. The first number is the number of beats per measure and the second number indicates the type of note that constitutes one beat. See [http://en.wikipedia.org/wiki/Time_signature Time Signature - Wikipedia] for additional information.",
                "type": "Par",
                "name": "signature2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Time",
        "opFamily": "COMP",
        "long": "The Time Component allows each component to have its own timeline (clock). The Time Component contains a network of operators that can drive a [[Timeline]], drive animations in [[Animation COMP]]s, or be used to drive any custom time-based system. The Time Component's parameters define the speed, range, various options for the time system.  \t\t\n\t\t\t\nThe Time Component is often used in TouchDesigner to allow a component to have its own timeline / clock, this is called [[Component Time]]. It is useful for holding some parts of your system stationary while others are allowed to play forward. A Time Component's location must be in the <code>/local</code> network of a [[Component]] for the Time Component to create a '''Component Time'''. \t\t\t\n\t\t\t\nTo add Component Time to a component, right-click on the component and select '''Add Component Time...''' from the popup menu, this will add the following Time Component <code>/''comppath''/local/time</code>.\t\t\t\n\t\t\t\nThe Time Component's predefined network is [[Clone|Cloned]] from Master Component <code>/sys/local/time</code>.  The Time Component's network can be modified if the path in the Clone parameter is removed.",
        "opClass": "timeCOMP_Class",
        "short": "The Time Component allows each component to have its own timeline (clock).",
        "opType": "time",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "usdCOMP": {
        "label": "usdCOMP",
        "members": [
            {
                "text": "dropmenu : A menu to choose between the file FPS or custom sample rate.",
                "type": "Par",
                "name": "sampleratemode"
            },
            {
                "text": "dropmenu : A menu to specify the method used to play the animation.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "nolabel shortvalues dropmenu : Specifies a unit type for Cue Point. Changing this will convert the previous unit to the selected unit.",
                "type": "Par",
                "name": "cuepointunit"
            },
            {
                "text": "nolabel shortvalues dropmenu : Specifies a unit type for Index. Changing this will convert the previous unit to the selected unit.",
                "type": "Par",
                "name": "indexunit"
            },
            {
                "text": "nolabel shortvalues dropmenu : Specifies a unit type for Trim Start. Changing this will convert the previous unit to the selected unit.",
                "type": "Par",
                "name": "tstartunit"
            },
            {
                "text": "nolabel shortvalues dropmenu : Specifies a unit type for Trim End. Changing this will convert the previous unit to the selected unit.",
                "type": "Par",
                "name": "tendunit"
            },
            {
                "text": "dropmenu : Determines how USD COMP handles animation positions that lie before the Trim Start position. For example, if Trim Start is set to 1, and the animation current index is -10, the Extend Left menu determines how the animation position is calculated.",
                "type": "Par",
                "name": "textendleft"
            },
            {
                "text": "dropmenu : Determines how USD COMP handles animation positions that lie after the Trim End position. For example, if Trim End is set to 20, and the animation current index is 25, the Extend Right menu determines how the animation position is calculated.",
                "type": "Par",
                "name": "textendright"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "usdCOMP",
        "opLabel": "USD",
        "opClass": "usdCOMP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The USD COMP loads and imports most geometric schemas from a [[USD]] file in crate/binary or ASCII file formats with extensions as (<code>.usd</code>), (<code>.usda</code>), (<code>.usdc</code>), and (<code>.usdz</code>). Currently the USD version 20.08 is being used in USD COMP.",
        "long": "The USD COMP loads and imports most geometric schemas from a [[USD]] file in crate/binary or ASCII file formats with extensions as (<code>.usd</code>), (<code>.usda</code>), (<code>.usdc</code>), and (<code>.usdz</code>). Currently the USD version 0.18.9 is being used in USD COMP. You can drag-drop a USD file into a TouchDesigner network, or import it via the USD File parameter. See also [[File Types]].\n\nThe assets from the USD file are saved into a \"<code>.tdc</code>\" file with the same name as the USD file inside the TDImportCache folder, which is created next to your toe file. Assets are read from the \"<code>.tdc</code>\" file using Import Select OPs ([[Import Select TOP]] / [[Import Select SOP]] / [[Import Select CHOP]]). Upon reloading a <code>.toe</code> file, the assets can be imported directly from the \"<code>.tdc</code>\" cache, and the USD file will not need to be re-imported. However, if there is no existing \"<code>.tdc</code>\" (for instance, if the toe file changed computers) then the USD file will be reopened to grab the assets and a new \"<code>.tdc</code>\" will be saved out.\n\nTo open a USD file in an USD COMP:\n\n1) Specify a valid file path in the \"USD File\" parameter, including the name of the file with correct .usd extension.\n\n2) This step is varied depending on whether the USD COMP is just created and if any changes in the default values of parameters are required or not. If the file is being loaded for the first time in the network and the default parameter values are accepted then simply press the \"Build Network\" to generate the USD network and import the assets. Note that we recommend toggling the \"Merge Geometry\" for any medium or large files as it can significantly improve performance. Generally, any changes in the parameters above the \"Build Network\" requires the network to be built again.\n\n3) The \"Reload\" button is being used for reloading the internal assets (e.g. meshes, points, etc.) and this is specifically useful if the file has moved to another location and when the <code>.toe</code> file is opened the assets were not found and reloaded properly.\n\n4) The \"Update\" button is used when some changes on USD file are made and we want to merge those changes into the current network without fully rebuilding it.\n\nHere are some examples: https://developer.apple.com/augmented-reality/quick-look/\n\nSee also: [[USD]], [[USD In TouchDesigner]], [[Import Select CHOP]], [[Import Select TOP]], [[Import Select SOP]], [[FBX COMP]]",
        "opCategories": ""
    },
    "widgetCOMP": {
        "label": "widgetCOMP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "COMP",
        "opType": "widgetCOMP",
        "opLabel": "Widget",
        "opClass": "widgetCOMP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "",
        "long": "",
        "opCategories": ""
    },
    "windowCOMP": {
        "label": "windowCOMP",
        "members": [
            {
                "text": "Menu : All the positioning parameters below are done relative to the location you specify here. Your window can span more than the specified 'area', it's just used as the reference for positioning.",
                "type": "Par",
                "name": "justifyoffsetto"
            },
            {
                "text": "Menu : Aligns the window horizontally with the monitor or bounds of all monitors.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Aligns the window vertically with the monitor or bounds of all monitors.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Horizontal offset applied to window after justifying.",
                "type": "Par",
                "name": "winoffsetx"
            },
            {
                "text": "Horizontal offset applied to window after justifying.",
                "type": "Par",
                "name": "winoffsety"
            },
            {
                "text": "Menu : Options for managing DPI scaling on high DPI monitors. To inspect a monitor's DPI scaling setting, you can use the [[Monitors DAT]] and refer to the <code>dpi_scale</code> column.",
                "type": "Par",
                "name": "dpiscaling"
            },
            {
                "text": "Menu : Determines how the size of the window is determined.",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Controls whether or not the cursor remains visible when over this window.",
                "type": "Par",
                "name": "cursorvisible"
            },
            {
                "text": "Menu : Controls how the window is updated with regards to V-Sync. Enabled means it will update in sync with the monitors refresh which avoids tearing and lost frames. Disabled means it can update at any point during the refresh which can result in tearing or lost frames. FPS is Half Monitor Rate should be used when doing things such as running a 30fps file on a 60Hz display. This makes each update be shown for exactly 2 refreshes which keeps motion looking smooth.",
                "type": "Par",
                "name": "vsyncmode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Window",
        "opFamily": "COMP",
        "long": "The Window Component allows you to create and maintain a separate floating or fixed window displaying the contents of any [[Panel]] or any [[Node Viewer]]. \n\nMost frequently you are setting up the Window COMP <code>/perform</code> in the default TouchDesigner project. <code>/perform</code> is the default window for [[Perform Mode]]. In the Parameter dialog of the Window component you adjust its settings such as resolution, centering, and which monitor(s) the window will get displayed on.\n\nYou then press F1 to go into [[Perform Mode]] and operate/display the panel standalone.\n\t\t\t\nPress Esc over a window to close it and go back to [[Designer Mode]].\n\nYou can create more Window Components, point them to panels or other Operators like TOPs, adjust their parameters and then pulse the parameter Open as Separate Window to see its effect.\n\nUse the Dialog-> [[Window Placement Dialog]] which controls which window COMPs get displayed on startup. All Window COMPS in your project are listed there and you can test them individually.\n\nA window can be fit to a single monitor, or span several monitors.\n\t\t\t\nAttach an [[Info CHOP]] to the Window component - it will show you the window's current location and size, and whether the window is actually open.\n\nSee also [[Window]], [[Multiple Monitors]].",
        "opClass": "windowCOMP_Class",
        "short": "The Window Component allows you to create and maintain a separate floating window displaying the contents of any [[Panel]] or any other [[Node Viewer]].",
        "opType": "window",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "addTOP": {
        "label": "addTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]].",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLabel": "Add",
        "opType": "add",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opClass": "addTOP_Class",
        "opFilter": "True",
        "short": "The Add TOP composites the input images together by adding the pixel values.",
        "long": "The Add TOP composites the input images together by adding the pixel values. Output = Input1 + Input2. It clamps a color channel if the sum exceeds 1.",
        "opCategories": ""
    },
    "analyzeTOP": {
        "label": "analyzeTOP",
        "members": [
            {
                "text": "Menu : The operation to perform on the input image.",
                "type": "Par",
                "name": "op"
            },
            {
                "text": "Menu : Determines what value the operation is being performed on. For example, when the operation is Minimum and the Analyze Channel is Red, the output will be the pixel with the lowest red value (not necessarily the lowest Blue or Green values). To separately find the lowest value in each channel, set this parameter to RGBA Independent.",
                "type": "Par",
                "name": "analyzechannel"
            },
            {
                "text": "Menu : Determines how pixels are grouped together to calculate the results.",
                "type": "Par",
                "name": "scope"
            },
            {
                "text": "Menu : This parameter allows you to exclude certain pixels based on the values in one or more channels in the input. For example, if set to Alpha, only pixels that have a non-zero value in the alpha will be included. This can be useful, for example, if you need to find the average position of a point cloud image that is using an Active channel to indicate which pixels store valid point data.",
                "type": "Par",
                "name": "mask"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "analyzeTOP",
        "opLabel": "Analyze",
        "opClass": "analyzeTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Analyze TOP takes any image and determines various characteristics of it, such as the average pixel color, or the pixel with the maximum luminance.",
        "long": "The Analyze TOP takes any image and determines various characteristics of it, such as the average pixel color, the pixel with the maximum luminance, or the min and max values in each channel. The result is stored in a 1x1, 1xN or Nx1 image depending on the chosen scope (See Scope parameter below). The calculated values can be brought into CHOPs using the [[TOP to CHOP]] node.\n    \n'''Note:''' When using the minimum and maximum operators, the default behaviour is to select the pixel with the highest value as chosen in the Analyze Channel parameter. For example, if Luminance is selected, the output will be the RGBA values of the pixel with the highest luminance, not the luminance value itself. Similarly, if a single channel is selected e.g. Red, Green, Blue, etc, then the output will be the pixel with the highest red value, rather than the highest values in each channel. To find the min or max values in each channel separately, set the Analyze Channel to RGBA Independent.\n\n'''Note:''' When the operation is set to Count Pixels or Sum, the output image will default to a 32 bit floating point format in order to properly store the output data. For all other operations, the default output format will match the input format. The image format can be set manually using the parameter on the Common page.\n\n'''Note:''' Using the Exclude NaNs or Mask features will slow down the performance of the node and should only be enabled if they are necessary.",
        "opCategories": ""
    },
    "antialiasTOP": {
        "label": "antialiasTOP",
        "members": [
            {
                "text": "Menu : Controls the quality of the anti-alias process. A higher quality will require more GPU power to compute.",
                "type": "Par",
                "name": "quality"
            },
            {
                "text": "Menu : This controls how edges are detected in the image. Anti-aliasing is only done along detected edges.",
                "type": "Par",
                "name": "edgedetectsource"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "antialiasTOP_Class",
        "short": "The Anti-Alias TOP uses a screen space antialiasing technique called \u2018SMAA: Enhanced Subpixel Morphological Antialiasing\u2019.",
        "opFilter": "True",
        "opLabel": "Anti Alias",
        "opFamily": "TOP",
        "long": "The Anti-Alias TOP uses a screen space antialiasing technique called \u2018SMAA: Enhanced Subpixel Morphological Antialiasing\u2019. Detailed information here: http://www.iryoku.com/smaa/  It uses an image\u2019s luminance, color or a depth map to detect edges of objects and then applies anti-aliasing to those edges. The current implementation does not yet use the temporal features of it, so each image is individually anti-aliased without requiring knowledge of other frames. It doesn\u2019t require the extra memory that regular Render TOP anti-aliasing does, and avoids work involved with antialiasing polygon edges that are ultimately occluded by another object.",
        "opType": "antialias",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "blobtrackTOP": {
        "label": "blobtrackTOP",
        "members": [
            {
                "text": "Menu : Blob tracking is done using a single channel. This menu controls what single channel is used to detect blobs.",
                "type": "Par",
                "name": "monosource"
            },
            {
                "text": "Determines the color of the rectangles that are drawn to show the blobs.",
                "type": "Par",
                "name": "blobcolorr"
            },
            {
                "text": "Determines the color of the rectangles that are drawn to show the blobs.",
                "type": "Par",
                "name": "blobcolorg"
            },
            {
                "text": "Determines the color of the rectangles that are drawn to show the blobs.",
                "type": "Par",
                "name": "blobcolorb"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "blobtrackTOP_Class",
        "short": "The Blob Track TOP is implemented using [https://opencv.org/ OpenCV].",
        "opFilter": "True",
        "opLabel": "Blob Track",
        "opFamily": "TOP",
        "long": "The Blob Track TOP is implemented using [https://opencv.org// OpenCV].\n    \nTo get the results of the Blob Track TOP, attach an [[Info DAT]] or [[Info CHOP]] to it. The Info reports the current blob IDs, coordinates and sizes in pixels. The blob ID increases for every new blob that is detected.\t\t\t\n\t\t\t\nIt converts the incoming image to monochrome (since it operates on an single color channel), but to better prepare the image, preceed it with a Monochrome TOP followed by a Luma Level TOP, and adjust Black Level, Brightness and Gamma.\n\nTypical usage is connecting a video source (such as  [[Video Device In TOP]] to the Blob Track TOP).\n\t\t\t\n'''NOTE:''' can track an unlimited number of blobs in Pro and Commercial, and up to 2 blobs in the Non-Commercial version of TouchDesigner.\t\t\n\nSee also [[Blob Track CHOP]]",
        "opType": "blobtrack",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "blurTOP": {
        "label": "blurTOP",
        "members": [
            {
                "text": "Menu : Determines how the blur is applied.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : Determines the mathematical function used to create the blur.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : Sets the extend conditions to determine what happens to the blur at the edge of the image.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to blur the image. A Sample Step of 3 would sample pixels 3 pixels away.",
                "type": "Par",
                "name": "offset1"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to blur the image. A Sample Step of 3 would sample pixels 3 pixels away.",
                "type": "Par",
                "name": "offset2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "blurTOP_Class",
        "short": "The Blur TOP blurs the image with various kernel filters and radii.",
        "opFilter": "True",
        "opLabel": "Blur",
        "opFamily": "TOP",
        "long": "The Blur TOP blurs the image with various kernel filters and radii. It can do multi-pass blurs and can do horizontal-only or vertical-only blurs. \t\t\n\t\t\t\nUse Pre-shrink when the blurs are high and you want to optimize performance.\t\t\t\n\t\t\t\n'''Tip:''' Filter Size is expressed in pixels. If you want resolution-independent blurs, use an expression like <code>me.par.resolutionw/100</code> in the Filter Size parameter, which gives a 1% image blur.",
        "opType": "blur",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "cacheselectTOP": {
        "label": "cacheselectTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "cacheselectTOP_Class",
        "short": "The Cache Select TOP grabs an image from a [[Cache TOP]] based on the index parameter.",
        "opFilter": "False",
        "opLabel": "Cache Select",
        "opFamily": "TOP",
        "long": "The Cache Select TOP grabs an image from a [[Cache TOP]] based on the index parameter. This gives direct, random access to any image stored in a Cache TOP.The Cache Select TOP grabs an image from a [[Cache TOP]] based on the index parameter. This gives direct, random access to any image stored in a Cache TOP.",
        "opType": "cacheselect",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "cacheTOP": {
        "label": "cacheTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Cache TOP stores a sequence of images into GPU memory. These cached images can be read by the graphics card much faster than an image cache in main memory or reading images off disk. \t\n\t\t\nThe Cache TOP can be used to freeze images in the TOP by turning the Active parameter Off. (You can set the cache size too <code>1</code>.)\t\t\n\t\t\nThe Cache TOP acts as a delay if you set Output Index to negative numbers and leave the Active parameter On.\t\t\n\t\t\nOnce a sequence of images has been captured by turning the Active parameter On or toggling the Active Pulse parameter, they can be looped by animating the Output Index parameter.",
        "opLabel": "Cache",
        "opClass": "cacheTOP_Class",
        "opType": "cache",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "short": "The Cache TOP stores a sequence of images into GPU memory.",
        "opCategories": ""
    },
    "channelmixTOP": {
        "label": "channelmixTOP",
        "members": [
            {
                "text": "Red output mix. Use these 4 values to mix the RGBA inputs into the output's red channel.",
                "type": "Par",
                "name": "red1"
            },
            {
                "text": "Red output mix. Use these 4 values to mix the RGBA inputs into the output's red channel.",
                "type": "Par",
                "name": "red2"
            },
            {
                "text": "Red output mix. Use these 4 values to mix the RGBA inputs into the output's red channel.",
                "type": "Par",
                "name": "red3"
            },
            {
                "text": "Red output mix. Use these 4 values to mix the RGBA inputs into the output's red channel.",
                "type": "Par",
                "name": "red4"
            },
            {
                "text": "Green output mix. Use these 4 values to mix the RGBA inputs into the output's green channel.",
                "type": "Par",
                "name": "green1"
            },
            {
                "text": "Green output mix. Use these 4 values to mix the RGBA inputs into the output's green channel.",
                "type": "Par",
                "name": "green2"
            },
            {
                "text": "Green output mix. Use these 4 values to mix the RGBA inputs into the output's green channel.",
                "type": "Par",
                "name": "green3"
            },
            {
                "text": "Green output mix. Use these 4 values to mix the RGBA inputs into the output's green channel.",
                "type": "Par",
                "name": "green4"
            },
            {
                "text": "Blue output mix. Use these 4 values to mix the RGBA inputs into the output's blue channel.",
                "type": "Par",
                "name": "blue1"
            },
            {
                "text": "Blue output mix. Use these 4 values to mix the RGBA inputs into the output's blue channel.",
                "type": "Par",
                "name": "blue2"
            },
            {
                "text": "Blue output mix. Use these 4 values to mix the RGBA inputs into the output's blue channel.",
                "type": "Par",
                "name": "blue3"
            },
            {
                "text": "Blue output mix. Use these 4 values to mix the RGBA inputs into the output's blue channel.",
                "type": "Par",
                "name": "blue4"
            },
            {
                "text": "Alpha output mix. Use these 4 values to mix the RGBA inputs into the output's alpha channel.",
                "type": "Par",
                "name": "alpha1"
            },
            {
                "text": "Alpha output mix. Use these 4 values to mix the RGBA inputs into the output's alpha channel.",
                "type": "Par",
                "name": "alpha2"
            },
            {
                "text": "Alpha output mix. Use these 4 values to mix the RGBA inputs into the output's alpha channel.",
                "type": "Par",
                "name": "alpha3"
            },
            {
                "text": "Alpha output mix. Use these 4 values to mix the RGBA inputs into the output's alpha channel.",
                "type": "Par",
                "name": "alpha4"
            },
            {
                "text": "Use these 4 values to add or subtract a constant amount to the output channels.",
                "type": "Par",
                "name": "constant1"
            },
            {
                "text": "Use these 4 values to add or subtract a constant amount to the output channels.",
                "type": "Par",
                "name": "constant2"
            },
            {
                "text": "Use these 4 values to add or subtract a constant amount to the output channels.",
                "type": "Par",
                "name": "constant3"
            },
            {
                "text": "Use these 4 values to add or subtract a constant amount to the output channels.",
                "type": "Par",
                "name": "constant4"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "channelmixTOP_Class",
        "short": "The Channel Mix TOP allows mixing of the input RGBA channels to any other color channel of the output.",
        "opFilter": "True",
        "opLabel": "Channel Mix",
        "opFamily": "TOP",
        "long": "The Channel Mix TOP allows mixing of the input RGBA channels to any other color channel of the output. For example, the pixels in the blue channel of the input can be added to the output's red channel, added or subtracted by the amount in Red parameter's blue column.\t\t\n\t\t\t\nSee also [[Reorder TOP]].",
        "opType": "chanmix",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "choptoTOP": {
        "label": "choptoTOP",
        "members": [
            {
                "text": "Menu : Determines how the input CHOP channels will be turned into an image. If the CHOP is missing channels required to provide all the data for a scanline, the extra channels are ignored.",
                "type": "Par",
                "name": "dataformat"
            },
            {
                "text": "Menu : Controls the dimensions of the output image and how the CHOP samples are arranged as pixels. This menu replaces the previous 'Crop Long Channels' and 'Fit to Square' parameters.",
                "type": "Par",
                "name": "activechannel"
            },
            {
                "text": "If the current Image Layout results in more pixels than there are available samples in the input CHOP, the values specified here will be used to fill in the extra pixels. (All textures require full rows of pixels, in other words all rows of pixels have the same number of pixels.)",
                "type": "Par",
                "name": "rgba1"
            },
            {
                "text": "If the current Image Layout results in more pixels than there are available samples in the input CHOP, the values specified here will be used to fill in the extra pixels. (All textures require full rows of pixels, in other words all rows of pixels have the same number of pixels.)",
                "type": "Par",
                "name": "rgba2"
            },
            {
                "text": "If the current Image Layout results in more pixels than there are available samples in the input CHOP, the values specified here will be used to fill in the extra pixels. (All textures require full rows of pixels, in other words all rows of pixels have the same number of pixels.)",
                "type": "Par",
                "name": "rgba3"
            },
            {
                "text": "If the current Image Layout results in more pixels than there are available samples in the input CHOP, the values specified here will be used to fill in the extra pixels. (All textures require full rows of pixels, in other words all rows of pixels have the same number of pixels.)",
                "type": "Par",
                "name": "rgba4"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "choptoTOP_Class",
        "short": "The CHOP to TOP puts CHOP channels into a TOP image.",
        "opFilter": "False",
        "opLabel": "CHOP to",
        "opFamily": "TOP",
        "long": "The CHOP to TOP puts CHOP channels into a TOP image. By default the texture created will be 32-bit floating point to match the precision of the CHOP data. This can be changed setting the TOP's Pixel Format to something other than 'Input'.\n    \nThe Data Format parameter determines how the input channels are converted into pixel colors in the output image. For example, when the Data Format is set to 'R', each channel will be interpreted as a row of red pixel data. Likewise, if the Data Format is RGBA, then the first 4 channels will become a set of red, blue, green and alpha data for one row of pixels and each subsequent set of 4 channels will become additional rows. ''Note:'' Channels are grouped by their order in the CHOP rather than their names i.e. just because a channel is named g0 or b1 does not mean it will necessarily be be placed in a blue or green pixel.\n\nThe Image Layout parameter controls how the pixel rows are arranged in the output image. By default, the width of the image will be equal to the number of samples in the CHOP, clamped to a maximum texture width (often 32768) (the sample rate is ignored), and the height will be equal to the number of channel sets. For example, when the Data Format is RGB and the there are 9 input channels (for example, r0 g0 b0 r1 g1 b1 r2 g2 b2), there will be 3 rows of pixels using the default image layout.\n\nIf the channel length is longer than the image width, the wrapped layout option can be used to continue the channel data onto additional rows of pixels. Each new set of channels will still begin on a new row of pixels. \n\nIf the Image Layout parameter is set to Fit to Square, the TOP determines the image resolution based on the total number of samples across all channel sets (approximately the square root of the number of samples + 1) in width and height. This layout is most often used for point cloud data, where an efficient layout is preferred and the position of a pixel is not generally important. Unlike in the wrapped layout, channel sets in this mode are appended immediately to the end of the previous set, so that any empty pixels will appear at the end of the image.  Where there are some unused pixels, you can fill the unused pixels at the top with a special value based on the Extra Pixel Values parameter, (0, 0, 0, 0) by default. To put (0, 0, 0, -1) you have to set the pixel format to 32-bit float so you can represent negative and positive numbers of any value.",
        "opType": "chopto",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "chromakeyTOP": {
        "label": "chromakeyTOP",
        "members": [
            {
                "text": "Menu : Determines the output of the RGB channels from the Chroma Key TOP.",
                "type": "Par",
                "name": "rgbout"
            },
            {
                "text": "Menu : Determines the output of the Alpha channel from the Chroma Key TOP.",
                "type": "Par",
                "name": "alphaout"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "chromakeyTOP_Class",
        "short": "The Chroma Key TOP pulls a key matte from the image using Hue, Saturation, and Value settings.",
        "opFilter": "True",
        "opLabel": "Chroma Key",
        "opFamily": "TOP",
        "long": "The Chroma Key TOP pulls a key matte from the image using Hue, Saturation, and Value settings. If a pixel falls between the Min and Max parameters for all three settings, then it is included in the key. It outputs an alpha map, or the image with the key color removed.\t\t\n\t\t\t\nSee also the <code>chromaKey</code> component in the [[Palette]], which is a user interface around the Chroma Key TOP that lets you grab frames on-the-fly and interactively set the key color ranges. The UI also adds edge softening and color spill controls.",
        "opType": "chroma",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "circleTOP": {
        "label": "circleTOP",
        "members": [
            {
                "text": "X and Y radii of the Circle. For polygons, only the X radius is used.",
                "type": "Par",
                "name": "radiusx"
            },
            {
                "text": "X and Y radii of the Circle. For polygons, only the X radius is used.",
                "type": "Par",
                "name": "radiusy"
            },
            {
                "text": "Coordinates of the center of the shape. (0,0) corresponds to a perfectly centered shape.",
                "type": "Par",
                "name": "centerx"
            },
            {
                "text": "Coordinates of the center of the shape. (0,0) corresponds to a perfectly centered shape.",
                "type": "Par",
                "name": "centery"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the circle.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the circle.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Color to use for the fill of the shape.",
                "type": "Par",
                "name": "fillcolorr"
            },
            {
                "text": "Color to use for the fill of the shape.",
                "type": "Par",
                "name": "fillcolorg"
            },
            {
                "text": "Color to use for the fill of the shape.",
                "type": "Par",
                "name": "fillcolorb"
            },
            {
                "text": "Color to use for the border of the shape.",
                "type": "Par",
                "name": "borderr"
            },
            {
                "text": "Color to use for the border of the shape.",
                "type": "Par",
                "name": "borderg"
            },
            {
                "text": "Color to use for the border of the shape.",
                "type": "Par",
                "name": "borderb"
            },
            {
                "text": "Color to use for the background.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Color to use for the background.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Color to use for the background.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Float : Specifies the angles at which the shape is to start and end. The region between <code>beginarcangle</code> and <code>endarcangle</code>, with clockwise rotation, will not be drawn.",
                "type": "Par",
                "name": "arcangle"
            },
            {
                "text": "Menu : Choose which composite operation is performed from this menu. Search the web for 'blend modes' for more detailed information on the effects of each type.",
                "type": "Par",
                "name": "operand"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "circleTOP_Class",
        "short": "The Circle TOP can be used to generate circles, ellipses and N-sided polygons.",
        "opFilter": "False",
        "opLabel": "Circle",
        "opFamily": "TOP",
        "long": "The Circle TOP can be used to generate circles, ellipses and N-sided polygons.\t\t\n\t\t\t\nThe shapes can be customized with different sizes, rotation and positioning. An optional border can be added to the shape. Background, border and fill colors can all be set independently. Anti-aliasing can be turned on or off.\t\t\t\n\t\t\t\nYou can use the arc angles to cut out part of the shape. In the case of polygons, the number of visible sides will be preserved no matter how much is cut out.",
        "opType": "circle",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "compositeTOP": {
        "label": "compositeTOP",
        "members": [
            {
                "text": "Menu : Choose which composite operation is performed from this menu. Search the web for 'blend modes' for more detailed information on the effects of each type.",
                "type": "Par",
                "name": "operand"
            },
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]]",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "Translates the Overlay layers cumulatively, that is the first Overlay layer is translated by the amount specified, the second Overlay layer is translated by 2 times that amount, the third Overlay layer by 3 times that amount and so on.",
                "type": "Par",
                "name": "tstepx"
            },
            {
                "text": "Translates the Overlay layers cumulatively, that is the first Overlay layer is translated by the amount specified, the second Overlay layer is translated by 2 times that amount, the third Overlay layer by 3 times that amount and so on.",
                "type": "Par",
                "name": "tstepy"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "compositeTOP_Class",
        "short": "The Composite TOP is a multi-input TOP that will perform a composite operation for each input.",
        "opFilter": "True",
        "opLabel": "Composite",
        "opFamily": "TOP",
        "long": "The Composite TOP is a multi-input TOP that will perform a composite operation for each input. Select the composite operation using the Operation parameter on the Composite parameter page.\t\t\n\t\t\t\n'''Note:''' See also the [[Palette:blendModes|blendModes component]] in the Palette. Refer also to [[OP Snippets]].",
        "opType": "comp",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "constantTOP": {
        "label": "constantTOP",
        "members": [
            {
                "text": "Sets the red, green and blue color channels. Clicking on the color swatch opens a color picker with RGB and HSV (Hue, Sat, and Value) pickers.",
                "type": "Par",
                "name": "colorr"
            },
            {
                "text": "Sets the red, green and blue color channels. Clicking on the color swatch opens a color picker with RGB and HSV (Hue, Sat, and Value) pickers.",
                "type": "Par",
                "name": "colorg"
            },
            {
                "text": "Sets the red, green and blue color channels. Clicking on the color swatch opens a color picker with RGB and HSV (Hue, Sat, and Value) pickers.",
                "type": "Par",
                "name": "colorb"
            },
            {
                "text": "Menu : Specify the color values using different ranges. Note that this is only for purposes of setting the color, the data values in the TOP always use the RGBA Unit range 0-1.",
                "type": "Par",
                "name": "rgbaunit"
            },
            {
                "text": "Menu : Choose which composite operation is performed from this menu. Search the web for 'blend modes' for more detailed information on the effects of each type.",
                "type": "Par",
                "name": "operand"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "constantTOP_Class",
        "short": "The Constant TOP sets the red, green, blue, and alpha (r, g, b, and a) channels individually.",
        "opFilter": "False",
        "opLabel": "Constant",
        "opFamily": "TOP",
        "long": "The Constant TOP sets the red, green, blue, and alpha (r, g, b, and a) channels individually. It is commonly used to create a solid color TOP image.",
        "opType": "constant",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "convolveTOP": {
        "label": "convolveTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "convolveTOP_Class",
        "short": "The Convolve TOP uses a DAT table containing numeric coefficients.",
        "opFilter": "True",
        "opLabel": "Convolve",
        "opFamily": "TOP",
        "long": "The Convolve TOP uses a DAT table containing numeric coefficients. For each pixel, it combines its RGBA values and it's neighboring pixels' RGBA values by multiplying the values by the corresponding coefficients in the table, adding the results together. For example, if the table is 5 rows and 5 columns, the pixel and its 24 neighbors are combined.\t\n\t\t\nExample coefficient for 3x3 blur, edge, emboss, sharpen and vertical slope kernels. Be sure to turn on 'Normalize Coefficients' to use these coefficients as -is:\n\n[[image:ConvolveTOP.1.jpg]]",
        "opType": "convolve",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "cornerpinTOP": {
        "label": "cornerpinTOP",
        "members": [
            {
                "text": "The x and y position of the bottom left corner of the extraction.",
                "type": "Par",
                "name": "extractp31"
            },
            {
                "text": "The x and y position of the bottom left corner of the extraction.",
                "type": "Par",
                "name": "extractp32"
            },
            {
                "text": "The x and y position of the bottom right corner of the extraction.",
                "type": "Par",
                "name": "extractp41"
            },
            {
                "text": "The x and y position of the bottom right corner of the extraction.",
                "type": "Par",
                "name": "extractp42"
            },
            {
                "text": "The x and y position of the top left corner of the extraction.",
                "type": "Par",
                "name": "extractp11"
            },
            {
                "text": "The x and y position of the top left corner of the extraction.",
                "type": "Par",
                "name": "extractp12"
            },
            {
                "text": "The x and y position of the top right corner of the extraction.",
                "type": "Par",
                "name": "extractp21"
            },
            {
                "text": "The x and y position of the top right corner of the extraction.",
                "type": "Par",
                "name": "extractp22"
            },
            {
                "text": "Menu : Determines how the image is handled at its edges.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "The x and y position of the bottom left corner of the extraction.",
                "type": "Par",
                "name": "pinp31"
            },
            {
                "text": "The x and y position of the bottom left corner of the extraction.",
                "type": "Par",
                "name": "pinp32"
            },
            {
                "text": "The x and y position of the bottom right corner of the extraction.",
                "type": "Par",
                "name": "pinp41"
            },
            {
                "text": "The x and y position of the bottom right corner of the extraction.",
                "type": "Par",
                "name": "pinp42"
            },
            {
                "text": "The x and y position of the top left corner of the extraction.",
                "type": "Par",
                "name": "pinp11"
            },
            {
                "text": "The x and y position of the top left corner of the extraction.",
                "type": "Par",
                "name": "pinp12"
            },
            {
                "text": "The x and y position of the top right corner of the extraction.",
                "type": "Par",
                "name": "pinp21"
            },
            {
                "text": "The x and y position of the top right corner of the extraction.",
                "type": "Par",
                "name": "pinp22"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the corners of the Corner Pin have been positioned inside the original image space. Set the <span class=\"tipTextTOP\">Bottom Left</span> x-position to 1.0 and you will see the background color in the bottom left corner of the image.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the corners of the Corner Pin have been positioned inside the original image space. Set the <span class=\"tipTextTOP\">Bottom Left</span> x-position to 1.0 and you will see the background color in the bottom left corner of the image.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the corners of the Corner Pin have been positioned inside the original image space. Set the <span class=\"tipTextTOP\">Bottom Left</span> x-position to 1.0 and you will see the background color in the bottom left corner of the image.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the corners of the Corner Pin have been positioned inside the original image space. Set the <span class=\"tipTextTOP\">Bottom Left</span> x-position to 1.0 and you will see the background color in the bottom left corner of the image.",
                "type": "Par",
                "name": "bgcolora"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "cornerpinTOP_Class",
        "short": "The Corner Pin TOP can perform two operations.",
        "opFilter": "True",
        "opLabel": "Corner Pin",
        "opFamily": "TOP",
        "long": "The Corner Pin TOP can perform two operations. The Extract page lets you specify a sub-section of the image to use by moving 4 points. The Corner Pin page let you move the corner points of the extracted image to any location.\n \nSee also [[Projection Mapping]].",
        "opType": "corner",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "cplusplusTOP": {
        "label": "cplusplusTOP",
        "members": [
            {
                "text": "Menu : The level of anti-aliasing you want the framebuffer that will be created for you to have.",
                "type": "Par",
                "name": "antialias"
            },
            {
                "text": "Menu : Specifies the pixel format of the depth buffer you want, if any.",
                "type": "Par",
                "name": "depthbuffer"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "cplusplusTOP_Class",
        "short": "The CPlusPlus TOP allows you to make custom TOP operators by writing your own plugin using C++.",
        "opFilter": "False",
        "opLabel": "CPlusPlus",
        "opFamily": "TOP",
        "long": "The CPlusPlus TOP allows you to make custom TOP operators by writing your own plugin using C++.\t\t\n\t\t\t\nSee [[Write a CPlusPlus Plugin]] and the other articles in the [[:Category:C++ | C++ Category]] for more detailed information on how to make plugins for use with this node and how to access example projects.\t\t\t\n\t\t\t\nSee also: [[CPlusPlus CHOP]], [[CUDA]]",
        "opType": "cplusplus",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "cropTOP": {
        "label": "cropTOP",
        "members": [
            {
                "text": "Menu : This parameter determines what happens at the edges of the tiles.",
                "type": "Par",
                "name": "extend"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "cropTOP_Class",
        "short": "The Crop TOP crops an image by defining the position of the left, right, bottom, and top edges of the image.",
        "opFilter": "True",
        "opLabel": "Crop",
        "opFamily": "TOP",
        "long": "The Crop TOP crops an image by defining the position of the left, right, bottom, and top edges of the image. The cropped part of the image is discarded, thus reducing the resolution of the image.",
        "opType": "crop",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "crossTOP": {
        "label": "crossTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]]",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "crossTOP_Class",
        "short": "The Cross TOP blends between the two input images based on the value of the Cross parameter (refered to as ''Cross_value'' below).",
        "opFilter": "True",
        "opLabel": "Cross",
        "opFamily": "TOP",
        "long": "The Cross TOP blends between the two input images based on the value of the Cross parameter (refered to as ''Cross_value'' below).\t\t\n\t\t\t\n<code>Output = Input1*(1-''Cross_value'') + Input2*(''Cross_value'')</code>",
        "opType": "cross",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "cubemapTOP": {
        "label": "cubemapTOP",
        "members": [
            {
                "text": "Menu : Determine how the cube map is created from the input images.",
                "type": "Par",
                "name": "mode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Cube Map TOP builds a texture map in the [[Cube Map]] internal texture format. It accepts a vertical cross image, or 1 input per side of the cube. The [[Phong MAT]] can use the cube maps from the Cube Map TOP for reflections. The [[Render TOP]] can also create cube maps. You can sample a cube map in a GLSL shader by declaring them like this\t\t\n<syntaxhighlight lang=glsl>uniform samplerCube <name>;</syntaxhighlight>\t\t\t\nand sampling them using this in GLSL 3.30+\t\t\t\n<syntaxhighlight lang=glsl>texture(samplerCube name, vec3 texcoords)</syntaxhighlight>\t\t\t\n\t\t\t\nor this in GLSL 1.20\t\t\t\n<syntaxhighlight lang=glsl>textureCube(samplerCube name, vec3 texcoords)</syntaxhighlight>",
        "opLabel": "Cube Map",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "short": "The Cube Map TOP builds a texture map in the [[Cube Map]] internal texture format.",
        "opType": "cubemap",
        "opFilter": "True",
        "opClass": "cubemapTOP_Class",
        "opCategories": ""
    },
    "depthTOP": {
        "label": "depthTOP",
        "members": [
            {
                "text": "Menu : The pixel format the Depth texture should be output as.",
                "type": "Par",
                "name": "pixelformat"
            },
            {
                "text": "Menu : The space the depth values should be output in.",
                "type": "Par",
                "name": "depthspace"
            },
            {
                "text": "The range to convert from when using 'Rerange from Camera Space'. This would often be your area of interest in the camera's depth.",
                "type": "Par",
                "name": "rangefrom1"
            },
            {
                "text": "The range to convert from when using 'Rerange from Camera Space'. This would often be your area of interest in the camera's depth.",
                "type": "Par",
                "name": "rangefrom2"
            },
            {
                "text": "The range of values you want to convert the depth values to. This is the range you would find the depth to more useful for processing, often 0-1.",
                "type": "Par",
                "name": "rangeto1"
            },
            {
                "text": "The range of values you want to convert the depth values to. This is the range you would find the depth to more useful for processing, often 0-1.",
                "type": "Par",
                "name": "rangeto2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "depthTOP_Class",
        "short": "The Depth TOP reads an image containing depth information from a scene described in a specified [[Render TOP]]. The resulting image is black (0) at pixels where the surface is at the near depth value (Camera's parameter \"Near\"). It is white (1) at pixels where the surface is at the far depth value (parameter \"Far\").",
        "opFilter": "False",
        "opLabel": "Depth",
        "opFamily": "TOP",
        "long": "The Depth TOP reads an image containing depth information from a scene described in a specified [[Render TOP]]. The resulting image is black (0) at pixels where the surface is at the near depth value (Camera's parameter \"Near\"). It is white (1) at pixels where the surface is at the far depth value (parameter \"Far\"). \t\t\n\t\t\t\nThe Depth TOP is used to do shadow mapping. It can have many other uses also, such as edge detection based on depth. \t\t\t\n\t\t\t\nThe depth range is by definition the near plane -> far plane. Values in the Depth TOP will be 0 at the near plane, and 1 at the far plane. Generally the image in the Depth TOP will be white, unless you have your planes really tight around your object. But just because you can't visually see anything, it doesn't mean the information isn't there. \t\t\t\n\t\t\t\nAnother option is Linear Camera-Space Depth. If the Render TOP's Depth Buffer Format is set to 32-Bit Floating-Point and its Linear Camera-Space Depth parameter is on, then the Depth TOP will output linear camera space depth.\t\t\t\n\t\t\t\nYou can use the [[Level TOP]] to re-range the Depth TOP's values. However make sure you set the Pixel Format of the Level TOP to 16 or 32-bit, or you'll lose a lot of information from the Depth TOP's data (The Depth TOP has 24-bit data).\t\t\t\n\t\t\t\nThe Depth TOP creates a 24-bit fixed-point or 32-bit floating-point single channel image. When the Depth TOP is used as an input to another TOP, its data will be treated like an RGBA value of (D, D, D, 1). The same is true when sampling a depth texture in a GLSL shader.",
        "opType": "depth",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "differenceTOP": {
        "label": "differenceTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]]",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "differenceTOP_Class",
        "short": "The Difference TOP performs a difference composite on its two input images.",
        "opFilter": "True",
        "opLabel": "Difference",
        "opFamily": "TOP",
        "long": "The Difference TOP performs a difference composite on its two input images.",
        "opType": "diff",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "directxinTOP": {
        "label": "directxinTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "directxinTOP_Class",
        "short": "The DirectX In TOP brings DirectX textures from other applications into TouchDesigner.",
        "opFilter": "False",
        "opLabel": "DirectX In",
        "opFamily": "TOP",
        "long": "The DirectX In TOP brings DirectX textures from other applications into TouchDesigner. This feature is accessed through the DirectX Sharing Resources feature. This supports DirectX 9.0 and higher.\t\n\t\t\nSee also: [[DirectX Out TOP]]",
        "opType": "directxin",
        "opLicense": "Commercial",
        "os": "Microsoft Windows",
        "opCategories": ""
    },
    "directxoutTOP": {
        "label": "directxoutTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "directxoutTOP_Class",
        "opLabel": "DirectX Out",
        "opFamily": "TOP",
        "opLicense": "Commercial",
        "os": "Microsoft Windows",
        "opType": "directxout",
        "opFilter": "True",
        "long": "The DirectX Out TOP creates textures that a DirectX application can access, or any instance of TouchDesigner with a DirectX In TOP. This features is accessed though the DirectX Sharing Resources feature. This supports DirectX 9.0 and higher.\t\n\t\t\nSee also: [[DirectX In TOP]]",
        "short": "The DirectX Out TOP creates textures that a DirectX application can access, or any instance of TouchDesigner with a DirectX In TOP.",
        "opCategories": ""
    },
    "displaceTOP": {
        "label": "displaceTOP",
        "members": [
            {
                "text": "Menu : Instead of using the Red channel to displace horizontally, you can choose a different channel.",
                "type": "Par",
                "name": "horzsource"
            },
            {
                "text": "Menu : Instead of using the Blue channel to displace vertically, you can choose a different channel.",
                "type": "Par",
                "name": "vertsource"
            },
            {
                "text": "This value is the color values that will result in no displacement. Values below this will cause the displacement to come from the left/bottom of the pixel, while values above this will cause the displacement to come from the right/top of the pixel.",
                "type": "Par",
                "name": "midpoint1"
            },
            {
                "text": "This value is the color values that will result in no displacement. Values below this will cause the displacement to come from the left/bottom of the pixel, while values above this will cause the displacement to come from the right/top of the pixel.",
                "type": "Par",
                "name": "midpoint2"
            },
            {
                "text": "This scales the offset caused by the Displace Image. It will cause the pixels fetched to be closer/farther along the sample vector created by the Horizontal and Vertical Source.",
                "type": "Par",
                "name": "displaceweight1"
            },
            {
                "text": "This scales the offset caused by the Displace Image. It will cause the pixels fetched to be closer/farther along the sample vector created by the Horizontal and Vertical Source.",
                "type": "Par",
                "name": "displaceweight2"
            },
            {
                "text": "The Offset is first multiplied by the Offset Weight. Then it will be added to the coordinates caluclated after looking up into the displacement map. These final coordinates is what will be used to sample from the source image.",
                "type": "Par",
                "name": "offsetx"
            },
            {
                "text": "The Offset is first multiplied by the Offset Weight. Then it will be added to the coordinates caluclated after looking up into the displacement map. These final coordinates is what will be used to sample from the source image.",
                "type": "Par",
                "name": "offsety"
            },
            {
                "text": "Menu : This parameter determines what happens at the edges of the tiles.",
                "type": "Par",
                "name": "extend"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "displaceTOP_Class",
        "opLabel": "Displace",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "displace",
        "opFilter": "True",
        "long": "The Displace TOP will cause one image to be warped by another image. A pixel of the output image at (Uo,Vo) gets its RGBA value from a different pixel (Ui, Vi) of the Source Image by using the second input image (the Displace Image). \t\t\n\t\t\t\nFor each pixel in the output image, three factors affect which pixel to fetch from the source:\t\t\t\n* The horizontal and vertical source channels of the Displace Image (Red and Blue by default).\n* the Uo and Vo coordinate of the output pixel.\t\t\t\n* A constant Ua and Va anchor point (Offset).\t\t\t\n\t\t\t\n'''Displace Image''' - In using the Displace Image, for each pixel in the output, it gets the corresponding pixel from the input, and uses the red channel and blue channel as its U and V displacement. If the red and blue are .5, .5, then Uo = Ui and Vo = Vi. That is, there is no warp if the Displace Image is a 50% grey. Also the warp is reduced to 0 if the Displace Weight is 0. Where red < .5 in the Displace Image, it fetches a pixel from the left of Uo in the Source Image. If blue < .5, it fetches a pixel from below Vo in the Source Image. Thus the pixel is retrieved from Ui, Vi at Uo*Scale*(red-.5), Vo*Scale*(.5-blue) of the Source Image.\t\t\t\n\t\t\t\n'''Uo and Vo offset''' - By default, the warping of each output pixel is relative to its Uo, Vo. But when the UV Weight parameter is 0, the displacement is relative to the center pixel of the Source Image.\t\t\t\n\t\t\t\n'''Ua and Va anchor (offset) point''' - This zooms into a pixel of the input if you bring the two other weights down to 0.\t\t\t\n\t\t\t\nFor the Displace Image, you can change which of its RGBA channels cause the warp. \t\t\t\n\t\t\t\nYou can choose if there is wraparound in the image warping. If the computed Uo and Vo is less than 0 or greater than 1, it can wraparound, clamp or mirror.\t\t\t\n\t\t\t\nThe Displace Image can be any photograph followed by a Slope TOP, which will give luminance gradients in red and blue, with the neutral value at .5, exactly the form required by the Displace TOP.\t\t\t\n\t\t\t\nOne way to experiment is to make a Displace Image from Ramp TOPs. Alternately use a Constant TOP set to .5, .5, .5, 1, then subtract a photo using a Subtract TOP, and add another photo image using an Add TOP. Before subtracting and adding the images, you can lower their effect using Level TOPs and adjusting Brightness.\t\t\t\n\t\t\t\nSee also: [[Remap TOP]], [[Lookup TOP]]",
        "short": "The Displace TOP will cause one image to be warped by another image.",
        "opCategories": ""
    },
    "edgeTOP": {
        "label": "edgeTOP",
        "members": [
            {
                "text": "Menu : This menu determines how the edges are pulled from the image.",
                "type": "Par",
                "name": "select"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to find edges. A <span class=\"tipTextTOP\">Sample Step</span> of 3 would sample pixels 3 pixels away to look for edges.",
                "type": "Par",
                "name": "offset1"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to find edges. A <span class=\"tipTextTOP\">Sample Step</span> of 3 would sample pixels 3 pixels away to look for edges.",
                "type": "Par",
                "name": "offset2"
            },
            {
                "text": "The color of the edges in RGBA.",
                "type": "Par",
                "name": "edgecolorr"
            },
            {
                "text": "The color of the edges in RGBA.",
                "type": "Par",
                "name": "edgecolorg"
            },
            {
                "text": "The color of the edges in RGBA.",
                "type": "Par",
                "name": "edgecolorb"
            },
            {
                "text": "The color of the edges in RGBA.",
                "type": "Par",
                "name": "edgecolora"
            },
            {
                "text": "Menu : This menu determines how the alpha channel is output from the Edge TOP.",
                "type": "Par",
                "name": "alphaoutputmenu"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "edgeTOP_Class",
        "opLabel": "Edge",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "edge",
        "opFilter": "True",
        "long": "The Edge TOP finds edges in an image and highlights them. For each pixel, it looks at the values at neighboring pixels, and where differences are greater than a threshold, the output's value is higher.\t\t\n\t\t\t\nSee also the [[Convolve TOP]].",
        "short": "The Edge TOP finds edges in an image and highlights them.",
        "opCategories": ""
    },
    "embossTOP": {
        "label": "embossTOP",
        "members": [
            {
                "text": "Menu : This menu selects how the edges in the image are found. The edges will appear raised or depressed in the output image depending on their slope.",
                "type": "Par",
                "name": "select"
            },
            {
                "text": "Menu : Determines what pixels to use when calculating the slope at each pixel in the image.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to find edges. A <span class=\"tipTextTOP\">Sample Step</span> of 3 would sample pixels 3 pixels away to look for edges.",
                "type": "Par",
                "name": "offset1"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to find edges. A <span class=\"tipTextTOP\">Sample Step</span> of 3 would sample pixels 3 pixels away to look for edges.",
                "type": "Par",
                "name": "offset2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "embossTOP_Class",
        "opLabel": "Emboss",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "emboss",
        "opFilter": "True",
        "long": "The Emboss TOP creates the effect that an image is embossed in a thin sheet of metal. Edges in the image will appear raised.",
        "short": "The Emboss TOP creates the effect that an image is embossed in a thin sheet of metal.",
        "opCategories": ""
    },
    "feedbackTOP": {
        "label": "feedbackTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "feedbackTOP_Class",
        "opLabel": "Feedback",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "feedback",
        "opFilter": "True",
        "long": "The Feedback TOP can be used to create feedback effects in TOPs. It can give fake motion blur by not clearing the color buffer. The Feedback TOP's input image will be passed through whenever Feedback is bypassed (by setting the <span class=\"tipTextTOP\">Bypass Feedback</span> parameter = 1). When feedback is activated (<span class=\"tipTextTOP\">Bypass Feedback</span> parameter = 0) the Feedback TOP will output an image stream sourced from its Target TOP. By selecting a Target TOP downstream in the feedback network, other filter TOPs can be added in between the Feedback TOP and its Target TOP to achive feedback effects. See the example networks below.\t\n\t\t\nSee [[OP Snippets]] for some examples on how to use the Feedback TOP.",
        "short": "The Feedback TOP can be used to create feedback effects in TOPs.",
        "opCategories": ""
    },
    "fitTOP": {
        "label": "fitTOP",
        "members": [
            {
                "text": "Menu : Determines how the input is fit to the specified resolution.",
                "type": "Par",
                "name": "fit"
            },
            {
                "text": "Menu : The menu attached to this parameter allows you to specify the order in which the changes to your TOP will take place. Changing the Transform order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "The two fields for Translate and Scale allows you to specify transforms in x and y axes. The field for Rotate allow you to specify the amount of rotation.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "The two fields for Translate and Scale allows you to specify transforms in x and y axes. The field for Rotate allow you to specify the amount of rotation.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "The two fields for Scale allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "The two fields for Scale allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "The Pivot point edit fields allow you to define the point about which the TOP scales and rotates. Altering the pivot point of a TOP produces different results depending on the transformation performed on the TOP image.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of a TOP image is located at <code>-1,-1</code> and you wanted to scale the image by <code>0.5</code> (reduce its size by 50%), then the TOP would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "The Pivot point edit fields allow you to define the point about which the TOP scales and rotates. Altering the pivot point of a TOP produces different results depending on the transformation performed on the TOP image.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of a TOP image is located at <code>-1,-1</code> and you wanted to scale the image by <code>0.5</code> (reduce its size by 50%), then the TOP would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the image is translated or scaled down. Try scaling an image down 50% in size (Scale = 0.5,0.5) and setting the background color.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the image is translated or scaled down. Try scaling an image down 50% in size (Scale = 0.5,0.5) and setting the background color.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the image is translated or scaled down. Try scaling an image down 50% in size (Scale = 0.5,0.5) and setting the background color.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the image is translated or scaled down. Try scaling an image down 50% in size (Scale = 0.5,0.5) and setting the background color.",
                "type": "Par",
                "name": "bgcolora"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "fitTOP_Class",
        "opLabel": "Fit",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "fit",
        "opFilter": "True",
        "long": "The Fit TOP re-sizes its input to the resolution set on the Common Page using the method specified in the Fit parameter menu. This is useful for changing the aspect ratio of an image without distorting it horizontally or vertically. It will crop the image or fill with the background color depending on the Fit parameter options.",
        "short": "The Fit TOP re-sizes its input to the resolution set on the Common Page using the method specified in the Fit parameter menu.",
        "opCategories": ""
    },
    "flipTOP": {
        "label": "flipTOP",
        "members": [
            {
                "text": "Menu : Flops the image. Flop is a combination of a flip and a rotation. The X resolution becomes the Y resolution. The Y becomes the X.\t\n\t\t\t\n* No Flop - No flop performed.\t\t\t\n* Bottom Left - The image is flipped in X and then rotated 90 degrees clockwise.\t\t\t\n* Top Left - The image is flipped in X and then rotated 90 degrees counter-clockwise.",
                "type": "Par",
                "name": "flop"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "flipTOP_Class",
        "opLabel": "Flip",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "flip",
        "opFilter": "True",
        "long": "The Flip TOP will Flip an image in X and/or Y. It also offers a Flop option to turn each row of pixels into a column.",
        "short": "The Flip TOP will Flip an image in X and/or Y.",
        "opCategories": ""
    },
    "functionTOP": {
        "label": "functionTOP",
        "members": [
            {
                "text": "Applies a scale and shift to the input values before the function is calculated i.e. input = (input * rerange2) + rerange1. '''Note:''' This feature only affects integer texture formats and is not used on floating point formats.",
                "type": "Par",
                "name": "rerange1"
            },
            {
                "text": "Applies a scale and shift to the input values before the function is calculated i.e. input = (input * rerange2) + rerange1. '''Note:''' This feature only affects integer texture formats and is not used on floating point formats.",
                "type": "Par",
                "name": "rerange2"
            },
            {
                "text": "Menu : Applies the selected function to the R, G, B, and A channels.",
                "type": "Par",
                "name": "funcrgba"
            },
            {
                "text": "Menu : Applies the selected function to the R, G, and B channels.",
                "type": "Par",
                "name": "funcrgb"
            },
            {
                "text": "Menu : Applies the selected function to the R (red) channel.",
                "type": "Par",
                "name": "funcr"
            },
            {
                "text": "Menu : Applies the selected function to the G (green) channel.",
                "type": "Par",
                "name": "funcg"
            },
            {
                "text": "Menu : Applies the selected function to the B (blue) channel.",
                "type": "Par",
                "name": "funcb"
            },
            {
                "text": "Menu : Applies the selected function to the A (alpha) channel.",
                "type": "Par",
                "name": "funca"
            },
            {
                "text": "Menu : Determines whether the input values are measured in degrees, radians, etc for functions that require an angle input e.g. sine, cosine, etc.",
                "type": "Par",
                "name": "angunit"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "functionTOP",
        "opLabel": "Function",
        "opClass": "functionTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Function TOP can perform mathematical operations like sin, cos, or exp on the color values of the input image.",
        "long": "The Function TOP can perform mathematical operations like sin, cos, or exp on the color values of the input image. Different functions can be performed on each color channel. Some functions will take an additional value from the Base, Exponent or Constant Value parameters, and some functions take an additional input value from the second input image.\n    \nFor some functions, you can use the 'Replace Errors' parameter to insert a new value for values that would otherwise be undefined e.g. log(-1)\n    \n===== Supported functions: =====\n* ''Input'' - Pass along the input value unchanged\n* ''Constant'' - Replace the input with the value of the 'Constant' parameter.\n* ''Square Root'' - Find the square root of the input value i.e. sqrt(x).\n* ''Absolute Value'' - Get the absolute value of the input i.e. abs(x).\n* ''Sign'' - Returns -1 if the input value is below 0, 0 if it equals 0, and 1 if it's greater than zero.\n* ''Cosine'' - Returns the cosine of the input. <sup>1</sup>\n* ''Sine'' - Returns the sine of the input. <sup>1</sup>\n* ''Tangent'' - Returns the tangent of the input. <sup>1</sup>\n* ''Arccosine'' - Returns the arccosine of the input i.e. acos(x). <sup>1</sup>\n* ''Arcsine'' - Returns the sine of the input i.e. asin(x). <sup>1</sup>\n* ''Arctan (Input1)'' - Returns the arctangent of the input i.e. atan(x). <sup>1</sup>\n* ''Arctan (Input1 / Input2)'' - Returns the arctangent of input1 over input2 i.e. atan(x,y). <sup>1</sup>\n* ''Hyperbolic Cosine'' - Returns the hyperbolic cosine of the input i.e. cosh(x). <sup>1</sup>\n* ''Hyperbolic Sine'' - Returns the sine of the input i.e. sinh(x). <sup>1</sup>\n* ''Hyperbolic Tangent'' - Returns the tangent of the input i.e. tanh(x). <sup>1</sup>\n* ''Log Base 10'' - Returns the base 10 logarithm of the input i.e. log10(x).\n* ''Log Base 2'' - Returns the base 2 logarithm of the input i.e. log2(x).\n* ''Log Base N'' - Returns the base N logarithm of the input, where N is set by the 'Base Value' parameter.\n* ''Natural Log'' - Returns the natural log of the input i.e. ln(x).\n* ''Exponent'' - Returns e to the power of the input i.e. e^x.\n* ''Exponent 2'' - Returns 2 to the power of the input i.e. 2^x.\n* ''Exponent 10'' - Returns 10 to the power of the input i.e. 10^x.\n* ''Base Power'' - Returns the 'Base Value' parameter to the power of x. <sup>2</sup>\n* ''Input1 ^ Exponent'' - Returns the input value to the power of the exponent parameter. <sup>2</sup>\n* ''Input1 ^ Input2'' - Returns the value of input 1 to the power of input 2. <sup>2</sup>\n* ''dB to Power'' - Converts decibels to power.\n* ''Power to dB'' - Converts power to decibels. The result will be an error if the value is less than or equal to zero.\n* ''dB to Amplitude'' - Converts decibels to amplitude.\n* ''Amplitude to dB'' - Converts amplitude to decibels. The result will be an error if the value is less than or equal to zero.\n\n<sup>1</sup> The unit of the input for this function is determined by the 'Angle Units' parameter e.g. degrees, radians, etc.\n\n<sup>2</sup> Using a negative exponent i.e. pow(x, -2) will produce an error value since negative exponents are undefined according to the GLSL specifications.",
        "opCategories": ""
    },
    "glslmultiTOP": {
        "label": "glslmultiTOP",
        "members": [
            {
                "text": "Menu : Pick what version of GLSL to compile the shader with.",
                "type": "Par",
                "name": "glslversion"
            },
            {
                "text": "Menu : Choose what type of shader you are writing, vertex/pixel shader, or a compute shader.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "The dispatch size to use when executing a compute shader.",
                "type": "Par",
                "name": "dispatchsizex"
            },
            {
                "text": "The dispatch size to use when executing a compute shader.",
                "type": "Par",
                "name": "dispatchsizey"
            },
            {
                "text": "The dispatch size to use when executing a compute shader.",
                "type": "Par",
                "name": "dispatchsizez"
            },
            {
                "text": "Menu : Controls how the output textures will be accessed. If the textures will be read from (such as using previous frame's values), then the access should be changed to Read-Write instead of Write Only.",
                "type": "Par",
                "name": "outputaccess"
            },
            {
                "text": "Menu : Specify what type of texture to create. When creating  a 3D texture the TOP will render once for every slice of the output. Refer to [[Write a GLSL TOP#3D Textures and 2D Texture Arrays | 3D Textures and 2D Texture Arrays]] for more info.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : Set the depth of the 3D texture from the '''Input''' or the '''Custom Depth''' parameter.",
                "type": "Par",
                "name": "depth"
            },
            {
                "text": "",
                "type": "Par",
                "name": "clearvaluer"
            },
            {
                "text": "",
                "type": "Par",
                "name": "clearvalueg"
            },
            {
                "text": "",
                "type": "Par",
                "name": "clearvalueb"
            },
            {
                "text": "",
                "type": "Par",
                "name": "clearvaluea"
            },
            {
                "text": "Menu : Determines how the node's input(s) are passed into the shader for use when creating a 3D Texture. By default all of the inputs are passed to each slice. When using the '''N inputs per Slice''' mode, the first N inputs are passed to the first slice, the next N inputs are passed the second slice, and so on. When it runs out of inputs it loops back to the first input. N is selected by the parameter '''N Value'''.",
                "type": "Par",
                "name": "inputmapping"
            },
            {
                "text": "Menu : Controls what is returned from your texture sampling functions when the U and V texture coordinates (called S and T in the shader) are outside [0-1] range.",
                "type": "Par",
                "name": "inputextenduv"
            },
            {
                "text": "Menu : Controls what is returned from your texture sampling functions when the W texture coordinate (called W in the shader) are outside [0-1] range. Only useful for [[3D Texture]].",
                "type": "Par",
                "name": "inputextendw"
            },
            {
                "text": "The value(s) to give the uniform.",
                "type": "Par",
                "name": "value0x"
            },
            {
                "text": "The value(s) to give the uniform.",
                "type": "Par",
                "name": "value0y"
            },
            {
                "text": "The value(s) to give the uniform.",
                "type": "Par",
                "name": "value0z"
            },
            {
                "text": "The value(s) to give the uniform.",
                "type": "Par",
                "name": "value0w"
            },
            {
                "text": "Menu : The data type of the uniform in the shader.",
                "type": "Par",
                "name": "chopunitype0"
            },
            {
                "text": "Menu : The type of the uniform.",
                "type": "Par",
                "name": "choparraytype0"
            },
            {
                "text": "Menu : Specifies how the atomic counters receive their initial value, either through a single default value or a CHOP.",
                "type": "Par",
                "name": "acinitval0"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "glslmultiTOP_Class",
        "opLabel": "GLSL Multi",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "glslmulti",
        "opFilter": "True",
        "long": "The GLSL Multi TOP renders a GLSL shader into a TOP image. Its parameters and functionality are identical to the [[GLSL TOP]], except it allows for more than 3 inputs.<br>Refer to the [[GLSL TOP]] help page for more information.",
        "short": "The GLSL Multi TOP renders a GLSL shader into a TOP image.",
        "opCategories": ""
    },
    "glslTOP": {
        "label": "glslTOP",
        "members": [
            {
                "text": "Menu : Pick what version of GLSL to compile the shader with.",
                "type": "Par",
                "name": "glslversion"
            },
            {
                "text": "Menu : Choose what type of shader you are writing, vertex/pixel shader, or a compute shader.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "The dispatch size to use when executing a compute shader.",
                "type": "Par",
                "name": "dispatchsizex"
            },
            {
                "text": "The dispatch size to use when executing a compute shader.",
                "type": "Par",
                "name": "dispatchsizey"
            },
            {
                "text": "The dispatch size to use when executing a compute shader.",
                "type": "Par",
                "name": "dispatchsizez"
            },
            {
                "text": "Menu : Controls how the output textures will be accessed. If the textures will be read from (such as using previous frame's values), then the access should be changed to Read-Write instead of Write Only.",
                "type": "Par",
                "name": "outputaccess"
            },
            {
                "text": "Menu : Specify what type of texture to create. When creating  a 3D texture the TOP will render once for every slice of the output. Refer to [[Write a GLSL TOP#3D Textures and 2D Texture Arrays | 3D Textures and 2D Texture Arrays]] for more info.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : Set the depth of the 3D texture from the '''Input''' or the '''Custom Depth''' parameter.",
                "type": "Par",
                "name": "depth"
            },
            {
                "text": "The color value to clear all pixels to at the start of the cook.",
                "type": "Par",
                "name": "clearvaluer"
            },
            {
                "text": "The color value to clear all pixels to at the start of the cook.",
                "type": "Par",
                "name": "clearvalueg"
            },
            {
                "text": "The color value to clear all pixels to at the start of the cook.",
                "type": "Par",
                "name": "clearvalueb"
            },
            {
                "text": "The color value to clear all pixels to at the start of the cook.",
                "type": "Par",
                "name": "clearvaluea"
            },
            {
                "text": "Menu : Determines how the node's input(s) are passed into the shader for use when creating a 3D Texture. By default all of the inputs are passed to each slice. When using the '''N inputs per Slice''' mode, the first N inputs are passed to the first slice, the next N inputs are passed the second slice, and so on. When it runs out of inputs it loops back to the first input. N is selected by the parameter '''N Value'''.",
                "type": "Par",
                "name": "inputmapping"
            },
            {
                "text": "Menu : Controls what is returned from your texture sampling functions when the U and V texture coordinates (called S and T in the shader) are outside [0-1] range.",
                "type": "Par",
                "name": "inputextenduv"
            },
            {
                "text": "Menu : Controls what is returned from your texture sampling functions when the W texture coordinate (called W in the shader) are outside [0-1] range. Only useful for [[3D Texture]].",
                "type": "Par",
                "name": "inputextendw"
            },
            {
                "text": "The value(s) to give the uniform.",
                "type": "Par",
                "name": "value0x"
            },
            {
                "text": "The value(s) to give the uniform.",
                "type": "Par",
                "name": "value0y"
            },
            {
                "text": "The value(s) to give the uniform.",
                "type": "Par",
                "name": "value0z"
            },
            {
                "text": "The value(s) to give the uniform.",
                "type": "Par",
                "name": "value0w"
            },
            {
                "text": "Menu : The data type of the uniform in the shader.",
                "type": "Par",
                "name": "chopunitype0"
            },
            {
                "text": "Menu : The type of the uniform.",
                "type": "Par",
                "name": "choparraytype0"
            },
            {
                "text": "Menu : Specifies how the atomic counters receive their initial value, either through a single default value or a CHOP.",
                "type": "Par",
                "name": "acinitval0"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "glslTOP_Class",
        "opLabel": "GLSL",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "glsl",
        "opFilter": "True",
        "long": "The GLSL TOP renders a GLSL [[shader]] into a TOP image. Use the Info DAT to check for compile errors in your shaders.\t\t\n\t\t\t\nThe GLSL TOP can act as a pixel shader, or the more general and complex [[Compute Shader]]. Caveat: Compute Shaders need GLSL 4.30 or later.\t\t\t\n\t\t\t\nRefer to the [[Write a GLSL TOP]] article for more info on using this TOP.\t\t\t\n\t\t\t\nThe GLSL TOP has one docked compute shader as well as a normal GLSL shader. Change he Mode to Compute Shader. it will use the <code>glsl1_compute</code> DAT.\t\t\t\n\t\t\t\nSee the [[:Category:GLSL|GLSL Category]] for more information, and [[Compute Shader]].",
        "short": "The GLSL TOP renders a GLSL [[shader]] into a TOP image.",
        "opCategories": ""
    },
    "hsvadjustTOP": {
        "label": "hsvadjustTOP",
        "members": [
            {
                "text": "The start color is the hue that the HSV adjustment is centered around. When adjusting a small hue range, this is the color that will be altered. In the example image above, the Start Color color is cyan with a hue value of 180.",
                "type": "Par",
                "name": "startcolorr"
            },
            {
                "text": "The start color is the hue that the HSV adjustment is centered around. When adjusting a small hue range, this is the color that will be altered. In the example image above, the Start Color color is cyan with a hue value of 180.",
                "type": "Par",
                "name": "startcolorg"
            },
            {
                "text": "The start color is the hue that the HSV adjustment is centered around. When adjusting a small hue range, this is the color that will be altered. In the example image above, the Start Color color is cyan with a hue value of 180.",
                "type": "Par",
                "name": "startcolorb"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The HSV Adjust TOP adjust color values using hue, saturation, and value controls. If you change the Hue Offset, Saturation Multiplier and Value Multiplier without changing any of the other parameters then you will modify the color of all pixels in the image. The other parameters are used to narrow the range of pixels you want to modify based on their hue, saturation and value. For example if you leave the Hue Range untouched but reduce the saturation range, you will cause the TOP to modify only pixels who fall into the new saturation range. The range is the Start Color's saturation + the Range + the Falloff, in this example.",
        "opLabel": "HSV Adjust",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "short": "The HSV Adjust TOP adjust color values using hue, saturation, and value controls.",
        "opType": "hsvadj",
        "opFilter": "True",
        "opClass": "hsvadjustTOP_Class",
        "opCategories": ""
    },
    "hsvtorgbTOP": {
        "label": "hsvtorgbTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "hsvrgb",
        "opLabel": "HSV to RGB",
        "opLicense": "Non-Commercial",
        "opClass": "hsvtorgbTOP_Class",
        "opFilter": "True",
        "short": "",
        "long": "",
        "opCategories": ""
    },
    "importselectTOP": {
        "label": "importselectTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "importselectTOP",
        "opLabel": "Import Select",
        "opClass": "importselectTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Import Select TOP loads the texture map images such as Color Map, Normal Map, Metallic Map and so forth that are defined in [[FBX COMP]] or [[USD COMP]].",
        "long": "The Import Select TOP loads the texture map images such as Color Map, Normal Map, Metallic Map and so forth that are defined in [[FBX COMP]] or [[USD COMP]]. The image binaries can be encoded within the importing file (e.g. </code>.usdz</code> format) or specified as an external asset with an valid path.\n    \nSee also: [[FBX COMP]], [[USD COMP]]",
        "opCategories": ""
    },
    "inTOP": {
        "label": "inTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "inTOP_Class",
        "opLabel": "In",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "in",
        "opFilter": "True",
        "long": "The In TOP is used to create a TOP input in a Component. Component inputs are positioned alphanumerically on the left side of the Component.",
        "short": "The In TOP is used to create a TOP input in a Component.",
        "opCategories": ""
    },
    "insideTOP": {
        "label": "insideTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]].",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "insideTOP_Class",
        "opLabel": "Inside",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "inside",
        "opFilter": "True",
        "long": "The Inside TOP places Input1 'inside' Input2. The alpha of Input2 is used to determine what parts of the Input1 image are visible.",
        "short": "The Inside TOP places Input1 'inside' Input2.",
        "opCategories": ""
    },
    "kinectazureselectTOP": {
        "label": "kinectazureselectTOP",
        "members": [
            {
                "text": "Menu : A list of available image types to capture from the device and display in this TOP. All image types have a second version that is mapped (aligned) to the image space of the other camera so that color and depth image data can be matched. The resolution of the image is controlled by the Color Resolution or Depth Mode parameters of the primary [[Kinect Azure TOP]].",
                "type": "Par",
                "name": "image"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "kinectazureselectTOP",
        "opLabel": "Kinect Azure Select",
        "opClass": "kinectazureselectTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows 10 April 2018 or newer",
        "hardware": "An NVIDIA GEFORCE GTX 1070 or better graphics card is required to obtain efficient body tracking data from the camera, although a CPU-only mode can be enabled using the parameters.",
        "short": "The Kinect Azure Select TOP can be used to capture additional images from a Microsoft Kinect Azure camera that is controlled by a [[Kinect Azure TOP]].",
        "long": "The Kinect Azure Select TOP can be used to capture additional images from a Microsoft Kinect Azure camera that is controlled by a [[Kinect Azure TOP]].\n\nThis TOP must be used along with a [[Kinect Azure TOP]].",
        "opCategories": ""
    },
    "kinectazureTOP": {
        "label": "kinectazureTOP",
        "members": [
            {
                "text": "Menu : The resolution of images captured by the color camera. Different resolutions may have different aspect ratios. Note: 4096 x 3072 is not supported at 30 FPS.",
                "type": "Par",
                "name": "colorres"
            },
            {
                "text": "Menu : The depth mode controls which of the Kinect's two depth cameras (Wide or Narrow FOV) are used to produce the depth image and whether any 'binning' is used to process the data. In 'binned' modes, 2x2 blocks of pixels are combined to produce a filter, lower resolution image. Note: Body tracking is not supported when using the Passive IR depth mode.",
                "type": "Par",
                "name": "depthmode"
            },
            {
                "text": "Controls the frame rate of both the color and depth cameras. Some higher camera resolutions are not supported when running at 30FPS. Lower framerates can produce brighter color images in low light conditions.",
                "type": "Par",
                "name": "fps5"
            },
            {
                "text": "Controls the frame rate of both the color and depth cameras. Some higher camera resolutions are not supported when running at 30FPS. Lower framerates can produce brighter color images in low light conditions.",
                "type": "Par",
                "name": "fps15"
            },
            {
                "text": "Controls the frame rate of both the color and depth cameras. Some higher camera resolutions are not supported when running at 30FPS. Lower framerates can produce brighter color images in low light conditions.",
                "type": "Par",
                "name": "fps30"
            },
            {
                "text": "Menu : Determines how the body tracking model is processed. The default mode runs mostly on the GPU (supports Nvidia, AMD and Intel), but this can also be switched to a CPU mode when a compatible GPU is not available.",
                "type": "Par",
                "name": "proccessingmode"
            },
            {
                "text": "Menu : Used to indicate when the camera is mounted in a non-upright position. This can help improve body-tracking results.",
                "type": "Par",
                "name": "orientation"
            },
            {
                "text": "Menu : A list of available image types to capture from the device and display in this TOP. All image types have a second version that is mapped (aligned) to the image space of the other camera so that color and depth image data can be matched. The resolution of the image is controlled by the Color Resolution or Depth Mode parameters depending on the type of image selected. Use a [[Kinect Azure Select TOP]] to access additional image types from the same camera.",
                "type": "Par",
                "name": "image"
            },
            {
                "text": "Menu : Select the frequency of the power supply for use in the cameras noise cancellation system.",
                "type": "Par",
                "name": "powerfreq"
            },
            {
                "text": "Menu : When using more than one Kinect Azure camera, this setting can be used to determine which unit is the master and which are subordinates.",
                "type": "Par",
                "name": "syncmode"
            },
            {
                "text": "Controls the frame rate of both the color and depth cameras. Some higher camera resolutions are not supported when running at 30FPS. Lower framerates can produce brighter color images in low light conditions.",
                "type": "Par",
                "name": "fps5"
            },
            {
                "text": "Controls the frame rate of both the color and depth cameras. Some higher camera resolutions are not supported when running at 30FPS. Lower framerates can produce brighter color images in low light conditions.",
                "type": "Par",
                "name": "fps15"
            },
            {
                "text": "Controls the frame rate of both the color and depth cameras. Some higher camera resolutions are not supported when running at 30FPS. Lower framerates can produce brighter color images in low light conditions.",
                "type": "Par",
                "name": "fps30"
            },
            {
                "text": "Menu : The resolution of images captured by the color camera. Different resolutions may have different aspect ratios. Note: 4096 x 3072 is not supported at 30 FPS.",
                "type": "Par",
                "name": "colorres"
            },
            {
                "text": "Menu : The depth mode controls which of the Kinect's two depth cameras (Wide or Narrow FOV) are used to produce the depth image and whether any 'binning' is used to process the data. In 'binned' modes, 2x2 blocks of pixels are combined to produce a filter, lower resolution image. Note: Body tracking is not supported when using the Passive IR depth mode.",
                "type": "Par",
                "name": "depthmode"
            },
            {
                "text": "Menu : Determines how the body tracking model is processed. The default mode runs mostly on the GPU (supports Nvidia, AMD and Intel), but this can also be switched to a CPU mode when a compatible GPU is not available.",
                "type": "Par",
                "name": "proccessingmode"
            },
            {
                "text": "Menu : Used to indicate when the camera is mounted in a non-upright position. This can help improve body-tracking results.",
                "type": "Par",
                "name": "orientation"
            },
            {
                "text": "Menu : A list of available image types to capture from the device and display in this TOP. All image types have a second version that is mapped (aligned) to the image space of the other camera so that color and depth image data can be matched. The resolution of the image is controlled by the Color Resolution or Depth Mode parameters depending on the type of image selected. Use a [[Kinect Azure Select TOP]] to access additional image types from the same camera.",
                "type": "Par",
                "name": "image"
            },
            {
                "text": "Menu : Select the frequency of the power supply for use in the cameras noise cancellation system.",
                "type": "Par",
                "name": "powerfreq"
            },
            {
                "text": "Menu : When using more than one Kinect Azure camera, this setting can be used to determine which unit is the master and which are subordinates.",
                "type": "Par",
                "name": "syncmode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "kinectazureTOP",
        "opLabel": "Kinect Azure",
        "opClass": "kinectazureTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows 10 April 2018 or newer",
        "hardware": "An NVIDIA GEFORCE GTX 1070 or better graphics card is required to obtain efficient body tracking data from the camera, although a CPU-only mode can be enabled using the parameters.",
        "short": "The Kinect Azure TOP can be used to configure and capture data from a Microsoft Kinect Azure camera.",
        "long": "The Kinect Azure TOP can be used to configure and capture data from a Microsoft Kinect Azure camera. \n    \nThe TOP can be used to configure the settings of the camera (resolution, frame rate, synchronization, etc) as well to retrieve captured images from either its color or depth cameras. Image data from one camera can be remapped (aligned) to the other camera in order to match color and depth information. Only one Kinect Azure TOP can be connected to a single Kinect camera. To retrieve additional images from the same camera, use a [[Kinect Azure Select TOP]].\n    \nThe Kinect Azure can also extract body tracking information and skeleton positions using the depth camera image. To access this data, use a [[Kinect Azure CHOP]] and set its Kinect TOP parameter to the primary [[Kinect Azure TOP]] that is connected to the device.\n\n'''TIP:''' See Elburz' video on using KinectAzure's point clouds and a bunch of Azure general tips. [https://www.youtube.com/watch?v=P_PjAr2Yzao Kinect Azure Point Cloud in TouchDesigner Tutorial] on the Interactive and Immersive HQ.\n\nSee also [[Kinect Azure CHOP]], [[Kinect Azure Select TOP]], [[Palette:pointRender]], [[Palette:kinectCalibration]], [[Palette:kinectRecorder]], [[Palette:kinectPointcloud]].",
        "opCategories": ""
    },
    "kinectTOP": {
        "label": "kinectTOP",
        "members": [
            {
                "text": "Menu : Choose between Kinect  v1 or Kinect v2 sensors.",
                "type": "Par",
                "name": "hwversion"
            },
            {
                "text": "Menu : Selects between the Color, Depth, Infrared, Player Index, or Color Point Cloud modes.",
                "type": "Par",
                "name": "image"
            },
            {
                "text": "Menu : Only used for Kinect 1 devices. Selects the resolution of the camera capture.",
                "type": "Par",
                "name": "camerares"
            },
            {
                "text": "Menu : Only used for Kinect 1 devices. Specify whether to track full skeleton or seated skeleton.",
                "type": "Par",
                "name": "skeleton"
            },
            {
                "text": "Menu : When using the 'Color Point Cloud' some pixel's position can not be determined. This parameter controls what value to assign those pixels instead.",
                "type": "Par",
                "name": "unknownpointvalue"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "kinectTOP_Class",
        "opLabel": "Kinect",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "kinect",
        "opFilter": "False",
        "os": "Microsoft Windows",
        "hardware": "This TOP only supports the '''Kinect for Windows''' hardware and the '''Kinect 2''', ''not'' Kinect for Xbox hardware.",
        "long": "The Kinect TOP captures video from the [[Kinect]] depth camera or RGB color camera. \t\t\n\nTo use a Kinect 2 device you need to install the [https://www.microsoft.com/en-ca/download/details.aspx?id=44561 Kinect for Windows 2.0 SDK] or [https://www.microsoft.com/en-ca/download/details.aspx?id=44559 runtime].\t\t\t\n\t\t\t\nTo use the original Kinect 1 device you will need to install the [http://www.microsoft.com/en-ca/download/details.aspx?id=40277 Kinect Runtime 1.8] for builds greater than 12000, or [http://www.microsoft.com/en-us/download/details.aspx?id=36997 Kinect Runtime 1.7] for builds below 12000.\t\t\t\n\nKinect 2 supports color point clouds - getting the camera space positions of the color pixels, outputted as a 32-bit float RGB texture with XYZ in RGB. For use in making point clouds renders.\t\t\t\n\t\t\t\nSee also [[Kinect CHOP]], [[Kinect]] and [[Kinect1]].",
        "short": "The Kinect TOP captures video from the [[Kinect]] depth camera or RGB color camera.",
        "opCategories": ""
    },
    "layoutTOP": {
        "label": "layoutTOP",
        "members": [
            {
                "text": "Menu : The menu determines how the inputs are laid out, in row, column , or grid format.",
                "type": "Par",
                "name": "align"
            },
            {
                "text": "Menu : Determines how the input images are fit to the space they are given. Depending on the setting, it will either fit the entire image inside the space given or crop some of the image off.",
                "type": "Par",
                "name": "fit"
            },
            {
                "text": "The color of the border around each input.",
                "type": "Par",
                "name": "bcolorr"
            },
            {
                "text": "The color of the border around each input.",
                "type": "Par",
                "name": "bcolorg"
            },
            {
                "text": "The color of the border around each input.",
                "type": "Par",
                "name": "bcolorb"
            },
            {
                "text": "The color of the border around each input.",
                "type": "Par",
                "name": "bcolora"
            },
            {
                "text": "The border width for each input. The borders will scale down the input.",
                "type": "Par",
                "name": "bordersl"
            },
            {
                "text": "The border width for each input. The borders will scale down the input.",
                "type": "Par",
                "name": "bordersr"
            },
            {
                "text": "The border width for each input. The borders will scale down the input.",
                "type": "Par",
                "name": "bordersb"
            },
            {
                "text": "The border width for each input. The borders will scale down the input.",
                "type": "Par",
                "name": "borderst"
            },
            {
                "text": "Color and alpha for the space not covered by the input images.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Color and alpha for the space not covered by the input images.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Color and alpha for the space not covered by the input images.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Color and alpha for the space not covered by the input images.",
                "type": "Par",
                "name": "bgcolora"
            },
            {
                "text": "Menu : The menu attached to this parameter allows you to specify the order in which the changes to your inputs will take place. Changing the Transform order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "The two fields for Translate allows you to specify transforms in x and y axes for each input image.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "The two fields for Translate allows you to specify transforms in x and y axes for each input image.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "The two fields for Scale allows you to specify transforms in x and y axes for each input image.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "The two fields for Scale allows you to specify transforms in x and y axes for each input image.",
                "type": "Par",
                "name": "sy"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "layout",
        "opLabel": "Layout",
        "opLicense": "Non-Commercial",
        "opClass": "layoutTOP_Class",
        "opFilter": "True",
        "short": "The Layout TOP positions multiple input TOPs into rows, columns, or grids.",
        "long": "The Layout TOP positions multiple input TOPs into rows, columns, or grids. It can either fit all the TOPs into a specific resolution (determined by the Common page) by scaling the inputs, or it can scale its own resolution to be larger to accomodate the native resolution of the inputs.\n    \nEach input image gets equal area of the output, and the Fit menu determines how each image fits into its designated area.\n\nMultiple inputs can be wired into the Layout TOP, or the TOP parameter can contain paths to multiple TOPs. In the final layout, the TOPs specified in the TOP parameter will appear before the TOPs of the wired inputs if both are used.",
        "opCategories": ""
    },
    "leapmotionTOP": {
        "label": "leapmotionTOP",
        "members": [
            {
                "text": "Menu : Select between Leap Motion V2 or V4/V5 SDKs for tracking. V5 offers the fastest and most stable tracking, V2 offers some legacy features like gestures.",
                "type": "Par",
                "name": "v2"
            },
            {
                "text": "Menu : Switches the device to '''H'''ead '''M'''ounted '''D'''isplay mode.",
                "type": "Par",
                "name": "hmd"
            },
            {
                "text": "Menu : Select between Leap Motion V2 or V4/V5 SDKs for tracking. V5 offers the fastest and most stable tracking, V2 offers some legacy features like gestures.",
                "type": "Par",
                "name": "v2"
            },
            {
                "text": "Menu : Switches the device to '''H'''ead '''M'''ounted '''D'''isplay mode.",
                "type": "Par",
                "name": "hmd"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "leapmotionTOP_Class",
        "opLabel": "Leap Motion",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "leapmotion",
        "opFilter": "False",
        "long": "The Leap Motion TOP gets the image from the [[Leap Motion]] controller's cameras. To enable this feature the option '''Allow Images''' must be turned on in the Leap Motion Control Panel.\n\t\t\n==== Licensing for Leap Motion ====\nTouchDesigner does not include a license to use the Leap Motion hardware or software. Make sure to check with the [https://www.ultraleap.com/ UltraLeap website] regarding any applicable licenses that you may need for your project.\n\n==== Installation ====\nAs of TouchDesigner 2022, the Leap Motion library files are no longer included with the TouchDesigner installer. These files, along with the drivers, are available from the UltraLeap website here: https://developer.leapmotion.com/releases\n* API Version 5 Gemini - Download Gemini v5.6.1\n* API Version 4 Orion - Download Orion Beta v4.1.0\n* API Version 2 Tracking - Download Orion Beta v3.2.1\n\nDepending on your operating system, there are different instructions for installing the library:\n\n'''On Windows:''' You can use the Library Folder parameter to point to the location of the LeapC.dll (Orion/Gemini) or Leap.dll (Version 2/3) files on your system. The file is installed as part of the LeapSDK and the location may vary depending on the version and options selected during installation.\n\n'''On MacOS:''' Requires legacy Mac driver available [https://developer.leapmotion.com/releases/mac-2-3-1 here]. The libLeap.dylib file must be copied into a folder where TouchDesigner can find it (the Library folder parameter is not available on MacOS). The file is available in the LeapSDK/lib folder of the driver package downloaded from UltraLeap. The file can be copied into <code>usr/local/lib</code> so that it is available to all copies of TouchDesigner on the system, or it can be copied into the frameworks folder inside the package contents of a particular TouchDesigner app i.e. <code>TouchDesigner.app/contents/frameworks</code>.\n\nSee also [[Leap Motion]], [[Leap Motion CHOP]]",
        "short": "The Leap Motion TOP gets the image from the Leap Motion Controller's cameras.",
        "opCategories": ""
    },
    "lensdistortTOP": {
        "label": "lensdistortTOP",
        "members": [
            {
                "text": "The position in the image that should be the center of the distortion. Depending on the unit mode selected, the position can be entered as an absolute position measured from the bottom-left corner, or as a relative position measured from the center of the image. The unit mode also controls whether the position is measured in pixels or normalized coordinates.",
                "type": "Par",
                "name": "center1"
            },
            {
                "text": "The position in the image that should be the center of the distortion. Depending on the unit mode selected, the position can be entered as an absolute position measured from the bottom-left corner, or as a relative position measured from the center of the image. The unit mode also controls whether the position is measured in pixels or normalized coordinates.",
                "type": "Par",
                "name": "center2"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "centerunit"
            },
            {
                "text": "The focal length components of the camera matrix descibed either as normalized resolution-independent values or as pixels. The focal length acts as a scalar on the other distortion parameters. The normalized unit mode can be used for systems that use millimeters or other physical units. Often abbreviated as Fx and Fy. See [https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html OpenCV] for details.",
                "type": "Par",
                "name": "focallength1"
            },
            {
                "text": "The focal length components of the camera matrix descibed either as normalized resolution-independent values or as pixels. The focal length acts as a scalar on the other distortion parameters. The normalized unit mode can be used for systems that use millimeters or other physical units. Often abbreviated as Fx and Fy. See [https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html OpenCV] for details.",
                "type": "Par",
                "name": "focallength2"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "focallengthunit"
            },
            {
                "text": "Menu : Determines how the transformed image is arranged inside the final output image space. This value can be useful to preserve the native pixel resolution of the input image, or ensuring a final output resolution and aspect ratio.",
                "type": "Par",
                "name": "layout"
            },
            {
                "text": "Menu : Determines what values are used when the output image exceeds the bounds of the input image.",
                "type": "Par",
                "name": "extendmode"
            },
            {
                "text": "Menu : Choose whether to preform an addition transformation to the image after the lens distortion is applied. This is useful for positioning and scaling the distorted image within the final image frame and can be used to preserve parts of the input image that would be shifted out of frame by the distortion.",
                "type": "Par",
                "name": "transformmode"
            },
            {
                "text": "A new optical center position that allows for shifting the transformed image within the output image frame. Using the same value as the Optical Center parameter will result in no post distortion offset. Using the Optimal Center value will produce the same results as the Optimal transform mode.",
                "type": "Par",
                "name": "newcenter1"
            },
            {
                "text": "A new optical center position that allows for shifting the transformed image within the output image frame. Using the same value as the Optical Center parameter will result in no post distortion offset. Using the Optimal Center value will produce the same results as the Optimal transform mode.",
                "type": "Par",
                "name": "newcenter2"
            },
            {
                "text": "Menu : Determines how the new center values are interpreted.",
                "type": "Par",
                "name": "newcenterunit"
            },
            {
                "text": "A new focal length that allows for scaling the transformed image relative to output image frame. Using the same value as the Focal Lengths parameter will result in no post distortion scaling. Using the Optimal Focal Length value will produce the same results as the Optimal transform mode.",
                "type": "Par",
                "name": "newfocallength1"
            },
            {
                "text": "A new focal length that allows for scaling the transformed image relative to output image frame. Using the same value as the Focal Lengths parameter will result in no post distortion scaling. Using the Optimal Focal Length value will produce the same results as the Optimal transform mode.",
                "type": "Par",
                "name": "newfocallength2"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "newfocallengthunit"
            },
            {
                "text": "Shifts the distorted image within the output image frame.",
                "type": "Par",
                "name": "centeroffset1"
            },
            {
                "text": "Shifts the distorted image within the output image frame.",
                "type": "Par",
                "name": "centeroffset2"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "centeroffsetunit"
            },
            {
                "text": "Performs an additional post-distortion scale on the image. The scale is relative to the original camera matrix, so values greater than 1 will stretch the image, while values less than 1 will shrink it.",
                "type": "Par",
                "name": "scale1"
            },
            {
                "text": "Performs an additional post-distortion scale on the image. The scale is relative to the original camera matrix, so values greater than 1 will stretch the image, while values less than 1 will shrink it.",
                "type": "Par",
                "name": "scale2"
            },
            {
                "text": "Menu : Crop the transformed image so that only part of the image will appear in the final output. Unless a custom resolution is given, the cropped region will be used to determine the final output resolution.",
                "type": "Par",
                "name": "cropmode"
            },
            {
                "text": "Defines a custom cropping region in the order of Left, Bottom, Right, Top. The values can either be as a fraction of the image (0-1) or as pixels of the input image size. Entering the ROI values from an attached Info CHOP will produce the same results as using the Region of Interest cropping mode.",
                "type": "Par",
                "name": "cropregionx"
            },
            {
                "text": "Defines a custom cropping region in the order of Left, Bottom, Right, Top. The values can either be as a fraction of the image (0-1) or as pixels of the input image size. Entering the ROI values from an attached Info CHOP will produce the same results as using the Region of Interest cropping mode.",
                "type": "Par",
                "name": "cropregiony"
            },
            {
                "text": "Defines a custom cropping region in the order of Left, Bottom, Right, Top. The values can either be as a fraction of the image (0-1) or as pixels of the input image size. Entering the ROI values from an attached Info CHOP will produce the same results as using the Region of Interest cropping mode.",
                "type": "Par",
                "name": "cropregionz"
            },
            {
                "text": "Defines a custom cropping region in the order of Left, Bottom, Right, Top. The values can either be as a fraction of the image (0-1) or as pixels of the input image size. Entering the ROI values from an attached Info CHOP will produce the same results as using the Region of Interest cropping mode.",
                "type": "Par",
                "name": "cropregionw"
            },
            {
                "text": "Menu : The units used to interpret the values of the custom cropping region. Can be as fractions (0-1) of the image or as pixels of the input image size.",
                "type": "Par",
                "name": "cropunit"
            },
            {
                "text": "Menu : Determines how the scale values are used.",
                "type": "Par",
                "name": "scaleunit"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "lensdistortTOP",
        "opLabel": "Lens Distort",
        "opClass": "lensdistortTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "Applies or removes lens distortion from an image using the Brown-Conrady model.",
        "long": "The Lens Distort TOP applies or removes lens distortion from an image using the [https://en.wikipedia.org/wiki/Distortion_(optics) Brown-Conrady model]. This can be used to rectify images taken from a physical camera, to apply distortion to a rendering for use in augmented reality (AR), or as a visual effect. \n\nThe distortion algorithm used by the Lens Distort TOP can be broken down into three components: radial distortion, tangential distortion and the camera matrix.\n\nRadial distortion shifts pixels in the output relative to their distance from the center of the image (defined by the Optical Center parameter). Radial distortion is controlled by the k1, k2 and k3 constants, with k1 having the greatest effect and k3 the least. Positive k values create a barrel or fisheye effect as if the image was wrapped around the surface of a sphere. Negative k values will bend the image inward to create a pincushion or pillow effect. The equations for radial distortion are:\n\n<syntaxhighlight>x_distorted = x * (1 + k1 * r^2 + k2 * r^4 + k3 * r^6)\n\ny_distorted = y * (1 + k1 * r^2 + k2 * r^4 + k3 * r^6)\n\nwhere, \n  r = distance from center</syntaxhighlight>\n\nTangential distortion shifts pixels as if they were on a surface being tilted away from the camera and is controlled by the p1 and p2 parameters. p1 tilts the image up and down depending on the sign, and p2 tilts the image left and right. The equations for tangential distortion are:\n\n<syntaxhighlight>x_distorted = x + (2 * p1 * x * y + p2 * (r^2 + 2 * x^2))\n\ny_distorted = y + (p1 * (r^2 + 2 * y^2) + 2 * p2 * x * y)\n\nwhere, \n  r = distance from center</syntaxhighlight>\n\nThe camera matrix is defined by the Optical Center and Focal Length parameters and is used to transform the image positions before the distortion is applied. The Optical Center values control where the center of the distortion effect is, while the Focal Length parameters act as a scale on the other effects. The camera matrix is usually represented as a 3x3 matrix:\n\n<syntaxhighlight lang=python>\nfx 0  cx\n0  fy cy\n0  0  1\n</syntaxhighlight>\n    \nDistortion values for a camera lens can be determined using [https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html OpenCV calibration routines] or through functions for a particular camera (see [[KinectazureTOP_Class|kinectazureTOP class]]).\n\n<gallery>\nFile:Barrel Distortion.jpg|thumb|Barrel or Fisheye Radial Distortion, k > 0\nFile:Pincushion distort.jpg|thumb|Pillow or Pincushion Radial Distortion, k < 0\nFile:P1 distort.jpg|thumb|Tangential Distortion,   p1 < 0\nFile:P2 distort.jpg|thumb|Tangential Distortion,   p2 < 0\n</gallery>\n\nThe Layout page has parameters to control how the distorted (or undistorted) image is arranged inside the output image frame. These features can be helpful to preserve parts of the input image that might otherwise be projected offscreen, to preserve input image resolution, or to establish a consistent output frame when lens distortion parameters are changing.\n\nFor example, setting the Post Transform parameter to Optimal and keeping Optimal Alpha at 1, the distorted image will be scaled and shifted so that the entire input image is kept within the output frame. Switching the Layout parameter to Native Resolution, will then scale the output resolution so that no detail from the input image is lost. Attaching an [[Info CHOP]] will provide Region of Interest (ROI) bounds that can be used to crop out the original distorted image from the output image.",
        "opCategories": ""
    },
    "levelTOP": {
        "label": "levelTOP",
        "members": [
            {
                "text": "Toggle : This option will clamp pixel values in between 0 and 1. When using higher bit depth floating pixel formats, it is recommended to set it to Unclamped to allow the full range of values to be operated on. Auto should detect the pixel format as set accordingly.",
                "type": "Par",
                "name": "clampinput"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "levelTOP_Class",
        "opLabel": "Level",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "level",
        "opFilter": "True",
        "long": "The Level TOP adjusts image contrast, brightness, gamma, black level, color range, quantization, opacity and more. See also the [[Luma Level TOP]] which preserves hue and saturation more accurately, but is slower.\t\n\t\t\nThe Level TOP's features have been built into one TOP to maximize performance in a single pass. It takes all its parameters to make a lookup table on the CPU, so animating parameters in the Level TOP will decrease its performance as the lookup table is recreated each frame that a parameter changes.",
        "short": "The Level TOP adjusts image contrast, brightness, gamma, black level, color range, quantization, opacity and more.",
        "opCategories": ""
    },
    "limitTOP": {
        "label": "limitTOP",
        "members": [
            {
                "text": "Menu : The wrapping method used when applying limits to the pixel values in the image.",
                "type": "Par",
                "name": "minop"
            },
            {
                "text": "Menu : The wrapping method used when applying limits to the pixel values in the image.",
                "type": "Par",
                "name": "minop"
            },
            {
                "text": "Menu : The function used to quantize the pixel values in the output image.",
                "type": "Par",
                "name": "quantvalue"
            },
            {
                "text": "Menu : The function used for spacial quantization e.g. quantizing the UV coordinates so that pixel values are merged into larger blocks.",
                "type": "Par",
                "name": "quantpos"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "limitTOP",
        "opLabel": "Limit",
        "opClass": "limitTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Limit TOP can limit the pixel values of the input image to fall between a minimum and maximum value, and can quantize the pixels by value or position.",
        "long": "The Limit TOP can limit the pixel values of the input image to fall between a minimum and maximum value, and can quantize the pixels by value or position.\n\nLimiting a channel causes all of its values to lie within the given range. Several different methods are available to determine what happens to values outside of the Minimum/Maximum range.\n\nQuantizing pixel values will snap each channel to the closest allowable value (the \"quantized values\"). Quantizing methods are: Floor, Ceiling, and Round.\n\nQuantizing pixel positions will cause all pixels within the quantization step to take the same value. This is equivalent to lowering the image resolution and then scaling the image back to its original size with no filtering applied.",
        "opCategories": ""
    },
    "lookupTOP": {
        "label": "lookupTOP",
        "members": [
            {
                "text": "Menu : Choose to use a line from the 2nd input (defined using UV coordinates) or CHOP values to define the lookup table.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "The Index Range maps the index values to the lookup table's start and end and defaults to 0 and 1. The first parameter represents the start of the lookup table. When the index color has this value, it will index the start of the lookup table. The second parameter represents the end of the lookup table and behaves in the same way. '''Note:''' When the index goes outside of this range, it will '''hold''' on the first or last value of the lookup table.",
                "type": "Par",
                "name": "index1"
            },
            {
                "text": "The Index Range maps the index values to the lookup table's start and end and defaults to 0 and 1. The first parameter represents the start of the lookup table. When the index color has this value, it will index the start of the lookup table. The second parameter represents the end of the lookup table and behaves in the same way. '''Note:''' When the index goes outside of this range, it will '''hold''' on the first or last value of the lookup table.",
                "type": "Par",
                "name": "index2"
            },
            {
                "text": "The Index Range maps the index values to the lookup table's start and end and defaults to 0 and 1. The first parameter represents the start of the lookup table. When the index color has this value, it will index the start of the lookup table. The second parameter represents the end of the lookup table and behaves in the same way. '''Note:''' When the index goes outside of this range, it will '''hold''' on the first or last value of the lookup table.",
                "type": "Par",
                "name": "index1"
            },
            {
                "text": "The Index Range maps the index values to the lookup table's start and end and defaults to 0 and 1. The first parameter represents the start of the lookup table. When the index color has this value, it will index the start of the lookup table. The second parameter represents the end of the lookup table and behaves in the same way. '''Note:''' When the index goes outside of this range, it will '''hold''' on the first or last value of the lookup table.",
                "type": "Par",
                "name": "index2"
            },
            {
                "text": "Menu : The Index Channel controls how the color from the input is turned into a index to do the lookup. By default, the RGBA Independent option will do a separate lookup in each channel i.e. the red output channel will be based on the red value in the lookup table and the red value in the index image. For other options, like Luminance or RGBA Average, a single index value is calculated from the index color and all channels of the output image will be taken from the same pixel of the lookup table at the given index.",
                "type": "Par",
                "name": "channel"
            },
            {
                "text": "Set the UV position to use for dark end of the lookup table. In the original image connected to the first input, any pixel with a value of (0,0,0) will be replaced by the value found at this UV position in the image connected to the second input.",
                "type": "Par",
                "name": "darkuv1"
            },
            {
                "text": "Set the UV position to use for dark end of the lookup table. In the original image connected to the first input, any pixel with a value of (0,0,0) will be replaced by the value found at this UV position in the image connected to the second input.",
                "type": "Par",
                "name": "darkuv2"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darkuvunit"
            },
            {
                "text": "Set the UV position to use for light end of the lookup table. In the original image connected to the first input, any pixel with a value of (1,1,1) will be replaced by the value found at this UV position in the image connected to the second input.",
                "type": "Par",
                "name": "lightuv1"
            },
            {
                "text": "Set the UV position to use for light end of the lookup table. In the original image connected to the first input, any pixel with a value of (1,1,1) will be replaced by the value found at this UV position in the image connected to the second input.",
                "type": "Par",
                "name": "lightuv2"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "lightuvunit"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "lookupTOP_Class",
        "opLabel": "Lookup",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "lookup",
        "opFilter": "True",
        "long": "The Lookup TOP replaces color values in the TOP image connected to its first input with values derived from a lookup table created from its second input or a lookup table created using the CHOP parameter. When using the 2nd input, the lookup table is created by defining a line (start and end position) on the TOP image. When using a CHOP the lookup table is created directly from the CHOP's values and the 2nd input is ignored.\t\t\n\t\t\t\nThe Index Range parameter can be used to define the minimum and maximum index values that will map to the first and last values in the lookup table. When the index goes outside of this range, it will '''hold''' on the first or last value of the lookup table.\n\nSee also [[Remap TOP]], [[Displace TOP]].",
        "short": "The Lookup TOP replaces color values in the TOP image connected to its first input with values derived from a lookup table created from its second intput or a lookup table created using the CHOP parameter.",
        "opCategories": ""
    },
    "lumablurTOP": {
        "label": "lumablurTOP",
        "members": [
            {
                "text": "Menu : Determines the mathematical function used to create the blur.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : The greyscale can be any channel of the second input, or composites like luminance and RGB average.",
                "type": "Par",
                "name": "widthchan"
            },
            {
                "text": "Menu : Sets the extend conditions to determine what happens to the blur at the edge of the image.",
                "type": "Par",
                "name": "extend"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "[[image:LumaBlurTOP.png|300px]]\t\t\n\t\t\t\nThe Luma Blur TOP blurs image on a per-pixel basis depending on the luminance or greyscale value of its second input.\t\t\t\n\t\t\t\nThe image is blurred with separate parameters for white and black filter sizes, which correspond to the white and black luminance values of the second input. The minimum is applied where the second input is black, and the maximum is applied where the second input is white.",
        "opLabel": "Luma Blur",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "short": "The Luma Blur TOP blurs image on a per-pixel basis depending on the luminance or greyscale value of its second input.",
        "opType": "lumablur",
        "opFilter": "True",
        "opClass": "lumablurTOP_Class",
        "opCategories": ""
    },
    "lumalevelTOP": {
        "label": "lumalevelTOP",
        "members": [
            {
                "text": "Menu : Determines the source of the image that is adjusted by the parameters. The output is determined by: \t\n <code>InColor * 1/Source * Lookup(Source)</code> \t\t\t\nLookup is the lookup table build by the parameter settings in the TOP.",
                "type": "Par",
                "name": "source"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "lumalevelTOP_Class",
        "opLabel": "Luma Level",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "lumalevel",
        "opFilter": "True",
        "long": "The Luma Level TOP adjusts image brightness, gamma, black level, quantization, opacity and more. It has similar parameters to the [[Level TOP]], but it maintains the hue and saturation more accurately when you use Gamma and Black Level. \t\t\n\t\t\t\nIn the Level TOP, lowering the gamma will raise the saturation and shift the hue. Luma Level preserves saturation and hue.\t\t\t\n\t\t\t\nIt also includes a Source parameter which allows the level adjustment to be applied only to certain parts of the image. For example, if source is set to Luminance, then the adjustments made with the Luma Level's parameters will be applied to the luminance of the image (ie. Invert = 1 would invert the luminance of the image, not the color).",
        "short": "The Luma Level TOP adjusts image brightness, gamma, black level, quantization, opacity and more.",
        "opCategories": ""
    },
    "mathTOP": {
        "label": "mathTOP",
        "members": [
            {
                "text": "Menu : A menu of unary operations that are performed on each channel as it comes in to the Math TOP include:",
                "type": "Par",
                "name": "preop"
            },
            {
                "text": "Menu : A choice of operations is performed between the channels of the input TOP. Input and output channels are selected by the 'Combine Channels Input' and 'Combine Channels Output' parameters below. The Nth pixel of one channel is combined with the Nth pixel of other channels.",
                "type": "Par",
                "name": "chanop"
            },
            {
                "text": "Menu : A menu (same as Channel Pre OP) is performed as the finale stage upon the channels resulting from the above operations.",
                "type": "Par",
                "name": "postop"
            },
            {
                "text": "Menu : The resulting values can be converted to integers.",
                "type": "Par",
                "name": "integer"
            },
            {
                "text": "Menu : The math operation performed.",
                "type": "Par",
                "name": "op"
            },
            {
                "text": "Working on all channels, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromrange1"
            },
            {
                "text": "Working on all channels, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromrange2"
            },
            {
                "text": "Working on all channels, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "torange1"
            },
            {
                "text": "Working on all channels, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "torange2"
            },
            {
                "text": "Working on the red channel, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromranger1"
            },
            {
                "text": "Working on the red channel, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromranger2"
            },
            {
                "text": "Working on the red channel, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "toranger1"
            },
            {
                "text": "Working on the red channel, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "toranger2"
            },
            {
                "text": "Working on the green channel, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromrangeg1"
            },
            {
                "text": "Working on the green channel, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromrangeg2"
            },
            {
                "text": "Working on the green channel, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "torangeg1"
            },
            {
                "text": "Working on the green channel, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "torangeg2"
            },
            {
                "text": "Working on the blue channel, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromrangeb1"
            },
            {
                "text": "Working on the blue channel, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromrangeb2"
            },
            {
                "text": "Working on the blue channel, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "torangeb1"
            },
            {
                "text": "Working on the blue channel, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "torangeb2"
            },
            {
                "text": "Working on the alpha channel, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromrangea1"
            },
            {
                "text": "Working on the alpha channel, converts the specified From Range (low-high range) into the To Range below.",
                "type": "Par",
                "name": "fromrangea2"
            },
            {
                "text": "Working on the alpha channel, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "torangea1"
            },
            {
                "text": "Working on the alpha channel, converts the specified From Range (low-high range) above into this To Range.",
                "type": "Par",
                "name": "torangea2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "mathTOP_Class",
        "opLabel": "Math",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "math",
        "opFilter": "True",
        "long": "The Math TOP performs specific mathematical operations on the pixels of the input image.",
        "short": "The Math TOP performs specific mathematical operations on the pixels of the input image.",
        "opCategories": ""
    },
    "matteTOP": {
        "label": "matteTOP",
        "members": [
            {
                "text": "Menu : Select which channel from input3 is used to create the matte.",
                "type": "Par",
                "name": "mattechannel"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "matteTOP_Class",
        "opLabel": "Matte",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "matte",
        "opFilter": "True",
        "long": "The Matte TOP composites input1 over input2 using the specified channel of input3 as a matte. Using the default setting of Matte Channel = Alpha, white (one) pixels in input3's alpha channel will draw input1 over input2, black (or zero) will make input1 transparent, leaving the input2 image at that pixel.",
        "short": "The Matte TOP composites input1 over input2 using a specified channel of input3 as a matte.",
        "opCategories": ""
    },
    "mirrorTOP": {
        "label": "mirrorTOP",
        "members": [
            {
                "text": "The pivot point determines where in the image the Rotate parameter will rotate around.",
                "type": "Par",
                "name": "pivotx"
            },
            {
                "text": "The pivot point determines where in the image the Rotate parameter will rotate around.",
                "type": "Par",
                "name": "pivoty"
            },
            {
                "text": "nolabel shortvalues dropmenu : Specify the units used to position the pivot point.",
                "type": "Par",
                "name": "pivotunit"
            },
            {
                "text": "dropmenu : This parameter determines what happens at the edge of the image.",
                "type": "Par",
                "name": "extend"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "mirrorTOP",
        "opLabel": "Mirror",
        "opClass": "mirrorTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "Mirrors part of an image on top of itself.",
        "long": "Mirrors part of an image on top of itself.",
        "opCategories": ""
    },
    "monochromeTOP": {
        "label": "monochromeTOP",
        "members": [
            {
                "text": "Menu : This menu selects how the monochrome conversion is calculated for the RGB channels.",
                "type": "Par",
                "name": "rgb"
            },
            {
                "text": "Menu : This menu selects how the monochrome conversion is calculated for the alpha channel.",
                "type": "Par",
                "name": "alpha"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "monochromeTOP_Class",
        "opLabel": "Monochrome",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "mono",
        "opFilter": "True",
        "long": "The Monochrome TOP changes an image to greyscale colors. You can choose from a number of different methods to convert the image to greyscale using the RGB and Alpha menus.",
        "short": "The Monochrome TOP changes an image to greyscale colors.",
        "opCategories": ""
    },
    "mosysTOP": {
        "label": "mosysTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "mosysTOP",
        "opLabel": "MoSys",
        "opClass": "mosysTOP_Class",
        "opFilter": "True",
        "opLicense": "Pro",
        "opCategories": "",
        "os": "",
        "hardware": "",
        "short": "The MoSys TOP works with MoSys camera tracking systems to perform simulated lens distortion using channels from a connected [[MoSys CHOP]].",
        "long": "The MoSys TOP works with MoSys camera tracking systems to perform simulated lens distortion using channels from a connected [[MoSys CHOP]]."
    },
    "moviefileinTOP": {
        "label": "moviefileinTOP",
        "members": [
            {
                "text": "Menu : Specifies the method used to play the movie, there are 3 options.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "cuepointunit"
            },
            {
                "text": "Menu : Customize the Cue parameter's behavior.",
                "type": "Par",
                "name": "cuebehavior"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "indexunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "loopcrossfadeunit"
            },
            {
                "text": "Menu : This menu helps you determine how to treat the audio as the end of a movie approaches. This is needed because of all the cases of playing a movie, like when driving with an index, the TOP will not know if you intend to loop it or not.",
                "type": "Par",
                "name": "audioloop"
            },
            {
                "text": "Menu : Determines how an image sequence is ordered.",
                "type": "Par",
                "name": "imageindexing"
            },
            {
                "text": "Menu : For movies that are stored as fields, where each image is made of two images interleaved together. A 30-frame per second movie would contain 60 fields per second. For each image, the even scanlines of the first field are interleaved with the odd scanlines of the second field. The Movie File In TOP has several ways of dealing with this:",
                "type": "Par",
                "name": "deinterlace"
            },
            {
                "text": "Menu : Where fields are extracted one field at a time, this will extract the Even field first by default, otehrwise it will extract the odd field first. The video industry has not standardized on one or the other.",
                "type": "Par",
                "name": "precedence"
            },
            {
                "text": "Menu : Premultiplies the image.",
                "type": "Par",
                "name": "multalpha"
            },
            {
                "text": "Menu : When the file can not be loaded for some reason, select what to display instead.",
                "type": "Par",
                "name": "loadingerrorimage"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "tstartunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "tendunit"
            },
            {
                "text": "Menu : Determines how the Movie File In TOP handles movie positions that lie before the Trim Start position. For example, if Trim Start is set to 1, and the movie's current index is -10, the Extend Left menu determines how the movie position is calculated.",
                "type": "Par",
                "name": "textendleft"
            },
            {
                "text": "Menu : Determines how the Movie File In TOP handles movie positions that lie after the Trim End position. For example, if Trim End is set to 20, and the movie's current index is 25, the Extend Right menu determines how the movie position is calculated.",
                "type": "Par",
                "name": "textendright"
            },
            {
                "text": "Menu : When on, if the Disk Read Timeout is reached TouchDesigner will use the latest available frame in place of the skipped frame.",
                "type": "Par",
                "name": "frametimeoutstrat"
            },
            {
                "text": "Menu : Specifies the method used to play the movie, there are 3 options.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "cuepointunit"
            },
            {
                "text": "Menu : Customize the Cue parameter's behavior.",
                "type": "Par",
                "name": "cuebehavior"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "indexunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "loopcrossfadeunit"
            },
            {
                "text": "Menu : This menu helps you determine how to treat the audio as the end of a movie approaches. This is needed because of all the cases of playing a movie, like when driving with an index, the TOP will not know if you intend to loop it or not.",
                "type": "Par",
                "name": "audioloop"
            },
            {
                "text": "Menu : Determines how an image sequence is ordered.",
                "type": "Par",
                "name": "imageindexing"
            },
            {
                "text": "Menu : For movies that are stored as fields, where each image is made of two images interleaved together. A 30-frame per second movie would contain 60 fields per second. For each image, the even scanlines of the first field are interleaved with the odd scanlines of the second field. The Movie File In TOP has several ways of dealing with this:",
                "type": "Par",
                "name": "deinterlace"
            },
            {
                "text": "Menu : Where fields are extracted one field at a time, this will extract the Even field first by default, otehrwise it will extract the odd field first. The video industry has not standardized on one or the other.",
                "type": "Par",
                "name": "precedence"
            },
            {
                "text": "Menu : Premultiplies the image.",
                "type": "Par",
                "name": "multalpha"
            },
            {
                "text": "Menu : When the file can not be loaded for some reason, select what to display instead.",
                "type": "Par",
                "name": "loadingerrorimage"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "tstartunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Index, Frames, Seconds, and Fraction (percentage).",
                "type": "Par",
                "name": "tendunit"
            },
            {
                "text": "Menu : Determines how the Movie File In TOP handles movie positions that lie before the Trim Start position. For example, if Trim Start is set to 1, and the movie's current index is -10, the Extend Left menu determines how the movie position is calculated.",
                "type": "Par",
                "name": "textendleft"
            },
            {
                "text": "Menu : Determines how the Movie File In TOP handles movie positions that lie after the Trim End position. For example, if Trim End is set to 20, and the movie's current index is 25, the Extend Right menu determines how the movie position is calculated.",
                "type": "Par",
                "name": "textendright"
            },
            {
                "text": "Menu : When on, if the Disk Read Timeout is reached TouchDesigner will use the latest available frame in place of the skipped frame.",
                "type": "Par",
                "name": "frametimeoutstrat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "moviefileinTOP_Class",
        "opLabel": "Movie File In",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "moviefilein",
        "opFilter": "False",
        "long": "The Movie File In TOP loads movies, still images, or a sequence of still images into TOPs. It will read images in <code>.jpg</code>, <code>.gif</code>, <code>.tif</code>, or <code>.bmp</code> format. It will read movies in QuickTime's <code>.mov</code> format, <code>.mp4</code>, <code>.mpg</code>, <code>.mpeg</code>, <code>.avi</code>, <code>.wmv</code>, <code>.dpx</code>, [[GoPro Cineform|Cineform]] and [[Hap]] Q formats (including Hap Q with Alpha).  \n    \nIt also supports the [[NotchLC]] codec, [[EXR]] files (<code>.exr</code>) and some <code>.swf</code> and <code>.flv</code> Flash files as well as DXT1/3/5 and RG compressed <code>.dds</code> files. Images and movies can also be fetched from the web by using <code>http://</code> to specify a URL.\n\nAccess the hardware decoder on Nvidia GPUs with the Hardware Decode parameter on the 'Tune' page. This supports 10 and 12-bit H264/H265s and YUV 444 files on supporting hardware, converted into 16-bit pixel channels. Other codecs that this also decodes include VP8, VP9, JPEG, AV1, VC1.\nMore information [https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new here.]\n\nWhen reading file formats that support higher bit depths such as 10-bit/16-bit/32-bit, an appropriate pixel format will be automatically used as long as the 'Pixel Format' menu on the Common page is left as 'Use Input'. i.e. a 16-bit file will cause each pixel to have 16-bits per color channel automatically.\n\nFor a complete list, see [[File Types]].\t\t\t\n\t\t\t\nExamine the state of a Movie File In TOP by attaching an [[Info CHOP]] to it (see below on Info CHOP). This will show info like movie length, resolution, the number of images per second (the <code>sample_rate</code> channel), and whether there is audio in the file.  It also shows dynamic information like movie open status, current frame, readahead frames and queue size, dropped frame count, CPU decode time and GPU upload time.\t\t\n\nNote that a movie's \"images per second\" (sample_rate) may be different than the timeline's frames per second. When referring to the movie's \"index\", it's in reference to the sequence of images in the movie file, not related to the global project frame rate.\n\t\t\t\nSee also the page on Movie File In TOP optimizations [[Movie Playback]], plus [[Hap]], [[Movie File Out TOP]] and [[GoPro Cineform|Cineform]].",
        "short": "The Movie File In TOP loads movies, still images, or a sequence of still images into TOPs.",
        "opCategories": ""
    },
    "moviefileoutTOP": {
        "label": "moviefileoutTOP",
        "members": [
            {
                "text": "Menu : Output either a movie, image, image sequence, or stop-frame movie.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : Select the video compression codec used to encode the movie.",
                "type": "Par",
                "name": "videocodec"
            },
            {
                "text": "Menu : Choose what file type to use when <span class=\"tipTextTOP\">Type</span> is set to Image.",
                "type": "Par",
                "name": "imagefiletype"
            },
            {
                "text": "Menu : Options for the pixel format based on the <span class=\"tipTextTOP\">Video Codec</span> selected.",
                "type": "Par",
                "name": "moviepixelformat"
            },
            {
                "text": "Menu : Select the audio compression codec used to encode the audio.",
                "type": "Par",
                "name": "audiocodec"
            },
            {
                "text": "Menu : The bitrate to write the audio out at.",
                "type": "Par",
                "name": "audiobitrate"
            },
            {
                "text": "Menu : Select the H.264 profile to use.",
                "type": "Par",
                "name": "profile"
            },
            {
                "text": "Menu : Select from the available presets.",
                "type": "Par",
                "name": "preset"
            },
            {
                "text": "Menu : Select between Constant or Variable bit rate, and regular or high quality bit rate modes.",
                "type": "Par",
                "name": "bitratemode"
            },
            {
                "text": "Menu : This setting can effect the final size of the compressed video but depends greatly on the complexity of the scene being encoded. The menu entries refers to the distance between pixels (quarter distance, half distance, or full distance which is a full pixel) as the motion vector precision for motion estimation during video compression. Quarter pixel precision can increase the quality of the motion prediction signal over half pixel precision, and this can sometimes result in better overall size compression if the improved prediction signal can offset the additional bits it takes to encode the higher precision motion vectors.",
                "type": "Par",
                "name": "motionpredict"
            },
            {
                "text": "Menu : Select the EntropyMode to use for H.264.",
                "type": "Par",
                "name": "profile"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Movie File Out TOP saves a TOP stream out to a movie file (<code>.mov</code>/<code>.mp4</code>) using a variety of codecs, including the H.264/H.265, [[Hap|Hap Q]], [[NotchLC]] and Animation video codecs. It can also save single frame images, image sequences, or stop-frame movies. \t\t\n\t\t\t\nThe [[Export Movie Dialog]] is a user interface built around the Movie File Out TOP.\t\t\t\n\t\t\t\nTo record movies with audio using the Movie File Out TOP, a [[Time_Slicing|Time Sliced]] CHOP with mono or stereo channels of audio is required. If TouchDesigner is running at a lower frame rate than the target video frame rate and a CHOP is specified for audio, the Movie File Out TOP will automatically repeat video frames to ensure the video and audio stay in sync.\t\t\t\n\t\t\t\nRecording a movie without frame drops can be done in non-realtime by turning off the Realtime flag at the top of the user interface.\t\t\t\t\nThe length of the video is not predetermined and depends on the amount of time the Record parameter is on. \t\n\nYou can record a sequence of <code>.tif</code> or <code>.exr</code> files by setting the Type parameter to Image Sequence. When Image File Type is set to OpenEXR, the EXR page has options to record any number of color channels from multiple TOPs into an EXR image file, and can create it with metadata that would get read by a [[Point File In TOP]].\n\t\t\t\n'''H264/H265 NOTE:''' Encoding movies in H.264/H.265 codec is only available with a [[TouchDesigner Commercial|Commercial]] or [[TouchDesigner Pro|Pro]] license. Nvidia graphic hardware is also required.\t\t\t\n\t\n'''*** WARNING - GPU Driver Timeout on long GPU activities ***''' Encoding some formats at high-resolution may be a slow, GPU-intensive operation. Generally only the RGBA BC7 mode for HapQ can suffer from this though. Consequently it will usually take longer than the default 2 seconds per frame that Windows gives the GPU driver to complete an operation. If you see a message saying that Windows has reset the GPU driver, this is the issue you are running into. To fix the issue, create this registry value:\t\t\t\n<code>HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\GraphicsDrivers\\TdrDelay</code><br>\t\t\t\nThe value should be of type <code>REG_DWORD</code>. The value is the number of seconds an operation can take before the OS resets the GPU driver. Set it to something larger, like 20-40 (seconds), depending on the resolution you intend to encode. You must reboot your machine for this setting to take effect. If you still get driver resets, make it even larger.\t\t\t\n\nRecording still images and stop-frame animation can be done by changing the 'Type' parameter. Then the 'Add Frame' pulse button can be pulsed manually or via a script to cause the frames to be written.\n\nSee also [[Movie File In TOP]], [[Recording Movies with Audio]].",
        "short": "The Movie File Out TOP saves a TOP stream out to a [http://www.apple.com/quicktime/ QuickTime] or MP4 (<code>.mp4</code>) movie in a variety of formats, plus the Animation, Cineform and Hap Q video codecs.",
        "opLicense": "Non-Commercial",
        "opLabel": "Movie File Out",
        "opFilter": "True",
        "opType": "moviefileout",
        "opClass": "moviefileoutTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "multiplyTOP": {
        "label": "multiplyTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]]",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Multiply TOP performs a multiply operation on Input1 and Input2.",
        "short": "The Multiply TOP performs a multiply operation on Input1 and Input2.",
        "opLicense": "Non-Commercial",
        "opLabel": "Multiply",
        "opFilter": "True",
        "opType": "multiply",
        "opClass": "multiplyTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "ncamTOP": {
        "label": "ncamTOP",
        "members": [
            {
                "text": "Menu : Select what type of output this TOP should produce. Some output modes like 'Composite' and 'Distort Input' require an input image from another TOP. Not all image streams may be available from the Ncam server. If a stream is not available, the TOP will produce an error.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "ncamTOP",
        "opLabel": "Ncam",
        "opClass": "ncamTOP_Class",
        "opFilter": "False",
        "opLicense": "Pro",
        "short": "The Ncam TOP can receive image data from an external Ncam Reality tracking system for use in virtual production.",
        "long": "The Ncam TOP can receive image data from an external Ncam Reality tracking system for use in virtual production. To receive data, the TOP must reference an [[Ncam CHOP]] that is connected to the Ncam server. The type of image displayed in the TOP is chosen using the Output parameter. Multiple image streams may be available depending on the server settings, and additional Ncam TOPs can be used to access more than one stream.\n    \nPossible image streams include the primary film stream captured by the external camera, a lens distortion map, and a depth image. The lens distortion map is a 32 bit floating point image where the R and G channels contain coordinates of where that pixel's color data should be taken from. The distortion map is used to warp a rendered image so that it matches the optical properties of an image captured with a physical lens.\n\nThe lens distortion map can be applied to a rendered image by connecting a TOP with the rendered content to the Ncam TOP's input and setting the Output parameter to 'Distort Input'. Additionally, the rendered content can be distorted and composited onto the film content using the 'Composite' option.",
        "opCategories": ""
    },
    "ndiinTOP": {
        "label": "ndiinTOP",
        "members": [
            {
                "text": "Menu : Choose High or Low bandwidth option.",
                "type": "Par",
                "name": "bandwidth"
            },
            {
                "text": "Menu : Choose Native or 8-bit pixel format.",
                "type": "Par",
                "name": "inputpixelformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The NDI In TOP will obtain its image data over IP from other DI\u00ae (Network Data Interface) enabled applications. The [[NDI|NDI\u00ae]] protocol is created by [http://www.newtek.com/ndi/applications/ Newtek].\n    \nAttach an [[Audio NDI CHOP]] to the NDI In DAT to extract audio from the NDI stream. \n\nMetadata can also be sent to the NDI In TOP from an [[NDI Out TOP]] or another system that has attached metadata to the NDI stream. Attach an [[Info DAT]] to the NDI In DAT to get the metadata as text. It is in an XML format. To better see and access the XML, attach an [[XML DAT]] to the Info DAT. \n\nBut you can also send a table-format DAT in the [[NDI Out TOP]] and it will be received in the Info DAT as a table.  \n\nTo send metadata in an NDI stream, see the NDI Out TOP's Metadata DAT parameter.\n\nTo see details of the available NDI streams, use the [[NDI DAT]].\n\t\t\nSee also [[NDI]], [[NDI Out TOP]] and [[NDI DAT]].\n\n'''NOTE for Windows OS - If experiencing connection issues, check Windows firewall settings.'''",
        "short": "The NDI In TOP will obtain its image data over IP from other [[NDI|NDI\u00ae (Network Data Interface)]] enabled applications.",
        "opLabel": "NDI In",
        "opFilter": "False",
        "opType": "ndiin",
        "opClass": "ndiinTOP_Class",
        "opFamily": "TOP",
        "opLicense": "",
        "opCategories": ""
    },
    "ndioutTOP": {
        "label": "ndioutTOP",
        "members": [
            {
                "text": "Menu : When the NDI sending thread isn't able to keep up due to insufficient system resources (usually available CPU time), this controls the resulting behavior of the node.",
                "type": "Par",
                "name": "lowperformancebehavior"
            },
            {
                "text": "Menu : Controls the pixel format the output is encoded into.",
                "type": "Par",
                "name": "outputpixelformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The NDI Out TOP will send image and audio data over IP to other [[NDI|Newtek NDI\u00ae (Network Data Interface)]] enabled applications. The [[NDI|NDI\u00ae]] protocol is created by [http://www.newtek.com/ndi/applications/ Newtek].\t\n\t\t\nSee also [[NDI]], [[NDI In TOP]] and [[NDI DAT]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "short": "The NDI Out TOP will send image and audio data over IP to other [[NDI|NDI (Network Data Interface)]] enabled applications.",
        "opLicense": "Non-Commercial",
        "opLabel": "NDI Out",
        "opFilter": "True",
        "opType": "ndiout",
        "opClass": "ndioutTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "noiseTOP": {
        "label": "noiseTOP",
        "members": [
            {
                "text": "Menu : The noise function used to generate noise. The functions available are:",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : The menu attached to this parameter allows you to specify the order in which the transforms will take place. Changing the Transform order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : The rotational matrix presented when you click on this option allows you to set the transform order for the rotations. As with transform order (above), changing the order in which the rotations take place will alter the final position.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "Translate the sampling plane through the noise space.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translate the sampling plane through the noise space.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Translate the sampling plane through the noise space.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Rotate the sampling plane in the noise space.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "Rotate the sampling plane in the noise space.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "Rotate the sampling plane in the noise space.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "Scale the sampling plane.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scale the sampling plane.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Scale the sampling plane.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "Control the pivot for the transform of the sampling plane.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Control the pivot for the transform of the sampling plane.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "Control the pivot for the transform of the sampling plane.",
                "type": "Par",
                "name": "pz"
            },
            {
                "text": "Menu : When an input is connected to the Noise TOP, the noise pattern is placed over the input image using UV coordinates and the settings from this menu.",
                "type": "Par",
                "name": "rgb"
            },
            {
                "text": "Menu : Sets the alpha channel for the output image.",
                "type": "Par",
                "name": "alpha"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Noise TOP generates a variety of noise patterns including perlin, simplex, sparse, alligator and random. Some types of noise run on the CPU, while others are calculated on the GPU. The ones that are calculated on the GPU will have GPU in their name.\n \nThe first input can be combined with the generated noise in various ways depending on the parameters.\n\nThe second input can be used to specify noise coordinates per-pixel. Without a 2nd input connected, the noise coordinates are the 0-1 texture coordinates of the output texture, i.e, the position of the pixel in the output texture. With a 2nd input connected the position of the pixel in the output texture is used to look-up into the 2nd input, and the RGBA of the 2nd input for that sampled pixel will be used as the XYZ and W for the noise coordinate.",
        "short": "The Noise TOP generates a variety of noise patterns including perlin, simplex, sparse, alligator and random.",
        "opLicense": "Non-Commercial",
        "opLabel": "Noise",
        "opFilter": "False",
        "opType": "noise",
        "opClass": "noiseTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "normalmapTOP": {
        "label": "normalmapTOP",
        "members": [
            {
                "text": "Menu : This menu selects how the edges in the image are found. The edges will appear raised or depressed in the output image depending on their slope.",
                "type": "Par",
                "name": "source"
            },
            {
                "text": "Menu : Determines what pixels to use when calculating the slope at each pixel in the image.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to find edges. A <span class=\"tipTextTOP\">Sample Step</span> of 3 would sample pixels 3 pixels away to look for edges.",
                "type": "Par",
                "name": "offset1"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to find edges. A <span class=\"tipTextTOP\">Sample Step</span> of 3 would sample pixels 3 pixels away to look for edges.",
                "type": "Par",
                "name": "offset2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Normal Map TOP takes an input image and creates a normal map by finding edges in the image. This can then be used for bump mapping (See [[Phong MAT]] and [[PBR MAT]]).\n    \nSee also [[Normal Mapping]].",
        "short": "The Normal Map TOP takes an input image and creates a normal map by finding edges in the image.",
        "opLicense": "Non-Commercial",
        "opLabel": "Normal Map",
        "opFilter": "True",
        "opType": "normal",
        "opClass": "normalmapTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "notchTOP": {
        "label": "notchTOP",
        "members": [
            {
                "text": "Menu : A menu to specify the method used for playback of the block.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "Menu : Sets the units used in the Index parameter.",
                "type": "Par",
                "name": "indexunit"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Notch TOP will load a Notch Block (extension <code>.dfxdll</code>) compiled from [https://www.notch.one/products/notch-builder/ Notch Builder]. For Commercial and Educational licenses there is a limit of 2 active blocks at a resolution 1920x1080.",
        "opLicense": "Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Notch",
        "opClass": "notchTOP_Class",
        "opType": "notch",
        "os": "Microsoft Windows",
        "long": "The Notch TOP will load a Notch Block (extension <code>.dfxdll</code>) compiled from [https://www.notch.one/products/notch-builder/ Notch Builder]. For Commercial and Educational licenses there is a limit of 2 active blocks at a resolution 1920x1080.\n\n'''Note: [https://www.wibu.com/support/user/user-software.html CodeMeter Runtime] v7.60+ is now required to load Notch blocks.''' \n\nLoading the Notch Block into the Notch TOP will generate custom parameters for all the exposed properties in the block. They are split up by page, with each page representing a layer of the block. The output layer can be selected using the 'Layer' parameter.\n\nThe custom parameter labels will be generated using the Exposed Name of the exposed property with any special characters or spaces removed. If the Unique Identifier is custom (and not the default auto-generated value) then it will be used as the name of the custom parameter instead. Using a custom Unique Identifier on all exposed properties is recommended for TouchDesigner.\n\nSee also: [[Notch]]",
        "opCategories": ""
    },
    "nullTOP": {
        "label": "nullTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Null TOP has no effect on the image. It is an instance of the TOP connected to its input. The Null TOP is often used when making reference to a TOP network, allowing new TOPs to be added to the network (upstream) without the need to update the reference.",
        "short": "The Null TOP has no effect on the image. It is an instance of the TOP connected to its input.",
        "opLicense": "Non-Commercial",
        "opLabel": "Null",
        "opFilter": "True",
        "opType": "null",
        "opClass": "nullTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "nvidiabackgroundTOP": {
        "label": "nvidiabackgroundTOP",
        "members": [
            {
                "text": "Menu : Select the GPU device to run the AI models on. The GPU must be a Nvidia RTX compatible card.",
                "type": "Par",
                "name": "gpu"
            },
            {
                "text": "Menu : Choose which mode to run the AI model in.",
                "type": "Par",
                "name": "mode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "nvidiabackgroundTOP",
        "opLabel": "Nvidia Background",
        "opClass": "nvidiabackgroundTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This TOP uses the AI Green Screening module from the [https://developer.nvidia.com/maxine Nvidia Maxine Video Effects] engine and requires a 20 or 30 series Nvidia RTX card to operate. 40 series cards are not currently supported.",
        "short": "The Nvidia Background TOP uses AI to generates a monochrome key image that separates a person from the background.",
        "long": "The Nvidia Background TOP performs AI image segmentation to separate a person from the background of a given image. Unlike the [[RGB Key TOP]] or the [[Chroma Key TOP]], the background top uses AI to identify the foreground and background portions of the image and does not require a solid background color. The output of the node is a monochrome key image where white pixels indicate the foreground person and black pixels represent the background. Commonly, this key image is used to replace the background of the source image using the [[Matte TOP]] or other compositing nodes.\n\nDue to the time it takes to run the AI model, the output of the Background TOP will be multiple frames behind the original image when processing a video input. For accurate compositing you will want to match the output key image with the original frame that was used to produce it. An easy way to do this is to use a [[Cache TOP]] with the Output Index set to a negative number of frames. When placed between the source video and the compositor input, this will delay the source image so that it synchronizes with the key image.\n\nTip: The AI model is tuned for a single person sitting in front of a webcam. Videos including full body images, multiple people or indirect camera angles may not perform well.\n\nTip: In addition to selecting Performance using the mode parameter, you can also reduce GPU load by reducing the resolution of the input image. The [[Blur TOP]] and [[Level TOP]] may also be useful to refine the output key image before compositing.",
        "opCategories": ""
    },
    "nvidiadenoiseTOP": {
        "label": "nvidiadenoiseTOP",
        "members": [
            {
                "text": "Menu : Select the GPU device to run the AI models on. The GPU must be a Nvidia RTX compatible card.",
                "type": "Par",
                "name": "gpu"
            },
            {
                "text": "Menu : Choose the type of noise to remove from the source image.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : Choose how much noise to remove from the image. Removing more noise may also remove original details from the source.",
                "type": "Par",
                "name": "strength"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "nvidiadenoiseTOP",
        "opLabel": "Nvidia Denoise",
        "opClass": "nvidiadenoiseTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This TOP uses the [https://developer.nvidia.com/maxine Nvidia Maxine Video Effects] engine and requires a 20 or 30 series Nvidia RTX card to operate. 40 series cards are not currently supported.",
        "short": "The Nvidia Denoise TOP uses AI models to remove different types of noise from a still image or movie.",
        "long": "The Nvidia Denoise TOP uses AI models to remove different types of noise from a still image or movie while retaining original details and crispness. The TOP will reduce different types of noise depending on the setting of the Mode parameter. Each mode can also be set to a low or high strength level to control how much noise is removed. \n\nThe denoising engine only supports videos with a ''width from 80-1920 pixels'' and ''height from 90-1080 pixels''.",
        "opCategories": ""
    },
    "flexTOP": {
        "label": "flexTOP",
        "members": [
            {
                "text": "Menu : The simulation data to return.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "flexTOP",
        "opLabel": "Nvidia Flex",
        "opClass": "flexTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This feature is only available on systems with a Nvidia GPU.",
        "short": "The Nvidia Flex TOP can grab the Nvidia Flex simulation data of an [[Actor COMP]]. The Actor COMP must be in a valid [[Flex|Nvidia Flex]] simulation (ie. controlled by an [[Nvidia Flex Solver COMP]]).",
        "long": "The Nvidia Flex TOP can grab the Nvidia Flex simulation data of an [[Actor COMP]]. The Actor COMP must be in a valid [[Flex|Nvidia Flex]] simulation (ie. controlled by an [[Nvidia Flex Solver COMP]]). \n\n\tThe data will be stored in the texture with each color channel storing a data component. Eg. For positional data the resulting texture is 32-bit float RGBA with x positions in the red channel, y positions in the green channel, and z positions in the blue channel.\n\n\tSee also: [[Flex]], [[Nvidia Flex Solver COMP]], [[Actor COMP]], [[Force COMP]]",
        "opCategories": ""
    },
    "flowTOP": {
        "label": "flowTOP",
        "members": [
            {
                "text": "The position of the simulation volume's center, in the world. The simulation cannot extend outside of the volume.",
                "type": "Par",
                "name": "simpositionx"
            },
            {
                "text": "The position of the simulation volume's center, in the world. The simulation cannot extend outside of the volume.",
                "type": "Par",
                "name": "simpositiony"
            },
            {
                "text": "The position of the simulation volume's center, in the world. The simulation cannot extend outside of the volume.",
                "type": "Par",
                "name": "simpositionz"
            },
            {
                "text": "The size of the simulation volume in the world. The simulation cannot extend outside of the volume. Also controls the size of simulation blocks, so the total number of blocks in the volume stays the same. Smaller size blocks will require more blocks for the same size simulation. This increases accuracy but makes the simulation more taxing on the GPU as there are more blocks to calculate.",
                "type": "Par",
                "name": "simsizex"
            },
            {
                "text": "The size of the simulation volume in the world. The simulation cannot extend outside of the volume. Also controls the size of simulation blocks, so the total number of blocks in the volume stays the same. Smaller size blocks will require more blocks for the same size simulation. This increases accuracy but makes the simulation more taxing on the GPU as there are more blocks to calculate.",
                "type": "Par",
                "name": "simsizey"
            },
            {
                "text": "The size of the simulation volume in the world. The simulation cannot extend outside of the volume. Also controls the size of simulation blocks, so the total number of blocks in the volume stays the same. Smaller size blocks will require more blocks for the same size simulation. This increases accuracy but makes the simulation more taxing on the GPU as there are more blocks to calculate.",
                "type": "Par",
                "name": "simsizez"
            },
            {
                "text": "Gravity direction for use with Buoyancy parameter, where amount controls strength of buoyancy force.",
                "type": "Par",
                "name": "gravityx"
            },
            {
                "text": "Gravity direction for use with Buoyancy parameter, where amount controls strength of buoyancy force.",
                "type": "Par",
                "name": "gravityy"
            },
            {
                "text": "Gravity direction for use with Buoyancy parameter, where amount controls strength of buoyancy force.",
                "type": "Par",
                "name": "gravityz"
            },
            {
                "text": "The position of the simulation volume's center, in the world. The simulation cannot extend outside of the volume.",
                "type": "Par",
                "name": "simpositionx"
            },
            {
                "text": "The position of the simulation volume's center, in the world. The simulation cannot extend outside of the volume.",
                "type": "Par",
                "name": "simpositiony"
            },
            {
                "text": "The position of the simulation volume's center, in the world. The simulation cannot extend outside of the volume.",
                "type": "Par",
                "name": "simpositionz"
            },
            {
                "text": "The size of the simulation volume in the world. The simulation cannot extend outside of the volume. Also controls the size of simulation blocks, so the total number of blocks in the volume stays the same. Smaller size blocks will require more blocks for the same size simulation. This increases accuracy but makes the simulation more taxing on the GPU as there are more blocks to calculate.",
                "type": "Par",
                "name": "simsizex"
            },
            {
                "text": "The size of the simulation volume in the world. The simulation cannot extend outside of the volume. Also controls the size of simulation blocks, so the total number of blocks in the volume stays the same. Smaller size blocks will require more blocks for the same size simulation. This increases accuracy but makes the simulation more taxing on the GPU as there are more blocks to calculate.",
                "type": "Par",
                "name": "simsizey"
            },
            {
                "text": "The size of the simulation volume in the world. The simulation cannot extend outside of the volume. Also controls the size of simulation blocks, so the total number of blocks in the volume stays the same. Smaller size blocks will require more blocks for the same size simulation. This increases accuracy but makes the simulation more taxing on the GPU as there are more blocks to calculate.",
                "type": "Par",
                "name": "simsizez"
            },
            {
                "text": "Gravity direction for use with Buoyancy parameter, where amount controls strength of buoyancy force.",
                "type": "Par",
                "name": "gravityx"
            },
            {
                "text": "Gravity direction for use with Buoyancy parameter, where amount controls strength of buoyancy force.",
                "type": "Par",
                "name": "gravityy"
            },
            {
                "text": "Gravity direction for use with Buoyancy parameter, where amount controls strength of buoyancy force.",
                "type": "Par",
                "name": "gravityz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "flowTOP",
        "opLabel": "Nvidia Flow",
        "opClass": "flowTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This operator only works with '''Nvidia GPUs'''.",
        "short": "The Nvidia Flow TOP calculates the Flow simulation and renders it.",
        "long": "NVIDIA Flow is a volumetric fluid based simulation of a burning gas system. The user controls the 3 main factors of temperature, fuel, and smoke to create fire and smoke simulations. \n\nThe Nvidia Flow TOP calculates the Flow simulation and renders it. It requires a [[Nvidia Flow Emitter COMP]] to emit gas into the Flow simulation. \n\nSee also [[Nvidia Flow Emitter COMP]], [[Nvidia Flow]].\n\nRead more here [https://docs.nvidia.com/gameworks/content/artisttools/Flow/index.html Nvidia Flow Artist Tools]",
        "opCategories": ""
    },
    "nvidiaupscalerTOP": {
        "label": "nvidiaupscalerTOP",
        "members": [
            {
                "text": "Menu : Select the GPU device to run the AI models on. The GPU must be a Nvidia RTX compatible card.",
                "type": "Par",
                "name": "gpu"
            },
            {
                "text": "Menu : Choose the mode (Upscale or Super-Resolution) and factor by which the resolution will increase.",
                "type": "Par",
                "name": "mode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "nvidiaupscalerTOP",
        "opLabel": "Nvidia Upscaler",
        "opClass": "nvidiaupscalerTOP_Class",
        "opFilter": "True",
        "opLicense": "TouchDesigner Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This TOP uses the [https://developer.nvidia.com/maxine Nvidia Maxine Video Effects] engine and requires a 20 series or later Nvidia card to operate.",
        "short": "The Nvidia Upscaler TOP upscales the resolution of an input video.",
        "long": "The Nvidia Upscaler TOP upscales the resolution of an input video. It can run either the [https://docs.nvidia.com/deeplearning/maxine/vfx-sdk-programming-guide/index.html#upscale-filter Upscale Filter] or [https://docs.nvidia.com/deeplearning/maxine/vfx-sdk-programming-guide/index.html#super-res-filter Super-Resolution Filter]. The Upscale Filter is faster and offers a Strength parameter. The Super Resolution mode is higher quality and doesn't offer a Strength parameter, but it does have an optional Artifact Reduction toggle. Refer to the Table [https://docs.nvidia.com/deeplearning/maxine/vfx-sdk-programming-guide/index.html#upscale-filter Scale and Resolution Support for Input Videos] for the requirements of the input resolution.",
        "opCategories": ""
    },
    "oakselectTOP": {
        "label": "oakselectTOP",
        "members": [
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "outputindexunit"
            },
            {
                "text": "Menu : TouchDesigner can apply basic image-processing that depthai does not yet do. For example, if the Output Format is \"Point Cloud\", the stream is a depth stream, and the stream name contains \"depth\", then the image in the OAK Select will be a 32-bit XYZ point cloud derived from the depth image and the camera's intrinsic matrix.",
                "type": "Par",
                "name": "outputformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "oakselectTOP",
        "opLabel": "OAK Select",
        "opClass": "oakselectTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "Receives image streams from the OAK Camera",
        "long": "The OAK Select can receive images of many different formats from the OAK Camera. These formats include RGB, monochrome, depth images, and XYZ [[Point Clouds]].\n    \nSee Also: [[OAK-D]] [[OAK Device CHOP]] [[OAK Select CHOP]]"
    },
    "oculusriftTOP": {
        "label": "oculusriftTOP",
        "members": [
            {
                "text": "Menu : Select what will be displayed in the debug HUD in the headset.",
                "type": "Par",
                "name": "debugperfhud"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Oculus Rift TOP connects to an [[Oculus Rift]] device and applies a distortion to input textures based on the device's calibration parameters. There are separate inputs for each eye.\t\t\n\t\t\t\nSee also [[Oculus Rift]]",
        "short": "The Oculus Rift TOP connects to an [[Oculus Rift]] device and applies a distortion to input textures based on the device's calibration parameters.",
        "opLicense": "Non-Commercial",
        "opLabel": "Oculus Rift",
        "opFilter": "True",
        "opType": "oculusrift",
        "opClass": "oculusriftTOP_Class",
        "opFamily": "TOP",
        "os": "Microsoft Windows",
        "opCategories": ""
    },
    "opviewerTOP": {
        "label": "opviewerTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The OP Viewer TOP can display the [[Node Viewer]] for any other operator as a TOP image. If the operator source is a [[Panel Component]], panel interaction through the TOP image is also supported.",
        "short": "The OP Viewer TOP can display the [[Node Viewer]] for any other operator as a TOP image.",
        "opLicense": "Non-Commercial",
        "opLabel": "OP Viewer",
        "opFilter": "False",
        "opType": "opview",
        "opClass": "opviewerTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "opencolorioTOP": {
        "label": "opencolorioTOP",
        "members": [
            {
                "text": "Menu : Interpolation method of the file.",
                "type": "Par",
                "name": "interpolation"
            },
            {
                "text": "Menu : The direction of the transform. To invert the transform, select Inverse.",
                "type": "Par",
                "name": "filedirection"
            },
            {
                "text": "Menu : Color Decision List - Select this transform's effect on the image, either manually using parameter values or using a color correction file (.cc). https://en.wikipedia.org/wiki/ASC_CDL",
                "type": "Par",
                "name": "cdlmode"
            },
            {
                "text": "Adjust the gain.",
                "type": "Par",
                "name": "slopex"
            },
            {
                "text": "Adjust the gain.",
                "type": "Par",
                "name": "slopey"
            },
            {
                "text": "Adjust the gain.",
                "type": "Par",
                "name": "slopez"
            },
            {
                "text": "Adjust the offset.",
                "type": "Par",
                "name": "offsetx"
            },
            {
                "text": "Adjust the offset.",
                "type": "Par",
                "name": "offsety"
            },
            {
                "text": "Adjust the offset.",
                "type": "Par",
                "name": "offsetz"
            },
            {
                "text": "Adjust the gamma.",
                "type": "Par",
                "name": "powerx"
            },
            {
                "text": "Adjust the gamma.",
                "type": "Par",
                "name": "powery"
            },
            {
                "text": "Adjust the gamma.",
                "type": "Par",
                "name": "powerz"
            },
            {
                "text": "Menu : The direction of the transform. To invert the transform, select Inverse.",
                "type": "Par",
                "name": "cdldirection"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The OpenColorIO TOP utilizes the OpenColorIO library (http://opencolorio.org/) to apply various transforms and lookup tables to your textures and images. The default order that the transforms are applied is: Color Space, File, CDL, Output (Display).<br><br>\t\t\nThis order can be changed using multiple OpenColorIO TOPs in a chain, with any unnecessary transforms toggled off.\t<br><br>\nThe color space of TouchDesigner TOPs is linear, so generally, images inported to TouchDesigner have to be converted to linear, if they are non-linearly encoded.",
        "short": "The OpenColorIO TOP utilizes the OpenColorIO library (http://opencolorio.org/) to apply various transforms and lookup tables to your textures and images.",
        "opLicense": "Non-Commercial",
        "opLabel": "OpenColorIO",
        "opFilter": "True",
        "opType": "ocio",
        "opClass": "opencolorioTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "openvrTOP": {
        "label": "openvrTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The OpenVR TOP takes two images, one for the left eye and one for the right eye, and outputs it to the connected VR device. You usually want to have SteamVR running when using the OpenVR TOP, to ensure everything is connected and functioning properly.\n\nSee also [[OpenVR]], [[OpenVR CHOP]], [[OpenVR SOP]], [[Audio Render CHOP]]",
        "short": "See also [[OpenVR]], [[OpenVR CHOP]], [[OpenVR SOP]], [[Audio Render CHOP]]",
        "opLicense": "Non-Commercial",
        "opLabel": "OpenVR",
        "opFilter": "True",
        "opType": "openvr",
        "opClass": "openvrTOP_Class",
        "opFamily": "TOP",
        "os": "Microsoft Windows",
        "opCategories": ""
    },
    "opticalflowTOP": {
        "label": "opticalflowTOP",
        "members": [
            {
                "text": "Menu : Determines the output resolution. A smaller grid corresponds to a larger output image. [https://en.wikipedia.org/wiki/Turing_(microarchitecture) Turing GPUs] only support `4x4`, whereas newer GPUs can use any option.",
                "type": "Par",
                "name": "gridsize"
            },
            {
                "text": "Menu : Specify the optical flow model. Higher quality is slower to compute, and low quality is faster to compute.",
                "type": "Par",
                "name": "quality"
            },
            {
                "text": "A post-multiply for the optical flow in the RG channels, allowing control of output intensity.",
                "type": "Par",
                "name": "gainx"
            },
            {
                "text": "A post-multiply for the optical flow in the RG channels, allowing control of output intensity.",
                "type": "Par",
                "name": "gainy"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "opticalflowTOP",
        "opLabel": "Optical Flow",
        "opClass": "opticalflowTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "os": "Microsoft Windows",
        "hardware": "This operator currently only works with '''Nvidia GPUs'''.",
        "short": "",
        "long": "Optical Flow detects patterns of motion in its input. The motion detected in the X-direction is output in the red (R) channel, while the motion in the Y-direction is output in the green (G) channel.\n    \nThe pixel values stored in the red and green channels are 32-bit floating point numbers. A value of 1.0 in a pixel of the red channel means that the horizontal motion of what is at that part of the image is moving left-to-right at 1 screen-width per second. In a 16x9 image, a green value of 1.0 at that pixel means the motion is upward at 1 screen-width per second, or 1 * 16/9 = 1.77 times the screen height per second.\n \nThe values can be scaled with the Gain parameters. The TOP can drive forces in the particlesGpu component."
    },
    "ousterselectTOP": {
        "label": "ousterselectTOP",
        "members": [
            {
                "text": "Menu : Use this parameter to determine how data is arranged in the output image. The layout of data is generally not important when used as a point cloud.",
                "type": "Par",
                "name": "layout"
            },
            {
                "text": "Menu : Select what sensor data will be placed into the red channel of the output image.",
                "type": "Par",
                "name": "redchannel"
            },
            {
                "text": "Menu : Select what sensor data will be placed into the green channel of the output image.",
                "type": "Par",
                "name": "greenchannel"
            },
            {
                "text": "Menu : Select what sensor data will be placed into the blue channel of the output image.",
                "type": "Par",
                "name": "bluechannel"
            },
            {
                "text": "Menu : Select what sensor data will be placed into the alpha channel of the output image.",
                "type": "Par",
                "name": "alphachannel"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "ousterselectTOP",
        "opLabel": "Ouster Select",
        "opClass": "ousterselectTOP_Class",
        "opFilter": "False",
        "opLicense": "Commercial",
        "short": "The Ouster Select TOP can be used to create additional output images from sensor data collected by an [[Ouster TOP]].",
        "long": "The Ouster Select TOP can be used to create additional output images from sensor data collected by an [[Ouster TOP]]. Each output image contains 4 channels of 32bit floating point data encoded into the red, green, blue and alpha channels of the image. Available sensor data channels include: Range, Intensity, Reflectivity and Noise as well as 3D XYZ position values. Raw range data is measured in millimeters, while XYZ positions are calculated using a table of beam azimuth and altitude angles and then converted to meters.\n    \nSee also: [[Ouster TOP]]",
        "opCategories": ""
    },
    "ousterTOP": {
        "label": "ousterTOP",
        "members": [
            {
                "text": "Menu : Select a scanning mode to set the sensor's horizontal resolution and number of revolutions per second. The vertical resolution is determined by the hardware e.g. an OS1-64 sensor has vertical resolution of 64 pixels (samples).",
                "type": "Par",
                "name": "scanmode"
            },
            {
                "text": "Menu : Use this parameter to determine how data is arranged in the output image. The layout of data is generally not important when used as a point cloud.",
                "type": "Par",
                "name": "layout"
            },
            {
                "text": "Menu : Select what sensor data will be placed into the red channel of the output image.",
                "type": "Par",
                "name": "redchannel"
            },
            {
                "text": "Menu : Select what sensor data will be placed into the green channel of the output image.",
                "type": "Par",
                "name": "greenchannel"
            },
            {
                "text": "Menu : Select what sensor data will be placed into the blue channel of the output image.",
                "type": "Par",
                "name": "bluechannel"
            },
            {
                "text": "Menu : Select what sensor data will be placed into the alpha channel of the output image.",
                "type": "Par",
                "name": "alphachannel"
            },
            {
                "text": "Menu : Select how the sensor generates timestamp information.",
                "type": "Par",
                "name": "timemode"
            },
            {
                "text": "Menu : The polarity of the SYNC_PULSE_IN signal to use.",
                "type": "Par",
                "name": "pulseinpolarity"
            },
            {
                "text": "Menu : Determines how the sensor uses the SYNC_PULSE_OUT signal.",
                "type": "Par",
                "name": "iomode"
            },
            {
                "text": "Menu : Polarity of the output signal pulse.",
                "type": "Par",
                "name": "pulseoutpolarity"
            },
            {
                "text": "Menu : Sets the polarity of the NMEA URT input $GPRMC messages. Set to 'Active High' if UART is active high, idle low, and the start bit is after a falling edge.",
                "type": "Par",
                "name": "nmeainpolarity"
            },
            {
                "text": "Menu : The baud rate for the incoming NMEA URT input $GPRMC messages.",
                "type": "Par",
                "name": "nmeabaudrate"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "ousterTOP_Class",
        "short": "The Ouster TOP is used to send and receive data with an Ouster Imaging Lidar.",
        "opFilter": "False",
        "opLabel": "Ouster",
        "opFamily": "TOP",
        "opType": "ouster",
        "opLicense": "Commercial",
        "long": "[[Ouster]] makes LIDAR devices for scanning 3D environments. The [[Ouster TOP]] sends and receives data with an Ouster Imaging Lidar, converting to point cloud data on the GPU. For more information see the user guides at [https://www.ouster.io/resources Ouster.io]\n\n'''Requirements:'''\n* The TOP currently supports Ouster devices using version 2.0 firmware or higher. \n* Access to your local network to connect with the sensor device. Check your firewall settings if you have trouble accessing the device.\n* High resolution scanning modes require up to 130Mbps of bandwidth. Gigabit Ethernet hardware is required for full operation. Insufficient bandwidth will cause broken images and missing frames.\n\n'''Features include:'''\n* Additional sensor data like IMU (Inertial Measurement Unit - the gyroscope and accelerometer), packet counts, matrices via Info CHOP and Info DAT.\n* Visual Panoramic and Scan Order capture formats selectable in 'Image Layout' parameter.\n* Flexible X, Y, Z, Range, Intensity and Noise plane mapping to RGBA GPU Image Channels\n* Time Sync Mode for supporting multiple devices in the same area (Internal OSC, Sync Pulse In, PTP 1588)\n* Auto startup features\n\n'''Connection Instructions:'''</br>\nTo connect to the sensor, you will need either the IP addressed assigned by the local DHCP server or the name of the device. The name is based on the serial number that is usually printed on the top of the sensor in the format \"os-############\". This name can be entered directly into the Device Address parameter (see parameter help below). You can also connect to the device through a web browser using the IP or name in the format <code>http://os-###########/</code>. The web interface allows you to check the status of the device and gives additional error information.\n\nOnce the device is configured, it will continue to send output to the target IP address so it is not required to enter the device address again unless you need to change the configuration.\n\nRange data collected from the device is presented as 32bit floating point values in the RGBA channels of the output image. Output can be arranged either in chronological scan order or as a panoramic image using the Image Layout parameter. IMU data from the device can be accessed by connecting an [[Info CHOP]]. If more than 4 output channels are needed, you can use a [[Ouster Select TOP]] to create additional output images.\n\n'''Note:''' All 3D coordinates are transformed into TouchDesigner space where Y is up and X and Z represent the ground plane. This is different from the original coordinate space defined in the Ouster documentation.\n\nThe lookup tables used to convert the range values into 3D points can be accessed with an [[Info DAT]].\n\nSee also: [[Ouster Select TOP]]",
        "opCategories": ""
    },
    "outTOP": {
        "label": "outTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Out TOP is used to create a TOP output in a Component. Component outputs are positioned alphanumerically on the right side of the Component.",
        "short": "The Out TOP is used to create a TOP output in a Component.",
        "opLicense": "Non-Commercial",
        "opLabel": "Out",
        "opFilter": "True",
        "opType": "out",
        "opClass": "outTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "outsideTOP": {
        "label": "outsideTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]]",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Outside TOP places Input1 'outside' Input2. Input1 is visible in the output wherever Input2's alpha is &lt;1. This is the opposite operation to the Inside TOP.",
        "short": "The Outside TOP places Input1 'outside' Input2.",
        "opLicense": "Non-Commercial",
        "opLabel": "Outside",
        "opFilter": "True",
        "opType": "outside",
        "opClass": "outsideTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "overTOP": {
        "label": "overTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]]",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Over TOP places Input1 'over' Input2. The alpha of Input1 is used to determine what parts of the Input2 image are visible in the result.",
        "short": "The Over TOP places Input1 'over' Input2.",
        "opLicense": "Non-Commercial",
        "opLabel": "Over",
        "opFilter": "True",
        "opType": "over",
        "opClass": "overTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "packTOP": {
        "label": "packTOP",
        "members": [
            {
                "text": "Menu : Controls the direction and behavior of the packing/unpacking.",
                "type": "Par",
                "name": "packtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Pack TOP can be used to pack 32-bit floating point values into a larger 8-bit texture, so it can saved in a lossless format such as .tiff or Animation codec. The Pack TOP can then later be used to unpack these values back to 32-bit floats. This is useful for things such as point cloud data from the [[Kinect TOP]], or [[RealSense TOP]].",
        "short": "The Pack TOP can be used to pack 32-bit floating point values into a larger 8-bit texture, so it can saved in a lossless format such as .tiff or Animation codec.",
        "opLicense": "Non-Commercial",
        "opLabel": "Pack",
        "opFilter": "True",
        "opType": "pack",
        "opClass": "packTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "photoshopinTOP": {
        "label": "photoshopinTOP",
        "members": [
            {
                "text": "Menu : Determines what format the Photoshop stream is transferred with.",
                "type": "Par",
                "name": "imageformat"
            },
            {
                "text": "Menu : Determines how the image is updated.",
                "type": "Par",
                "name": "updatemode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Photoshop In TOP can stream the output from Photoshop into TouchDesigner.  Photoshop can be running on the same computer as TouchDesigner or any other computer on the network.  Photoshop can be running on a Windows or Mac computer.  If the <span class=\"tipTextTOP\">Lock Document Name</span> parameter is left empty, then the TOP will grab whichever document is currently active in Photoshop.\n\t\t\t\n===<div class=\"subSectionLineTOP\">Photoshop Setup</div>===\t\t\t\n\t\t\t\nTo connect to the Photoshop In TOP, a remote connection must be setup in the Photoshop application.\t\t\t\n\t\t\t \n# Open a file in Photoshop.\t\t\t\n# Under the '''Edit''' menu, select '''Remote Connections...'''\t\t\t\n# In the dialog that opens, enter a '''Service Name''' and '''Password'''.  Then turn on the '''Enable Remote Connections''' checkbox.\t\t\t\n# Photoshop is now ready to connect to TouchDesigner.  The image below shows the Remote Connections dialog in Photoshop.\t\t\t\n\t\t\t\n\t\t\t\n[[image:RemoteConnections.png]].",
        "short": "The Photoshop In TOP can stream the output from Photoshop into TouchDesigner.",
        "opLicense": "Non-Commercial",
        "opLabel": "Photoshop In",
        "opFilter": "False",
        "opType": "photoshopin",
        "opClass": "photoshopinTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "pointfileinTOP": {
        "label": "pointfileinTOP",
        "members": [
            {
                "text": "Menu : Select one of the available point data channels to place it into the red channel of the output image. Selecting One or Zero will place the constance value into the output channel.",
                "type": "Par",
                "name": "red"
            },
            {
                "text": "Menu : Select one of the available point data channels to place it into the green channel of the output image. Selecting One or Zero will place the constance value into the output channel.",
                "type": "Par",
                "name": "green"
            },
            {
                "text": "Menu : Select one of the available point data channels to place it into the blue channel of the output image. Selecting One or Zero will place the constance value into the output channel.",
                "type": "Par",
                "name": "blue"
            },
            {
                "text": "Menu : Select one of the available point data channels to place it into the alpha channel of the output image. Selecting One or Zero will place the constance value into the output channel.",
                "type": "Par",
                "name": "alpha"
            },
            {
                "text": "Menu : Specifies the method used to play the animation, there are 3 options.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "cuepointunit"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "cuebehavior"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "indexunit"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "loopcrossfadeunit"
            },
            {
                "text": "Menu : This menu helps you determine how to treat the audio as the end of an animation approaches. This is needed because in some cases of playing an animation, like when driving with an index, the TOP will not know if you intend to loop it or not.",
                "type": "Par",
                "name": "audioloop"
            },
            {
                "text": "Menu : Determines how a file sequence is ordered.",
                "type": "Par",
                "name": "imageindexing"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "loadingerrorimage"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "tstartunit"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "tendunit"
            },
            {
                "text": "Menu : Determines how the Point File In TOP handles animation positions that lie before the Trim Start position. For example, if Trim Start is set to 1, and the animation's current index is -10, the Extend Left menu determines how the animation position is calculated.",
                "type": "Par",
                "name": "textendleft"
            },
            {
                "text": "Menu : Determines how the Point File In TOP handles animation positions that lie after the Trim End position. For example, if Trim End is set to 20, and the animation's current index is 25, the Extend Right menu determines how the movie position is calculated.",
                "type": "Par",
                "name": "textendright"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "frametimeoutstrat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "pointfileinTOP",
        "opLabel": "Point File In",
        "opClass": "pointfileinTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Point File In TOP loads 3D point data into TOPs from either a single file or a sequence of files.",
        "long": "The Point File In TOP loads 3D point data into TOPs from either a single file or a sequence of files. Points are composed of one or more floating point values such as XYZ positions, RGB color values, 3D normals, scanner intensity, etc. The Point File in TOP will load all available point data, but only four channels can be placed into the output image. By default, the first four point data channels are placed into the red, green, blue and alpha channels respectively; however, you can assign any point channel to a colour channel using the parameters on the Point Data page. Attach a [[Point File Select TOP]] to create additional output images from the same source file.\n        \nThe Point File In TOP will read point data from various mesh and floating point data files including: <code>.obj</code>, <code>.ply</code>, <code>.fits</code> (astronomy format), and <code>.exr</code>. It can also load ASCII point files (<code>.xyz</code>, <code>.pts</code>, <code>.csv</code>, <code>.txt</code>, etc) with one point per line and comma or space separated fields. The first line in ASCII point files can either be the number of points, the names of the point fields or the first point in the file.\n\nFor a complete list, see [[File Types]]. The [[OpenEXR]] file format is generally best to use as it is binary, can be read in multi-frame file sequences that uses TouchDesigner's movie file pre-reading and buffering, and can be written from TouchDesigner's [[Movie File Out TOP]] with unlimited numbers of channels.\n\t\t\t\nExamine the state of a Point File In TOP by attaching an [[Info CHOP]]. This will show information like the number of points, fields per point and the number of frames. It also shows dynamic information like the file open status, current frame, readahead frames and queue size, dropped frame count, CPU decode time and GPU upload time.\n\n'''Headers''': If the file contains any additional header data, this can be viewed by attaching an [[Info DAT]]. Header data is stored as key-value pairs with the keys in the first column and the corresponding data in the second column, which can easily be interpreted with python.\n\nAll of the ASCII point list formats are loaded the same way whether their extention is <code>txt</code>, <code>csv</code>, <code>xyz</code>, etc.  The parser looks for the first separating character (comma, space or tab) and then uses that to delimit the rest of the file. It will ignore delimiters that are inside single or double quotes. There are a few special rules depending on the delimiter style e.g. multiple spaces are merged together, but a comma at the end of a line indicates a blank field afterwards. Once a delimiter is established, The first line can be the number of points, but it is ignored. If the next line are strings then it is treated as a row of headers (channel names). Each row after that is considered a point.\n\nSee also [[OpenEXR]].",
        "opCategories": ""
    },
    "pointfileselectTOP": {
        "label": "pointfileselectTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "pointfileselectTOP",
        "opLabel": "Point File Select",
        "opClass": "pointfileselectTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Point File Select TOP allows you to create additional output images from a point file loaded into a [[Point File In TOP]].",
        "long": "The Point File Select TOP allows you to create additional output images from a point file loaded into a [[Point File In TOP]]. This TOP is useful if your point data file has more than 4 channels e.g. XYZ position and RGB colors. It is more efficient to use a Point File Select TOP rather than a second [[Point File In TOP]] since the file will only be loaded once.",
        "opCategories": ""
    },
    "pointtransformTOP": {
        "label": "pointtransformTOP",
        "members": [
            {
                "text": "Menu : Choose if the RGB channels of the input texture should be treated as positions or vectors. Vectors will not have the translation portion of the transform applied to them, and can be normalized before and/or after the transformation is applied.",
                "type": "Par",
                "name": "inputtype"
            },
            {
                "text": "Menu : Changes the order that the translate, rotate and scale operations are performed on the input. Analogous to how you would end up in different locations if you were to move a block and turn east, versus turning east and then moving a block.  In matrix math terms, if we use the 'multiply vector on the right' (column vector) convention, a transform order of Scale, Rotate, Translate would be written as T * R * S * Position",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : As with transform order (above), changing the order in which the rotations take place will alter the final position and orientation. A Rotation order of Rx Ry Rz would create the final rotation matrix as follows R = Rz * Ry * Rx",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "Move the input positions in the X, Y and Z axes. If the input is set to 'Vector', the translate values will have no effect.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Move the input positions in the X, Y and Z axes. If the input is set to 'Vector', the translate values will have no effect.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Move the input positions in the X, Y and Z axes. If the input is set to 'Vector', the translate values will have no effect.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Rotate the input RGB values around the corresponding X, Y and Z axes. Angles are given in degrees.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "Rotate the input RGB values around the corresponding X, Y and Z axes. Angles are given in degrees.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "Rotate the input RGB values around the corresponding X, Y and Z axes. Angles are given in degrees.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "Scale the input RGB values in the corresponding X, Y and Z axes. If 'Normalize Output' is on, then all output values will be rescaled to a length of one regardless of the scale values.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scale the input RGB values in the corresponding X, Y and Z axes. If 'Normalize Output' is on, then all output values will be rescaled to a length of one regardless of the scale values.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Scale the input RGB values in the corresponding X, Y and Z axes. If 'Normalize Output' is on, then all output values will be rescaled to a length of one regardless of the scale values.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "The pivot is the point about which the input points or vectors are scaled and rotated. Altering the pivot point produces different results depending on the transformation performed on the object.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "The pivot is the point about which the input points or vectors are scaled and rotated. Altering the pivot point produces different results depending on the transformation performed on the object.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "The pivot is the point about which the input points or vectors are scaled and rotated. Altering the pivot point produces different results depending on the transformation performed on the object.",
                "type": "Par",
                "name": "pz"
            },
            {
                "text": "When orienting an object towards the 'Look At' target, the Up Vector is used to determine where the positive Y axis points.",
                "type": "Par",
                "name": "upvectorx"
            },
            {
                "text": "When orienting an object towards the 'Look At' target, the Up Vector is used to determine where the positive Y axis points.",
                "type": "Par",
                "name": "upvectory"
            },
            {
                "text": "When orienting an object towards the 'Look At' target, the Up Vector is used to determine where the positive Y axis points.",
                "type": "Par",
                "name": "upvectorz"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "forwarddir"
            },
            {
                "text": "Menu : Controls whether the transformation from the given CHOP is applied to the input values before or after the transformation describe by this node.",
                "type": "Par",
                "name": "multiplyorder"
            },
            {
                "text": "Menu : Select how to use the colors of the second input image as weights for transforming the points of the first input.",
                "type": "Par",
                "name": "weightchannel"
            },
            {
                "text": "Set the range of weight values used to control how much of the transformation is applied to a point. Points with the minimum weight will '''not''' be transformed, while points with the maximum weight will be '''fully''' transformed. A linear interpolation is applied to points with weights that fall between the minimum and maximum.",
                "type": "Par",
                "name": "weightrange1"
            },
            {
                "text": "Set the range of weight values used to control how much of the transformation is applied to a point. Points with the minimum weight will '''not''' be transformed, while points with the maximum weight will be '''fully''' transformed. A linear interpolation is applied to points with weights that fall between the minimum and maximum.",
                "type": "Par",
                "name": "weightrange2"
            },
            {
                "text": "Menu : Determines the order that align operations are performed on the input points. '''Note''': Unlike Scaling on the transform page, the alignment scale is always done relative to the center of the point cloud so that the point cloud's center does not change.",
                "type": "Par",
                "name": "alignxformorder"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alignopord"
            },
            {
                "text": "Menu : Determines the final position of points along the X axis i.e. shifts values in the red channel.",
                "type": "Par",
                "name": "aligntx"
            },
            {
                "text": "Menu : Determines how the points are aligned relative to the dimensions of the input points.",
                "type": "Par",
                "name": "fromx"
            },
            {
                "text": "Menu : Determines how the final points are aligned relative to the reference node.",
                "type": "Par",
                "name": "tox"
            },
            {
                "text": "Menu : Determines the final position of points along the Y axis i.e. shifts values in the green channel.",
                "type": "Par",
                "name": "alignty"
            },
            {
                "text": "Menu : Determines how the points are aligned relative to the dimensions of the input points.",
                "type": "Par",
                "name": "fromy"
            },
            {
                "text": "Menu : Determines how the final points are aligned relative to the reference node.",
                "type": "Par",
                "name": "toy"
            },
            {
                "text": "Menu : Determines the final position of points along the Z axis i.e. shifts values in the blue channel.",
                "type": "Par",
                "name": "aligntz"
            },
            {
                "text": "Menu : Determines how the points are aligned relative to the dimensions of the input points.",
                "type": "Par",
                "name": "fromz"
            },
            {
                "text": "Menu : Determines how the final points are aligned relative to the reference node.",
                "type": "Par",
                "name": "toz"
            },
            {
                "text": "Menu : The Align Scale can be used to resize the point cloud to fit inside the given bounds. Scaling can be done per axis (maintaining proportions or stretching), or on all axes.",
                "type": "Par",
                "name": "alignscale"
            },
            {
                "text": "Menu : The point cloud is resized based on its width in the X axis.",
                "type": "Par",
                "name": "alignscalex"
            },
            {
                "text": "Menu : The point cloud is resized based on its height in the Y axis.",
                "type": "Par",
                "name": "alignscaley"
            },
            {
                "text": "Menu : The point cloud is resized based on its depth in the Z axis.",
                "type": "Par",
                "name": "alignscalez"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "pointtransformTOP",
        "opLabel": "Point Transform",
        "opClass": "pointtransformTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Point Transform TOP treats the RGB values of the input image as a point cloud of XYZ positions or vectors and performs 3D transformations and alignments.",
        "long": "The Point Transform TOP treats the RGB values of the input image as a point cloud of XYZ positions or vectors and performs 3D transformations and alignments. When the input type is set to 'Vector', translations are ignored and only rotation and scaling operations are performed. The alpha channel, if present, is passed along to the output image unchanged.\n\nTransformations can be defined directly on the Transform page, taken from an input CHOP (see [[Transform CHOP]]), using the Look At parameter, or as a combination of any of those methods.\n\nThe Align page allows you to move or scale the point cloud relative to the origin, a 1x1x1 cube, or to a reference object. For example, you can scale the cloud to fit inside another point cloud or piece of geometry, or you can align the point cloud to sit on the XZ plane, or directly beside another cloud.\n\nThe second input can optionally be used as a weight map to control how much of the transformation is applied to each individual point.",
        "opCategories": ""
    },
    "prefiltermapTOP": {
        "label": "prefiltermapTOP",
        "members": [
            {
                "text": "Menu : Select between calculating the PreFilter for the Diffuse Map or Specular Map.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The PreFilter TOP uses spherical harmonics to calculate a Pre-Filtered Diffuse Map or Pre-Filtered Specular Map for use in the [[Environment Light COMP]].\nThe output of the PreFilter Map TOP can not have further processing done to them before being used by the Environment Light.",
        "short": "The PreFilter TOP calculates a Pre-Filtered Diffuse Map or Pre-Filtered Specular Map for use in the Environment Light COMP.",
        "opLicense": "Non-Commercial",
        "opLabel": "PreFilter Map",
        "opFilter": "True",
        "opType": "prefiltermap",
        "opClass": "prefiltermapTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "projectionTOP": {
        "label": "projectionTOP",
        "members": [
            {
                "text": "Menu : At this time the only option is a Cube Map input. You can generate a Cube Map by rendering one using the [[Render TOP]], or converting 2D images into one using the [[Cube Map TOP]].",
                "type": "Par",
                "name": "input"
            },
            {
                "text": "Menu : Select output format from the menu.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Use this parameter to rotate the map on any axis.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "Use this parameter to rotate the map on any axis.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "Use this parameter to rotate the map on any axis.",
                "type": "Par",
                "name": "rz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Projection TOP takes an image, often created with a [[Render TOP]], in a [[Cube Map]], Equirectangular, Fish Eye or Dual Paraboloid format, and converts that to a Fisheye or Equirectangular projection suitable for domes, or a Cube Map format. For Equirectangular images, u-v horizontal-vertical is the latitude-longitude, suitable for spheres. This produces superior-quality when it's based on the cube maps.\t\t\n\t\t\t\nFor every pixel of output, it takes one sample from the input cube map. Better anti-aliasing may be achieved by rendering double-resolution and scaling down to your desired resolution with the High Quality Resize option of the [[Resolution TOP]]\n\nWhen converting to a Equirectangular image, it is recommended you set the output resolution to a 2x1 aspect ratio, like 4096x2038. Fish Eyes are best output as a 1x1 aspect ratio.\t\t\t\n\t\t\t\n[[Image:ProjectionTOP.2.jpg|800px]]",
        "short": "TThe Projection TOP takes an image, often created with a [[Render TOP]], in a [[Cube Map]], Equirectangular, Fish Eye or Dual Paraboloid format, and converts that to a Fisheye or Equirectangular projection suitable for domes, or a Cube Map format. For Equirectangular images, u-v horizontal-vertical is the latitude-longitude, suitable for spheres. This produces superior-quality when it's based on the cube maps.",
        "opLicense": "Non-Commercial",
        "opLabel": "Projection",
        "opFilter": "True",
        "opType": "projection",
        "opClass": "projectionTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "rampTOP": {
        "label": "rampTOP",
        "members": [
            {
                "text": "The color and alpha of each ramp keyframe can be set here. Select between an HSV or RGB colorpicker, or click the \"+\" button to open a color dialog box with predefined colors.",
                "type": "Par",
                "name": "color1"
            },
            {
                "text": "The color and alpha of each ramp keyframe can be set here. Select between an HSV or RGB colorpicker, or click the \"+\" button to open a color dialog box with predefined colors.",
                "type": "Par",
                "name": "color2"
            },
            {
                "text": "The color and alpha of each ramp keyframe can be set here. Select between an HSV or RGB colorpicker, or click the \"+\" button to open a color dialog box with predefined colors.",
                "type": "Par",
                "name": "color3"
            },
            {
                "text": "The color and alpha of each ramp keyframe can be set here. Select between an HSV or RGB colorpicker, or click the \"+\" button to open a color dialog box with predefined colors.",
                "type": "Par",
                "name": "color4"
            },
            {
                "text": "Menu : The type of ramp, choose between vertical, horizontal, radial, and circular.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Sets the center point for radial and circular ramps.",
                "type": "Par",
                "name": "position1"
            },
            {
                "text": "Sets the center point for radial and circular ramps.",
                "type": "Par",
                "name": "position2"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the ramp beyond the defined range. This parameter determines what happens at the edges of the ramp.",
                "type": "Par",
                "name": "extendleft"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the ramp beyond the defined range. This parameter determines what happens at the edges of the ramp.",
                "type": "Par",
                "name": "extendright"
            },
            {
                "text": "Menu : Change type of interpolation between the color keyframes in the ramp.",
                "type": "Par",
                "name": "interp"
            },
            {
                "text": "Menu : Adjusts the fit of Radial and Circular type ramps based on aspect ratio.",
                "type": "Par",
                "name": "fitaspect"
            },
            {
                "text": "Menu : Choose which composite operation is performed from this menu. Search the web for 'blend modes' for more detailed information on the effects of each type.",
                "type": "Par",
                "name": "operand"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Ramp TOP allows you to interactively create vertical, horizontal, radial, and circular ramps. Using the ramp bar and the color picker, you can add as many color tabs to the ramp as you like, each with its own color and alpha values. Click on a color tab to select it and change its color. Click elsewhere on the ramp bar to add another color keyframe. Drag a color tab off the ramp bar to delete it.\t\t\n\t\t\t\nThe data for each color keyframe in the ramp is held in the [[DAT]] specified by the <span class=\"tipTextTOP\">DAT</span> parameter. Each row in this DAT (in [[Table DAT|Table Format]]) represents a color keyframe entry in the ramp. The first column is the color keyframe's position on the ramp, the range is 0-1. The next 4 columns are the RGBA value for the color keyframe at that position. The DAT can be edited directly and the ramp will update in real-time.",
        "short": "The Ramp TOP allows you to interactively create vertical, horizontal, radial, and circular ramps.",
        "opLicense": "Non-Commercial",
        "opLabel": "Ramp",
        "opFilter": "False",
        "opType": "ramp",
        "opClass": "rampTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "realsenseTOP": {
        "label": "realsenseTOP",
        "members": [
            {
                "text": "Menu : Select the model of device to use.",
                "type": "Par",
                "name": "model"
            },
            {
                "text": "Menu : Select the image type to output.",
                "type": "Par",
                "name": "image"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "[[RealSense]] is a tracking device from Intel. The RealSense TOP connects to Intel [[RealSense]] devices and outputs color, depth and IR data from it.\n    \n<!--'''NOTE:''' D415, D435, D435i, T265 and L515 cameras are currently disabled on macOS due to bugs in the [https://github.com/IntelRealSense/librealsense Intel librealsense API].\n-->\nSee also [[RealSense]] for hardware information and installation instruction, and the [[RealSense CHOP]].",
        "short": "The RealSense TOP connects to Intel [[RealSense]] devices and outputs color, depth and IR data from it.",
        "opLicense": "Non-Commercial",
        "opLabel": "RealSense",
        "opFilter": "False",
        "opType": "realsense",
        "opClass": "realsenseTOP_Class",
        "opFamily": "TOP",
        "hardware": "The [https://github.com/IntelRealSense/librealsense/releases librealsense SDK v2.50.0] does not look like it will be updated for Apple Silicon, so it is not an option to add to these builds.",
        "opCategories": ""
    },
    "rectangleTOP": {
        "label": "rectangleTOP",
        "members": [
            {
                "text": "Width and Height of the rectangle to draw.",
                "type": "Par",
                "name": "sizex"
            },
            {
                "text": "Width and Height of the rectangle to draw.",
                "type": "Par",
                "name": "sizey"
            },
            {
                "text": "Coordinates of the center of the shape. (0,0) corresponds to a perfectly centered shape.",
                "type": "Par",
                "name": "centerx"
            },
            {
                "text": "Coordinates of the center of the shape. (0,0) corresponds to a perfectly centered shape.",
                "type": "Par",
                "name": "centery"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the rectangle.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the rectangle.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Color to use for the fill of the shape.",
                "type": "Par",
                "name": "fillcolorr"
            },
            {
                "text": "Color to use for the fill of the shape.",
                "type": "Par",
                "name": "fillcolorg"
            },
            {
                "text": "Color to use for the fill of the shape.",
                "type": "Par",
                "name": "fillcolorb"
            },
            {
                "text": "Color to use for the border of the shape.",
                "type": "Par",
                "name": "borderr"
            },
            {
                "text": "Color to use for the border of the shape.",
                "type": "Par",
                "name": "borderg"
            },
            {
                "text": "Color to use for the border of the shape.",
                "type": "Par",
                "name": "borderb"
            },
            {
                "text": "Color to use for the background.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Color to use for the background.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Color to use for the background.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Menu : Choose which composite operation is performed from this menu. Search the web for 'blend modes' for more detailed information on the effects of each type.",
                "type": "Par",
                "name": "operand"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Rectangle TOP can be used to generate Rectangles with rounded corners.\t\t\n\t\t\t\nThe shapes can be customized with different sizes, rotation and positioning. An optional border can be added to the shape. Background, border and fill colors can all be set independently. Anti-aliasing can be turned on or off.",
        "short": "The Rectangle TOP can be used to generate Rectangles with rounded corners.",
        "opLicense": "Non-Commercial",
        "opLabel": "Rectangle",
        "opFilter": "False",
        "opType": "rectangle",
        "opClass": "rectangleTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "remapTOP": {
        "label": "remapTOP",
        "members": [
            {
                "text": "Menu : Select which of the second input's channels to use for the horizontal warp of the first input.",
                "type": "Par",
                "name": "horzsource"
            },
            {
                "text": "Menu : Select which of the second input's channels to use for the vertical warp of the first input.",
                "type": "Par",
                "name": "vertsource"
            },
            {
                "text": "Menu : Controls what is returned from your first input when the second input's values are outside the [0-1] range.",
                "type": "Par",
                "name": "extend"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Remap TOP uses the second input to warp the first input. For every pixel of the output, it uses the red channel and green channel of the second input to choose which pixel to pick from the first input. Red == 0  will pick from the left column of pixels, red == 1 will pick from the right column of pixels. Green == 0  will pick from the bottom row of pixels, green == 1 will pick from the top row of pixels. Red == .5 and green == .5 will pick from the middle pixel of the first input.  Pixels from the first input are interpolated.\t\t\n\t\t\t\nIt is best that the second input contain a 16-bit-per-channel image or better, like 32-bit floats. Otherwise if the second input is 8-bits per color channel, the output images will be steppy: there are only 256x256 pixels from the first input that will be sampled. See the Pixel Format parameter on the Common page of the TOP feeding into the Remap TOP second input, and see its current pixel format settings with the MMB Info popup on the TOP.\n\t\t\t\nNote: The [[Displace TOP]] does the same thing if you set the Vertical Source to Green the UV Weight parameter set to 0, and the Displace Weight set to .5.  The Displace TOP does more general warping, whereas the Remap TOP is often used for warping images with other tools like the Stitcher component in the [[Palette]], or for projection mapping.\n\t\t\t\nSee also: [[Displace TOP]], [[Lookup TOP]]",
        "short": "The Remap TOP uses the second input to warp the first input.",
        "opLicense": "Non-Commercial",
        "opLabel": "Remap",
        "opFilter": "True",
        "opType": "remap",
        "opClass": "remapTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "renderpassTOP": {
        "label": "renderpassTOP",
        "members": [
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, +X, +Y, or +Z.",
                "type": "Par",
                "name": "possidex"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, +X, +Y, or +Z.",
                "type": "Par",
                "name": "possidey"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, +X, +Y, or +Z.",
                "type": "Par",
                "name": "possidez"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, -X, -Y, or -Z.",
                "type": "Par",
                "name": "negsidex"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, -X, -Y, or -Z.",
                "type": "Par",
                "name": "negsidey"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, -X, -Y, or -Z.",
                "type": "Par",
                "name": "negsidez"
            },
            {
                "text": "Menu : Refer to to the same parameter in the [[Render TOP]]s help page.",
                "type": "Par",
                "name": "transparency"
            },
            {
                "text": "Menu : Controls if blending (as enabled by the MAT common page setting) will be enabled for extra buffers beyond the first one. Often the extra buffers are used to write other types of information such as normals or positions, where blending wouldn't be desirable.",
                "type": "Par",
                "name": "allowbufblending"
            },
            {
                "text": "Menu : Front Faces, Back Faces, Both Faces, Neither. Will cause the render to avoid rendering certain polygon faces depending on their orientation to the camera. Refer to [[Back-Face Culling]] for more information.",
                "type": "Par",
                "name": "cullface"
            },
            {
                "text": "Menu : Select the units for this parameter from Pixels, Fraction (0-1), Fraction Aspect (0-1 considering aspect ratio).",
                "type": "Par",
                "name": "cropleftunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Pixels, Fraction (0-1), Fraction Aspect (0-1 considering aspect ratio).",
                "type": "Par",
                "name": "croprightunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Pixels, Fraction (0-1), Fraction Aspect (0-1 considering aspect ratio).",
                "type": "Par",
                "name": "cropbottomunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Pixels, Fraction (0-1), Fraction Aspect (0-1 considering aspect ratio).",
                "type": "Par",
                "name": "croptopunit"
            },
            {
                "text": "TOP : This is the TOP that will be referenced by the above sampler name above it.",
                "type": "Par",
                "name": "top0extendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0filter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0anisotropy"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0x"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0y"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0z"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0w"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Render Pass TOP is used along with a [[Render TOP]] to achieve multipass rendering. It can build upon its inputs render by using the existing depth/color information in the framebuffers, or it can optionally clear one or both of the depth/color buffers before it does its render.",
        "short": "The Render Pass TOP is used along with a [[Render TOP]] to achieve multipass rendering.",
        "opLicense": "Non-Commercial",
        "opLabel": "Render Pass",
        "opFilter": "True",
        "opType": "renderpass",
        "opClass": "renderpassTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "renderselectTOP": {
        "label": "renderselectTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Render Select TOP allows you to select one of the color buffers from any [[Render TOP]].",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Render Select",
        "opClass": "renderselectTOP_Class",
        "opType": "renderselect",
        "long": "The Render Select TOP allows you to select one of the color buffers from any [[Render TOP]].",
        "opCategories": ""
    },
    "renderTOP": {
        "label": "renderTOP",
        "members": [
            {
                "text": "Menu : Helps the Render TOP optimize rendering when multiple cameras are used. Controls the [[Multi-Camera Rendering]] behavior for this node.",
                "type": "Par",
                "name": "multicamerahint"
            },
            {
                "text": "Menu : Sets the level of anti-aliasing in the scene. Setting this to higher values uses more graphics memory.",
                "type": "Par",
                "name": "antialias"
            },
            {
                "text": "Menu : You can render different projections:  normal 2D, Cube Map, Fish Eye (180), or Dual Paraboloid. The Cube Map renders 6 views as needed for environment maps in the [[Phong MAT]] and [[Environment Light COMP]]. \t\t\n\t\t\t\t\nSee also the [[Cube Map TOP]] and the [[Projection TOP]].",
                "type": "Par",
                "name": "rendermode"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, +X, +Y, or +Z.",
                "type": "Par",
                "name": "possidex"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, +X, +Y, or +Z.",
                "type": "Par",
                "name": "possidey"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, +X, +Y, or +Z.",
                "type": "Par",
                "name": "possidez"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, -X, -Y, or -Z.",
                "type": "Par",
                "name": "negsidex"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, -X, -Y, or -Z.",
                "type": "Par",
                "name": "negsidey"
            },
            {
                "text": "When Render Mode is Cube Map, specify which sides if the cube map are rendered, -X, -Y, or -Z.",
                "type": "Par",
                "name": "negsidez"
            },
            {
                "text": "Menu : When Render Mode is UV Unwrap Coord, select which Texture Layer the coordinates are rendered to,",
                "type": "Par",
                "name": "uvunwrapcoord"
            },
            {
                "text": "Menu : Helps to render transparent geometry in proper depth order. This eliminates the need to sort the geometry based on distance from camera. This process is multi-pass. For every pixel the closest surface is rendered in the first pass, the second closest surface second, up to the number of passes specified by the <span class=\"tipTextTOP\">Transparency Passes</span> parameter below. Turning this option on will disable some advanced features in the Render TOP, as well as anti-aliasing.\t\t\n\t\t\t\t\nThe feature is a pixel-based approach, not object-based. So its performance is not directly related to the number of objects, but rather how they are layered.\t\t\t\t\n\t\t\t\t\nIt uses a technique called Depth Peeling. First you render the normal frame. On your next render you peel away all of the pixels you saw in the first frame, and reveal the pixels underneath them. The next frame you do the same, peeling away the pixels you could see from the 2nd render. And so on. Once all of the renders are done, you re composite each layer Over the other, starting at the farthest back layer.\t\t\t\t\n\t\t\t\t\nIf you take a sphere for example, you'll need to do 2 passes, the first one for the front of the sphere, and then 2nd will be the inside of the sphere.\t\t\t\t\n\t\t\t\t\nIf you have 10 spheres, one behind the other. You'll need 19-20 passes to get the correct image.\t\t\t\t\n\t\t\t\t\nIf you have 10 spheres, each next to each other across the screen, you'll only need 2 passes.\t\t\t\t\n\t\t\t\t\nIn reality though you will only need 3-5 passes to get an image that's acceptable. It may not be 100% correct, but it'll look pretty close to correct.\t\t\t\t\n\t\t\t\t\nEach pass is a full render, so each pass adds significant overhead.",
                "type": "Par",
                "name": "transparency"
            },
            {
                "text": "Menu : Use either a 24-bit Fixed-Point or 32-bit Floating-Point depth buffer (single channel image).",
                "type": "Par",
                "name": "depthformat"
            },
            {
                "text": "Menu : Front Faces, Back Faces, Both Faces, Neither. Will cause the render to avoid rendering certain polygon faces depending on their orientation to the camera. Refer to [[Back-Face Culling]] for more information.",
                "type": "Par",
                "name": "cullface"
            },
            {
                "text": "Menu : Select the units for this parameter from Pixels, Fraction (0-1), Fraction Aspect (0-1 considering aspect ratio).",
                "type": "Par",
                "name": "cropleftunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Pixels, Fraction (0-1), Fraction Aspect (0-1 considering aspect ratio).",
                "type": "Par",
                "name": "croprightunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Pixels, Fraction (0-1), Fraction Aspect (0-1 considering aspect ratio).",
                "type": "Par",
                "name": "cropbottomunit"
            },
            {
                "text": "Menu : Select the units for this parameter from Pixels, Fraction (0-1), Fraction Aspect (0-1 considering aspect ratio).",
                "type": "Par",
                "name": "croptopunit"
            },
            {
                "text": "The resolution of the image output. This does not need to be the same as the resolution the main Render is doing.",
                "type": "Par",
                "name": "imageresw"
            },
            {
                "text": "The resolution of the image output. This does not need to be the same as the resolution the main Render is doing.",
                "type": "Par",
                "name": "imageresh"
            },
            {
                "text": "Menu : Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to [[Pixel Formats]] for more information.",
                "type": "Par",
                "name": ""
            },
            {
                "text": "Menu : Specify what type of texture to create with the image output.",
                "type": "Par",
                "name": "imagetype"
            },
            {
                "text": "Menu : Controls how the output textures will be accessed. If the textures will be read from (such as using values generated by other shader executions within the same frame), then the access should be changed to Read-Write instead of Write Only.",
                "type": "Par",
                "name": "imageaccess"
            },
            {
                "text": "TOP : This is the TOP that will be referenced by the above sampler name above it.",
                "type": "Par",
                "name": "top0extendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0filter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0anisotropy"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0x"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0y"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0z"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0w"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Render TOP is used to render all 3D scenes in TouchDesigner. You need to give it a [[Camera COMP|Camera]] object and a [[Geometry COMP|Geometry]] object as a minimum. \t\t\t\n\t\t\t\t\nThe Geometry object needs to have a [[MAT|Material]] assigned to it. Materials can be pre-packaged ones like the [[Phong MAT|Phong]] material, or they can be OpenGL GLSL shaders. All textures and bump maps in TouchDesigner materials are TOPs, i.e. files must be read in via [[Movie File In TOP]]s.\t\t\t\t\n\t\t\t\t\nRendering in TouchDesigner ties in nicely with compositing via the Render TOP and all other TOPs.\t\t\t\t\n\t\t\t\t\nThe Render TOP renders in many RGBA and single-channel formats, in 8-bit fixed-point up to to 32-bit floating point per pixel component.\t\t\t\t\n\t\t\t\t\nIt can render transparent surfaces correctly using Multi-Pass Depth Peeling. See below: Order Independent Transparency.\t\t\t\t\n\t\t\t\t\nMultiple Cameras: The Render TOP is able to render multiple cameras (more quickly than separately) in a single node. You specify multiple cameras in one Camera parameter, and use Render Select TOP to pull out those camera results. This feature is even faster on GPUs that support [[Multi-Camera Rendering]].\t\t\t\t\n\t\t\t\t\n\t\t\t\t\nSee also [[Rendering]], all the articles in the [http://www.derivative.ca/wiki/index.php?title=Category:Rendering Rendering Category], the [[Render Pass TOP]], and the troubleshooting page [[Why is My Render Black]].\t\t\t\t\n\t\t\t\t\nNOTE: If you are doing non-realtime GPU-intensive renders (ones that take multiple seconds to render a single SOP), see the note in Windows GPU Driver Timeouts in the [[Movie File Out TOP]].",
        "short": "The Render TOP is used to render all 3D scenes in TouchDesigner.",
        "opLicense": "Non-Commercial",
        "opLabel": "Render",
        "opFilter": "False",
        "opType": "render",
        "opClass": "renderTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "renderstreaminTOP": {
        "label": "renderstreaminTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "renderstreaminTOP",
        "opLabel": "RenderStream In",
        "opClass": "renderstreaminTOP_Class",
        "opFilter": "False",
        "opLicense": "Pro",
        "opCategories": "",
        "os": "Microsoft Windows",
        "short": "",
        "long": "This node brings in image data sent over the [[RenderStream]] protocol from [https://www.disguise.one/en/products/renderstream/ Disguise]. The actual setup and sync of the RenderStream connection is done with the [[RenderStream In CHOP]].\n    \nSee also [[RenderStream In CHOP]], [[RenderStream Out TOP]], [[RenderStream]]."
    },
    "renderstreamoutTOP": {
        "label": "renderstreamoutTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "renderstreamoutTOP",
        "opLabel": "RenderStream Out",
        "opClass": "renderstreamoutTOP_Class",
        "opFilter": "True",
        "opLicense": "Pro",
        "opCategories": "",
        "os": "Microsoft Windows",
        "short": "",
        "long": "Send image data out to [[RenderStream]]. The actual setup and sync of the RenderStream connection is done with the [[RenderStream In CHOP]].\n    \nSee also [[RenderStream In CHOP]], [[RenderStream In TOP]], [[RenderStream]]."
    },
    "reorderTOP": {
        "label": "reorderTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Reorder TOP is a multi-input TOP which lets you choose any of the input channels for the R, G, B, and A output.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Reorder",
        "opClass": "reorderTOP_Class",
        "opType": "reorder",
        "long": "The Reorder TOP is a multi-input TOP which lets you choose any of the input channels for the R, G, B, and A output. It also gives the option of outputting one, zero or the input luminance to any of the output channels.\t\n\t\t\nSee also [[Channel Mix TOP]].",
        "opCategories": ""
    },
    "resolutionTOP": {
        "label": "resolutionTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Resolution TOP changes the resolution of the TOP image.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Resolution",
        "opClass": "resolutionTOP_Class",
        "opType": "res",
        "long": "The Resolution TOP changes the resolution of the TOP image. This can also be done on the Common page of most other TOPs.",
        "opCategories": ""
    },
    "rgbkeyTOP": {
        "label": "rgbkeyTOP",
        "members": [
            {
                "text": "Menu : Determines the output of the RGB channels from the RGB Key TOP.",
                "type": "Par",
                "name": "rgbout"
            },
            {
                "text": "Menu : Determines the output of the Alpha channel from the RGB Key TOP.",
                "type": "Par",
                "name": "alphaout"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The RGB Key TOP pulls a key from the image using Red, Green, and Blue channel settings. If a pixel falls between the Min and Max parameters for all three settings, then it is included in the key.",
        "short": "The RGB Key TOP pulls a key from the image using Red, Green, and Blue channel settings.",
        "opLicense": "Non-Commercial",
        "opLabel": "RGB Key",
        "opFilter": "True",
        "opType": "rgbkey",
        "opClass": "rgbkeyTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "rgbtohsvTOP": {
        "label": "rgbtohsvTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The RGV to HSV TOP converts the image from RGB to HSV colorspace. The R channel becomes Hue, the G channel becomes Saturation, and the B channel becomes Value.",
        "short": "The RGV to HSV TOP converts the image from RGB to HSV colorspace.",
        "opLicense": "Non-Commercial",
        "opLabel": "RGB to HSV",
        "opFilter": "True",
        "opType": "rgbhsv",
        "opClass": "rgbtohsvTOP_Class",
        "opFamily": "TOP",
        "opCategories": ""
    },
    "scalabledisplayTOP": {
        "label": "scalabledisplayTOP",
        "members": [
            {
                "text": "Sets the eye point for dynamic (ie. POL) files.",
                "type": "Par",
                "name": "eyepoint1"
            },
            {
                "text": "Sets the eye point for dynamic (ie. POL) files.",
                "type": "Par",
                "name": "eyepoint2"
            },
            {
                "text": "Sets the eye point for dynamic (ie. POL) files.",
                "type": "Par",
                "name": "eyepoint3"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Scalable Display TOP lets you load calibration data retrieved from running the [http://www.scalabledisplay.com/ Scalable Display Calibration Software].",
        "opLicense": "Pro",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Scalable Display",
        "opClass": "scalabledisplayTOP_Class",
        "opType": "scalabledisplay",
        "os": "Microsoft Windows",
        "long": "The Scalable Display TOP lets you load calibration data retrieved from running the [http://www.scalabledisplay.com/ Scalable Display Calibration Software].\t\t\n \t\t\nPlease refer to [[How-to calibrate your projector with Scalable Displays]] for a complete guide on TouchDesigners integration of the Scalable Displays SDK.\t\t\n\t\t\nUse the <code>projection</code> and <code>cameraTransform</code> python members of this node in a [[Camera COMP]] to make use of the camera information contained in the configuration file.\n\nSee also [[Projection Mapping]], [[Vioso]], [[Palette:kantanMapper|kantanMapper]], [[Palette:camSchnappr|camSchnappr]], [[Palette:projectorBlend|projectorBlend]]",
        "opCategories": ""
    },
    "screengrabTOP": {
        "label": "screengrabTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Screen Grab TOP turns the main screen output into a TOP image.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Screen Grab",
        "opClass": "screengrabTOP_Class",
        "opType": "screengrab",
        "long": "The Screen Grab TOP turns the main screen output into a TOP image. It can be captured in real-time while you work.",
        "opCategories": ""
    },
    "screenTOP": {
        "label": "screenTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]]",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Screen TOP brightens the underlying layers depending on how bright the screened layer's pixels are.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Screen",
        "opClass": "screenTOP_Class",
        "opType": "screen",
        "long": "The Screen TOP brightens the underlying layers depending on how bright the screened layer's pixels are. If the screened pixel is black, it will look completely transparent. A white pixel will be white.",
        "opCategories": ""
    },
    "scriptTOP": {
        "label": "scriptTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "scriptTOP",
        "opLabel": "Script",
        "opClass": "scriptTOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "Generates a TOP image via a Python script.",
        "long": "The Script TOP can be used to generate a TOP image using a Python script. The core feature it exposes is <code>copyNumpyArray</code>, which takes a NumPy array as input, and fills the TOP with the given image. How the NumPy array is generated is entirely up to the script writter, custom code, OpenCV, etc. \n\nThe source can be 3 or 4 channels for <code>copyNumpyArray()</code>.\n\nThe [[Script CHOP]] enables numPy arrays to be converted into the CHOP's channels.  Also any CHOP can get its channels converted into numPy arrays. (May 2021)\n\nSee <code>numPyArray()</code> in [[TOP Class]]., [[Script DAT]].\n\nSee also [[Script CHOP]], [[Script SOP]]",
        "opCategories": ""
    },
    "selectTOP": {
        "label": "selectTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Select TOP allows you to reference a TOP from any other location in TouchDesigner.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Select",
        "opClass": "selectTOP_Class",
        "opType": "select",
        "long": "The Select TOP allows you to reference a TOP from any other location in TouchDesigner. To save graphics memory, the Select TOP creates an instance of the TOP references.",
        "opCategories": ""
    },
    "sharedmeminTOP": {
        "label": "sharedmeminTOP",
        "members": [
            {
                "text": "Menu : Reads from a '''Local''' or a '''Global''' memory location.",
                "type": "Par",
                "name": "memtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Shared Mem In TOP will read image data from a shared memory block.",
        "opLicense": "Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Shared Mem In",
        "opClass": "sharedmeminTOP_Class",
        "opType": "sharedmemin",
        "long": "The Shared Mem In TOP will read image data from a shared memory block. This memory block can be created by another TouchDesigner process or a 3rd party application.\t\t\t\n\t\t\t\nSee [[Using Shared Memory in TouchDesigner]] and [[Shared Mem Out TOP]].",
        "opCategories": ""
    },
    "sharedmemoutTOP": {
        "label": "sharedmemoutTOP",
        "members": [
            {
                "text": "Menu : Writes to a '''Local''' or a '''Global''' memory location.",
                "type": "Par",
                "name": "memtype"
            },
            {
                "text": "Menu : Select between Immediate(Slow) and Next Frame(Fast) for better performance.",
                "type": "Par",
                "name": "downloadtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Shared Mem Out TOP will write image data out to a shared memory block for use by other TouchDesigner processes or other 3rd party applications.",
        "opLicense": "Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Shared Mem Out",
        "opClass": "sharedmemoutTOP_Class",
        "opType": "sharedmemout",
        "long": "The Shared Mem Out TOP will write image data out to a shared memory block for use by other TouchDesigner processes or other 3rd party applications.\t\t\t\n\t\t\t\nSee [[Using Shared Memory in TouchDesigner]] and [[Shared Mem In TOP]].",
        "opCategories": ""
    },
    "slopeTOP": {
        "label": "slopeTOP",
        "members": [
            {
                "text": "Menu : Select which method is used to calculate the slope of the Red channel. Horizontal and Vertical options let you calculate the slope by sampling points horizontally or vertically.",
                "type": "Par",
                "name": "red"
            },
            {
                "text": "Menu : Select which method is used to calulate the slope of the Green channel. Horizontal and Vertical options let you calculate the slope by sampling points horizontally or vertically.",
                "type": "Par",
                "name": "green"
            },
            {
                "text": "Menu : Select which method is used to calulate the slope of the Blue channel. Horizontal and Vertical options let you calculate the slope by sampling points horizontally or vertically.",
                "type": "Par",
                "name": "blue"
            },
            {
                "text": "Menu : Select which method is used to calculate the slope of the Alpha channel. Horizontal and Vertical options let you calculate the slope by sampling points horizontally or vertically.",
                "type": "Par",
                "name": "alpha"
            },
            {
                "text": "Menu : Determines what pixels to use when calculating the slope at each pixel in the image.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to find edges. A <span class=\"tipTextTOP\">Sample Step</span> of 3 would sample pixels 3 pixels away to look for edges.",
                "type": "Par",
                "name": "offset1"
            },
            {
                "text": "When sampling the image, this determines the distance from each pixel to the sample pixel. When units are set to pixels, it is the number of pixels away from the current pixel which is sampled to find edges. A <span class=\"tipTextTOP\">Sample Step</span> of 3 would sample pixels 3 pixels away to look for edges.",
                "type": "Par",
                "name": "offset2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Slope TOP generates pixels that represent the difference between its value and its neighbouring pixels' values.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Slope",
        "opClass": "slopeTOP_Class",
        "opType": "slope",
        "long": "The Slope TOP generates pixels that represent the difference between its value and its neighbouring pixels' values. Given that default RGBA pixel values are between 0 and 1, the value of .5 means the neighbor's values are the same as the pixel's value. Values output in the red channel that are above .5 indicate the values are increasing left-to-right. Values output in the blue channel that are above .5 indicate the values are increasing bottom-to-top.\t\n    \nHowever it's more clear if you switch the Pixel Format parameter to 32-bit float RGBA so you get a proper representation of negative numbers. Also set the Zero Point parameter to 0, and view the TOP view as Normalized Split to see a good representation of negative numbers.",
        "opCategories": ""
    },
    "spectrumTOP": {
        "label": "spectrumTOP",
        "members": [
            {
                "text": "Menu : Selects the transform mode (ie. direction). Either DFT or IDFT.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : Selects the coordinate system for output/input in the DFT/IDFT cases respectively.",
                "type": "Par",
                "name": "coord"
            },
            {
                "text": "Menu : Selects which channel of the input TOP to use for the discrete fourier transform.",
                "type": "Par",
                "name": "chan"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "TOP",
        "opType": "spectrumTOP",
        "opLabel": "Spectrum",
        "opClass": "spectrumTOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This operator only works with Nvidia GPUs.",
        "short": "The Spectrum TOP uses CUDA and OpenCV's DFT operation to perform discrete fourier transforms (DFT) or inverse discrete fourier transforms (IDFT) on a TOP input.",
        "long": "The Spectrum TOP uses CUDA and OpenCV's DFT operation to perform discrete fourier transforms (DFT) or inverse discrete fourier transforms (IDFT) on a TOP input.",
        "opCategories": ""
    },
    "ssaoTOP": {
        "label": "ssaoTOP",
        "members": [
            {
                "text": "Menu : Determines the visual quality of the results. The higher the quality, the more computationally expensive it is.",
                "type": "Par",
                "name": "quality"
            },
            {
                "text": "Menu : The SSAO pass can be set to Full, Half, or Quarter the resolution of the input image.",
                "type": "Par",
                "name": "ssaopassres"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The SSAO TOP performs Screen Space Ambient Occlusion on the output of a [[Render TOP]] or [[Render Pass TOP]].",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "SSAO",
        "opClass": "ssaoTOP_Class",
        "opType": "ssao",
        "long": "The SSAO TOP performs Screen Space Ambient Occlusion on the output of a [[Render TOP]] or [[Render Pass TOP]]. Because this technique requires access to the [[Depth Buffer]], no other TOP can be in between the Render/RenderPass TOP and the SSAO TOP. Screen Space Ambient Occlusion is a real-time rendering trick that creates an approximation of ambient occlusion by using the [[Depth Buffer]] of the rendered scene. It is done as 2D post-processes, so the complexity of the scene has no bearing on how expensive it is. This is in comparison to true ambient occlusion which becomes more expensive with each new object that is rendered. There are two parts to a SSAO technique. First a SSAO pass is done that determines how much ambient occlusion each pixel is affected by. This result tends to be very noisy. A blur operation is then performed to even out this noise.",
        "opCategories": ""
    },
    "stypeTOP": {
        "label": "stypeTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "stypeTOP_Class",
        "opLabel": "Stype",
        "opFamily": "TOP",
        "opLicense": "Pro",
        "opType": "stype",
        "opFilter": "False",
        "long": "The Stype TOP works with [[Stype]] ('''RedSpy''') camera trackers to perform simulated lens distortion using channels from a connected CHOP. \t\t\n\t\t\t\n'''NOTE:''' This CHOP works with [https://www.stype.tv Stype] hardware.\t\nSee also [[Stype]] and [[Stype CHOP]].",
        "short": "The Stype TOP performs simulated lens distortion using channels from a connected CHOP.",
        "opCategories": ""
    },
    "substanceselectTOP": {
        "label": "substanceselectTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Substance Select TOP allows you to select a single texture out of the [[Substance TOP]] for further filtering and manipulation in TOPs.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Substance Select",
        "opClass": "substanceselectTOP_Class",
        "opType": "subselect",
        "long": "The Substance Select TOP allows you to select a single texture out of the [[Substance TOP]] for further filtering and manipulation in TOPs.",
        "opCategories": ""
    },
    "substanceTOP": {
        "label": "substanceTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "There is a tight integration between TouchDesigner and [http://www.allegorithmic.com/products/substance-designer Allegorithmic's Substance Designer], a material creation package that is also node-based and has extensive material libraries.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Substance",
        "opClass": "substanceTOP_Class",
        "opType": "substance",
        "long": "There is a tight integration between TouchDesigner and [http://www.allegorithmic.com/products/substance-designer Allegorithmic's Substance Designer], a material creation package that is also node-based and has extensive material libraries. The Substance TOP allows you to load <code>.sbsar</code> files from [https://www.allegorithmic.com/products/substance-designer Substance Designer] to use with the [[PBR MAT|PBR Material]].\t\n\t\t\nThe Substance TOP will load a material from a <code>.sbsar</code> file saved out from Substance Designer giving you access to all the parametric settings of the material inside TouchDesigner via automatically-generated parameters. Adjusting the parameters in TouchDesigner causes the materials to update on the fly. \t\t\n\t\t\nThe Substance TOP outputs multiple images, one for each layer, typically five or more for base color, roughness, metallic, etc. The Substance TOP can be dragged to the PBR material which assigns all the layers to the appropriate PBR layers. Alternately, the [[Substance Select TOP]] can extract a single layer to which you can apply any TOP image operations, then assign the result to one of the PBR layer parameters.",
        "opCategories": ""
    },
    "subtractTOP": {
        "label": "subtractTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]].",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Subtract TOP composites the input images together by subtracting the pixel values.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Subtract",
        "opClass": "subtractTOP_Class",
        "opType": "sub",
        "long": "The Subtract TOP composites the input images together by subtracting the pixel values.\t\t\n\t\t\t\nOutput = Input1 - Input2. The pixel values below 0 are clammped to 0.",
        "opCategories": ""
    },
    "svgTOP": {
        "label": "svgTOP",
        "members": [
            {
                "text": "Menu : Sets the level of anti-aliasing in the scene. Setting this to higher values uses more graphics memory.",
                "type": "Par",
                "name": "antialias"
            },
            {
                "text": "Sets the background color in the image.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Sets the background color in the image.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Sets the background color in the image.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Menu : The menu attached to this parameter allows you to specify the order in which the changes to your TOP will take place. Changing the Transform order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : The rotational matrix presented when you click on this option allows you to set the transform order for the TOP's rotations. As with transform order (above), changing the order in which the TOP's rotations take place will alter the TOP's final position.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "The two fields for Translate allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "The two fields for Translate allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "The three fields for Rotate allow you to specify the amount of rotation along any of the three axes.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "The three fields for Rotate allow you to specify the amount of rotation along any of the three axes.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "The three fields for Rotate allow you to specify the amount of rotation along any of the three axes.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "The two fields for Scale allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "The two fields for Scale allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "The Pivot point edit fields allow you to define the point about which the TOP scales and rotates. Altering the pivot point of a TOP produces different results depending on the transformation performed on the TOP image.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of a TOP image is located at <code>-1,-1</code> and you wanted to scale the image by <code>0.5</code> (reduce its size by 50%), then the TOP would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "The Pivot point edit fields allow you to define the point about which the TOP scales and rotates. Altering the pivot point of a TOP produces different results depending on the transformation performed on the TOP image.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of a TOP image is located at <code>-1,-1</code> and you wanted to scale the image by <code>0.5</code> (reduce its size by 50%), then the TOP would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The SVG TOP loads [https://en.wikipedia.org/wiki/Scalable_Vector_Graphics SVG] files into TouchDesigner.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "SVG",
        "opClass": "svgTOP_Class",
        "opType": "svg",
        "long": "The SVG TOP has been deprecated and no longer works. Try [[palette:webSvg]] as an alternative.\t\t\n\t\t\t\nSee also the [[Web Render TOP]].",
        "opCategories": ""
    },
    "switchTOP": {
        "label": "switchTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Switch TOP is a multi-input operator which lets you switch which input is passed through using the <span class=\"tipTextTOP\">Input</span> parameter.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Switch",
        "opClass": "switchTOP_Class",
        "opType": "switch",
        "long": "The Switch TOP is a multi-input operator which lets you switch which input is passed through using the <span class=\"tipTextTOP\">Input</span> parameter.",
        "opCategories": ""
    },
    "syphonspoutinTOP": {
        "label": "syphonspoutinTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Syphon Spout In TOP will obtain its texture image via shared memory from other applications that support the [http://spout.zeal.co/ Spout framework] on Windows or [http://syphon.v002.info/ Syphon] on macOS.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Syphon Spout In",
        "opClass": "syphonspoutinTOP_Class",
        "opType": "syphonspoutin",
        "long": "'''Note:''' For Spout on Windows, an Nvidia or AMD GPU is required, Intel does not work.\n    \nThe Syphon Spout In TOP will obtain its texture image via shared memory from other applications that support the [http://spout.zeal.co/ Spout framework] on Windows or [http://syphon.v002.info/ Syphon] on macOS. Since this uses shared memory, it only works on the computer it's running on and does not transmit textures across a network to another computer. To send textures to another computer, see [[Touch In TOP]] and [[Touch Out TOP]], or [[NDI In TOP]] and [[NDI Out TOP]].\t\n\t\t\nYou can download a Spout setup package at http://spout.zeal.co/ for testing and example applications.\t\t\nYou can download a [https://github.com/Syphon/Simple/releases/download/public-beta-2/Syphon.Demo.Apps.Public.Beta.2.dmg Syphon simple server] setup to testing.\t\t\n\t\t\nBy default Spout on Windows is limited to 10 senders active on the computer. This limit can be changed by setting the Windows registry DWORD:<br>\t\t\nHKEY_CURRENT_USER\\\\Software\\\\Leading Edge\\\\Spout\\\\MaxSenders\t\t\n\t\t\nSee also: [[Syphon Spout Out TOP]]",
        "opCategories": ""
    },
    "syphonspoutoutTOP": {
        "label": "syphonspoutoutTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Syphon Spout Out TOP will share its input texture with other applications that support the [http://spout.zeal.co/ Spout framework] on Windows or [http://syphon.v002.info/ Syphon] on macOS.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Syphon Spout Out",
        "opClass": "syphonspoutoutTOP_Class",
        "opType": "syphonspoutout",
        "long": "'''Note:''' For Spout on Windows, an Nvidia or AMD GPU is required, Intel does not work.\n    \nThe Syphon Spout Out TOP will share its input texture with other applications that support the [http://spout.zeal.co/ Spout framework] on Windows or [http://syphon.v002.info/ Syphon] on macOS. Since this uses shared memory, it only works on the computer it's running on and does not transmit textures across a network to another computer. Spout can send textures in various pixel formats up to and including 32-bit float RGBA. Syphon is limited to 8-bit RGBA. To send textures to another computer, see [[Touch In TOP]] and [[Touch Out TOP]], or [[NDI In TOP]] and [[NDI Out TOP]].\t\n\t\t\nYou can download a Spout setup package at http://spout.zeal.co/ for testing and example applications.\t\t\nYou can download a [https://github.com/Syphon/Simple/releases/download/public-beta-2/Syphon.Demo.Apps.Public.Beta.2.dmg Syphon simple server] setup for testing on macOS.\t\t\n\t\t\nBy default Spout on Windows is limited to 10 senders active on the computer. This limit can be changed by setting the Windows registry DWORD:<br>\t\t\nHKEY_CURRENT_USER\\\\Software\\\\Leading Edge\\\\Spout\\\\MaxSenders\t\t\n\t\t\nSee also: [[Syphon Spout In TOP]]",
        "opCategories": ""
    },
    "textTOP": {
        "label": "textTOP",
        "members": [
            {
                "text": " : Select which character set to use.",
                "type": "Par",
                "name": "charset"
            },
            {
                "text": "Menu : The display method used.",
                "type": "Par",
                "name": "dispmethod"
            },
            {
                "text": "StrMenu : Smoothes out the edges of the text. Not available for Texture Display Mode.",
                "type": "Par",
                "name": "antialias"
            },
            {
                "text": "Menu : Automatically controls font size using one of the following 3 options. When using this feature along with Word Wrap turned on, it will first word-wrap the text based on the specified font size, then auto size the resulting block of text.",
                "type": "Par",
                "name": "fontautosize"
            },
            {
                "text": "Menu : Use to set whether the language reads Left to Right or Right to Left.",
                "type": "Par",
                "name": "readingdirection"
            },
            {
                "text": "The amount of space to add between letters in X and Y. Tracking is way of adding an arbitrary offset between letters. There already is a default offset associated with each font so the letters are flush against each other. The Tracking parameter this adds to that and allows for a Y offset.",
                "type": "Par",
                "name": "tracking1"
            },
            {
                "text": "The amount of space to add between letters in X and Y. Tracking is way of adding an arbitrary offset between letters. There already is a default offset associated with each font so the letters are flush against each other. The Tracking parameter this adds to that and allows for a Y offset.",
                "type": "Par",
                "name": "tracking2"
            },
            {
                "text": "The starting position of the text in X and Y.\t\t\n\t\t\t\t\n<span class=\"tipTextTOP\">TIP:</span> Inside the Text and Post Text fields the position can be overridden by using brackets.\t\t\t\t\n\t\t\t\t\n* '''[x,y]''' - <code>\"bleh[x,y]newtext\"</code> will place ''newtext'' at position (x,y) on the screen.\t\t\t\t\n* '''{X,Y}''' - <code>\"bleh{(+/-)x,(+/-)y}newtext\"</code> will offset ''newtext'' x,y from current position.\t\t\t\t\n* '''\\n''' - using <code>\"\\n\"</code> causes the text to move down to the next line and reset its position. (i.e. New Line and Carriage Return)",
                "type": "Par",
                "name": "position1"
            },
            {
                "text": "The starting position of the text in X and Y.\t\t\n\t\t\t\t\n<span class=\"tipTextTOP\">TIP:</span> Inside the Text and Post Text fields the position can be overridden by using brackets.\t\t\t\t\n\t\t\t\t\n* '''[x,y]''' - <code>\"bleh[x,y]newtext\"</code> will place ''newtext'' at position (x,y) on the screen.\t\t\t\t\n* '''{X,Y}''' - <code>\"bleh{(+/-)x,(+/-)y}newtext\"</code> will offset ''newtext'' x,y from current position.\t\t\t\t\n* '''\\n''' - using <code>\"\\n\"</code> causes the text to move down to the next line and reset its position. (i.e. New Line and Carriage Return)",
                "type": "Par",
                "name": "position2"
            },
            {
                "text": "menu : Sets the horizontal alignment.",
                "type": "Par",
                "name": "alignx"
            },
            {
                "text": "menu : Determines how horizontal alignment is calculated.",
                "type": "Par",
                "name": "alignxmode"
            },
            {
                "text": "Menu : Sets the vertical alignment.",
                "type": "Par",
                "name": "aligny"
            },
            {
                "text": "menu : Determines how vertical alignment is calculated.",
                "type": "Par",
                "name": "alignymode"
            },
            {
                "text": "When using Auto-Size Font, it will further shrink the text to give it a border.",
                "type": "Par",
                "name": "borderspace1"
            },
            {
                "text": "When using Auto-Size Font, it will further shrink the text to give it a border.",
                "type": "Par",
                "name": "borderspace2"
            },
            {
                "text": "RGBA values for the text displayed. (default: white (1,1,1,1))",
                "type": "Par",
                "name": "fontcolorr"
            },
            {
                "text": "RGBA values for the text displayed. (default: white (1,1,1,1))",
                "type": "Par",
                "name": "fontcolorg"
            },
            {
                "text": "RGBA values for the text displayed. (default: white (1,1,1,1))",
                "type": "Par",
                "name": "fontcolorb"
            },
            {
                "text": "RGBA values for the background. (default: black (0,0,0,0))",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "RGBA values for the background. (default: black (0,0,0,0))",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "RGBA values for the background. (default: black (0,0,0,0))",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "RGBA values for border A color.",
                "type": "Par",
                "name": "borderar"
            },
            {
                "text": "RGBA values for border A color.",
                "type": "Par",
                "name": "borderag"
            },
            {
                "text": "RGBA values for border A color.",
                "type": "Par",
                "name": "borderab"
            },
            {
                "text": "RGBA values for border B color.",
                "type": "Par",
                "name": "borderbr"
            },
            {
                "text": "RGBA values for border B color.",
                "type": "Par",
                "name": "borderbg"
            },
            {
                "text": "RGBA values for border B color.",
                "type": "Par",
                "name": "borderbb"
            },
            {
                "text": "Menu : Choose which composite operation is performed from this menu. Search the web for 'blend modes' for more detailed information on the effects of each type.",
                "type": "Par",
                "name": "operand"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Text TOP displays text strings in an image. It allows for multiple fonts, sizes, colors, borders, character separation and line separation. The text can be displayed as bit maps, anti-aliased lines, or filled polygon characters. Any TrueType font can be rendered by the Text TOP. [[Unicode]] is supported.\tThe new Scalable Display Method uses [[Slug Library]] to render scalable, resolution independent text at the highest qulaity available in the Text TOP.\t\n\t\t\t\t\nIt can display simple text strings with embedded numeric values. It can also format lines of text and numbers in decimal or floating point format, reading the numbers from a CHOP, using special formatting characters.\t\n\nIt can also render text strings from a [[Table DAT]] via the Specification DAT parameter, where column headings are the parameter names that are to ve overidden when rendering a line of text for reach row of the table.\n\t\t\t\t\nAny [http://en.wikipedia.org/wiki/TrueType TrueType] or [http://en.wikipedia.org/wiki/OpenType OpenType] font that has been loaded into Windows can be rendered by the Text TOP. To import a new font into your Windows system, open the '''Fonts''' folder in the '''Control Panel''', then drag and drop your [[File Types| font files]] in (<code>.ttf/.otf</code> file format). Fonts can also be specified as <code>.ttf/.otf</code> file paths in the Font File parameter.\t\t\t\t\n\t\t\t\t\nYou can render '''Unicode''' text by reading the text as a python string. See [[Unicode]].\n\n'''Tip:''' You can use the [[textTOP_Class]].textWidth member to calculate the width of the text in the Text TOP.\n\t\t\t\t\nSee also: [[Field COMP]], [[Text SOP]], [[Unicode]].\t\t\t\t\n\t\t\t\t\n[[image:TextTOP.jpg]]",
        "opLabel": "Text",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "short": "The Text TOP displays text strings in an image. It allows for multiple fonts, sizes, colors, borders, character separation and line separation.",
        "opType": "text",
        "opFilter": "False",
        "opClass": "textTOP_Class",
        "opCategories": ""
    },
    "texture3dTOP": {
        "label": "texture3dTOP",
        "members": [
            {
                "text": "Menu : Specifies the texture type to create.",
                "type": "Par",
                "name": "type"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Texture 3D TOP creates a 3D texture map. It saves a series of images in one array of pixels.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Texture 3D",
        "opClass": "texture3dTOP_Class",
        "opType": "tex3d",
        "long": "The Texture 3D TOP creates a 3D texture map. It saves a series of images in one array of pixels. This TOP can be used with [[Time Machine TOP]], as well as materials. Using materials, a particular image in this array can be accessed by specifying a W texture coordinate, while the U and V coordinates are used to specify a texture location on that image. Refer to the '''[[3D Texture]]''' article for more information.\t\t\n\t\t\t\nThe Texture 3D TOP is similar to the [[Cache TOP]] which holds a set of images in a different form: the images are separate and you cannot use the W texture coordinate in a material to interpolate to access all of them in a shader.\t\t\t\n\t\t\t\nThe Texture 3D TOP replaces one slice of its 3D data with its input every frame. When it has filled up all of its slices it wraps around and starts overwriting the oldest slice.\t\t\t\n\t\t\t\nThe Texture 3D TOP can also create a '''[[2D Texture Array]]'''. 2D Texture arrays are much like 3d textures, except are sampled using a non-normalized w texture coordinate. (i.e, 0 is the first slice, 1 is the 2nd slice, 2 is the 3rd slice etc.). Texture arrays also don't support blending between different slices when sampling at coordinate that falls between two slices. This a much faster alternative to 3d textures when interpolation between slices is not required. The non-normalized w coordinate makes it very easy to directly access a particular slice in the array. 2D Texture arrays also don't have a concept of w extend mode: they only work in their 0->(N-1) range.\n\t\t\t\n[[Lock Flag|Locking]] the Texture 3D TOP preserves the entire 3D and 2D array in a [[.toe]] or [[.tox]] file.",
        "opCategories": ""
    },
    "thresholdTOP": {
        "label": "thresholdTOP",
        "members": [
            {
                "text": "Menu : Select the operation to compare the Threshold parameter to.",
                "type": "Par",
                "name": "comparator"
            },
            {
                "text": "Menu : Determines which part of the image used to calculate threshold. This parameter determines the output for the R, G, and B channels.",
                "type": "Par",
                "name": "rgb"
            },
            {
                "text": "Menu : This parameter determines the output for the alpha channel.",
                "type": "Par",
                "name": "alpha"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Threshold TOP creates a matte with pixel values set to 0 for pixels below the threshold value, and 1 for pixels greater than or equal to the threshold value.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Threshold",
        "opClass": "thresholdTOP_Class",
        "opType": "thresh",
        "long": "The Threshold TOP creates a matte with pixel values set to 0 for pixels below the threshold value, and 1 for pixels greater than or equal to the threshold value.",
        "opCategories": ""
    },
    "tileTOP": {
        "label": "tileTOP",
        "members": [
            {
                "text": "Menu : This parameter determines what happens at the edges of the tiles.",
                "type": "Par",
                "name": "extend"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Tile TOP tiles images in a repeating pattern.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Tile",
        "opClass": "tileTOP_Class",
        "opType": "tile",
        "long": "The Tile TOP tiles images in a repeating pattern. It also has a Crop option which crops an image by defining the position of the left, right, bottom, and top edges of the image.",
        "opCategories": ""
    },
    "timemachineTOP": {
        "label": "timemachineTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Time Machine TOP combines pixels in a sequence of images stored in a [[Texture 3D TOP]]. Whereas \"morphing\" warps an image \"spatially\" (in xy), Time Machine warps images only in time (specifically, the third dimension of a 3D texture map).",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Time Machine",
        "opClass": "timemachineTOP_Class",
        "opType": "tima",
        "long": "The Time Machine TOP combines pixels in a sequence of images stored in a [[Texture 3D TOP]]. Whereas \"morphing\" warps an image \"spatially\" (in xy), Time Machine warps images only in time.\t\n\t\t\nTime Machine, originally known as \"tima\" in PRISMS, was first used in 1995 for warping effects in Ghost in the Shell, a Japanimation cyber film that heavily used PRISMS for camera perspective effects, compositing, 3D and effects.\t\t\n\t\t\nYou must connect a Texture 3D TOP to the Time Machine's first input. It uses this array of images and displays different depths of the 3D texture. \n\t\t\nThe second input determines the time offset of the output image. The second input is expected to be monochrome, but uses the red channel when it is not monochrome. By default, where there is a black pixel in the second input, it gets the oldest layer of the 3D texture.  Where there is a white pixel in the second input, it gets the most recent layer of the 3D texture.  Black Offset and White Offset adjust the range of time that the black to white parts of the image are offset within. For example, if Black Offset is -10 and White Offset is 0, then a black pixel would be 10 frames behind in time, a white pixel the current frame, and a 50% grey pixel would be 5 frames behind in time (in between the Black and White Offsets).",
        "opCategories": ""
    },
    "touchinTOP": {
        "label": "touchinTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Touch In TOP will read in image data send over a TCP/IP network connection from a [[Touch Out TOP]].",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Touch In",
        "opClass": "touchinTOP_Class",
        "opType": "touchin",
        "long": "The Touch In TOP will read in image data send over a TCP/IP network connection from a [[Touch Out TOP]]. The other TouchDesigner process can be on the same computer or from another computer anywhere on the connected network.\t\n\t\t\nIt can receive [[Hap|Hap Q]], Hap Q Alpha, and Uncompressed video.\t\t\n\t\t\nMake sure Windows Firewall settings are set to UNBLOCK for TouchDesigner, otherwise the data will be blocked.\t\t\n\t\t\nSee also [[Touch Out TOP]].\t\t\n\t\t\nFor other protocols over IP see [[Video Stream Out TOP]], [[Video Stream In TOP]], [[NDI Out TOP]] and [[NDI In TOP]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opCategories": ""
    },
    "touchoutTOP": {
        "label": "touchoutTOP",
        "members": [
            {
                "text": "Menu : Choose between Uncompressed and HAP Q codecs to transmit the image stream.",
                "type": "Par",
                "name": "videocodec"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Touch Out TOP sends a TOP image stream over TCP/IP to a Touch In TOP.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Touch Out",
        "opClass": "touchoutTOP_Class",
        "opType": "touchout",
        "long": "The Touch Out TOP sends a TOP image stream over TCP/IP to a Touch In TOP. The Touch In TOP can be in another TouchDesigner session on the same computer or on a computer anywhere on the connected network.\t\t\n\t\t\t\nIt can output [[Hap|Hap Q]], Hap Q Alpha, and Uncompressed video.\t\t\t\n\t\t\t\nMake sure Windows Firewall settings are set to UNBLOCK for TouchDesigner, otherwise the data will be blocked.\t\t\t\n\t\t\t\nSee also [[Touch In TOP]].\t\t\t\n\t\t\t\nFor other protocols over IP see [[Video Stream Out TOP]], [[Video Stream In TOP]], [[NDI Out TOP]] and [[NDI In TOP]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opCategories": ""
    },
    "transformTOP": {
        "label": "transformTOP",
        "members": [
            {
                "text": "Menu : The menu attached to this parameter allows you to specify the order in which the changes to your TOP will take place. Changing the Transform order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "The two fields for Translate allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "The two fields for Translate allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "The two fields for Scale allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "The two fields for Scale allows you to specify transforms in x and y axes.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Grow/Shrink is a scale that is given in pixel units. A positive value will cause the image to grow that many pixels while a negative will cause the image to shrink that many pixels.",
                "type": "Par",
                "name": "growshrinkx"
            },
            {
                "text": "Grow/Shrink is a scale that is given in pixel units. A positive value will cause the image to grow that many pixels while a negative will cause the image to shrink that many pixels.",
                "type": "Par",
                "name": "growshrinky"
            },
            {
                "text": "The Pivot point edit fields allow you to define the point about which the TOP scales and rotates. Altering the pivot point of a TOP produces different results depending on the transformation performed on the TOP image.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of a TOP image is located at <code>-1,-1</code> and you wanted to scale the image by <code>0.5</code> (reduce its size by 50%), then the TOP would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "The Pivot point edit fields allow you to define the point about which the TOP scales and rotates. Altering the pivot point of a TOP produces different results depending on the transformation performed on the TOP image.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of a TOP image is located at <code>-1,-1</code> and you wanted to scale the image by <code>0.5</code> (reduce its size by 50%), then the TOP would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the image is translated or scaled down. Try scaling an image down 50% in size (Scale = 0.5,0.5) and setting the background color.",
                "type": "Par",
                "name": "bgcolorr"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the image is translated or scaled down. Try scaling an image down 50% in size (Scale = 0.5,0.5) and setting the background color.",
                "type": "Par",
                "name": "bgcolorg"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the image is translated or scaled down. Try scaling an image down 50% in size (Scale = 0.5,0.5) and setting the background color.",
                "type": "Par",
                "name": "bgcolorb"
            },
            {
                "text": "Color applied behind the foreground image. The background is visible when the image is translated or scaled down. Try scaling an image down 50% in size (Scale = 0.5,0.5) and setting the background color.",
                "type": "Par",
                "name": "bgcolora"
            },
            {
                "text": "Menu : This parameter determines what happens at the edges of the tiles.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "The first Tile U parameter sets the number of tiles to repeat on the left of the source image. The second Tile U parameter sets the number of tiles to repeat on the right of the source image. The image must be scaled down (using the<span class=\"tipTextTOP\"> Scale</span> parameters on the Transform page) to view these tiles.",
                "type": "Par",
                "name": "tileu1"
            },
            {
                "text": "The first Tile U parameter sets the number of tiles to repeat on the left of the source image. The second Tile U parameter sets the number of tiles to repeat on the right of the source image. The image must be scaled down (using the<span class=\"tipTextTOP\"> Scale</span> parameters on the Transform page) to view these tiles.",
                "type": "Par",
                "name": "tileu2"
            },
            {
                "text": "The first Tile V parameter sets the number of tiles to repeat on the botttom of the source image. The second Tile V parameter sets the number of tiles to repeat on the top of the source image. The image must be scaled down (using the<span class=\"tipTextTOP\"> Scale</span> parameters on the Transform page) to view these tiles.",
                "type": "Par",
                "name": "tilev1"
            },
            {
                "text": "The first Tile V parameter sets the number of tiles to repeat on the botttom of the source image. The second Tile V parameter sets the number of tiles to repeat on the top of the source image. The image must be scaled down (using the<span class=\"tipTextTOP\"> Scale</span> parameters on the Transform page) to view these tiles.",
                "type": "Par",
                "name": "tilev2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Transform TOP applies 2D transformations to a TOP image like translate, scale, rotate, and multi-repeat tiling.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Transform",
        "opClass": "transformTOP_Class",
        "opType": "transform",
        "long": "The Transform TOP applies 2D transformations to a TOP image like translate, scale, rotate, and multi-repeat tiling. The background can be filled with solid color and alpha.",
        "opCategories": ""
    },
    "underTOP": {
        "label": "underTOP",
        "members": [
            {
                "text": "Menu : The selected input will become the fixed layer and the other input will be the overlay. This does not change the order of the composite (Input1 + Input2), only which layer is considered fixed and which layer is adjustable by the parameters on the Transform page. The resolution and aspect ratio of the Fixed Layer is used as the composite's final resolution and aspect ratio unless manually on the [[#Parameters - Common Page|Common Page]].",
                "type": "Par",
                "name": "size"
            },
            {
                "text": "Menu : Determines how the Overlay layer (Overlay layer is the input that is NOT the Fixed Layer) fills the composite.",
                "type": "Par",
                "name": "prefit"
            },
            {
                "text": "Menu : Specify the horizontal alignment of the Overlay.",
                "type": "Par",
                "name": "justifyh"
            },
            {
                "text": "Menu : Specify the vertical alignment of the Overlay.",
                "type": "Par",
                "name": "justifyv"
            },
            {
                "text": "Menu : Sets the extend (or repeat) conditions of the Overlay layer. This parameter determines what happens at the edges of the Overlay layer.",
                "type": "Par",
                "name": "extend"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the Overlay layer in x and y.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the Overlay layer in x and y.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to define the point about which the Overlay layer scales and rotates. Altering the pivot point produces different results depending on the Transform Order.",
                "type": "Par",
                "name": "py"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Under TOP places Input1 'under' Input2.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Under",
        "opClass": "underTOP_Class",
        "opType": "under",
        "long": "The Under TOP places Input1 'under' Input2. The alpha of Input2 is used to determine what parts of the Input1 image are visible in the result.",
        "opCategories": ""
    },
    "videodeviceinTOP": {
        "label": "videodeviceinTOP",
        "members": [
            {
                "text": "Menu : Selects the library to use to interface with the cameras.",
                "type": "Par",
                "name": "library"
            },
            {
                "text": "StrMenu : Select which camera or decoder you want from this menu.",
                "type": "Par",
                "name": "device"
            },
            {
                "text": "Menu : Sets which fields to capture.",
                "type": "Par",
                "name": "deinterlace"
            },
            {
                "text": "Menu : When using Bob (Split) deinterlacing, this selects which field is shown first for each frame.",
                "type": "Par",
                "name": "precedence"
            },
            {
                "text": "Menu : Some capture devices support pixel formats other than 8-bit. For supported devices (Blackmagic Design) this will make the node attempt to use that capability.",
                "type": "Par",
                "name": "inputpixelformat"
            },
            {
                "text": "Menu : Controls how the frames are transferred from the input device to CPU memory, and how they are transferred from CPU memory to the GPU.",
                "type": "Par",
                "name": "transfermode"
            },
            {
                "text": "Menu : Controls the memory type used to transfer data between the capture card and the GPU.",
                "type": "Par",
                "name": "memorymode"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "preset"
            },
            {
                "text": "",
                "type": "Par",
                "name": "wbcoeffsr"
            },
            {
                "text": "",
                "type": "Par",
                "name": "wbcoeffsg"
            },
            {
                "text": "",
                "type": "Par",
                "name": "wbcoeffsb"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "custombandwidth"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "camerabitdepth"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Video Device In TOP can be used to capture video from an external camera, capture card, capture dongle, IP camera, or video decoder connected to the system. Multiple devices can simultaneously stream video into TouchDesigner by using multiple Device In TOPs. HD-SDI video can be streamed into TouchDesigner through capture cards such and those from [[Blackmagic Design]], [[AJA]] and [[Deltacast]].\t\t\t\t\t\n\t\t\t\t\t\t\n[[image:Magewell.2.jpg]]\t\t\t\t\t\t\n[[image:Webcam2.png]]\t\t\t\t\t\t\n[[image:CaptureCard.jpg]]\t\t\t\t\t\t\n[[image:DVcam.jpg]]\t\t\t\t\t\t\n[[image:WebcamMan.jpg]]\t\t\t\t\t\t\n\t\t\t\t\t\t\nIf the device does not seem to provide a video stream but it is visible in the <span class=\"tipTextTOP\">Cameras</span> parameter menu, make sure no other applications are currently using the device.\t\n\n'''TIP''': Create an [[Info DAT]] and point it to the Video Device In TOP to see what devices are currently attached. The [[Info CHOP]] gives data for analyzing the performance of Video Device In and Out TOPs. Six channels of data help with monitoring, as well a \u201cReset Stats\u201d option clears history.\n\nDevices currently supported:\n* [[Blackmagic Design]]\t\t\t\t\t\n* [[AJA]]\n* [[Deltacast]]\n* [[Bluefish444]]\n\nAJA and Blackmagic Design devices now support 12-bit input and output formats, including AJA\u2019s ability to capture at a full 12-bit RGB 4:4:4. Furthermore, 10-bit input and output have received performance improvements and better support for a wider selection of firmware.\n\t\t\nAlso supported with native drivers are some models from Datapath SDI, Allied Vision, Imaging Development Systems (IDS), FLIR/Point Grey, and Ximea.\t\t\t\t\t\n\t\t\t\t\t\t\nFor Magewell HDMI-to-USB3 capture (highly recommended, no drivers, plug-and-play), see [http://www.magewell.com/usb-capture-hdmi Magewell].\n\n'''IP Cameras''' include models from [https://www.alliedvision.com/en/products/cameras.html Allied Vision] (PvAPI SDK models only, not Vimba SDK), [https://www.ptgrey.com/ Point Grey FLIR Flycapture2 and Spinnaker] and [https://en.ids-imaging.com/ Imaging Development Systems (IDS)]. In case of IDS's Cameras, TouchDesigner implements the ''uEye IDS Software Suite''. ''GigE Vision'' cameras are currently not supported.\n\n'''USB3 Cameras''' include models from [https://www.alliedvision.com/en/products/cameras.html Allied Vision] (PvAPI SDK models only, not Vimba SDK), [https://www.ptgrey.com/ Point Grey FLIR Flycapture2 and Spinnaker] and [https://en.ids-imaging.com/ Imaging Development Systems (IDS)]\n\nOnly a small subset of cameras from each manufacturer has been tested in-house, however it's expected that any modern camera from the supported manufacturer should work. If any issues are encountered please contact <code>support@derivative.ca</code>.\t\t\t\t\t\t\n\t\t\t\t\t\t\nSee also [[Video Device Out TOP]].",
        "opLabel": "Video Device In",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "short": "The Video Device In TOP can be used to capture video from an external camera, capture card, capture dongle, or dideo decoder connected to the system.",
        "opType": "videodevin",
        "opFilter": "False",
        "opClass": "videodeviceinTOP_Class",
        "opCategories": ""
    },
    "videodeviceoutTOP": {
        "label": "videodeviceoutTOP",
        "members": [
            {
                "text": "Menu : Select the driver library to use.",
                "type": "Par",
                "name": "library"
            },
            {
                "text": "StrMenu : A menu of available video devices to output to. Set the Library parameter above prior to selecting your device.",
                "type": "Par",
                "name": "device"
            },
            {
                "text": "Menu : Set the pixel format of the output when possible (depends what type of device is used).\tData may be converted to YUV colorspace depending on what the device and settings require.",
                "type": "Par",
                "name": "outputpixelformat"
            },
            {
                "text": "Menu : Set the color space of the data sent out, for supported devices.",
                "type": "Par",
                "name": "outputcolorspace"
            },
            {
                "text": "Menu : On AJA devices what input to use as a reference source input.",
                "type": "Par",
                "name": "referencesource"
            },
            {
                "text": "Menu : Describes the number of bits of information used for each sample.",
                "type": "Par",
                "name": "audiobitdepth"
            },
            {
                "text": "Menu : Controls how the image data is transfered between the GPU and the output card.",
                "type": "Par",
                "name": "transfermode"
            },
            {
                "text": "Menu : Select the driver library to use.",
                "type": "Par",
                "name": "library"
            },
            {
                "text": "StrMenu : A menu of available video devices to output to. Set the Library parameter above prior to selecting your device.",
                "type": "Par",
                "name": "device"
            },
            {
                "text": "Menu : Set the pixel format of the output when possible (depends what type of device is used).\tData may be converted to YUV colorspace depending on what the device and settings require.",
                "type": "Par",
                "name": "outputpixelformat"
            },
            {
                "text": "Menu : Set the color space of the data sent out, for supported devices.",
                "type": "Par",
                "name": "outputcolorspace"
            },
            {
                "text": "Menu : On AJA devices what input to use as a reference source input.",
                "type": "Par",
                "name": "referencesource"
            },
            {
                "text": "Menu : Describes the number of bits of information used for each sample.",
                "type": "Par",
                "name": "audiobitdepth"
            },
            {
                "text": "Menu : Controls how the image data is transfered between the GPU and the output card.",
                "type": "Par",
                "name": "transfermode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Video Device Out TOP routes video and audio to output devices using their native driver libraries.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Video Device Out",
        "opClass": "videodeviceoutTOP_Class",
        "opType": "videodevout",
        "long": "The Video Device Out TOP routes video to output devices using their native driver libraries.\t\t\n\t\t\t\nDevices currently supported:\t\t\t\n* [[Blackmagic Design]] devices.\t\t\t\n* [[Bluefish444]] devices.\t\t\t\n* [[AJA]] devices.\t\t\t\n* [[Deltacast]] devices.\n\nSee also [[Video Device In TOP]].",
        "opCategories": ""
    },
    "videostreaminTOP": {
        "label": "videostreaminTOP",
        "members": [
            {
                "text": "Menu : Select the mode: either a Server (for RTSP, HLS or SRT URLs), or WebRTC.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : For movies that are stored as fields, where each image is made of two images interleaved together. A 30-frame per second movie would contain 60 fields per second. For each image, the even scanlines of the first field are interleaved with the odd scanlines of the second field. The Video Stream In TOP has several ways of dealing with this:",
                "type": "Par",
                "name": "deinterlace"
            },
            {
                "text": "Menu : Where fields are extracted one field at a time, this will extract the Even field first by default, otehrwise it will extract the odd field first. The industry has not standardized on one or the other.",
                "type": "Par",
                "name": "precedence"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Video Stream In TOP creates a client to receive video and audio across the network from RTSP, HLS, or SRT sources; or from a WebRTC peer via a WebRTC DAT.",
        "opLicense": "Non-Commercial",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Video Stream In",
        "opClass": "videostreaminTOP_Class",
        "opType": "videostreamin",
        "long": "The Video Stream In TOP creates a client to receive video and audio across the network from RTSP, HLS, or SRT sources; or from a WebRTC peer via a WebRTC DAT.\n\nThe URL to connect to a RTSP server is in the form:\t\t\n\t\t\t\n<code>rtsp://<ipaddress>:<port>/<streamName></code>\tfor example <code>rtsp://192.168.0.1:554/tdvidstream</code>\n\nIf the server requires a username/password, those can be specified using the form.\n\n<code>rtsp://username:password@192.168.0.1:554/tdvidstream</code>\n\nAccess '''[https://en.wikipedia.org/wiki/HTTP_Live_Streaming HLS/DASH]''' input streams via URLs that point to m3u8 files.\n\nAccess streams using '''[https://en.wikipedia.org/wiki/Secure_Reliable_Transport SRT (Secure Reliable Transport)]''' protocol with <code>srt://</code> URLs. For more information on SRT URLs, please see [[Video Stream Out TOP]].\n\nSee also [[Audio Stream In CHOP]], [[WebRTC DAT]].\n\nSRT sent in the Video Stream In TOP can include per-frame metadata making it easy to send and receive CHOP/DAT data in sync with video. Attach an [[Info DAT]] to the TOP.\n\t\t\t\nFor other protocols over IP see [[NDI|NDI (Network Data Interface)]], and [[Touch Out TOP]] / [[Touch In TOP]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opCategories": ""
    },
    "videostreamoutTOP": {
        "label": "videostreamoutTOP",
        "members": [
            {
                "text": "Menu : Selects if the mode works as an RTSP server, sends RTMP to a receiever such as a distribution service like YouTube or Twitch, or sends to an SRT destination.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "videocodec"
            },
            {
                "text": "Menu : The H.264 profile to use to encode the frames. Some decoders can only support H.264 encoder at certain profiles.",
                "type": "Par",
                "name": "profile"
            },
            {
                "text": "Menu : The quality level of the encoding.",
                "type": "Par",
                "name": "quality"
            },
            {
                "text": "Menu : Chooses between constant (CBR) and variable (VBR) bit rate modes. Mode streaming services prefer a constant bit rate mode.",
                "type": "Par",
                "name": "bitratemode"
            },
            {
                "text": "Menu : Set the bit rate used for encoding audio.",
                "type": "Par",
                "name": "audiobitrate"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "includesilentaudio"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Video Stream Out TOP creates an RTSP server to send H.264 video and MP3 audio across the network.",
        "opLicense": "Commercial",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Video Stream Out",
        "opClass": "videostreamoutTOP_Class",
        "opType": "videostreamout",
        "long": "'''Note:''' This TOP uses the Nvidia Hardware Encoder to create the stream and therefore requires an Nvidia GPU and Windows to operate.\n    \nThe Video Stream Out TOP creates either an [[RTSP]] server, or can act as an [[RTMP]] or [[SRT]] sender, to send H.264 video and MP3 audio across the network. It uses Nvidia's hardware H264 encoder. For RTSP, it can handle multiple clients connecting to it at the same time. Multiple Video Stream Out TOPs using the same port will be handled using the same underlying RTSP server. The Video Stream Out TOP can also be used to send a video stream through [[WebRTC]] video/audio tracks.\t\n\n===== RTSP =====\nObtain the URL to connect to the Video Steam Out TOP's RTSP server by using an Info DAT or by middle clicking on the node. It will be in the form:\t\t\t\n\t\t\t\n<code>rtsp://<ipaddress>:<port>/<streamName></code>\t\t\t\n\t\t\t\ne.g.\t\t\t\n\t\t\t\n<code>rtsp://192.168.0.1:554/tdvidstream</code>\t\t\t\n\n===== RTMP =====\nTo obtain the RTMP URL stream to, you may need to search to find the correct URL depending on your location and the service you are using. This should be in the format:\n\n<code>{service url}/{stream key}</code>. \n\nFor example for Twitch the URL would be something like\n\n<code>rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY</code>\n\nFor more information on different services checkout  [[RTMP]].\n\n===== SRT =====\n[https://en.wikipedia.org/wiki/Secure_Reliable_Transport SRT] can use either H.264 or H.265 video codec. It can also send per-frame metadata when a CHOP or DAT is specified in the Per-Frame Metadata parameter. The SRT server is settings are controlled by URL options. E.g to create a listener you'd specify the URL:\n\n<code>srt://0.0.0.0:9494?mode=listener</code>\n\nTo connect to listener, you'd do:\n\n<code>srt://127.0.0.1:9494?mode=caller</code>\n\nEither side of the connection can be the listener or the caller, it doesn't matter which is sending the video and which is receiving the video. The receiver would set their mode to be the opposite of whatever the sender is setting their mode to be.\n\nAll the options that are available are listed [https://ffmpeg.org/ffmpeg-protocols.html#srt here]. Multiple options can be set using a & as separator. E.g\n\n<code>srt://127.0.0.1:9494?mode=caller&send_buffer_size=100000</code>\n\nSRT sent from the Video Stream Out TOP can include per-frame metadata making it easy to send and receive CHOP/DAT data in sync with video. It can be read with the [[Video Stream In TOP]].\n\n\n===== Limitations =====\nRTSP streaming does not support sending directly to another RTSP server via RTP.\n\nThe maximum stream outs on a NVIDIA Geforce card is 2: The number of streams the GPU can handle is different depending on driver versions and hardware, however in general it is 2 streams max on Geforce level cards. Using a lower resolution does not avoid the 2 stream limit. Quadros can do more streams.\tRefer to [https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new Nvidia Video GPU Support Matrix] for more information.\n\t\t\t\nOne test using the default TouchDesigner startup file on a M6000 was able to do 13 1080p@30hz Video Stream Out TOPs.\t\t\t\n\nSee also the [[Video Stream In TOP]], [[RTMP]], [[RTSP]] and [[Video Streaming User Guide]].\t\t\t\n\t\t\t\nFor other protocols over IP see [[NDI|NDI (Network Data Interface)]], and [[Touch Out TOP]] / [[Touch In TOP]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opCategories": ""
    },
    "viosoTOP": {
        "label": "viosoTOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Vioso TOP lets you load calibration data retrieved from running the [https://vioso.com/software/vioso6/ VIOSO 6] software.",
        "opLicense": "Pro",
        "opFamily": "TOP",
        "opFilter": "True",
        "opLabel": "Vioso",
        "opClass": "viosoTOP_Class",
        "opType": "vioso",
        "long": "The Vioso TOP lets you load calibration data retrieved from running the [https://vioso.com/software/vioso6/ VIOSO 6] software.\t\t\nPlease refer to the [[Vioso]] entry for a complete guide on TouchDesigners integration of the VIOSO 6.",
        "opCategories": ""
    },
    "webrenderTOP": {
        "label": "webrenderTOP",
        "members": [
            {
                "text": "Toggle : Let the browser process play audio if the web page contains audio.  This option will restart the browser process.",
                "type": "Par",
                "name": "type"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Web Render TOP takes a URL or DAT and renders a webpage via a separate browser process that uses Chromium Embedded Frameworks (CEF), and passes the result back through shared memory.",
        "opLicense": "",
        "opFamily": "TOP",
        "opFilter": "False",
        "opLabel": "Web Render",
        "opClass": "webrenderTOP_Class",
        "opType": "webrender",
        "long": "The Web Render TOP takes a URL or DAT and renders a webpage via a separate browser process that uses Chromium Embedded Frameworks, and passes the result back through shared memory. It renders non-Flash pages, including HTML, HTML5, PDF, SVG and more. Targets can be on the internet, in local files with a <code>file://</code> syntax, or a [[DAT]].\t\n\t\t\nIt is implemented with the [https://bitbucket.org/chromiumembedded/cef Chromium Embedded Frameworks] project (CEF).\t\t\n\t\t\nAttach an [[Info CHOP]] to get the loaded status <code>loaded</code> of the page, and <code>num_handle_updates</code>, the number of times the page has been rendered.\t\t\n\t\t\nAttach an [[Info DAT]] to get the shared memory <code>handle</code>, the <code>status</code> of the browser process, the <code>process_id</code>, versions for Chromium Embedded Frameworks <code>cef</code> and Chromium <code>chromium</code>, the <code>url</code> currently displayed, page <code>title</code> and <code>error</code> state of the process.\t\t\n\t\t\nSee also [[Palette:webBrowser]], [[Audio Web Render CHOP]], [[Palette:SVG]]",
        "opCategories": ""
    },
    "zedTOP": {
        "label": "zedTOP",
        "members": [
            {
                "text": "Menu : Choose between Left or Right camera.",
                "type": "Par",
                "name": "perspective"
            },
            {
                "text": "Menu : Selects between the Color, Depth, Confidence, Disparity, Normals, Point Cloud or Spatial Texture modes.",
                "type": "Par",
                "name": "image"
            },
            {
                "text": "Menu : Selects the resolution of the camera capture.",
                "type": "Par",
                "name": "cameraresolution"
            },
            {
                "text": "Menu : Selects betweem Standard and Fill mode.",
                "type": "Par",
                "name": "sensingmode"
            },
            {
                "text": " : Selects the depth computation mode of the camera.",
                "type": "Par",
                "name": "depthmode"
            },
            {
                "text": "Menu : Select between World and Camera reference frames for the Point Cloud pixels.",
                "type": "Par",
                "name": "referenceframe"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "zedTOP_Class",
        "opLabel": "ZED",
        "opFamily": "TOP",
        "opLicense": "Non-Commercial",
        "opType": "zed",
        "opFilter": "False",
        "os": "Microsoft Windows",
        "long": "The ZED TOP captures video from the ZED depth camera. \t\t\n\t\t\t\n'''NOTE:''' This TOP works with the [https://www.stereolabs.com/zed/ Stereolabs ZED] hardware. For more information and to know what ZED SDK to install refer to the [[ZED]] article.\n\t\t\t\nIt supports point clouds - getting the camera space positions of the color pixels, outputted as a 32-bit float RGB texture with XYZ in the RGB channels. It can be used in making point clouds renders as it is in the format for [[Geometry COMP]] instancing.\t\t\t\n\t\t\t\nSee also [[ZED CHOP]] and [[ZED SOP]].",
        "short": "The ZED TOP captures video from the ZED depth camera.",
        "opCategories": ""
    },
    "abletonlinkCHOP": {
        "label": "abletonlinkCHOP",
        "members": [
            {
                "text": "Specifies the time signature. The first number is the number of beats per measure and the second number indicates the type of note that constitutes one beat. See [http://en.wikipedia.org/wiki/Time_signature Time Signature - Wikipedia] for additional information.",
                "type": "Par",
                "name": "signature1"
            },
            {
                "text": "Specifies the time signature. The first number is the number of beats per measure and the second number indicates the type of note that constitutes one beat. See [http://en.wikipedia.org/wiki/Time_signature Time Signature - Wikipedia] for additional information.",
                "type": "Par",
                "name": "signature2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Ableton Link CHOP retrieves timing information from an Ableton Link supported network. For more information see:  http://www.ableton.com/en/link/",
        "opClass": "abletonlinkCHOP_Class",
        "opFilter": "True",
        "long": "The Ableton Link CHOP retrieves timing information from an Ableton Link supported network.\t\t\nFor more information see:  http://www.ableton.com/en/link/\n\nThe full support of the Ableton Live system is [[TDAbleton]], a group of components that give you access to Ableton Songs, Tracks, Chains, Parameters and MIDI.\t\t\t\n\t\t\t\nAbleton's Link FAQ is very helpful for issues on the Ableton end: https://help.ableton.com/hc/en-us/articles/209776125-Link-FAQs. \n\nOne common problem is that Ableton Link doesn't work with all sound drivers, including DirectX. The free application [http://www.asio4all.com/ ASIO4All] is an easy replacement that acts as a virtual ASIO device.\n\nSee also [[Ableton]].",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "ableton",
        "opLabel": "Ableton Link",
        "opCategories": ""
    },
    "analyzeCHOP": {
        "label": "analyzeCHOP",
        "members": [
            {
                "text": "Menu : This menu determines the function applied to the channel.",
                "type": "Par",
                "name": "function"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Analyze CHOP looks at the values of all the values of a channel, and outputs a single-number result into the output.",
        "opClass": "analyzeCHOP_Class",
        "opFilter": "True",
        "long": "The Analyze CHOP looks at the values of all the values of a channel, and outputs a single-number result into the output. The output is one sample long. It can analyze for maximum, average, peaks and other aspects of a channel.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "analyze",
        "opLabel": "Analyze",
        "opCategories": ""
    },
    "angleCHOP": {
        "label": "angleCHOP",
        "members": [
            {
                "text": "Menu : Units of incoming channels:",
                "type": "Par",
                "name": "inunit"
            },
            {
                "text": "Menu : The order that rotation angles are assumed to be applied in (Euler angles as they are called). Applicable when converting to and from Quaternions or Vectors.",
                "type": "Par",
                "name": "inorder"
            },
            {
                "text": "Menu : Units of outgoing channels:",
                "type": "Par",
                "name": "outunit"
            },
            {
                "text": "Menu : The order that rotation angles are assumed to be applied in (Euler angles as they are called). Applicable when converting to and from Quaternions or Vectors.",
                "type": "Par",
                "name": "outorder"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Angle CHOP is a general purpose converter between degrees, radians, quaternions and vectors.",
        "opClass": "angleCHOP_Class",
        "opFilter": "True",
        "long": "The Angle CHOP is a general purpose converter between degrees, radians, quaternions and vectors. Different formats assume a specific ordering of input channels.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "angle",
        "opLabel": "Angle",
        "opCategories": ""
    },
    "attributeCHOP": {
        "label": "attributeCHOP",
        "members": [
            {
                "text": "Menu : The function to perform on the attributes:",
                "type": "Par",
                "name": "slerp"
            },
            {
                "text": "Menu : Sets the rotation order of the rotation triplet.",
                "type": "Par",
                "name": "rord"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Attribute CHOP adds, removes or updates attributes of the input CHOP. Currently there is only one attribute type, a \"quaternion\".",
        "opClass": "attributeCHOP_Class",
        "opFilter": "True",
        "long": "The Attribute CHOP adds, removes or updates attributes of the input CHOP. Currently there is only one attribute type, a \"quaternion\". This attribute type is used to group rotation channel triplets (rx,ry,rz) together.\t\t\n\t\t\t\nRotations sometimes need to be grouped together since interpolations on independent X, Y and Z rotations do not produce smooth results. Rotations often need Quaternion interpolation to rotate through the most direct path.\t\t\t\n\t\t\t\nOperations such as resampling and blending recognize the rotation triplet with the \"quaternion\" attribute. They blend or resample the rotation channels using \"spherical linear interpolation\". Ordinary interpolation can produce poor blending results, whereas quaternion blending produces the shortest rotation path between two sets of rotations.\t\t\t\n\t\t\t\nSee some of the CHOPs that use the attribute: the [[Join CHOP]], [[Composite CHOP]] and [[Interpolate CHOP]]. Other CHOPs may quietly use the Quaternion attribute, such as the [[Object CHOP]], [[Stretch CHOP]] and the [[Resample CHOP]].\t\t\t\n\t\t\t\nThe Scope is needed to specify the channels that will be grouped.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "attribute",
        "opLabel": "Attribute",
        "opCategories": ""
    },
    "audiobandeqCHOP": {
        "label": "audiobandeqCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Band EQ CHOP is a 16-band [http://en.wikipedia.org/wiki/Equalization_(audio) equalizer] which filters audio input channels in the same way that a conventional band (graphic) equalizer uses a bank of sliders to filter fixed-frequency bands of sound.",
        "opClass": "audiobandeqCHOP_Class",
        "opFilter": "True",
        "long": "The Audio Band EQ CHOP is a 16-band [http://en.wikipedia.org/wiki/Equalization_(audio) equalizer] which filters audio input channels in the same way that a conventional band (graphic) equalizer uses a bank of sliders to filter fixed-frequency bands of sound.\t\n\t\t\nThe CHOP has 16 bands from 25 Hz to 22 kHz with one parameter per band. The bandwidth per band is approximately half the frequency between the prior and next bands.\t\t\n\t\t\nSee [[Audio Filter CHOP]], [[Audio Para EQ CHOP]], [[Audio Dynamics CHOP]], [[Audio Spectrum CHOP]]",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audioband",
        "opLabel": "Audio Band EQ",
        "opCategories": ""
    },
    "audiobinauralCHOP": {
        "label": "audiobinauralCHOP",
        "members": [
            {
                "text": "Menu : Select the input format to convert from. The input CHOP is required to have the correct number of channels (eg. 6 for 5.1 Surround).",
                "type": "Par",
                "name": "inputformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "audiobinauralCHOP",
        "opLabel": "Audio Binaural",
        "opClass": "audiobinauralCHOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "",
        "long": "The Audio Binaural CHOP uses the [https://valvesoftware.github.io/steam-audio/ Steam Audio API] to convert from multi-channel speaker-based audio (eg. stereo, quadraphonic, 5.1, 7.1, etc.) to binaural using [https://en.wikipedia.org/wiki/Head-related_transfer_function HRTF]-based binaural rendering. The HRTF used is the default provided by Steam Audio. \n    \nThe Audio Binaural CHOP is useful for converting audio from a variety of formats to a 2-channel binaural format that is VR-friendly.\n\nThe sample rate of the output is determined by the audio source, which must be either 44100 or 48000.\n\nSee also: [[Audio Render CHOP]], [[OpenVR]], [[Oculus Rift]]"
    },
    "audiodeviceinCHOP": {
        "label": "audiodeviceinCHOP",
        "members": [
            {
                "text": "Menu : Select between default DirectSound/CoreAudio, ASIO, or native device supported drivers.",
                "type": "Par",
                "name": "driver"
            },
            {
                "text": "Menu : When Driver is set to DirectSound, this set mono, stereo, or multi-channel. Also determines how many channels are created 1(mono) or 2(stereo left and stereo right), or when set to multi-channel set the number of channels active on the Input 1 and Input 2 parameter pages.",
                "type": "Par",
                "name": "format"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Device In CHOP receives audio from any of the attached audio input devices using DirectSound/CoreAudio or ASIO.",
        "opClass": "audiodeviceinCHOP_Class",
        "opFilter": "False",
        "long": "The Audio Device In CHOP receives audio from any of the attached audio input devices using DirectSound/CoreAudio or ASIO. It always outputs time sliced audio data. \n    \nIf you want to capture the data in memory, use a [[Trail CHOP]] or [[Record CHOP]].\tIf you want to record to a file, use [[Audio File Out CHOP]] or [[Movie File Out TOP]].\t\n    \nThe Audio Device In CHOP can receive analog control voltages ('''CVs''') as long as your audio device's analog to digital converters can handle constant non-zero voltages.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiodevin",
        "opLabel": "Audio Device In",
        "opCategories": ""
    },
    "audiodeviceoutCHOP": {
        "label": "audiodeviceoutCHOP",
        "members": [
            {
                "text": "Menu : Select between default DirectSound/CoreAudio or ASIO drivers.",
                "type": "Par",
                "name": "driver"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Device Out CHOP sends audio to any of the attached audio output devices using DirectSound/CoreAudio or ASIO.",
        "opClass": "audiodeviceoutCHOP_Class",
        "opFilter": "True",
        "long": "The Audio Device Out CHOP sends audio to any of the attached audio output devices using DirectSound/CoreAudio or ASIO. \t\t\t\nThe second input on the Audio Device Out CHOP can be used for volume control.\t\t\t\n\t\t\t\n'''Tip''': If you get audio popping or audio dropouts, it may be caused by your actual frame rate of your main <code>timeline</code> - some frames may take too long to compute/render. See [[Time Slicing]]. There are four possible remedies:\t\t\t\n* The global CHOP [[Time Slice|Maximum Time Slice Size]] may be shorter than your worst-case time steps. Its default is .2 seconds set in Edit -> Preferences -> CHOPs -> Maximum Time Slice Size). If any frame takes longer than the Maximum Time Slice Size time to draw, audio will pop.\t\t\t\n* Then the audio buffer size can be increased (the Buffer Length parameter defaults to .15 seconds) up to the Maximum Time Slice Size.\t\t\t\n* Optimize your networks so under no condition your frame time exceeds the audio buffer size or the maximum time slice size. You can monitor this precisely with the [[Perform CHOP]].\t\t\t\n* Put audio in a separate TouchDesigner process.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiodevout",
        "opLabel": "Audio Device Out",
        "opCategories": ""
    },
    "audiodynamicsCHOP": {
        "label": "audiodynamicsCHOP",
        "members": [
            {
                "text": "Menu : Determines which compression method to use.",
                "type": "Par",
                "name": "compressiontype"
            },
            {
                "text": "Menu : As various channels come into the CHOP, they can either be compressed by an equal amount, or individually.  If they are compressed equally, all of the channels will be evaluated for the highest peak value, and this value will be used to determine the compression amount.\t\nIf they are compressed separately, each channel will be evaluated and compressed by different amounts.",
                "type": "Par",
                "name": "chanlinkingcomp"
            },
            {
                "text": "Menu : Same as compressor.",
                "type": "Par",
                "name": "chanlinkinglim"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Dynamics CHOP is designed to control the dynamic range of an audio signal.",
        "opClass": "audiodynamicsCHOP_Class",
        "opFilter": "False",
        "long": "The Audio Dynamics CHOP is designed to control the dynamic range of an audio signal. Dynamic range refers to how loud and quiet the audio is over some period of time. The Operator contains two types of dynamic control: compression and limiting.\t\t\nIt is recommended that you [[link]] this CHOP to an [[Info CHOP]], so that you can have some visual feedback:  The amount of compression or limiting which is being applied will be displayed in the Info CHOP.\t\t\t\n\t\t\t\n'''Compressor'''\t\t\t\nThe goal of a compressor is to reduce the amplitude of a signal when it crosses a certain threshold, while introducing little to no harmonic distortion.  The desired threshold is set by the user, and the amount of compression to be applied is determined by the compression ratio.  The attack and release parameters determine how quickly the compression will be applied and released, as incoming signal goes above and below the threshold.\t\t\t\n\t\t\t\n'''Limiter'''\t\t\t\nThe purpose of a limiter is to ensure a signal is within a certain dynamic range, while introducing as little harmonic distortion as possible.  Unlike the compressor, the goal is not to apply a smooth or musical form of dynamic control, but instead to keep the signal within a 'safe' range that is compatible with any CHOPS that are downstream (for example, an Audio Device Out).  This means that the Limiter has a much more abrupt (instant) attack value, which cannot be adjusted by the user.\t\t\t\n\t\t\t\nInput 2: '''Side Chain Channels''' - Other audio channels coming in can be used to determine the gains that are applied to the audio channels of the first input.\t\t\t\n\t\t\t\n'''NOTE''': This is a useful article for procedurally [http://gameaudionoise.blogspot.co.uk/p/all-in-mix-importance-of-real-time.html mixing audio for games].\t\t\t\n\t\t\t\nSee [[Audio Filter CHOP]], [[Audio Para EQ CHOP]], [[Audio Band EQ CHOP]], [[Audio Spectrum CHOP]]\t\t\t\nSee also: [[Envelope CHOP]].",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiodyna",
        "opLabel": "Audio Dynamics",
        "opCategories": ""
    },
    "audiofileinCHOP": {
        "label": "audiofileinCHOP",
        "members": [
            {
                "text": "Menu : Specifies the method used to playback the audio, there are 3 options.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "Menu : Repeats the audio stream when the end is reached.",
                "type": "Par",
                "name": "repeat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio File In CHOP reads audio from files on disk or at <code>http://</code> addresses.",
        "opClass": "audiofileinCHOP_Class",
        "opFilter": "False",
        "long": "The Audio File In CHOP reads audio from files on disk or at <code>http://</code> addresses. File types <code>.mp3</code>, <code>.aif</code>, <code>.aiff</code>, <code>.au</code>, and <code>.wav</code> files are supported. It always outputs time sliced audio data. If you want to record the data, use a [[Record CHOP]] or [[Movie File Out TOP]].\t\t\n\t\t\t\nSee [[Audio Movie CHOP]] for reading from movie files. See [[OSC In CHOP]] for receiving audio streams via OSC.\t\t\t\n\t\t\t\nFor large files the Audio File In CHOP streams the file from disk so loading the entire file into memory is not needed.\t\t\t\n\t\t\t\n* It streams files from disk and from <code>http:</code> locations (latter copies to local disk first) - It only keeps a few seconds in memory at a time.\t\t\t\n* The supported audio files are <code>.mp3 .aif .aiff .wav</code> and other [[File Types|audio formats]].\t\t\t\n* It also plays audio-only from any movie files that TouchDesigner supports, like <code>.mov, .mpg .mp4</code>. See also the [[Audio Movie CHOP]] for playing audio from movie files in sync with their video.\t\t\t\n* Audio files can be dragged/dropped onto TouchDesigner, double-clicked (if preferred), and RMB Open With... TouchDesigner.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiofilein",
        "opLabel": "Audio File In",
        "opCategories": ""
    },
    "audiofileoutCHOP": {
        "label": "audiofileoutCHOP",
        "members": [
            {
                "text": "Menu : Select the file type (container) of the output file.",
                "type": "Par",
                "name": "filetype"
            },
            {
                "text": "Menu : Select the compression codec for the WAV file type.",
                "type": "Par",
                "name": "codec"
            },
            {
                "text": "Menu : Selects the bit rate for the MP3 file type.",
                "type": "Par",
                "name": "bitrate"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "audiofileoutCHOP",
        "opLabel": "Audio File Out",
        "opClass": "audiofileoutCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Audio File Out CHOP saves an audio stream out to a file using a variety of different codecs.",
        "long": "The Audio File Out CHOP saves an audio stream out to a file using a variety of different codecs.\n    \nCurrently supports '''.wav''', '''.mp3''', '''.aiff''', and '''.ogg''' container formats.\n    \nSee also: [[Movie File Out TOP]].",
        "opCategories": ""
    },
    "audiofilterCHOP": {
        "label": "audiofilterCHOP",
        "members": [
            {
                "text": "Menu : The filter type:",
                "type": "Par",
                "name": "filter"
            },
            {
                "text": "Menu : The filter cutoff frequency can be expressed in Hz (menu set to Frequency) or power-of-10 (menu set to Logarithmic). It enables one of the next 2 Filter Cutoff parameters.",
                "type": "Par",
                "name": "units"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Filter CHOP removes low frequencies, high frequencies, both low and high, or removes a mid-frequency range.",
        "opClass": "audiofilterCHOP_Class",
        "opFilter": "True",
        "long": "The Audio Filter CHOP removes low frequencies, high frequencies, both low and high, or removes a mid-frequency range. \t\t\n\t\t\t\nA Low pass filter removes the higher frequencies of a sound, while a high pass filter reduces the bass of the sound. A band pass filter is used to extract a frequency range (i.e. extracting a person's voice from background noise) and a band reject filter is used to cut out a frequency range.\t\t\t\n\t\t\t\nIf a certain frequency lies outside the pass band, sounds at that frequency will be reduced in magnitude. The farther outside the pass band the frequency is, the more it will be reduced.\t\t\t\n\t\t\t\nThe Cutoff frequency is also known as the \"half-power\" frequency. A wave at the cutoff frequency will be reduced to half power.\t\t\t\n\t\t\t\nThe Rolloff of a filter determines how quickly the drop occurs at its Cutoff frequencies. A low rolloff will produce a gradual filter falloff (more of the sounds outside the frequency range are heard), and a high rolloff will produce a sharp filter falloff.\t\t\t\n\t\t\t\nRefer to [http://en.wikipedia.org/wiki/Audio_filter audio filter] for more insight.\t\t\t\n\t\t\t\nYou can see the effects of the Audio Filter CHOP by passing it white noise from an Oscillator CHOP and sending the result to an Audio Spectrum CHOP. The Audio Filter CHOP is implemented with a 4-pole filter internally.\t\t\t\n\t\t\t\nMoving the Dry / Wet parameter to Dry will bring back the incoming signal un-affected.\t\t\t\n\t\t\t\nInput 2: See [[Audio_Filter_CHOP#Cutoff_Modulation_Channels_Input| Cutoff Modulation Channels]]\t\t\t\n\t\t\t\nSee [[Audio Para EQ CHOP]], [[Audio Band EQ CHOP]], [[Audio Spectrum CHOP]], [[Audio Dynamics CHOP]]",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiofilter",
        "opLabel": "Audio Filter",
        "opCategories": ""
    },
    "audiomovieCHOP": {
        "label": "audiomovieCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Movie CHOP plays the audio of a movie file that is played back with a [[Movie File In TOP]].",
        "opClass": "audiomovieCHOP_Class",
        "opFilter": "False",
        "long": "The Audio Movie CHOP plays the audio of a movie file that is played back with a [[Movie File In TOP]]. Use the Movie File In TOP parameter to specify which Movie File In TOP to get the audio signal from.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiomovie",
        "opLabel": "Audio Movie",
        "opCategories": ""
    },
    "audiondiCHOP": {
        "label": "audiondiCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "audiondiCHOP",
        "opLabel": "Audio NDI",
        "opClass": "audiondiCHOP_Class",
        "opFilter": "False",
        "short": "Gets audio from an [[NDI]] stream.",
        "long": "Retrieves the audio from a [[NDI In TOP]]'s NDI stream. The audio signal can then be modified or output via CHOPs.  See [[NDI]].",
        "opLicense": "",
        "opCategories": ""
    },
    "audiooscillatorCHOP": {
        "label": "audiooscillatorCHOP",
        "members": [
            {
                "text": "Menu : The shape of the waveform to repeat, unless overridden by the Playback Source:",
                "type": "Par",
                "name": "wavetype"
            },
            {
                "text": "Menu : This menu determines how the Reset input triggers a reset of the channel(s).",
                "type": "Par",
                "name": "resetcondition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Oscillator CHOP generates sounds in three ways.",
        "opClass": "audiooscillatorCHOP_Class",
        "opFilter": "False",
        "long": "The Audio Oscillator CHOP generates sounds in three ways. It repeats common waveforms (sine, triangle), it generates white noise (a random number for each sample), or it repeats a prepared incoming audio clip of any duration. It outputs typically 44100 samples per second. In contrast, the [[LFO CHOP]] by default generates waves at lower frequencies and lower sample rates (60 samples/second), however both Audio Oscillator and LFO are interchangeable by changing their frequencies and sample rates.\t\t\n\t\t\t\nWhen it is synthesizing tones from the basic waveforms, the Audio Oscillator CHOP steps through the waveform at a rate that depends on the Pitch Control input. By default, a Pitch Control of 0 gives a middle A at 440 Hz; a 1 gives 880 Hz; a -1 gives 220 Hz. Steps of 1 in Pitch Control are 1 octave apart. Steps of 1/12 (.08333) are 1 semitone apart.\t\n\nThe Audio Oscillator is roughly modelled after the [https://www.google.com/search?q=ARP+2600+Oscillator+design&oq=ARP+2600+Oscillator+design APR 2600 voltage-controlled oscillator] (VCO).\n\t\t\t\nUp to three input CHOPs can be connected to the Audio Oscillator CHOP.\t\t\t\n\t\t\t\n'''Pitch Control''' - The first (optional) input affects the pitch. Output channels are generated for each Pitch Control channel. When pitch control is 0, it outputs a wave at the base frequency (default 440 Hz at 44,100 samples per second). It is \"logarithmic\": By default, increasing the pitch control by 1 increases the pitch by 1 octave, by 2 it increases by 2 octaves (4 times the frequency).\t\t\t\n\t\t\t\n'''Reset Pulse''' - The second (optional) input contains pulses that restart the oscillator from the beginning of the wave or the Playback Source. 0 in the input means \"play the oscillator\". 1 means \"stop the oscillator and cue it at the start of the waveform or Playback Source\".\t\t\t\n\t\t\t\n'''Playback Source''' - The third (optional) input is a replacement of the waveform Type. It is a sound clip to play at a rate modified by the Pitch Control, and can contain any number of channels. These channels are generated for each Pitch Control channel. The waveform Type and the Base Frequency parameters are disabled.\t\t\t\n\t\t\t\nIf you plug any sound clip into the Audio Oscillator CHOP's Playback Source, and Pitch Control is a constant value of 0 of any duration, it will just repeat the Playback Source. If you feed a [[Wave CHOP]] as its Pitch Control, it will raise and lower the speed/pitch of the input.\t\t\t\n\t\t\t\nThe Audio Oscillator CHOP can serve as a general motion time-warper and repeater. If you put motion channels into the third input, you can control the time warp by feeding different Pitch Control curves. 0 pitch is normal speed, 1 is double speed.\t\t\t\n\t\t\t\nUnlike the Wave CHOP, this is an iterating CHOP, that is, it steps through the waveform while the pitch changes. To see this effect, feed an LFO CHOP into the Audio Oscillator. Unlike the LFO CHOP, the Audio Oscillator CHOP is designed for audio frequencies.\t\t\t\n\t\t\t\nSee also: [[LFO CHOP]], [[Wave CHOP]].",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audioosci",
        "opLabel": "Audio Oscillator",
        "opCategories": ""
    },
    "audioparaeqCHOP": {
        "label": "audioparaeqCHOP",
        "members": [
            {
                "text": "Menu : How frequency is expressed:",
                "type": "Par",
                "name": "units"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Para EQ CHOP (parametric [http://en.wikipedia.org/wiki/Equalization_(audio) equalizer]) applies up to 3 parametric filters to the incoming sound.",
        "opClass": "audioparaeqCHOP_Class",
        "opFilter": "True",
        "long": "The Audio Para EQ CHOP (parametric [http://en.wikipedia.org/wiki/Equalization_(audio) equalizer]) applies up to 3 parametric filters to the incoming sound. The three filters are in series, where internally, the second filter takes its input from the output of the first filter, and so on.\t\t\n\t\t\t\nIt is called parametric because each filter has 3 controls - center frequency, bandwidth and boost, which in the old days, was more than usual analog filters.\t\t\t\n\t\t\t\nEach filter has a center frequency (the Frequency parameter) where the filter will have the most effect, and a bandwidth which is roughly expressed in octaves, and is typically 3 or 4. The Boost parameter, when it is greater than 0, will make louder the audio around the center frequency. When boost is less than 0, it will make the audio quieter around the center frequency. Boost is in decibels (dB) where 0 dB has no effect.\t\t\t\n\t\t\t\nYou can best hear the effects of the Audio Para EQ CHOP by passing it rich-spectrum music. The Audio Para EQ CHOP is implemented with three 4-pole filters internally.\t\t\t\n\t\t\t\nInput 2-4: See [[Audio_Para_EQ_CHOP#Frequency_Modulation_Channels_Input|Frequency Modulation Channels]], and the Scope parameter.\t\t\t\n\t\t\t\nThe Audio Para EQ CHOP is implemented as three 4-pole filters in series.\t\t\t\n\t\t\t\nSee [[Audio Filter CHOP]], [[Audio Band EQ CHOP]], [[Audio Spectrum CHOP]], [[Audio Dynamics CHOP]]",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiopara",
        "opLabel": "Audio Para EQ",
        "opCategories": ""
    },
    "audioplayCHOP": {
        "label": "audioplayCHOP",
        "members": [
            {
                "text": "Menu : Determines how the audio is triggered when using the first input to trigger.",
                "type": "Par",
                "name": "mode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Play CHOP plays back a sound file through any attached audio output device using DirectSound.",
        "opClass": "audioplayCHOP_Class",
        "opFilter": "False",
        "long": "The Audio Play CHOP plays back a sound file through any attached audio output device using DirectSound. It supports <code>.aif</code>, <code>.mp3</code>, <code>.mid</code>, <code>.wav</code> and <code>.m4a</code> files up to 48.000 kHz, which can have mono, stereo or even up to 5.1 channels in them. The audio channels can then be routed to any speaker location that DirectSound uses. See Outputs section below.\t\t\n\t\t\t\n'''NOTE''': With the Audio Play CHOP, audio samples do not enter or pass through TouchDesigner, so you will not see them in CHOPs, and you cannot process them in CHOPs. The Audio Play CHOP starts an external process that opens the file and sends it directly to the the audio outputs of your computer. If you want to process the audio within TouchDesigner or output them into a [[Movie File Out TOP]] or [[Audio Device Out CHOP]], use the [[Audio File In CHOP]].\t\t\t\n\t\t\t\nThe Audio Play CHOP contains a channel called ''state''.  This channel is 1 whenever any file is being played, 0 otherwise.\t\t\t\n\t\t\t\nThe first input (Input 0:Triggers) is used to trigger the audio file to play. The second input (Input 1: Volume) can be used to control volume, if no input is connected the <span class=\"tipTextCHOP\">Volume</span> parameter will be used. The third input (Input 2: Pan) is for panning, no input assumes it is centered. When using the <span class=\"tipTextCHOP\">DAT List</span> parameter, the inputs can contain mulitiple channels to manipulate each file individually. Multiple Audio Play CHOPs can output to different devices simutaneously.\t\t\t\n\t\t\t\nIt can also be triggered by the <span class=\"tipTextCHOP\">Trigger</span> parameter below, but in this case if multiple files are specified via the DAT List, then all files will be played at the same time when triggered.\t\t\t\n\t\t\t\nSound files can also be triggered through the <code>play()</code> method [[audioplayCHOP_Class]]. Some advanced options are only available through the [[audioplayCHOP_Class]].\t\t\t\n\t\t\t\nThe file can be read in from disk or from the web. Use <code>http://</code> when specifying a URL.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audioplay",
        "opLabel": "Audio Play",
        "opCategories": ""
    },
    "audiorenderCHOP": {
        "label": "audiorenderCHOP",
        "members": [
            {
                "text": "Menu : The output format of the audio: Binaural, Stereo, Quadraphonic Surround, 5.1 Surround, 7.1 Surround, Custom Setup, or Ambisonics (AmbiX). Ambisonics is a format for encoding three-dimensional 360 degree audio. The Ambisonics format used in the Audio Render CHOP is the 3rd order SN3D format consisting of 16 encoded channels (WXYZ, RSTUV, KLMNOPQ) that define the sphere of sound. Custom Setup requires use of the Mapping Table.",
                "type": "Par",
                "name": "outputformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "audiorender",
        "opLabel": "Audio Render",
        "opLicense": "Non-Commercial",
        "opClass": "audiorenderCHOP_Class",
        "opFilter": "True",
        "short": "The Audio Render CHOP uses the Steam Audio SDK to spatially render audio based on the full transforms of a listener and an audio source.",
        "long": "The Audio Render CHOP uses the Steam Audio SDK to spatially render audio based on the full transforms (translation, rotation, scale) of a listener and an audio source. The Audio Render CHOP takes a mono sound audio source as input, and spatially outputs the sound in the format specified from the Output Format parameter. The number of channels outputted by the Audio Render CHOP depends on the Output Format. \n\nYou specify a 3D component for the transform of the listener, plus a 3D component for the transform of a source.\n\nThe sample rate of the output is determined by the audio source, which must be either 44100 or 48000.\n\nLook at the Audio Render CHOP example in Help -> Operator Snippets.\n\nSee also [[Oculus Audio CHOP]].",
        "opCategories": ""
    },
    "audiospectrumCHOP": {
        "label": "audiospectrumCHOP",
        "members": [
            {
                "text": "Menu : Select which mode to use, modes described below.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : Converting to frequency needs a power-of-2 number of samples, like 512, 1024, 2048. (FFT means Fast [http://en.wikipedia.org/wiki/Joseph_Fourier Fourier] Transform.) The more samples, the more accurate the spectrum but the more it doesn't represent the most recent sound. Whatever the size, the CHOP uses the most recent samples. Knowing that audio at 44100 samples per second with a timeline frame rate of 60 frames per second gives 735 samples per frame, if the CHOP cooks 1 frame later and the FFT size is 1024, then it will re-use 1024-735 = 289 samples, which is good as there's a little overlap. However if it cooks 2 frames later, it will miss using 446 frames since it will have advanced 735*2=1470 samples and it will only use 1024 of them.",
                "type": "Par",
                "name": "fftsize"
            },
            {
                "text": "Menu : The method how output length will be determined.",
                "type": "Par",
                "name": "outputmenu"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Spectrum CHOP calculates and displays the frequency spectrum of the input channels.",
        "opClass": "audiospectrumCHOP_Class",
        "opFilter": "True",
        "long": "The Audio Spectrum CHOP calculates and displays the frequency spectrum of the input channels. \t\t\n\t\t\t\nIn the default Visualization Mode the CHOP is set to display the spectrum in a more understandable way by emphasizing the higher frequency levels and the lower frequency ranges.\t\t\t\n\t\t\t\nIn another Mode, the Time to Magnitude and Phase mode, the audio can be converted to the frequency spectrum domain, manipulated and then converted back to get a filtered audio signal. When converting a signal to its spectrum, two channels are created from the one containing the audio signal. One channel contains the magnitude of the frequency components, and the other contains the phase. The channels are named, for example <code>chan1_m</code> and <code>chan1_p</code> where <code>_m</code> and <code>_p</code> are the suffixes for the magnitude and phase channels.\t\t\t\n\t\t\t\n'''Tip''':  You can reduce cook time if you decrease the FFT Size from its default 8192 samples. The fastest form of this CHOP is by setting the Output Length parameter to \"Output Length Manually\". For example set the output buffer size to 2048 samples and the FFT Size to 2048. Each time it cooks, the CHOP is looking at the latest 2028 samples (at 44.1 KHz that amounts to the 50 msec, or 3 frames), which is plenty. Note the default form of the CHOP gives you 22,000 samples: 1 Hz to 22,050 Hz in steps of 1 Hz (when set to Frequency vs Logarithmic scaling), designed for clear interpretation: sample 1000 is the level of audio at 1000 Hz.\t\n\n'''Tip''':  To find the exact frequency of a wave entering the Audio Spectrum CHOP, look at the Info pop-up for that node (MMB on the node). It says:  Set \"Frequency <-> Logarithmic Scaling\" to 0, then multiply any sample to xxxx to get the Frequency at that sample.  xxxx depends on the sample rates etc and isn't a constant.\n\t\t\t\nSee [[Audio Filter CHOP]], [[Audio Para EQ CHOP]], [[Audio Band EQ CHOP]], [[Audio Oscillator CHOP]] set to White Noise.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiospect",
        "opLabel": "Audio Spectrum",
        "opCategories": ""
    },
    "audiostreaminCHOP": {
        "label": "audiostreaminCHOP",
        "members": [
            {
                "text": "Menu : Select the source type: either from a server URL, or a WebRTC peer.",
                "type": "Par",
                "name": "srctype"
            },
            {
                "text": "Menu : Specify which units to use for the Audio Sync Offset parameter.",
                "type": "Par",
                "name": "syncoffsetunit"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Stream In CHOP can stream audio into TouchDesigner from any [http://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol rtsp] server.",
        "opClass": "audiostreaminCHOP_Class",
        "opFilter": "False",
        "long": "The Audio Stream In CHOP can stream audio into TouchDesigner from any [http://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol rtsp] server, or from a [[WebRTC]] peer.  See [[Video Stream In TOP]].",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiostrin",
        "opLabel": "Audio Stream In",
        "opCategories": ""
    },
    "audiostreamoutCHOP": {
        "label": "audiostreamoutCHOP",
        "members": [
            {
                "text": "Menu : Select the stream out mode: either [[RTSP]] or [[WebRTC]].",
                "type": "Par",
                "name": "mode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Stream Out CHOP can stream audio out to any [http://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol rtsp] client such as VideoLAN's VLC media player and Apple's Quicktime, or to a [[WebRTC]] peer.",
        "opClass": "audiostreamoutCHOP_Class",
        "opFilter": "True",
        "long": "The Audio Stream Out CHOP can stream audio out to any [http://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol rtsp] client such as VideoLAN's VLC media player and Apple's Quicktime, or to a [[WebRTC]] peer.\n\t\t\nTo access the stream in one of these players, open a \"Network Stream\" or \"URL\" under the File menu.\t\t\n\t\t\n\t\t\nBelow is an example of a URL used to access the stream in a rtsp client.\t\t\n\t\t\n* IP Address = IP address of computer running TouchDesigner with the Audio Stream Out CHOP.\t\t\n* Port = number set in the Port parameter.\t\t\n* Stream Name = name given to stream in the Stream Name parameter.\t\t\nThe URL required is rtsp://<''IP address''>:<''Port''>/<''Stream Name''>",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiostrout",
        "opLabel": "Audio Stream Out",
        "opCategories": ""
    },
    "audiovstCHOP": {
        "label": "audiovstCHOP",
        "members": [
            {
                "text": "The time signature of the playhead. Not all plugins support changing of the time signature via the playhead.",
                "type": "Par",
                "name": "signature1"
            },
            {
                "text": "The time signature of the playhead. Not all plugins support changing of the time signature via the playhead.",
                "type": "Par",
                "name": "signature2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "audiovstCHOP",
        "opLabel": "Audio VST",
        "opClass": "audiovstCHOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "Loads VST3 Plugins.",
        "long": "The Audio VST CHOP loads VST3 Plugin files that generate (instruments) or process (filter) audio. See the [[VST]] overview.\n    \nThe plugin's parameters can be exposed and driven bi-directionally via a corresponding TouchDesigner parameter or the plugin's GUI control.  In order to get the full benefit of the bidirectional nature of the plugin parameters it is recommended to use [[Binding]] or a [[Bind CHOP]] when driving the parameter in TouchDesigner, rather than an expression or CHOP reference.\n\nPython calls let you [[AudiovstCHOP_Class|send MIDI messages]] to the plugin. And if the plugin generates MIDI, you can get and process the messages in the [[Docking|docked]] callbacks DAT.\n\nDepending on the plugin, the Audio VST CHOP takes up to 4 multi-channel inputs.\n    \nSee the discussion on which VST plugins work well with TouchDesigner - [https://derivative.ca/community-post/vst-plugin-testing/65712 VST Plugin Testing]. Also for a selection of free VSTs along with a useful set of affordable upgraded versions go here: https://hy-plugins.com.\n\n2 Free HY-Plugins are included with TouchDesigner and can be found using the Help > Browse Samples menu. This will open a file browser to the TouchDesigner application Samples folder which contains a VST3 folder holding one synthesizer and filter plugin for both Windows and MacOS. The Windows VST3 plugin files can be distinguished by their included \"64 Bit\" string.\n\nInstalled VST plugins are found in <code>C:Program Files/Common Files/VST</code> on Windows, and be <code>/Library/Audio/Plug-Ins/VST3</code> on macOS.\n\n'''Tip''': You can get detailed info about the VST plugin by attaching an [[Info DAT]] to the CHOP.\n\n[[VST]] is a trademark of Steinberg Media Technologies GmbH, registered in Europe and other countries."
    },
    "audiowebrenderCHOP": {
        "label": "audiowebrenderCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Audio Web Render CHOP plays the audio of a web page in a [[Web Render TOP]].",
        "opClass": "audiowebrenderCHOP_Class",
        "opFilter": "False",
        "long": "The Audio Web Render CHOP plays the audio of a web page in a [[Web Render TOP]].\tIn the Web Render TOP you need to have the Audio Options menus set to Route to Audio Web Render CHOPs, as well as the Active parameter on.",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "opType": "audiowebrender",
        "opLabel": "Audio Web Render",
        "opCategories": ""
    },
    "beatCHOP": {
        "label": "beatCHOP",
        "members": [
            {
                "text": "Menu : Specifies the method used to playback the output.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "Menu : This menu determines how the Reset input triggers a reset of the channel(s).",
                "type": "Par",
                "name": "resetcondition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Beat CHOP generates a variety of ramps, pulses and counters that are timed to the beats per minute and the sync as produced by the [[Beat Dialog]].\t\t\n\t\t\t\n* You can generate a ramp every 1/4 1/2 1 2 4 8 32 beats.\t\t\t\n* You can generate ramps of any other length, like 12 beats per bar (ramp) and fractional beats like 3.33 beats per ramp. \t\t\t\n* You can generate a set of channels, where each channel is delayed relative to the prior channel. This is useful, for example, for moving eight objects delayed by one beat each. \t\t\t\n* There also is a counter of how many ramps it has generated.\t\t\t\n* The Count+Ramp type generates a continuously-rising ramp equal to the number of cycles since the start.\t\n* If Play Mode is set to Local Sequential, it doesn't look at start/end of the timeline (i.e. doesn't reset when the timeline loops), so is more appropriate for long improvised playing.\n\t\t\t\nThe [[Beat Dialog]] is used to manually tap the beat to set the beats-per-minute (BPM). The Beat CHOP converts the BPM into a repeating ramp or pulse that keeps time with the music after you stop tapping.\t\t\n\nYou can set the global beats-per-minute with the python command:  <code>op('/local/time').tempo = 140</code>\n\t\t\t\nThe phase can be controlled with the Beat CHOP's Reset parameters. \n\nThe Beat CHOP's timing is defined by the [[Component Time]] of the Reference Node.  If the Reference Node parameter is left blank, then the time defined at the Beat CHOP's location is used. The default is in <code>/local/time</code>.\t\n\t\t\t\nSee also: [[Timeline CHOP]], [[Time COMP]].",
        "opLabel": "Beat",
        "opClass": "beatCHOP_Class",
        "opType": "beat",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Beat CHOP generates a variety of ramps, pulses and counters that are timed to the beats per minute and the sync produced by the [[Beat Dialog]] or the <code>beat</code> Command.",
        "opCategories": ""
    },
    "bindCHOP": {
        "label": "bindCHOP",
        "members": [
            {
                "text": "Menu : Match channels between inputs by name or index.",
                "type": "Par",
                "name": "match"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "bindCHOP",
        "opLabel": "Bind",
        "opClass": "bindCHOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "Allows for binding of CHOP channels and parameters.",
        "long": "Allows for [[binding]] of CHOP channels and parameters. \n    \nWhen a parameter is bound to a channel in the Bind CHOP (via the [[Parameter_Mode|parameter modes]] Export or Bind), any change in the channel will update the parameter value, and vice versa any change to the parameter will update the channel value. \n    \nAdditionally, the Bind CHOP is a multi-input CHOP and will match input channels by Channel Number or Channel Name. It monitors the matched channels and updates the Bind CHOP's output channel to match whichever input changed most recently. When bound to a parameter (via Export mode or Bind mode) changes to any matched input or the bound parameter will update the channel's value.\n\nA 'Callbacks DAT' is available for querying where the change was initiated and then taking further actions via python script.\n\nThis workflow is useful for binding multiple inputs to a parameter. For example, one input channel might be coming from a [[MIDI]] input device, and another channel coming from an [[OSC]] input device, and you want them both to control a given parameter. The Bind CHOP's output channel which is bound to the parameter will update to stay in sync with the most recent change from either of the inputs or the parameter. See video demonstration below.\n\n{{#widget:YouTube|id=N5yIlpIfu-E|width=781|height=217}}\n\n===== Tutorial =====\nBasic Bind CHOP setup: https://youtu.be/bLi-xrCUt-c",
        "opCategories": ""
    },
    "blacktraxCHOP": {
        "label": "blacktraxCHOP",
        "members": [
            {
                "text": "Menu : The network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Specifies the format for the CHOP channels (ie. how many beacons to add). \"From Mapping Table\" adds one beacon to the CHOP for every row in the mapping table. \"From Max Beacons\" adds the number specified in the \"Max Beacons\" parameter.",
                "type": "Par",
                "name": "outputformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "short": "The BlackTrax CHOP will provide motion tracking data from http://blacktrax.cast-soft.com.",
        "long": "The BlackTrax CHOP will provide motion tracking data from [http://blacktrax.cast-soft.com BlackTrax Motion Tracking Systems] is a vision-based real-time tracking system developed by [http://cast-soft.com/ CAST Software] that specializes in large-scale performances. BlackTrax Beacons (\"BTBeacons\") are attached to performers or rigid objects, and the BlackTrax system accurately tracks the Beacon's position, rotation, velocity, and acceleration.\n\nThe BlackTrax CHOP will accept tracking data from [http://blacktrax.cast-soft.com/ BlackTrax Motion Tracking Systems].  See [[BlackTrax]].\n\nThe BlackTrax CHOP works in conjunction with the BlackTrax system. BlackTrax tracks up to 85 BlackTrax Beacons and sends \ndata regarding their position, rotation, velocity, and acceleration to TouchDesigner inside [https://rttrp.github.io/RTTrP-Wiki/RTTrPM.html RTTrPM Packets]. Each Beacon can have up to 3 LEDs attached, which can also be independently tracked in TouchDesigner. Each Beacon will have an ID that is specified in BlackTrax software and that Beacon ID must be mapped correctly to CHOP channels in TouchDesigner using the Mapping Table. Alternatively if the IDs are incremental then the \"From Max Beacons\" option in \"Output Format\" can be used.\n\n=== Server Settings ===\t\t\t\nThe server software should be set to send data in the WYSIWYG coordinate system (which should be the default). Rotations should be sent in Euler angles, not Quaternions. TouchDesigner should support both endian settings, but it's best to leave those as their default values.\t\n\nSee also [[BlackTrax]], [[PosiStageNet CHOP]]",
        "opLabel": "BlackTrax",
        "opClass": "blacktraxCHOP_Class",
        "opType": "blacktrax",
        "opLicense": "Pro",
        "opFamily": "CHOP",
        "opCategories": ""
    },
    "blendCHOP": {
        "label": "blendCHOP",
        "members": [
            {
                "text": "Menu : The blend method:",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Blend CHOP combines two or more CHOPs in input 2, 3 and so on, by using a set of blending channels in input 1. The blending channels cause different strengths of the CHOPs to contribute to the output of the CHOP. It works like the [[Blend SOP]].\t\t\n\t\t\t\nThe first channel of input 2 is blended with the first channel of input 3 and input 4 and so on.\t\t\t\n\t\t\t\nInput 1 acts as the control input, which contains the blend weight channels for the rest of the inputs. In it there is one channel for each of the blended CHOPs coming in on input 2, 3 and so on.\t\t\t\n\t\t\t\nThe first channel in input 1 is input 2's blend weight, the second channel in input 1 is the input 3's blend weight, and so on. There should be as many blend channels in input 1 as there are inputs, excluding input 1.\t(However when using Differencing and Omit First Weight Channel is on, the first channel if inout 1 ias assumed to be the weight of input 3, as input 2 is the \"base\" and doesn't need a weight.)\t\t\n\t\t\t\nThe interval of the output of the CHOP is the interval of input 1 (the blend channels).\t\t\t\n\t\t\t\nIf input 2 onwards are just poses, it's acceptable, as the CHOP blends between poses by using extend conditions. \t\t\t\n\t\t\t\n'''Note:''' This CHOP is optimized and doesn't cook inputs that have zero weight.",
        "opLabel": "Blend",
        "opClass": "blendCHOP_Class",
        "opType": "blend",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Blend CHOP combines two or more CHOPs in input 2, 3 and so on, by using a set of blending channels in input 1.",
        "opCategories": ""
    },
    "blobtrackCHOP": {
        "label": "blobtrackCHOP",
        "members": [
            {
                "text": "Int : Controls how searching for blobs is done across all the points.",
                "type": "Par",
                "name": "searchmode"
            },
            {
                "text": "Menu : Limits the area in which blobs are tracked. Points outside the area of interest are ignored.",
                "type": "Par",
                "name": "areaofinterest"
            },
            {
                "text": "The center of the area of interest.",
                "type": "Par",
                "name": "centerx"
            },
            {
                "text": "The center of the area of interest.",
                "type": "Par",
                "name": "centery"
            },
            {
                "text": "The size of the area of interest.",
                "type": "Par",
                "name": "sizew"
            },
            {
                "text": "The size of the area of interest.",
                "type": "Par",
                "name": "sizeh"
            },
            {
                "text": "Menu : With prediction enabled, blobs from the last frame have their new position predicted before being matched to the current frame.",
                "type": "Par",
                "name": "predicttype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "blobtrackCHOP",
        "opLabel": "Blob Track",
        "opClass": "blobtrackCHOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Blob Track CHOP allows tracking blobs in 2D point data",
        "long": "The Blob Track CHOP allows tracking blobs in 2D point data.\n\nInput data should be have two channels named ''tx'' and ''ty'' describing the 2D points in cartesian coordinates. See the [[OP Snippets]] examples.\n\nGood sources for input scans are the [[Hokuyo CHOP]] (in Cartesian coordinate mode) and the [[Leuze ROD4 CHOP]]. These devices naturally output a radial scan from the device as the center point, where each point represents (angle, distance). Outputting each scan point in Cartesian coordinate mode gives an (x,y) for each point which is the format required for the Blob Track CHOP.  \n\nBut any set of (x,y) points in the two channels will be analyzed.  The tracker looks for consecutive points close to each other, and handles the case where one blob passes behind another blob giving the hidden blob a linear motion for a specifiable amount of time while it occluded before it removes the blob from the set of blobs being output.\n\nSee also [[Blob Track TOP]]",
        "opCategories": ""
    },
    "bodytrackCHOP": {
        "label": "bodytrackCHOP",
        "members": [
            {
                "text": "Menu : The GPU to run the body tracking models on. An Nvidia RTX or newer card is required.",
                "type": "Par",
                "name": "gpu"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "bodytrackCHOP",
        "opLabel": "Body Track",
        "opClass": "bodytrackCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "os": "Microsoft Windows",
        "hardware": "This operator uses the [https://docs.nvidia.com/deeplearning/maxine/ar-sdk-programming-guide/index.html Augmented Reality (AR) SDK] of the Nvidia Maxine system and requires a 20, 30, or 40 series Nvidia RTX GPU.",
        "short": "The Body Track CHOP can track bounding boxes and 34 key points of one or more human bodies, with optional joint angles, in 2D or 3D.",
        "long": "The Body Track CHOP can track bounding boxes and 34 key points of one or more human bodies, with optional joint angles, in 2D or 3D. \n    \nThe input image is taken from a provided TOP and can be of any resolution or format, and either a still image or video.\n\nThe coordinates of the detected features are given in u, v positions relative to the bottom-left corner of the input image. By default, the values range from 0 to 1, but the 'Aspect Correct' parameter can be enabled to scale the values so that they can be used as 3D coordinates while maintaining the aspect ratio of the original image."
    },
    "bulletsolverCHOP": {
        "label": "bulletsolverCHOP",
        "members": [
            {
                "text": "dropmenu : The space in which to output the transformation values. That is, the transform values (translation/rotation) will be outputted relative to the selected space.",
                "type": "Par",
                "name": "xformspace"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "bulletsolverCHOP",
        "opLabel": "Bullet Solver",
        "opClass": "bulletsolverCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Bullet Solver CHOP is used in conjunction with a [[Bullet Dynamics]] system. It outputs the solved results from a Bullet simulation and can include the results for the entire system ([[Bullet Solver COMP]]) or an individual actor ([[Actor COMP]]) within a system.",
        "long": "The Bullet Solver CHOP is used in conjunction with a [[Bullet Dynamics]] system. It outputs the solved results from a Bullet simulation and can include the results for the entire system ([[Bullet Solver COMP]]) or an individual actor ([[Actor COMP]]) within a system. \n    \nThe Bullet Solver CHOP can also be used with the \"Feedback CHOP\" parameter on the Bullet Solver COMP or Actor COMP. Bullet Solver simulation results can be grabbed using the Bullet Solver CHOP, modified, then fed back into the [[Bullet Solver COMP]] it came from. The values at the beginning of the next step of the simulation will be whatever values are in the CHOP that is fed back. This allows any CHOP data to be injected into the simulation at the beginning of the next frame (time step).\n\nFor example: making an actor in the simulation jump to the mouse cursor when clicked. \n    \n'''Output Channels:''' \n* '''actor_id:''' the OP id of the Actor COMP \n* '''body_id:''' the id of the body within the Actor COMP. Actor COMPs can have multiple bodies if they are static or if instancing (see: Actor COMP). Body id's increment from 0 to N-1, where N is the total number of bodies in an Actor COMP. \n* '''active:''' whether the body is active in the simulation\n* '''colliding:''' whether the body is currently colliding with another body\n* '''colliding_actor_id''' the ID of the Actor COMP that contains the body we are colliding with\n* '''colliding_body_id''' the ID of the body we are colliding with; together with colliding_actor_id will map back to a specific body in the simulation\n* '''total_collisions:''' the total number of collisions this body has had\n* '''t[xyz]:''' the translation of the body in the given transform space \n* '''r[xyz]:''' the rotation of the body in the given transform space \n* '''s[xyz]:''' the scale of the body in the given transform space \n* '''vel_t[xyz]:''' linear velocity of the body \n* '''vel_r[xyz]:''' angular velocity of the body \n    \nSee also: [[Bullet Dynamics]], [[Bullet Solver COMP]], [[Actor COMP]], [[Force COMP]], [[Impulse Force COMP]], [[Constraint COMP]].",
        "opCategories": ""
    },
    "clipblenderCHOP": {
        "label": "clipblenderCHOP",
        "members": [
            {
                "text": "This parameter works in conjunction with the root transform channels as defined on the Channels page of the clpblender CHOP as well as the [[Clip CHOP]] parameter called Position Type. When Position Type is set to \"Blend To Target\" it will blend the root transform channels for the current clip to the new position defined in this parameter.",
                "type": "Par",
                "name": "targetx"
            },
            {
                "text": "This parameter works in conjunction with the root transform channels as defined on the Channels page of the clpblender CHOP as well as the [[Clip CHOP]] parameter called Position Type. When Position Type is set to \"Blend To Target\" it will blend the root transform channels for the current clip to the new position defined in this parameter.",
                "type": "Par",
                "name": "targety"
            },
            {
                "text": "This parameter works in conjunction with the root transform channels as defined on the Channels page of the clpblender CHOP as well as the [[Clip CHOP]] parameter called Position Type. When Position Type is set to \"Blend To Target\" it will blend the root transform channels for the current clip to the new position defined in this parameter.",
                "type": "Par",
                "name": "targetz"
            },
            {
                "text": "",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "",
                "type": "Par",
                "name": "rz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Pro",
        "opLabel": "Clip Blender",
        "short": "The Clip Blender CHOP can be used as an animation system that blends between different animation clips, preserving rotation, changing target positions etc.",
        "opFilter": "False",
        "long": "The Clip Blender CHOP is a an engine for blending, sequencing and scripting animation clips. It loads animation channel data that is formatted using Clip CHOPs. It reads clip CHOP paths from a specified DAT list which can be dynamically scripted. The Clip Blender plays clips from the list DAT; each time it reads a clip, it pop's the item off the list, and when the next clip plays through it will continue playing and popping clips off the list until it is empty. Once the list is empty the last animation in the sequence is looped. \n    \nAnimation clips will typically come from an FBX or USD asset but can also be read using the Houdini bclip format or raw chan format. Animation clips found in FBX assets must be extracted from the asset hierarchy and then loaded speerately into a [[Clip CHOP]]. All [[Clip CHOP]]'s loaded into the same clipblender must have the same number of channels, all channel names must match and the all clips must be the same sample rate.  If any of these 3 important requirements are not met, there will likely be animation glitches.\n\t\t\t\nUse the [[Info CHOP]] and [[Info DAT]] to extract information about its current state. See also the [[Clip CHOP]] and [[Clip DAT]].",
        "opClass": "clipblenderCHOP_Class",
        "opType": "clipblender",
        "opCategories": ""
    },
    "clipCHOP": {
        "label": "clipCHOP",
        "members": [
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "transtion"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "abspos"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rottype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "See [[Clip Blender CHOP]].",
        "opLabel": "Clip",
        "opClass": "clipCHOP_Class",
        "opType": "clip",
        "opLicense": "Pro",
        "opFamily": "CHOP",
        "short": "See [[Clip Blender CHOP]].",
        "opCategories": ""
    },
    "clockCHOP": {
        "label": "clockCHOP",
        "members": [
            {
                "text": "Menu : Fractions or Units affects the channel data that is output from the Clock CHOP. Fraction gives convenient 0-1 ramps and Units give integers, like 0-23 for the hours of a day. For example, use Fractions and the day, hour and minute channels to drive a wall clock.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : 12 hour or 24 hour - Causes the hour channel to cycle through 12 or 24 hours. Also affects the AM/PM channel.",
                "type": "Par",
                "name": "hourformat"
            },
            {
                "text": "Menu : The date/time that corresponds to year 0, day 1, hour 0, minute 0. It can be relative to Jan 1, 2000 or to the time that the TouchDesigner process started.",
                "type": "Par",
                "name": "startref"
            },
            {
                "text": "Enter a latitude (hours/min north/south) of your location. (defaults to Toronto, Canada). Fractional hours are permitted. For example:  43.6532 hours and 0 minutes, is identical to 43 hours and 39 minutes. The parameter latitude1 is hours, latitude2 is minutes.",
                "type": "Par",
                "name": "latitude1"
            },
            {
                "text": "Enter a latitude (hours/min north/south) of your location. (defaults to Toronto, Canada). Fractional hours are permitted. For example:  43.6532 hours and 0 minutes, is identical to 43 hours and 39 minutes. The parameter latitude1 is hours, latitude2 is minutes.",
                "type": "Par",
                "name": "latitude2"
            },
            {
                "text": "Menu : Set if the Latitude value above is in the north or south hemisphere.",
                "type": "Par",
                "name": "northsouth"
            },
            {
                "text": "Enter a longitude (hours/min east/west) of your location. Fractional hours are permitted. The parameter longitude1 is hours, longitude2 is minutes.",
                "type": "Par",
                "name": "longitude1"
            },
            {
                "text": "Enter a longitude (hours/min east/west) of your location. Fractional hours are permitted. The parameter longitude1 is hours, longitude2 is minutes.",
                "type": "Par",
                "name": "longitude2"
            },
            {
                "text": "Menu : Set if the Longitude value above is in the east or west hemisphere.",
                "type": "Par",
                "name": "eastwest"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Clock CHOP generates channels that reflect the time of year, month, week, day, hour, minute, second and millisecond. It also has a moon cycle channel. It provides the date as separate channels and in different units. It presents the time in two ways:\t\t\n\t\t\t\n* It generates '''0-1 ramps''' that reflect the time of year, month, week, day, hour, minute, second and millisecond.\t\t\t\n* It generates '''integers that reflects the day-of month''' etc. In this form the year channel is 4 for 2004, etc.\t\t\t\n\t\t\t\nThere are sunrise/sunset features, and you can override the day-of-year by inputting 1-6 channels into the CHOP.",
        "opLabel": "Clock",
        "opClass": "clockCHOP_Class",
        "opType": "clock",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Clock CHOP generates channels that reflect the time of year, month, week, day, hour, minute, second and millisecond.",
        "opCategories": ""
    },
    "compositeCHOP": {
        "label": "compositeCHOP",
        "members": [
            {
                "text": "Menu : Matches channels in the base input with ones in the layer input by either index or name.",
                "type": "Par",
                "name": "match"
            },
            {
                "text": "Menu : Sets the meaning of the next four parameters - either Absolute values, Relative to the Start/End of the channel, or Relative to the Current Frame. The layer and base are never shifted.",
                "type": "Par",
                "name": "relative"
            },
            {
                "text": "Menu : How to interpolate from one CHOP to another. It is the shape of the segment between the Start and Peak indices.",
                "type": "Par",
                "name": "risefunc"
            },
            {
                "text": "Menu : How to interpolate from one CHOP to another. It is the shape of the segment between the Release and End.",
                "type": "Par",
                "name": "fallfunc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Composite CHOP layers (blends) the channels of one CHOP on the channels of another CHOP. The first input is the base input and the second is the layer input. It is designed for blending static multi-frame motion channels. Blending time-sliced channels or single-frame channels should be done with the [[Blend CHOP]].\t\t\n\t\t\t\nOver the interval of the layer, the layer channels are blended with the base channels. The contribution of the layer is eased-in and eased-out according to the Start, Peak, Release and End parameters. The base is unaffected outside the interval of the layer.\t\t\t\n\t\t\t\nThe Effect parameter determines the amount of contribution of the layer.\t\t\t\n\t\t\t\nIf Base Hold is 0, the layer input will completely replace the base input when the effect is 1. If the Base Hold is 1, the layer will be added to the base.\t\t\t\n\t\t\t\nThe interval of the output starts at the minimum of the base and layer. The interval of the output ends at the maximum of the base and layer. The base's extend conditions are used if the layer lies outside the base.\t\t\t\n\t\t\t\n'''Note:''' If the third input is supplied, the Effect page will be overridden by the third input's first channel, which should contain the effect values over the range of the layer.",
        "opLabel": "Composite",
        "opClass": "compositeCHOP_Class",
        "opType": "comp",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Composite CHOP layers (blends) the channels of one CHOP on the channels of another CHOP.",
        "opCategories": ""
    },
    "constantCHOP": {
        "label": "constantCHOP",
        "members": [
            {
                "text": "Menu : Select the units to use for this parameter, Samples, Frames, or Seconds.",
                "type": "Par",
                "name": "startunit"
            },
            {
                "text": "Menu : Select the units to use for this parameter, Samples, Frames, or Seconds.",
                "type": "Par",
                "name": "endunit"
            },
            {
                "text": "Menu : The left extend conditions (before range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Constant CHOP creates new constant-value channels. Each channel can be named and assigned a different value. To create a channel, simply enter a channel name in a name parameter on the Constant page, then adjust the below value.\t\t\n\t\t\t\nThe CHOP interval (length of time) is one sample long by default (one sample at index 0 = frame 1). An interval range can be optionally set in the Channel page.\n\nYou can use [[Pattern Expansion]] like <code>geo[1-4][xyz]</code> to generate multiple channels in one line.\n\t\t\t\nA simple Constant CHOP with no inputs is the most common use of the CHOP. However, the channels names and values can be set up by connecting any CHOP to its input and clicking the Snapshot Input button (Snap page). This allows you to get some channels from another CHOP and adjust them with sliders in the Constant CHOP.\t\t\t\n\t\t\t\nThe second input can be used to add offsets to the constant values. When the second input (Active) is greater than zero, any change to the first input will be added to the output of the CHOP. This is useful for adjusting Constant CHOP values from external input devices like a MIDI slider box. For example you can connect the mouse or a MIDI slider box to a [[Mouse In CHOP]] or [[MIDI In CHOP]], and you can raise/lower the Constant CHOP values by holding the Active input On, while moving the mouse or sliders.",
        "opLabel": "Constant",
        "opClass": "constantCHOP_Class",
        "opType": "constant",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Constant CHOP creates new constant-value channels.",
        "opCategories": ""
    },
    "copyCHOP": {
        "label": "copyCHOP",
        "members": [
            {
                "text": "Menu : Select which copy method to use from the menu options below.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : Select which output method to use from the menu options below.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : See Remainder parameter below..",
                "type": "Par",
                "name": "remainder"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Copy CHOP produces multiple copies of the second input along the timeline of the first input. The first input provides the trigger signals or the convolve levels.\t\t\n\t\t\t\nThe Copy CHOP can be used to produce a motion every time a trigger occurs. It can be used to trigger motion, such as eyelid blinks. The copies it produces can be identical, or the copies can be re-cooked each time a copy is added to the timeline. It is useful for triggering a sound multiple times, where the sounds may overlap in time.\t\t\t\n\t\t\t\nEach copy that is added to the output can be completely different than any other copy. By passing variables through the Variables page, the second (Copy) input can be any CHOP chain that uses the variables and recooks to create each copy.",
        "opLabel": "Copy",
        "opClass": "copyCHOP_Class",
        "opType": "copy",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Copy CHOP produces multiple copies of the second input along the timeline of the first input.",
        "opCategories": ""
    },
    "countCHOP": {
        "label": "countCHOP",
        "members": [
            {
                "text": "Menu : Determines whether a trigger occurs on an increasing slope or decreasing slope when passing the trigger threshold. A release will occur on the opposite slope.",
                "type": "Par",
                "name": "triggeron"
            },
            {
                "text": "Menu : Select limit options such as loop and/or clamp from the menu. The value will remain in the range from Min to Max.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : The operation to perform when a trigger event (off to on) occurs.",
                "type": "Par",
                "name": "offtoon"
            },
            {
                "text": "Menu : The operation to perform while the input remains triggered (on).",
                "type": "Par",
                "name": "on"
            },
            {
                "text": "Menu : The operation to perform when a release event (on to off) occurs.",
                "type": "Par",
                "name": "ontooff"
            },
            {
                "text": "Menu : The operation to perform while the input is not triggered (off).\t\n\t\t\t\n'''Note''': The scripts are run relative to the parent node of this CHOP, as if the script is in the node above this CHOP.",
                "type": "Par",
                "name": "off"
            },
            {
                "text": "Menu : This menu determines how the Reset input triggers a reset of the channel(s).",
                "type": "Par",
                "name": "resetcondition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Count CHOP counts the number of times a channel crosses a trigger or release threshold. It operates in either static or realtime (\"Cook to Current Frame\") mode.\t\t\n\t\t\t\nThe trigger value by default is 0, so the count occurs when the input goes from below (or equal to) 0 to a value that is greater than zero.\t\t\t\n\t\t\t\nCrossing the trigger threshold (increasing past the trigger level) creates a trigger event. Similarly, crossing the release threshold (decreasing past the release level) creates a release event. Operations may also be performed while the input remain above or below the trigger or release levels. On each event, the count may be increased or decreased by 1 or the time, or reset to zero. The time per sample varies with the sample rate (i.e. for 100 samples/second, the time for each sample would be 1/100th of a second).\t\t\t\n\t\t\t\nThe optional second input is a reset input. The first channel is interpreted as a channel containing reset pulses. Whenever this channel is non-zero, the count for all channels is reset.\t\t\t\n\t\t\t\nThe third input is labeled \"Increment Value\". It allows you to specify a value other than the default +-1 to count. If you want to count by Fives, then put a channel with a value of 5 in this input. It will increment by 5 each count, or by 5 per second depending on the On / Off menus on the second page.",
        "opLabel": "Count",
        "opClass": "countCHOP_Class",
        "opType": "count",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Count CHOP counts the number of times a channel crosses a trigger or release threshold.",
        "opCategories": ""
    },
    "cplusplusCHOP": {
        "label": "cplusplusCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The CPlusPlus CHOP allows you to make custom CHOP operators by writing your own plugin using C++.\t\n\nSee [[Write a CPlusPlus Plugin]] and the other articles in the [[:Category:C++ | C++ Category]] for more detailed information on how to make plugins for use with this node and how to access example projects.",
        "opLabel": "CPlusPlus",
        "opClass": "cplusplusCHOP_Class",
        "opType": "cplusplus",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The CPlusPlus CHOP allows you to make custom CHOP operators by writing your own plugin using C++.",
        "opCategories": ""
    },
    "crossCHOP": {
        "label": "crossCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Cross CHOP is a multi input OP that blends between 2 inputs at a time. This is similar to a [[Switch CHOP]] however the Cross CHOP allows for interpolation between the inputs.",
        "opLabel": "Cross",
        "opClass": "crossCHOP_Class",
        "opType": "cross",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Cross CHOP is a multi input OP that blends between 2 inputs at a time.",
        "opCategories": ""
    },
    "cycleCHOP": {
        "label": "cycleCHOP",
        "members": [
            {
                "text": "Menu : How to blend between cycles:",
                "type": "Par",
                "name": "blendmethod"
            },
            {
                "text": "Menu : The shape of the blending function:",
                "type": "Par",
                "name": "blendfunc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Cycle CHOP creates cycles. It can repeat the channels any number of times before and after the original. It can also make a single cycle have a smooth transition from its end to its beginning, so it loops smoothly.\t\t\n\t\t\t\nSince channels may not naturally loop well, the Cycle CHOP provides three different methods of blending between the cycles.",
        "opLabel": "Cycle",
        "opClass": "cycleCHOP_Class",
        "opType": "cycle",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Cycle CHOP creates cycles. It can repeat the channels any number of times before and after the original.",
        "opCategories": ""
    },
    "dattoCHOP": {
        "label": "dattoCHOP",
        "members": [
            {
                "text": "Menu : This parameter allows you to pick different ways of specifying the rows selected.",
                "type": "Par",
                "name": "extractrows"
            },
            {
                "text": "Menu : This parameter allows you to pick different ways of specifying the columns selected.",
                "type": "Par",
                "name": "extractcols"
            },
            {
                "text": "Menu : Specify the form of the channels output.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : Specifies whether the first row is ignored, names, or values.",
                "type": "Par",
                "name": "firstrow"
            },
            {
                "text": "Menu : Specifies whether the first columnn is ignored, names, or values.",
                "type": "Par",
                "name": "firstcolumn"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opClass": "dattoCHOP_Class",
        "opFamily": "CHOP",
        "long": "The DAT to CHOP will create a set of CHOP channels with values derived from a [[DAT]].",
        "short": "The DAT to CHOP will create a set of CHOP channels with values derived from a [[DAT]].",
        "opFilter": "False",
        "opType": "datto",
        "opLabel": "DAT to",
        "opCategories": ""
    },
    "delayCHOP": {
        "label": "delayCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Delay CHOP delays the input. Multiple channels can be fed in to delay each separately. Each channel can have a separate delay time using <code>me.chanIndex</code>. \t\n\t\t\nEchoes can be created by chains of Delay CHOPs with Math CHOPs between, or by using the [[Feedback CHOP]].",
        "opLabel": "Delay",
        "opClass": "delayCHOP_Class",
        "opType": "delay",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Delay CHOP delays the input. Multiple channels can be fed in to delay each separately and each channels can have a separate delay time.",
        "opCategories": ""
    },
    "deleteCHOP": {
        "label": "deleteCHOP",
        "members": [
            {
                "text": "Menu : Determines whether the scoped channels should be deleted or retained:",
                "type": "Par",
                "name": "discard"
            },
            {
                "text": "Menu : How to select channels - <span class=\"tipTextCHOP\">By Name</span>, or By <span class=\"tipTextCHOP\">Numeric</span> index.",
                "type": "Par",
                "name": "select"
            },
            {
                "text": "Menu : Chooses the type of value range selection:",
                "type": "Par",
                "name": "chanvalue"
            },
            {
                "text": "The lower and upper values of the range used for Range Selection.",
                "type": "Par",
                "name": "selrange1"
            },
            {
                "text": "The lower and upper values of the range used for Range Selection.",
                "type": "Par",
                "name": "selrange2"
            },
            {
                "text": "Menu : How to select channels used to compare against criteria - By <span class=\"tipTextCHOP\">Name</span>, by <span class=\"tipTextCHOP\">Numeric</span> index, by using the <span class=\"tipTextCHOP\">First Channel</span>, or by using the <span class=\"tipTextCHOP\">Last Channel</span>.",
                "type": "Par",
                "name": "compchans"
            },
            {
                "text": "Menu : If there is more that one compare channel, this determines how to treat the values in the compare channels before checking against the criteria:",
                "type": "Par",
                "name": "compmulti"
            },
            {
                "text": "Menu : Choose the criteria for the samples to be compare against:",
                "type": "Par",
                "name": "condition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Delete CHOP removes entire channels and/or individual samples of its input. \t\t\n\t\t\t\nFor deleting channels, on the Channels page, you can specify which channels to delete by channel name or a channel number range. A second method deletes channels using a value range to select channels whose values are all within a range. The third method deletes constant-valued channels. An option selects whether to delete or retain the matched channels.\t\t\t\n\t\t\t\nFor deleting individual samples (i.e. no channels are deleted), on the Samples page you can delete, for example, only the samples whose value is below 0, which will shorten the length of the CHOP. \t\t\t\n\t\t\t\nIn CHOPs with two or more channels, one or more \"compare\" channels are used to determine which samples are to be deleted. By default it uses the first channel to compare against. Deleting a sample at a certain index deletes a value for all the channels. If there are 4 channels, <code>red</code>, <code>green</code>, <code>blue</code>, <code>alpha</code> and you specify <code>alpha</code> as the \"compare\" channel, you can delete all the samples with an <code>alpha</code> of <code>0</code>. If a CHOP is 3 channels with an X,Y,Z position, you can delete all samples where the XYZ length is below a threshold.\t\t\t\n\t\t\t\nThis is useful, for example, for thinning your data before sending a CHOP to a Geometry component for instancing. \t\t\t\n\t\t\t\nWhen all the samples are deleted, the CHOP will keep one sample for all channels and will have a <code>length</code> of one sample. When this happens, if you have an Info CHOP attached to the Delete CHOP, it's \t\t\t\n\t\t\t\nSee also [[Splice CHOP]], [[Select CHOP]], [[Trim CHOP]]",
        "opLabel": "Delete",
        "opClass": "deleteCHOP_Class",
        "opType": "delete",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Delete CHOP removes entire channels and/or individual samples of its input.",
        "opCategories": ""
    },
    "dmxinCHOP": {
        "label": "dmxinCHOP",
        "members": [
            {
                "text": "Menu : Select the type of interface to connect to the device with.",
                "type": "Par",
                "name": "interface"
            },
            {
                "text": "Menu : Set the version of the KiNET protocol to use.",
                "type": "Par",
                "name": "kinetversion"
            },
            {
                "text": "Menu : Select between receiving Packet Per Sample (Timesliced), Packet Per Channel (Latest) or Packet Per Channel (All). When selecting Packet Per Channel (Latest), any messages outside the last cook are being discarded while the option Packet Per Channel (All) will append channels that would get otherwise skipped by dropped frames.",
                "type": "Par",
                "name": "format"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The DMX In CHOP receives channels from DMX, [[Art-Net]], [[sACN]] or KiNET devices. Channel values for DMX are 0-255. Note that input rate is limited to the DMX maximum refresh rate of 44Hz.\t\t\n\t\t\t\nA Filter Table can be provided in a DAT where addresses can be specified by adding rows for each channel and specifying '''net''', '''subnet''' and '''universe'''. Optionally, packets can be filtered using the '''srcaddress''' and '''destaddress''' columns; only packets that have a matching source IP address and destination IP address will be accepted. The cell values for these columns should be a single IP address (ie. regex not supported); if left blank then all packets will be accepted. \n\nThe '''srcaddress''' column is useful for when there is DMX noise on the network that needs to be filtered out; the IP of the desired controller can be specified in the '''srcaddress''' cell. The '''id''' column should be used in conjunction with '''srcaddress''' and '''destaddress''' to provide a unique channel suffix.\n\n[https://www.wireshark.org/ Wireshark] is a useful tool for debugging network issues. In the Art-Net case, packets can easily be filtered using '''artnet''', '''dmx''', or '''dmx_chan'''.\n\t\t\t\n'''ENTTEC NOTE:''' - Use ENTTEC's [http://www.enttec.com/us/products/controls/dmx-over-ethernet/nmu/ NMU (Node Management Utility)] to configure and inspect the ENTTEC devices found on your network. \t\t\t\n\t\t\t\nSee also: [[Art-Net]], [[DMX Out CHOP]], [[DMX]]",
        "opLabel": "DMX In",
        "opClass": "dmxinCHOP_Class",
        "opType": "dmxin",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The DMX In CHOP receives channels from DMX, [[Art-Net]]  or [[sACN]] devices.",
        "opCategories": ""
    },
    "dmxoutCHOP": {
        "label": "dmxoutCHOP",
        "members": [
            {
                "text": "Menu : Select the type of interface to connect to the device with.",
                "type": "Par",
                "name": "interface"
            },
            {
                "text": "Menu : Set the version of the KiNET protocol to use.",
                "type": "Par",
                "name": "kinetversion"
            },
            {
                "text": "Menu : Select between sending Packet Per Sample or Packet Per Channel.",
                "type": "Par",
                "name": "format"
            },
            {
                "text": "StrMenu : Select a DMX device from the menu.",
                "type": "Par",
                "name": "device"
            },
            {
                "text": "StrMenu : When the Interface parameter is set to Generic Serial this parameter lets you select which Serial (COM) port to use.",
                "type": "Par",
                "name": "serialport"
            },
            {
                "text": "StrMenu : When the sending machine is equipped with multiple network adapters, this parameter can be used to choose which adapter to send the data from by specifying its IP address here.",
                "type": "Par",
                "name": "localaddress"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The DMX Out CHOP sends channels to [[DMX]], [[Art-Net]], [[sACN]], KiNET, or FTDI devices. Channel values for DMX are 0-255.  \t\t\n\t\t\t\nThe first channel you send into the DMX Out will correspond to the first DMX address (DMX channel) As you add channels to the DMX Out, you will access the next DMX channels in order. For example, if you input 12 channels into the DMX out, you will be controlling DMX channels 1 thru 12.\t\t\t\n\t\t\t\nThe DMX in TouchDesigner was developed on the [http://www.enttec.com ENTTEC] device, namely their [http://www.enttec.com/?main_menu=Products&pn=70304 DMX USB Pro] and DMX over Ethernet devices, but it should work for many devices and software that support DMX/Art-Net/sACN/KiNET.\t\t\t\n\t\t\t\nA Routing Table can be provided in a DAT where addresses can be specified by adding rows for each channel and specifying net, subnet and universe. \t\t\t\n\t\t\t\n'''ENTTEC NOTE:''' - Use ENTTEC's [http://www.enttec.com/us/products/controls/dmx-over-ethernet/nmu/ NMU (Node Management Utility)] to configure and inspect the ENTTEC devices found on your network. \t\t\t\n\t\t\t\n'''macOS NOTE:''' - ENTTEC USB Pro may not connect automatically, to enable it enter the following command in the Terminal:\t\t\t\n\t\t\t\n<code>sudo kextunload -b com.apple.driver.AppleUSBFTDI</code>\n\n'''Tip''': See the [[OP Snippets]] for setup and usage examples.\n\n'''Tip''': Use [https://www.wireshark.org/ WireShark] to watch your DMX network traffic.\n\t\t\t\n\t\t\t\nSee also: [[Art-Net]], [[sACN]], [[DMX In CHOP]], [[DMX]]",
        "opLabel": "DMX Out",
        "opClass": "dmxoutCHOP_Class",
        "opType": "dmxout",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The DMX Out CHOP sends channels to DMX, Art-Net, or [[sACN]] devices.",
        "opCategories": ""
    },
    "envelopeCHOP": {
        "label": "envelopeCHOP",
        "members": [
            {
                "text": "Menu : The two methods of calculating the envelope:",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "bounds"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "interp"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Envelope CHOP outputs the maximum amplitude in the vicinity of each sample of the input. It takes the absolute value of the input, and uses a sliding window of a number of samples to find the maximum amplitude near each sample.\t\t\n\t\t\t\n'''Tip:''' The loudness levels of an audio track can be kept roughly constant by computing an envelope of the audio with a wide window, and then passing the original audio and the envelope to a [[Math CHOP]] and selecting '''Combine CHOPs - Divide'''. This will make the amplitude approximately 1.",
        "opLabel": "Envelope",
        "opClass": "envelopeCHOP_Class",
        "opType": "envelope",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Envelope CHOP outputs the maximum amplitude in the vicinity of each sample of the input.",
        "opCategories": ""
    },
    "etherdreamCHOP": {
        "label": "etherdreamCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "EtherDream is a laser controller. The EtherDream CHOP takes as input up to five channels interpreted as X and Y (horizontal and vertical) position values in the first 2 channels, and red, green and blue color values in the next 3 channels. It outputs the data to an [http://ether-dream.com/ EtherDream] device via a network connection. The EtherDream device is connected to a laser using an ILDA cable. The user can then control the image that the laser should output using the EtherDream CHOP. Applications of the EtherDream CHOP include displaying computer-generated shape animations or other special effects of a light show.\t\n\t\t\nThe EtherDream CHOP needs the IP address of the EtherDream device, which you can get from the output of an [[EtherDream DAT]].\t\t\n\t\t\nBlanking (all-off) occurs when the incoming RGB CHOP channels are all zero, or the Red Scale, Green Scale, and Blue Scale parameters are all zero.\t\t\n\t\t\nIt is sometimes helpful to have additional information with respect to the general state of the hardware, whether any warnings are generated by the connected devices, how well the EtherDream is receiving points, the point output rate, and the point buffer capacity. Such details can be seen by connecting the EtherDream CHOP to an [[Info CHOP]], and may be useful for troubleshooting display images.\t\t\n\t\t\nThe <code>maxrate</code> column of the EtherDream DAT indicates the maximum number of samples per second that can be sent to the EtherDream device, though in practice, most lasers are reflected into position by a set of mechanical reflectors, with their own mechanical characteristics.  As a result, attempting to quickly scan a square over a large area too quickly, for example, may result in a very curved corners as the physical components lag behind their target positions.\t\t\n\t\t\nLarge changes in RGB values from sample-to-sample will likely be visibly correct as lasers generally can switch on-off quickly.\t\t\n\t\t\nThe range of X and Y is typically -1 to +1, and the range of RGB is typically 0 to 1.\t\t\n\t\t\nIf <code>maxrate</code> is 100,000, and given that the CHOP takes time-sliced data, it is appropriate to send a time-sliced CHOP with a sample rate of up to 100,000 samples per second to the EtherDream CHOP.\t\t\n\t\t\nSee also: [[EtherDream DAT]], [[Laser CHOP]], and the [[Pattern CHOP]], [[Helios DAC CHOP]].",
        "opLabel": "EtherDream",
        "opClass": "etherdreamCHOP_Class",
        "opType": "etherdream",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "EtherDream is a laser controller.",
        "opCategories": ""
    },
    "eventCHOP": {
        "label": "eventCHOP",
        "members": [
            {
                "text": "Menu : Determines the reset behavior of using the 2nd Input Reset Trigger. This parameter is only active if there is an input connected to the CHOP's 2nd input.",
                "type": "Par",
                "name": "resetcondition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Event CHOP manages the birth and life of overlapping events triggered by devices like a MIDI keyboard. It can be seen as a simple particle system designed for MIDI keyboards.\t\t\n\t\t\t\nThe Event CHOP generates one sample for each off-to-on event in the input channels, which would often come from a [[MIDI In CHOP]], [[MIDI In Map CHOP]], [[Keyboard In CHOP]], or python events sent to the Event CHOP. The sample exists for the duration of the event's attack+decay+sustain+release time.\t\t\t\n\t\t\t\n'''NOTE''': See the examples in Help->[[OP Snippets]]\t\t\t\n\t\t\t\nThe Event CHOP can used to follow a polyphonic music keyboard with MIDI velocity, and can generate generating one object, polygon or geometry instance for each event. It assures the object, polygon or instance exists until the event ends after an attack-decay-sustain-release phase. The Event CHOP is often fed through other OPs to the Instance parameters of a Geometry component.\t\t\t\n\t\t\t\nThe Event CHOP outputs up to 8 channels, with one sample generated per off-to-on event that is active. The sample is active until the attack-decay-sustain-release is over, at which moment the sample disappears (like particle death).\t\t\t\n\t\t\t\nWatch the channel graph of the Event CHOP to understand what it is doing. It can be sent to a [[Limit SOP]] or a [[CHOP to SOP|Channel SOP]] to place geometry for each event. You can send event information to the SOP via the Event CHOP channels that get transformed into geometry channels like <code>tx</code>, <code>ty</code>, <code>scale</code>, texture v (giving movie time offsets), alpha, r, g and b colors.\t\t\t\n\t\t\t\nOn a MIDI keyboard, you can trigger many events simultaneously, and, like particles, you may want to launch objects that remain in existence the next time you press the same key.\t\t\t\n\t\t\t\nThe Event CHOP is designed to handle this. It creates one sample every time you press any key, and that sample lives for any length of time. This CHOP is lightweight - the minimum number of channels and samples are created, even with 88-key MIDI keyboards and lots of pounding on the keyboard.\t\t\t\n\t\t\t\nThere are channels that represent age, note number and MIDI velocity when you pressed the key, as well as a flag telling if the key has since been released.\t\t\t\n\t\t\t\nEach event has a unique ID, held in the <code>id</code> channel that can be used to generate random XY displacements of each note, for example.\t\t\t\n\t\t\t\nA movie index is set by the <code>state</code> channel which rises from 0 to 1 and loops between 1 to 2 continuously until the note goes into its release state at which time it goes from 2 to 3. So for a bird cycle, you use the 0 to 1 state for the jump phase, 1 to 2 for the flappin in flight phase, and 2 to 3 for the landing phase.\t\t\t\n\t\t\t\nThe Event CHOP's 1st input is for event triggers.\t\t\t\n\t\t\t\nThe 2nd input resets the triggers.\t\t\t\n\t\t\t\nThe 3rd input is optional and allows for sampling values for each event.\t\t\t\n\t\t\t\nSee also: [[Timer CHOP]], [[Count CHOP]], [[Speed CHOP]], [[Trigger CHOP]]",
        "opLabel": "Event",
        "opClass": "eventCHOP_Class",
        "opType": "event",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Event CHOP manages the birth and life of overlapping events triggered by devices like a MIDI keyboard.",
        "opCategories": ""
    },
    "expressionCHOP": {
        "label": "expressionCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Expression CHOP allows you to modify input channels by using math expressions. Each input channel is modified by exactly one expression, and the expressions are looped for multiple channels.\t\n\t\t\nThe output is the same length and set of channels as the first input, but its sample values are changed according to the expressions.\t\t\n\t\t\nAn expression is applied to each keyframe value or raw sample. If there are more channels coming from input 0 than expressions, the expressions are recycled. A Channels per Expression parameter controls how many channels to apply the first expression to before going on to the second expression.\n\t\t\nThe corresponding input values are <code>me.inputVal</code> in the expressions. <code>me.inputs[1][0]</code> gets from the first channel of the second input.\t\t\n\t\t\nSee also [[Evaluate DAT]] for easy evaluation of any expression.",
        "opLabel": "Expression",
        "opClass": "expressionCHOP_Class",
        "opType": "express",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Expression CHOP allows you to modify input channels by using math expressions.",
        "opCategories": ""
    },
    "extendCHOP": {
        "label": "extendCHOP",
        "members": [
            {
                "text": "Menu : The extend condition before the CHOP interval. They are:",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : Extend condition after the interval. Same options as Extend Left.",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Extend CHOP only sets the \"extend conditions\" of a CHOP, which determines what values you get when sampling the CHOP before or after its interval.\t\t\n\t\t\t\nThe Extend CHOP has separate menus to control both the pre-interval and the post-interval. For example, before the interval, you may want to hold a constant value, and after the interval you may want to cycle or repeat the curves in the interval.\t\t\t\n\t\t\t\nTo shorten or lengthen the interval (the start or end of the CHOP), use the [[Trim CHOP]].\t\t\t\n\t\t\t\nYou can see the state of Extend Conditions in the pop-up info of any CHOP (use middle-mouse click on the CHOP).",
        "opLabel": "Extend",
        "opClass": "extendCHOP_Class",
        "opType": "extend",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Extend CHOP only sets the \"extend conditions\" of a CHOP, which determines what values you get when sampling the CHOP before or after its interval.",
        "opCategories": ""
    },
    "facetrackCHOP": {
        "label": "facetrackCHOP",
        "members": [
            {
                "text": "Menu : The GPU to run the face tracking models on. An Nvidia RTX or newer card is required.",
                "type": "Par",
                "name": "gpu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "landmarks"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "facetrackCHOP",
        "opLabel": "Face Track",
        "opClass": "facetrackCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This operator uses the Augmented Reality (AR) SDK of the Nvidia Maxine system and requires a 20 or 30 series Nvidia RTX card to operate. 40 series cards are not currently supported.",
        "short": "The Face Track CHOP can detect faces and facial landmarks in a given image stream.",
        "long": "The Face Track CHOP can detect faces and facial landmark points in an image, as well as the direction the face is looking relative to the camera. Using a compatible 3D Morphable Face Model (3DMM) and the [[Face Track SOP]], it can also be used to fit and animate a 3D mesh to the detected face.\n    \nThe input image is taken from a provided TOP and can be of any resolution or format, and either a still image or video. If multiple faces are present in an image, the CHOP will attempt to track the largest one detected.\n\nThe coordinates of the detected features are given in u, v positions relative to the bottom-left corner of the input image. By default, the values range from 0 to 1, but the 'Aspect Correct' parameter can be enabled to scale the values so that they can be used as 3D coordinates while maintaining the aspect ratio of the original image.\n\nTo align a 3D rendering of the points with the original input image, set the 'Projection' of your [[Camera COMP]] to 'Orthographic', the 'Ortho Origin' parameter to 'Bottom-Left', and the 'Ortho Width' to 1, while also enabling 'Aspect Correct' on the Face Track CHOP.\n\nTo use the mesh fitting features you will need a compatible face mesh file in the Nvidia 'nvf' format. This file is not included with TouchDesigner, but can be generated using files available online. \n\nTo create the file:\n\n1. Download the Surrey Face Model files from the [https://github.com/patrikhuber/eos/tree/master/share eos project on GitHub]:\n* ''sfm_shape_3448.bin''\n* ''expression_blendshapes_3448.bin''\n* ''sfm_3448_edge_topology.json''\n* ''sfm_model_contours.json''\n* ''ibug_to_sfm.txt''\n\n2. Download the mesh conversion tool ''ConvertSurreyFaceModel.exe'' from the [https://github.com/NVIDIA/BROADCAST-AR-SDK/tree/master/tools Nvidia AR SDK page on GitHub]\n\n3. Run the conversion tool to generate the nvf file. The 'path' is only necessary if the model files are in a different folder than the conversion tool.\n<syntaxhighlight lang=python>\nConvertSurreyFaceModel.exe \n--shape=<i>path/</i>sfm_shape_3448.bin\n--blend_shape=<i>path/</i>expression_blendshapes_3448.bin\n--topology=<i>path/</i>sfm_3448_edge_topology.json\n--contours=<i>path/</i>sfm_model_contours.json\n--ibug=<i>path/</i>ibug_to_sfm.txt\n--out=<i>output-path/</i>face_model0.nvf</syntaxhighlight>",
        "opCategories": ""
    },
    "fanCHOP": {
        "label": "fanCHOP",
        "members": [
            {
                "text": "Menu : Selects either Fan In or Fan Out.",
                "type": "Par",
                "name": "fanop"
            },
            {
                "text": "Menu : Determines how to handle input values that are outside the index range (0 to N-1).",
                "type": "Par",
                "name": "range"
            },
            {
                "text": "Menu : For a Fan In operation, when all input channels are off, set the output to -1 or 0.",
                "type": "Par",
                "name": "alloff"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Fan CHOP converts one channel out to many channels, or converts many channels down to one.\t\t\n\t\t\t\nIts first operation, '''Fan Out''', takes one channel and generates 2 or more channels. It sets to 1 one of the output channels while all others are 0, based on the input channel's value. The first output channel is index value 0, the second, 1, and so on. If the input value is above N-1 or below 0, the value can be clamped, cycled or ignored.\t\t\t\n\t\t\t\nFor example, if the value of the input channel at a certain frame is 4, and if the CHOP outputs 8 channels, the fifth channel will have a value of 1, and all other channels will have a zero value at that frame.\t\t\t\n\t\t\t\nThe input is assumed to have 1 channel which contains integer values; fractions are truncated and extra channels are ignored. The output channels are binary (0 or 1) channels.\t\t\t\n\t\t\t\nThe second operation, '''Fan In''', does the opposite: it takes a bunch of binary inputs and produces one channel containing the index of the \"On\" channel. If more than one input channel is \"On\", the first \"On\" input channel is selected.",
        "opLabel": "Fan",
        "opClass": "fanCHOP_Class",
        "opType": "fan",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Fan CHOP converts one channel out to many channels, or converts many channels down to one.",
        "opCategories": ""
    },
    "feedbackCHOP": {
        "label": "feedbackCHOP",
        "members": [
            {
                "text": "Menu : Choose what to output from this menu.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Feedback CHOP stores channels from the current frame to be used in a later frame, without forcing recooking back one frame. It allows you to get the state of a CHOP as it was one frame or time slice ago.\t\t\n\t\t\t\nFor example, if you need the position or speed of an object from a frame ago in order to compute its position, displacement or speed at the current frame, you would select a CHOP containing those values, and it will output it a frame or time slice later.\t\t\t\n\t\t\t\nCHOPs like the [[Lag CHOP]] and [[Filter CHOP]] look back in time (iterate) internal to the CHOP, but sometimes the output of a chain of CHOPs is needed as the input of the same chain one frame later.\t\t\t\n\t\t\t\nIt allows connecting CHOPs in circular loops without '''Infinite Recursion''' errors. It simply copies its input without cooking it first.",
        "opLabel": "Feedback",
        "opClass": "feedbackCHOP_Class",
        "opType": "feedback",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Feedback CHOP stores channels from the current frame to be used in a later frame, without forcing recooking back one frame.",
        "opCategories": ""
    },
    "fileinCHOP": {
        "label": "fileinCHOP",
        "members": [
            {
                "text": "Menu : Use this menu to control the names of the loaded channels.",
                "type": "Par",
                "name": "nameoption"
            },
            {
                "text": "Menu : Use this menu to adjust the sample rate of the loaded channels.",
                "type": "Par",
                "name": "rateoption"
            },
            {
                "text": "Menu : The left extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The File In CHOP reads in channel and audio files for use by CHOPs. The file can be read in from disk or from the web. Use <code>http://</code> when specifying a URL.\t\t\n\t\t\t\n===<div class=\"subSectionLineCHOP\">Valid Formats</div>===\t\t\t\n\t\t\t\nFor a complete listing of all valid formats for CHOPs, see the [[File Types]] section. The types of files that can be read into CHOPs include:\t\t\t\n\t\t\t\n* <code>'''.chan'''</code> - Raw ASCII channel files; a row of numbers per frame. The channels are named automatically.\t\t\t\n* <code>'''.clip .bclip'''</code> - TouchDesigner native CHOP clip files.\t\t\t\n* <code>'''.aiff'''</code> - Audio files.\t\t\t\n* <code>'''.wav'''</code> - Audio files.\t\t\t\n\t\t\t\n===<div class=\"subSectionLineCHOP\"> Outputting Channel Files </div>===\t\t\t\n\t\t\t\nThe same files can be output from the [[Mouse Click|RMB]] menu on the CHOP by selecting '''Save Data Channels'''.\t\t\t\n\t\t\t\n===<div class=\"subSectionLineCHOP\"> Other Input Devices </div>===\t\t\t\n\t\t\t\nFor MIDI files (<code>.mid</code> or <code>.midi</code>), see the [[MIDI In CHOP]].",
        "opLabel": "File In",
        "opClass": "fileinCHOP_Class",
        "opType": "filein",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The File In CHOP reads in channel and audio files for use by CHOPs.",
        "opCategories": ""
    },
    "fileoutCHOP": {
        "label": "fileoutCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The File Out CHOP writes CHOP channel data out to .chan files. The data can be written out every frame or at intervals (set by the Interval parameter) into a log file. \t\n\t\t\n* <code>'''.chan'''</code> format - Raw ASCII channel files; a row of numbers per frame. The channels are named automatically.",
        "opLabel": "File Out",
        "opClass": "fileoutCHOP_Class",
        "opType": "fileout",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The File Out CHOP writes CHOP channel data out to .chan files.",
        "opCategories": ""
    },
    "filterCHOP": {
        "label": "filterCHOP",
        "members": [
            {
                "text": "Menu : There are seven types of filters:",
                "type": "Par",
                "name": "type"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Filter CHOP smooths or sharpens the input channels. It filters by combining each sample and a range of its neighbor samples to set the new value of that sample. Each filter type uses its own weighting factors for the neighboring samples. The <span class=\"tipTextCHOP\">Filter Width</span> determines the number of neighbors to use.\t\t\n    \nThe default Gaussian filter nicely smooths out data, typically with a Filter Width around .3 seconds. The Box Filter is interesting when your inputs are step changes to new values: the values linearly interpolate to the new value. \n\nIt is useful to follow the Filter CHOP with a [[Trail CHOP]] and connect the filtered and pre-filtered signal to its inputs.\n\nIf you want to pass one or more channels in, each with multi-samples, and you want to filter each sample as if each sample was its own filter, turn on the Filter per Sample parameter. \n\t\t\t\nFor a similar, more-abrupt effect, see the [[Lag CHOP]].\t\t\t\n\t\t\t\nThe Filter CHOP can filter both motion and sound, but other CHOPs are more appropriate for filtering sound (see the [[Audio Filter CHOP]], [[Band EQ CHOP]], and [[Parametric EQ CHOP]]).",
        "opLabel": "Filter",
        "opClass": "filterCHOP_Class",
        "opType": "filter",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Filter CHOP smooths or sharpens the input channels.",
        "opCategories": ""
    },
    "freedCHOP": {
        "label": "freedCHOP",
        "members": [
            {
                "text": "Menu : The network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "StrMenu : Specify an IP address to receive on, useful when the system has mulitple NICs (Network Interface Card) and you want to select which one to use.",
                "type": "Par",
                "name": "localaddress"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "freedCHOP",
        "opLabel": "FreeD",
        "opClass": "freedCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The FreeD CHOP reads incoming camera tracking data sent over a network using the FreeD protocol and outputs CHOP channels that can be used to control a virtual 3D camera.",
        "long": "The FreeD CHOP reads incoming camera tracking data sent over a network using the FreeD protocol and outputs CHOP channels that can be used to control a virtual 3D camera. FreeD is not exclusive to any particular tracking system, but is frequenty used as an interchange protocol since it is supported by a wide range of hardware and software. However, as an older standard, it is lower precision and does not contain len distortion data like [[Stype In CHOP|Stype]] or [[Ncam CHOP|Ncam]], so it is recommended to use the hardware specific protocol when possible. Examples of hardware and software that support FreeD are [https://www.vizrt.com/products/viz-virtual-studio Viz Virtual Studio] and [https://na.panasonic.com/us/ar-vr-virtual-set-production-with-panasonic-robotic-ptz-camera Panasonic PTZ cameras.] \n\nThe channels exported by the FreeD CHOP are:\n:''camera_id'' - a number from 0 - 255 that can be used to store an id number for the camera\n:''tx, ty, tz'' - camera position, can be connected to the [[Camera COMP]] Translate parameters\n:''rx, ry, rz'' - camera rotation, can be connected to the [[Camera COMP]] Rotate parameters\n:''focus'' - a 24-bit positive integer (0-16 million) in arbitrary units that relates to the focus ring on a camera lens. Applications can interpret this value according to the hardware in use.\n:''zoom'' - a 24-bit positive integer (0-16 million) in arbitrary units that relates to the zoom ring on a camera lens. Applications can interpret this value according to the hardware in use.\n:''user'' - a 16-bit positive integer (0 - 65k) that can be used by the camera system to send custom user-defined data\n\n'''Note:''' The FreeD CHOP only processes the 'D1' camera position and orientation message that is part of the FreeD protocol. All other message types will be ignored.\n\nFor more information or to diagnose connection problems, an [[Info CHOP]] can be connected to see if any packets have been dropped or skipped.",
        "opCategories": ""
    },
    "freedoutCHOP": {
        "label": "freedoutCHOP",
        "members": [
            {
                "text": "Menu : Selects the network protocol to use. Refer to the Network Protocols article for more information.",
                "type": "Par",
                "name": "protocol"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "freedoutCHOP",
        "opLabel": "FreeD Out",
        "opClass": "freedoutCHOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "",
        "long": "The FreeD Out CHOP sends camera tracking information, including position and orientation, to an external device or program over the network using the popular device-indepedent FreeD protocol. This can be used to emulate a physical camera or to send data to another program/device that can process FreeD tracking data. Data packets are sent out once per frame based on the current data in the CHOP channels. If one of the expected channels is not found in the input, then a default value will be sent. FreeD data can be received from other devices using the corresponding [[FreeD In CHOP]].\n  \nThe channels used by the FreeD Out CHOP are:\n:''camera_id'' - a number from 0 - 255 that can be used to store an id number for the camera\n:''tx, ty, tz'' - camera position, can be connected to the [[Camera COMP]] Translate parameters. Values can range from +/- 131.07m.\n:''rx, ry, rz'' - camera rotation, can be connected to the [[Camera COMP]] Rotate parameters. Values can range from +/- 256 degrees.\n:''focus'' - a 24-bit positive integer (0-16 million) in arbitrary units that relates to the focus ring on a camera lens. Applications can interpret this value according to the hardware in use.\n:''zoom'' - a 24-bit positive integer (0-16 million) in arbitrary units that relates to the zoom ring on a camera lens. Applications can interpret this value according to the hardware in use.\n:''user'' - a 16-bit positive integer (0 - 65k) that can be used by the camera system to send custom user-defined data\n\n'''Note:''' The FreeD Out CHOP sends the 'D1' camera position and orientation message that is part of the FreeD protocol."
    },
    "functionCHOP": {
        "label": "functionCHOP",
        "members": [
            {
                "text": "Menu : Which math function to apply to the channels. All of the functions are unary functions except for the binary functions 'arctan (Input1/Input2)' and 'Input1 ^ Input2'. In the cases of power functions, a negative base is inverted first to avoid imaginary numbers, and the result is negated.",
                "type": "Par",
                "name": "func"
            },
            {
                "text": "Menu : For trigonometric functions, the angles can be measured in Degrees, Radians, or Cycles (0 to 1).",
                "type": "Par",
                "name": "angunit"
            },
            {
                "text": "Menu : How to pair channels together from the two inputs for the binary functions, by name or by channel index.",
                "type": "Par",
                "name": "match"
            },
            {
                "text": "Menu : How to correct samples with math errors:",
                "type": "Par",
                "name": "error"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Function CHOP provides more complicated math functions than found in the [[Math CHOP]] : trigonometic functions, logarithmic functions and exponential functions, and also audio decibels (dB)-power-amplitude conversions.\t\t\n\t\t\t\nMost of the functions require only one parameter, and they are applied as a unary operator to each input channel. Some functions take two parameters, and these require the use of the second input. The first parameter, X, is always a value from a channel in the first input. The second parameter, Y, is a value from a corresponding channel in the second input. Channels from each input are paired by name or index.\t\t\t\n\t\t\t\nSince many of these functions can produce math errors, an error handling tab is provided for error handling and recovery. \t\t\t\nErrors can be handled by replacing the bad sample with a pre-defined value or by using the value of the previous sample. Alternatively, cooking can be aborted upon error for debugging networks.\t\n\nFunction types in decibels: as you would employ for audio or other signal strengths. -10dB means 1/10 the power, -20dB means 1/100 the power. It turns out that each 3dB means almost exactly double the power, so +12dB is 2*2*2*2 = 16 times the power. Power is proportional to the square of the amplitude. So -20dB means 1/10 the amplitude, and 6dB is double the amplitude.",
        "opLabel": "Function",
        "opClass": "functionCHOP_Class",
        "opType": "function",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Function CHOP provides more complicated math functions than found in the [[Math CHOP]] : trigonometic functions, logarithmic functions and exponential functions, and also audio decibels (dB)-power-amplitude conversions.",
        "opCategories": ""
    },
    "gestureCHOP": {
        "label": "gestureCHOP",
        "members": [
            {
                "text": "Menu : Controls the gesture playback.",
                "type": "Par",
                "name": "playmode"
            },
            {
                "text": "Menu : This menu determines how the Reset input (the third input) triggers a reset of the channel(s).",
                "type": "Par",
                "name": "resetcondition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Gesture CHOP records a short segment of the first input and loops this segment in time with options as specified in the Gesture Page. The second input defines the \"listen\" input.  The third input is used to reset the gesture.\t\t\n\t\t\t\n'''Tip''': The <code>gestureCapture</code> component in the palette is much more powerful and flexible to capture and record channels, and has full UI.\t\t\t\n\t\t\t\nIn the Gesture CHOP, when the first channel of the listen input goes above zero, the Gesture CHOP begins recording the first input's channels. While listen is on, the input channels are output exactly as is. When the listen is turned off, the recorded segment of the channels is processed (trimmed and blended). While listen is off, the recorded segment is looped continuously.\t\t\t\n\t\t\t\nThe Gesture CHOP determines the number of beats that the listen was on for; this defines the period of the loop. If the beat frequency changes, the period will change with it.\t\t\t\n\t\t\t\nIf \"Fit to Nearest Cycle\" is Off, the beats are ignored and the gesture length is exactly the time it took to record - the recorded segment will be looped back with a period equal to the recorded length. When On, the captured gesture will be extended or trimmed to be a multiple of the beats per cycle.",
        "opLabel": "Gesture",
        "opClass": "gestureCHOP_Class",
        "opType": "gesture",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Gesture CHOP records a short segment of the first input and loops this segment in time with options as specified in the Gesture Page.",
        "opCategories": ""
    },
    "handleCHOP": {
        "label": "handleCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Handle CHOP is the \"engine\" which drives Inverse Kinematic solutions using the [[Handle COMP]]. The role of the Handle CHOP is to generate rotation values for the bones which will bring their attached handles as close to their respective targets as possible.\t\n\t\t\nThe use of this method is best described with an example:\t\t\n\t\t\n# Increase the frame range to 10000. Create a [[Null COMP]] called 'target' and animate a few random positions for it to travel to.\t\t\n# Create a three bone IK chain with No Kinematics. Append a [[Handle COMP]] to the last bone.\t\t\n# In the Handle COMP set the Target menu to Target. This is the Null COMP you just created.\t\t\n# The system is now specified. To actually start the IK enter a CHOP pane.\t\t\n# Place a Handle CHOP. In the Source field type in the names of the bones that were earlier created.\t\t\n# Click the Export button on the Handle CHOP and click Play. You should now see the two-bone system chasing the animated null.\t\t\n\t\t\n'''Tip:''' In the [[Geometry_Viewer|geometry viewer]], you can use the '''Select''' state to select the bones you created. Then in the Handle CHOP click the '''Grab Source Form Selection''' button. The names are entered automatically for you. You don't have to worry about being too picky when selecting objects this way, since non-bone objects are ignored.\t\t\n\t\t\nYou can place any number of bones with any number of (possibly zero) Handles attached to the system. The following parameter description will now give a more detailed explanation of the functionality:",
        "opLabel": "Handle",
        "opClass": "handleCHOP_Class",
        "opType": "handle",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "he Handle CHOP is the \"engine\" which drives Inverse Kinematic solutions using the [[Handle COMP]].",
        "opCategories": ""
    },
    "heliosdacCHOP": {
        "label": "heliosdacCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "Helios DAC is a laser controller. The Helios DAC CHOP takes as input up to five channels interpreted as X and Y (horizontal and vertical) position values in the first 2 channels, and red, green and blue color values in the next 3 channels. It outputs the data to a [http://pages.bitlasers.com/helios/ Helios DAC]. The Helios DAC device is connected to a laser using an ILDA cable. The user can then control the image that the laser should output using the Helios DAC CHOP. Applications of the Helios DAC CHOP include displaying computer-generated shape animations or other special effects of a light show.\t\n\t\t\nBlanking (all-off) occurs when the incoming RGB CHOP channels are all zero, or the Red Scale, Green Scale, and Blue Scale parameters are all zero.\t\t\n\t\t\nLarge changes in RGB values from sample-to-sample will likely be visibly correct as lasers generally can switch on-off quickly.\t\t\n\t\t\nThe range of X and Y is typically -1 to +1, and the range of RGB is typically 0 to 1.\n\n'''Note:''' The Helios DAC CHOP listens for any device changes on the system and will perform a Helios device re-scan when triggered. However, the re-scan can only be triggered if all Helios connections are closed, meaning all Helios DAC CHOPs are either deactivated or bypassed. To perform a Helios device re-scan with only a single Helios DAC CHOP, simply deactivate and reactivate the CHOP.\n\t\t\nSee also: [[EtherDream CHOP]], [[EtherDream DAT]], [[Laser CHOP]], and the [[Pattern CHOP]].",
        "opLabel": "Helios DAC",
        "opClass": "heliosdacCHOP_Class",
        "opType": "heliosdac",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "Helios DAC is a laser controller.",
        "opCategories": ""
    },
    "hogCHOP": {
        "label": "hogCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Hog CHOP eats up CPU cycles (ie it's a CPU hog - oink!). This can be used to simulate performance on slower machines, or to artifically slow down a synth's frame rate.",
        "opLabel": "Hog",
        "opClass": "hogCHOP_Class",
        "opType": "hog",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Hog CHOP eats up CPU cycles (ie it's a CPU hog - oink!).",
        "opCategories": ""
    },
    "hokuyoCHOP": {
        "label": "hokuyoCHOP",
        "members": [
            {
                "text": "Menu : Select the device interface.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : Outputs the scan data in either Polar or Cartesian coordinates.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "hokuyo",
        "opLabel": "Hokuyo",
        "opLicense": "Non-Commercial",
        "opClass": "hokuyoCHOP_Class",
        "opFilter": "False",
        "short": "The Hokuyo CHOP is used for communication with Hokuyo laser scanners (serial or ethernet interface): [http://www.hokuyo-aut.jp/search/ Hokuyo Products]",
        "long": "The Hokuyo CHOP is used for communication with Hokuyo laser scanners (serial or ethernet interface): [http://www.hokuyo-aut.jp/search/ Hokuyo Products]\n\nThe Hokuyo CHOP will work with all serial or ethernet Hokuyo laser scanners, though the only laser scanners tested in-house are the URG-04LX-UG01 (Serial) and the UST-10LX (Ethernet).\n\nIt can be used with the [[Blob Track CHOP]] to detect objects in its field. See the Snippet for Blob Track.\n\nAll of a computer's available serial ports can be found in the Device Manager under the Windows operating system. Their names begin with 'COM'. Example: COM1, COM2, COM3, etc.\n\nThe Hokuyo CHOP outputs the measurement data from the laser scan in meters, either in Polar or Cartesian Coordinates. The laser scan is done counter clockwise over N degrees (defined by the device, eg. URG-04LX-UG01 is 240 degrees, UST-10LX is 270 degrees) and returns the distance to the first object hit by the laser at that point. \n\nThe Hokuyo laser scanners have an angular resolution that specifies the number of data points returned from a full scan. For the URG-04LX-UG01 there is a data point every ~0.3515 degrees, so over a 240 degree scan there is a total of 682 data points. For the UST-10LX there is a data point every 0.25 degrees, so over a 270 degree scan there is a total of 1080 data points. The Hokuyo laser scanners also have a start and end step that define a total detection range. \n\nThe UST-10LX has the same measurement parameters as the UTM-30LX in the chart below. The UST-20LX ethernet model will also work like the UST-10LX.\n\nFor a visualization of the scan and a table of device specific numbers, see the image below:\n\n[[image:scan_info.jpg]]\n\nIf the Hokuyo device is an ethernet model like the UTM-30LX-EW, make sure Window Firewall is not blocking it. Each install of TD will need to be allowed through the firewall separately. This commonly catches people out with networking OPs, as sometimes the Windows \u201callow TD to network\u201d dialog doesn\u2019t open on first connection attempt. A quick disabling of the firewall will let you test this theory.\n\nSee also [[Serial DAT]], [[serialDAT_Class]], [[Arduino]]",
        "opCategories": ""
    },
    "holdCHOP": {
        "label": "holdCHOP",
        "members": [
            {
                "text": "Menu : Defines when to sample the input channels. The parameters are as follows.",
                "type": "Par",
                "name": "sample"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Hold CHOP waits for a 0 to 1 step on its second input, at which time it reads the current values from the first input (one value per channel). It holds the values constant until it receives another 0 to 1 step. The second input controls the sampling. When the second input changes from 0 to 1, the first input is sampled. This value is held in the output until the second input changes from 0 to 1 again. Hold does not sample while the second input is 1, nor on the falling edge (1 to 0).\t\t\n\t\t\t\nA common application for this CHOP is to grab the current value of a channel when an event occurs, so that value can be used until the event occurs again.",
        "opLabel": "Hold",
        "opClass": "holdCHOP_Class",
        "opType": "hold",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Hold CHOP waits for a 0 to 1 step on its second input, at which time it reads the current values from the first input (one value per channel).",
        "opCategories": ""
    },
    "inCHOP": {
        "label": "inCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The In CHOP gets channels that are connected to one of the inputs of the component. For each In CHOP inside a component, there is one input connector added to the In CHOP's parent component.",
        "opLabel": "In",
        "opClass": "inCHOP_Class",
        "opType": "in",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The In CHOP gets channels that are connected to one of the inputs of the component.",
        "opCategories": ""
    },
    "infoCHOP": {
        "label": "infoCHOP",
        "members": [
            {
                "text": "Menu : Select channel with values inside or outside the range specified in <span class=\"tipTextCHOP\">Range</span>.",
                "type": "Par",
                "name": "values"
            },
            {
                "text": "Set the bounds for selecting channels by value.",
                "type": "Par",
                "name": "range1"
            },
            {
                "text": "Set the bounds for selecting channels by value.",
                "type": "Par",
                "name": "range2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Info CHOP gives you extra information about a node. All nodes contain extra inside information, and different types of nodes (TOPs, CHOPs, etc) contain different subsets of information. This additional information can be accessed via an Info CHOP.\t\t\n\t\t\t\nThe Info CHOP's extra attributes for specific OPs are also expressed as python members of those operators. The the operators python class for more information.",
        "opLabel": "Info",
        "opClass": "infoCHOP_Class",
        "opType": "info",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Info CHOP gives you extra information about a node.",
        "opCategories": ""
    },
    "interpolateCHOP": {
        "label": "interpolateCHOP",
        "members": [
            {
                "text": "Menu : The shape of the interpolation curve:",
                "type": "Par",
                "name": "blendfunc"
            },
            {
                "text": "Menu : If an input is not a single frame, and if there are overlaps in the input CHOPs, an option is used to resolve the conflict.",
                "type": "Par",
                "name": "overlap"
            },
            {
                "text": "Menu : Specify how to match the channels of each input.",
                "type": "Par",
                "name": "match"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Interpolate CHOP treats its multiple-inputs as keyframes and interpolates between them. The inputs are usually single-frame CHOP channels like those produced by a [[Constant CHOP]]. The Interpolate CHOP first sorts the input CHOPs in time (without shifting them) and interpolates between them to fill the gaps.\t\t\n\t\t\t\nThe number of channels in the output is the same as the number of channels in the first input.\t\t\t\n\t\t\t\nIf a channel is missing in an input, and Match By is set to Channel Name, it is treated as if there is no keyframe at that frame for that channel, and the interpolation occurs between CHOPs before and after that frame.",
        "opLabel": "Interpolate",
        "opClass": "interpolateCHOP_Class",
        "opType": "interp",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Interpolate CHOP treats its multiple-inputs as keyframes and interpolates between them.",
        "opCategories": ""
    },
    "inversecurveCHOP": {
        "label": "inversecurveCHOP",
        "members": [
            {
                "text": "",
                "type": "Par",
                "name": "span1"
            },
            {
                "text": "",
                "type": "Par",
                "name": "span2"
            },
            {
                "text": "Menu : The type of guide curve to create with the guide components.",
                "type": "Par",
                "name": "interpolation"
            },
            {
                "text": "Control bone twist with this parameter.",
                "type": "Par",
                "name": "upvectorx"
            },
            {
                "text": "Control bone twist with this parameter.",
                "type": "Par",
                "name": "upvectory"
            },
            {
                "text": "Control bone twist with this parameter.",
                "type": "Par",
                "name": "upvectorz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Inverse Curve CHOP calculates an inverse kinematics simulation for [[Bone COMP |bone objects]] using a curve object.\t\t\n\t\t\t\nThe Inverse Curve CHOP will stretch and position a set of bones to follow a curve defined by another set of [[object]]s (guide).\t\t\t\n\t\t\t\nSpecify the first and last bone in the chain with Bone Start / Bone End.\t\t\t\n\t\t\t\nSpecify the Guide by listing them in order, space separated, in the Guide Components field. This parameter also accepts patterns and wildcards. Example: <code>null[1-5] null17 null4</code>. You can also specify bones in this group as well.\t\t\t\n\t\t\t\nThe CHOP will then create a set of rotate and bone-length channels for each bone. Additionally, the CHOP will also output 3 translate channels for the first bone in the chain. It will also setup the export links automatically, so you just have to turn on the export flag for this CHOP.\t\t\t\n\t\t\t\nThe way the CHOP solves this system is by creating a guide curve between the supplied Guide objects. Use the Interpolation and Order parameters to define what type of curve it will use. By default, the control vertices of the curve will be the centroids of the object. The curve is also given orientation, by adopting the orientation of each guide object. The bones line up their X axes with this orientation.\t\t\t\n\t\t\t\nYou can view this curve by using the [[Inverse Curve SOP]]. Just supply it with the name of the Inverse Curve CHOP and it will extract the geometry for viewing/debugging purposes. It actually will contain 3 curves (the original guide, and the guide displaced in +X and +Y). These curves can be skinned with a [[Skin SOP]] for better feedback, etc.\t\t\t\n\t\t\t\nThe span parameters can be used to trim out the beginning and end of the guide curve if so needed.\u00a0For example Span 0.3 0.7 will lay the bones along the middle 40% of the curve.\t\t\t\n\t\t\t\nIn the rare case that the user has setup a curve with all the X axes\u00a0(twists) pointing along the same direction of the curve, then the Up Vector parameter is used to break the tie, so to speak. However, this curve setup is likely degenerate to start with and should be avoided by twisting all the objects 90 degrees.",
        "opLabel": "Inverse Curve",
        "opClass": "inversecurveCHOP_Class",
        "opType": "inversecurve",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Inverse Curve CHOP calculates an inverse kinematics simulation for [[Bone COMP |bone objects]] using a curve object.",
        "opCategories": ""
    },
    "inversekinCHOP": {
        "label": "inversekinCHOP",
        "members": [
            {
                "text": "Menu : This parameter defines the method used to determine the motion of the Bone object when it, its ancestor, or its children are moved.",
                "type": "Par",
                "name": "solvertype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Inverse Kin CHOP calculates an inverse kinematics simulation for [[Bone COMP|Bone objects]].",
        "opLabel": "Inverse Kin",
        "opClass": "inversekinCHOP_Class",
        "opType": "inversekin",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Inverse Kin CHOP calculates an inverse kinematics simulation for [[Bone COMP|Bone objects]].",
        "opCategories": ""
    },
    "joinCHOP": {
        "label": "joinCHOP",
        "members": [
            {
                "text": "Menu : The blend method to produce a seamless sequence:",
                "type": "Par",
                "name": "blendmethod"
            },
            {
                "text": "Menu : The blend interpolation shape to use. See Shape in the [[Cycle CHOP]].",
                "type": "Par",
                "name": "blendfunc"
            },
            {
                "text": "Menu : Match channels between inputs by index or by name.",
                "type": "Par",
                "name": "match"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Join CHOP takes all its inputs and appends one CHOP after another. It is expected they all have the same channels.\t\t\n\t\t\t\nThe end section of the first CHOP is overlapped with the start section of the second CHOP, and so on for the rest of the input CHOPs. The second input is shifted to line up with the end of the first.\t\t\t\n\t\t\t\nBlending allows you to splice channels together by slowly phasing out one CHOP while phasing into the next, or by inserting interpolation curves between the channels of the adjacent CHOPs.\t\t\t\n\t\t\t\nQuaternion Blend blends rotation triplets (rx ry rz) together using the shortest rotation arc. Rotation triplets are identified by \"quaternion\" attributes, which are set in the [[Attribute CHOP]].\t\t\t\n\t\t\t\nTranslation Blending blends translation channels together by slowly changing from the final velocity of the previous channel to the initial velocity of the next. The next channel may be shifted up or down. If this is undesirable, use cubic blending instead (in the Shape menu). Translation Blending is done on channel triplets that represent translations or positions (*tx *ty *tz).",
        "opLabel": "Join",
        "opClass": "joinCHOP_Class",
        "opType": "join",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Join CHOP takes all its inputs and appends one CHOP after another.",
        "opCategories": ""
    },
    "joystickCHOP": {
        "label": "joystickCHOP",
        "members": [
            {
                "text": "Menu : Select between and axis range of 0 to 1 or -1 to 1.",
                "type": "Par",
                "name": "axisrange"
            },
            {
                "text": "Menu : The left extend conditions (before range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Joystick CHOP outputs values for all 6 possible axes on any game controller (joysticks, game controllers, driving wheels, etc.), as well as up to 32 button, 2 sliders and 4 POV Hats.\t\t\n\t\t\t\nIt handles game controllers connected to the gameport or USB ports, including the [http://www.3dconnexion.com/ 3D Connexion] mouse. You can have several devices attached, and any number of Joystick CHOPs in a project per device.\t\t\t\n\t\t\t\nBefore you use the game controller on your computer, calibrate them using Start -&gt; Settings -&gt; Control Panel -&gt; Gaming Options -&gt; Properties.\t\t\t\n\t\t\t\nThe main two outputs, the X-axis and Y-axis are output through channels called xaxis and yaxis. The other four axes are output through channels with similar names.\t\t\t\n\t\t\t\nThe range of the values for each channel is 0 to 1. For any axis, a value 0.5 is considered \"centered\". A value of 0 is given if the axis doesn't exist.\t\t\t\n\t\t\t\nFor any button, a value of 0 means the button is up or doesn't exist. A value of 1 means the button is pressed.\t\t\t\n\t\t\t\nPOV Hats behave like an X and Y axis. A POV axis only has 3 values though, 0, 0.5 and 1.",
        "opLicense": "Non-Commercial",
        "opClass": "joystickCHOP_Class",
        "opLabel": "Joystick",
        "opFamily": "CHOP",
        "opType": "joystick",
        "short": "The Joystick CHOP outputs values for all 6 possible axes on any game controller (joysticks, game controllers, driving wheels, etc.), as well as up to 32 button, 2 sliders and 4 POV Hats.",
        "opCategories": ""
    },
    "keyboardinCHOP": {
        "label": "keyboardinCHOP",
        "members": [
            {
                "text": "Menu : While '''On''', the keyboard inputs will be monitored and the CHOP will cook every frame. When set to '''Off''' it will not cook and the current keyboard values will not be output. '''While Playing''' will capture keyboard events only when the [[Timeline]] is playing forward.",
                "type": "Par",
                "name": "active"
            },
            {
                "text": "Menu : If it is set to Ctrl, the keys will only go On if you are also pressing the Ctrl key. This works similarly for Alt and Shift modifiers. If it set to Ignore, it doesn't matter if the Ctrl/Alt/Shift key is down or not.",
                "type": "Par",
                "name": "modifiers"
            },
            {
                "text": "Menu : Channel names are generated automatically using one of these criteria.",
                "type": "Par",
                "name": "channelnames"
            },
            {
                "text": "Menu : The left extend conditions (before range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Keyboard In CHOP receives ASCII input from the keyboard, and outputs channels for the number of keys specified. It creates a single-frame channel representing the current state of each key.\t\t\n\t\t\t\nThe channels for keys are created by specifying the first key, the number of keys to follow, and the order with which they are selected. Key channel names are either determined by the name of the key, or the channel number.\t\t\t\n\t\t\t\n'''NOTE:''' The Keyboard In CHOP does not handle rapid repeats of characters and does not output channels or all keys. A better way is as follows: Create a [[Panel Execute DAT]], and set the 'Panel' parameter to the panel in which keyboard keys need to be monitored.\t\t\t\nSet the Panel Value to: <code>key</code>.\t\t\t\nIn this DAT, if you enter <code>print(panelValue)</code> in the onValueChange() callback, you will see a line printed for every keystroke.",
        "opLicense": "Non-Commercial",
        "opClass": "keyboardinCHOP_Class",
        "opLabel": "Keyboard In",
        "opFamily": "CHOP",
        "opType": "keyboardin",
        "short": "The Keyboard In CHOP receives ASCII input from the keyboard, and outputs channels for the number of keys specified.",
        "opCategories": ""
    },
    "keyframeCHOP": {
        "label": "keyframeCHOP",
        "members": [
            {
                "text": "Menu : The left extend conditions (before range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Keyframe CHOP uses channel and keys data in an [[Animation COMP]] and creates channels of samples at a selectable sample rate (frames per second).\t\t\n\t\t\t\nSee also: [[Animation COMP]] and [[Animation Editor]]\t\t\t\n\t\t\t\nThe Keyframe CHOP lets you access the keyframed channel data inside an Animation component. The Animation CHOP allows the channels to be played back with the global frame or seconds index. It can be synced to the internal global beat clock, a specified index, or based on a timing or lookup channel sent into the input. It outputs all channels - either as a single sample or an entire start/end range.\t\t\t\n\t\t\t\nTo create/edit/delete keyframed channels, create an [[Animation COMP]] and open the [[Animation Editor]] by right-clicking on the component and selecting Edit Keyframes... from the pop-up menu. Inside the Animation component a Keyframe CHOP will be outputting the channels created in the editor.\t\t\t\n\t\t\t\nAdding an input to the Keyframe CHOP now acts as a lookup index. In addition it outputs a proper [[Time Slice]] if its input is a Time Slice.\t\t\t\n\t\t\t\nThe lookup cycles through all the input channels, though only 1 is necessary.",
        "opLicense": "Non-Commercial",
        "opClass": "keyframeCHOP_Class",
        "opLabel": "Keyframe",
        "opFamily": "CHOP",
        "opType": "keyframe",
        "short": "The Keyframe CHOP uses channel and keys data in an [[Animation COMP]] and creates channels of samples at a selectable sample rate (frames per second).",
        "opCategories": ""
    },
    "kinectazureCHOP": {
        "label": "kinectazureCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "kinectazureCHOP",
        "opLabel": "Kinect Azure",
        "opClass": "kinectazureCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows 10 April 2018 or newer",
        "hardware": "An NVIDIA GEFORCE GTX 1070 or better graphics card is required to obtain body tracking data from the camera; however, a slower CPU-only mode can also be enabled using the parameters. [https://docs.microsoft.com/en-us/azure/kinect-dk/system-requirements Kinect Azure System Requirements]",
        "short": "The Kinect Azure CHOP can be used to obtain body tracking information, including joint positions and rotations, and IMU sensor data from a Microsoft Kinect Azure camera.",
        "long": "The Kinect Azure CHOP can be used to obtain body tracking information, including joint positions and rotations, and IMU sensor data from a Microsoft Kinect Azure camera.\n\nThis CHOP requires a [[Kinect Azure TOP]] to connect to the camera and to configure the camera's settings. Not all configuration settings support body tracking e.g. Passive IR depth mode.\n\nUse the Max Players parameter to determine how many players you would like the camera to track. The TOP will automatically assign any bodies that are discovered by the device to the available player spaces. Due to the system used to detect player skeletons from the depth camera image, body tracking data can lag multiple frames behind the image data. To more closely synchronize body and image data, use the 'Sync Body Tracking To Image' option on the primary [[Kinect Azure TOP]] that is controlling the device (synchronization will increase lag in the image capture).\n\nFor a diagram of the joints tracked and their hierarchy, visit [https://docs.microsoft.com/en-us/azure/kinect-dk/body-joints Microsoft's Kinect Azure SDK].\n\nAcceleration and rotation data from the camera's IMU sensor can be obtained by enabling the 'IMU Channels' parameter.\n\nSee also [[Kinect Azure TOP]], [[Kinect Azure Select TOP]].",
        "opCategories": ""
    },
    "kinectCHOP": {
        "label": "kinectCHOP",
        "members": [
            {
                "text": "Menu : Choose between Kinect v1 or Kinect v2 sensors.",
                "type": "Par",
                "name": "hwversion"
            },
            {
                "text": "Menu : Selects options for skeletal tracking.",
                "type": "Par",
                "name": "skeleton"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Kinect CHOP reads positional and skeletal tracking data from the Kinect and Kinect2 sensors.  Up to 6 people's full skeletons can be tracked (2 on the original Kinect), and the center position of an addition 4 people in the camera view is tracked as well.  Multiple Kinect devices can be used by using multiple Kinect CHOPs and changing the Camera parameter.\t\t\n\t\t\t\nIt also supports face tracking.\n\t\t\t\nTo use a Kinect 2 device you need to install the Kinect 2 SDK or runtime from [http://www.microsoft.com/en-us/kinectforwindows/ here].  \t\t\t\n\t\t\t\nTo use the original Kinect 1 you will need to install the [http://www.microsoft.com/en-ca/download/details.aspx?id=40277 Kinect Runtime 1.8] for builds greater than 12000, or [http://www.microsoft.com/en-us/download/details.aspx?id=36997 Kinect Runtime 1.7] for builds below 12000.\t\t\t\nMultiple Kinects: The Kinect 2 SDK does not allow for multiple kinects to be used on one system at a time. There is no way to connect to different devices through the SDK. The Kinect 1 can do this, but not the 2.\n\t\t\t\nSee also [[Kinect TOP]], [[Kinect]] and [[Kinect1]].",
        "opLicense": "Non-Commercial",
        "opClass": "kinectCHOP_Class",
        "opLabel": "Kinect",
        "opFamily": "CHOP",
        "opType": "kinect",
        "os": "Microsoft Windows",
        "hardware": "This CHOP only supports the '''Kinect for Windows''' hardware and the '''Kinect 2''', ''not'' Kinect for Xbox hardware.",
        "short": "The Kinect CHOP reads positional and skeletal tracking data from the Kinect and Linect2 sensors.",
        "opCategories": ""
    },
    "lagCHOP": {
        "label": "lagCHOP",
        "members": [
            {
                "text": "Menu : The method by which lag is applied to the channels.",
                "type": "Par",
                "name": "lagmethod"
            },
            {
                "text": "Applies a lag to a channel. The first value is for lagging up, and the second is for lagging down. It is approximately the time that the output follows 90% of a change to the input.",
                "type": "Par",
                "name": "lag1"
            },
            {
                "text": "Applies a lag to a channel. The first value is for lagging up, and the second is for lagging down. It is approximately the time that the output follows 90% of a change to the input.",
                "type": "Par",
                "name": "lag2"
            },
            {
                "text": "Applies overshoot to a channel. The first value is for overshoot while moving up, and the second is for overshoot while moving down.",
                "type": "Par",
                "name": "overshoot1"
            },
            {
                "text": "Applies overshoot to a channel. The first value is for overshoot while moving up, and the second is for overshoot while moving down.",
                "type": "Par",
                "name": "overshoot2"
            },
            {
                "text": "The first value limits the slope when it is rising, and the second value limits the slope when it is decreasing.",
                "type": "Par",
                "name": "slope1"
            },
            {
                "text": "The first value limits the slope when it is rising, and the second value limits the slope when it is decreasing.",
                "type": "Par",
                "name": "slope2"
            },
            {
                "text": "The first value limits the acceleration when it is rising, and the second value limits the acceleration when it is decreasing.",
                "type": "Par",
                "name": "accel1"
            },
            {
                "text": "The first value limits the acceleration when it is rising, and the second value limits the acceleration when it is decreasing.",
                "type": "Par",
                "name": "accel2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Lag CHOP adds lag and overshoot to channels. It can also limit the velocity and acceleration of channels. Lag slows down rapid changes in the input channels. Overshoot amplifies the changes in the input channels.\t\t\n\t\t\t\nTwo values exist for each parameter. For example, in the Lag effect, when the input channel value is rising, the first lag parameter is used, and when the channel value is decreasing, the second lag parameter is used. This can give a quick rise, and a slow fall. But lag up and down are often kept at the same value.\t\t\t\n\t\t\t\nFor a similar, less-abrupt effect, see the [[Filter CHOP]].",
        "opLicense": "Non-Commercial",
        "opClass": "lagCHOP_Class",
        "opLabel": "Lag",
        "opFamily": "CHOP",
        "opType": "lag",
        "short": "The Lag CHOP adds lag and overshoot to channels.",
        "opCategories": ""
    },
    "laserCHOP": {
        "label": "laserCHOP",
        "members": [
            {
                "text": "Menu : Select the source operator type for the laser image.",
                "type": "Par",
                "name": "source"
            },
            {
                "text": "Menu : Control how the Laser CHOP pulls data from its source.\n    \nIn most cases you will want to keep this at the default setting \"When All Points Drawn\". \n\nThere is a specific usage case that requires the \"Every Frame\" update method. Background is that the Laser CHOP might have to draw the input values over multiple frames. For example given a source with 200 sampling values. After applying all blanking and step sizes at a certain sample rate, the Laser might need more than one frame to draw the full image. The effect will be visible by the Laser image flickering. With the default setting, the Laser will grab a new set of samples from its input once it has completed drawing all previous values. With the \"Every Frame\" update method, the Laser will grab the updated values for the remaining samples after each frame.",
                "type": "Par",
                "name": "updatemethod"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "laserCHOP",
        "opLabel": "Laser",
        "opClass": "laserCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Laser CHOP produces channels that can drive a laser projector. It uses the points and lines of a SOP or CHOP and outputs the channels at a specified sample rate.",
        "long": "The Laser CHOP produces channels that can drive a laser projector. It uses the points and lines of a SOP or CHOP and outputs the channels at a specified sample rate, typically 10,000 to 96,000 samples per second. The Laser CHOP gives optimal control over the movement of the reflectors of the laser projector as well as enhanced color control. In particular, it gives better control of lines being straight, end-points being not cut off or over-drawn, and eliminating tails, all adjustable using a set of parameters. \n    \nThe resulting channels can be sent to the [[EtherDream CHOP]] or [[Helios DAC CHOP]] in case of controlling a Laser via the [https://en.wikipedia.org/wiki/International_Laser_Display_Association ILDA Protocol], or the [[Audio Device Out CHOP]] in case of using one of LaserAnimation Sollinger's [https://en.wikipedia.org/wiki/Audio_Video_Bridging AVB] capable devices, where the audio is output via the [[Audio Device Out CHOP]] to a low-latency AVB-ready audio device like those from MOTU, RME, LaserAnimation Sollinger or Apple macOS. \n\n[https://laseranimation.com/en/products/avb-devices LaserAnimation Sollinger's AVB2ILDA devices] give you access to features for the professional sector including 24bit resolution on the x/y signal and all color channels. Additionally the AVB2ILDA device includes software for electronic masking, making it possible to limit the laser output for certain areas (for example to protect scanning areas such as auditoriums or sectors with optical equipment). Also packaged is a color correction tool that includes individual control of the color delay for 3 colors as well as a Digital Geometric Correction to allow for projection on for example uneven surfaces.    (The Laser CHOP replaces the Scan CHOP.)\n    \nThe CHOP was developed with the help of [https://laseranimation.com/en/ LaserAnimation Sollinger] who guided us in speccing and implementing the necessary parameters, especially in regards of the blanking timing settings.\n\n'''Tip''': See the [[OP Snippets]] for setup and usage examples.\n\n'''LASERS ARE DANGEROUS - DAMAGE TO YOUR OR THE AUDIENCE'S EYE SIGHT IS A VERY REAL RISK'''\n* If you plan to use lasers\n# Understand all the laws and regulations for laser operation in your area.\n# Become a certified Laser Safety Officer (this is required by law in some areas). Courses are available from ILDA directly: [https://www.ilda.com/LSOcourse.htm ILDA Laser Safety Courses]\n* Make sure an emergency stop button is close to you at all times.\n* Do not let anyone enter the laser projection area unless all precautions have been taken to limit the output.\n* Make sure there are no reflective surfaces in the projection area that might cause the beam to reflect unintendedly.",
        "opCategories": ""
    },
    "laserdeviceCHOP": {
        "label": "laserdeviceCHOP",
        "members": [
            {
                "text": "Menu : Specify the type of laser device.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : The units of queue time.",
                "type": "Par",
                "name": "queueunits"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "laserdeviceCHOP",
        "opLabel": "Laser Device",
        "opClass": "laserdeviceCHOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "",
        "long": "The Laser Device CHOP can send laser points to supported laser devices: EtherDream, Helios, and ShowNET. The devices can be connected to a laser using an ILDA cable, except in the case of ShowNET when an onboard DAC is used. Applications of the Laser Device CHOP include displaying computer-generated shape animations or other special effects of a light show. The Laser Device CHOP replaces the deprecated [[EtherDream CHOP]] and [[Helios DAC CHOP]].\n    \n'''Input/Output Channels:''' \n* '''x:''' the point's X position, between -1 and 1.\n* '''y:''' the point's Y position, between -1 and 1.\n* '''r:''' the point's red color component, between 0 and 1.\n* '''g:''' the point's green color component, between 0 and 1.\n* '''b:''' the point's blue color component, between 0 and 1.\n* '''i:''' the point's color intensity, between 0 and 1.\n* '''user1:''' Optional user field 1. Supported by EtherDream and ShowNET.\n* '''user2:''' Optional user field 2. Supported by EtherDream and ShowNET.\n* '''user3:''' Optional user field 3. Supported by EtherDream.\n* '''user4:''' Optional user field 4. Supported by EtherDream.\n    \nLarge changes in RGB values from sample-to-sample will likely be visibly correct as lasers generally can switch on-off quickly.\n\nBlanking (all-off) occurs when the incoming RGB CHOP channels are all zero, or the Red Scale, Green Scale, and Blue Scale parameters are all zero.\n\nSee also: [[Laser CHOP]], [[EtherDream DAT]], [[Pattern CHOP]]"
    },
    "leapmotionCHOP": {
        "label": "leapmotionCHOP",
        "members": [
            {
                "text": "Menu : Select between Leap Motion V2 or V4/V5 SDKs for tracking. V5 offers the fastest and most stable tracking, V2 offers some legacy features like gestures.",
                "type": "Par",
                "name": "v2"
            },
            {
                "text": "Menu : Switches the device to '''H'''ead '''M'''ounted '''D'''isplay mode.",
                "type": "Par",
                "name": "hmd"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Leap Motion CHOP reads hand, finger, tool and gesture data from the [[Leap Motion]] controller. It outputs hand, finger and tool positions, rotations and 'tracking' channels that indicate if these values are currently being detected and updated. Currently only 1 Leap Motion device can be connected at a time.\t\t\n\t\t\t\nTo connect with the device you will need to install the Leap Motion software which is available here:\t\nhttps://developer.leapmotion.com/releases\n* API Version 5 Gemini - Download Gemini v5.6.1\n* API Version 4 Orion - Download Orion Beta v4.1.0\n* API Version 2 Tracking - Download Orion Beta v3.2.1\n\nYou will also need to set the Library Folder parameter to the location of the Leap SDK on your machine. See the parameter details below for more information.\n\n'''Tip:''' If using Gemini V5, the Leap Motion will only work in one orientation. By default the hands enter from the bottom of the camera view, though this can be changed in setting to invert the direction. This is an important distinction between Gemini V5 and the older V2/V4 APIs which could work in either orientation.\n\n'''Note:''' TouchDesigner does not include a license to use the Leap Motion hardware or software. Make sure to check with the [https://www.ultraleap.com/ UltraLeap website] regarding any applicable licenses that you may need for your project.\n\nSee also [[Leap Motion]], [[Leap Motion TOP]]",
        "opLicense": "Non-Commercial",
        "opClass": "leapmotionCHOP_Class",
        "opLabel": "Leap Motion",
        "opFamily": "CHOP",
        "opType": "leapmotion",
        "short": "The Leap Motion CHOP reads hand, finger, tool and gesture data from the [[Leap Motion]] controller.",
        "opCategories": ""
    },
    "leuzerod4CHOP": {
        "label": "leuzerod4CHOP",
        "members": [
            {
                "text": "Menu : Selects which protocol to use. This must match the protocol the scanner was set to use in the RODplussoft setup utility for the device. You may still get some sort of data if the wrong protocol is selected, but the data will be random and incorrect.",
                "type": "Par",
                "name": "rod4porotocol"
            },
            {
                "text": "Menu : Available when using ROD4plus ASCII-Remote protocol, specifies whether to use Polar or Cartesian input coordinates. This must match the coordinate the scanner was set to use in the RODplussoft setup utility for the device.",
                "type": "Par",
                "name": "inputcoordinate"
            },
            {
                "text": "Menu : Select Raw Data or Blob Tracking mode for output channels. The parameters below are only available in Blob Tracking mode.",
                "type": "Par",
                "name": "outputmode"
            },
            {
                "text": "Menu : Limits the area in which blobs are tracked.",
                "type": "Par",
                "name": "areaofinterest"
            },
            {
                "text": "Specifies the lower left corner of the bounding box used when Area of Interest parameter is set to Bounding Box.",
                "type": "Par",
                "name": "lowerleft1"
            },
            {
                "text": "Specifies the lower left corner of the bounding box used when Area of Interest parameter is set to Bounding Box.",
                "type": "Par",
                "name": "lowerleft2"
            },
            {
                "text": "Specifies the upper right corner of the bounding box used when Area of Interest parameter is set to Bounding Box.",
                "type": "Par",
                "name": "upperright1"
            },
            {
                "text": "Specifies the upper right corner of the bounding box used when Area of Interest parameter is set to Bounding Box.",
                "type": "Par",
                "name": "upperright2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Leuze ROD4 CHOP connects to the [https://www.leuze.com/en-int/products/switching-sensors/area-scanners?p=1 Leuze ROD4] laser scanner via TCP/IP. Blob Tracking mode allows for turning the measured distances into blobs for use as an interaction surface. It should work with any of the ROD4 scanners currently available.\t\t\n\t\t\t\nThe 'object detection' mode available on some of the models is not currently supported.\t\t\n\nThe Leuze can be used with the [[Blob Track CHOP]] to detect objects in its field. See the OP Snippet for Blob Track.",
        "opLicense": "Commercial",
        "opClass": "leuzerod4CHOP_Class",
        "opLabel": "Leuze ROD4",
        "opFamily": "CHOP",
        "opType": "rod",
        "short": "The Leuze ROD4 CHOP connects to the [https://www.leuze.com/en-int/products/switching-sensors/area-scanners?p=1 Leuze ROD4] laser scanner via TCP/IP.",
        "opCategories": ""
    },
    "lfoCHOP": {
        "label": "lfoCHOP",
        "members": [
            {
                "text": "Menu : The shape of the waveform to repeat, unless overridden by the Source Wave:",
                "type": "Par",
                "name": "wavetype"
            },
            {
                "text": "Menu : This menu determines how the Reset input triggers resetting the channel(s).",
                "type": "Par",
                "name": "resetcondition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opClass": "lfoCHOP_Class",
        "opFamily": "CHOP",
        "long": "The LFO CHOP (low frequency oscillator) generates waves in real-time in two ways. It synthesizes curves using a choice of common waveforms like Sine or Pulse, or it repeats a prepared incoming curve.\t\t\n\t\t\t\nIt steps through the waveform at a rate that depends on the Frequency parameter and the Octave Control input. To watch its behavior, attach a Trail CHOP to its output and alter the Frequency parameter.\t\t\t\n\t\t\nUp to three input CHOPs can be connected to the LFO CHOP:\t\t\t\n\t\t\t\n'''Octave Control''' - Without this first (optional) input, the frequency is simply the Frequency parameter. If this input is connected, every unit doubles the frequency: When Octave Control is 1, the frequency is double, when it is 2 it is 4x, when it is -1 the frequency is half the Frequency parameter and when it is 0, there is no change in the frequency.\t\t\t\n\t\t\t\n'''Reset''' - The seond (optional) input contains on-off (<=0 or >0) that restarts the channels of the oscillator from the beginning of the wave. The reset depends on the setting of the Reset Condition menu. By default, when the Reset input goes from off to on, it resets the wave and starts the waveform immediately. If Reset Condition is set to \"While On\", the reset value will be held until the Reset input goes off. Reset means \"stop the oscillator and cue it at the start of the waveform\".\t\t\t\n\t\t\t\n'''Source Wave''' - The third (optional) input is a replacement of the waveform Type. It is a multi-sample CHOP curve and can contain any number of channels, limited to the channels defined on the Channel page. The waveform Type parameter is disabled.\t\t\t\n\t\t\t\nThe LFO CHOP can serve as a general motion time-warper and repeater. If you alter the Frequency, you can control the time warp.\t\t\t\n\t\t\t\nUnlike the [[Wave CHOP]], this is a time-sliced CHOP, that is, it generates its waveform as it goes, and speeds/slows how it steps through the waveform Type while the Frequency changes.  Unlike the [[Audio Oscillator CHOP]], the LFO CHOP is designed for non-audio frequencies. \t\t\t\n\t\t\t\nSee also: [[Audio Oscillator CHOP]], [[Wave CHOP]], [[Pulse CHOP]].",
        "short": "The LFO CHOP (low frequency oscillator) generates waves in real-time in two ways.",
        "opFilter": "False",
        "opType": "lfo",
        "opLabel": "LFO",
        "opCategories": ""
    },
    "limitCHOP": {
        "label": "limitCHOP",
        "members": [
            {
                "text": "Menu : Select limit options such as loop, clamp, or zigzag from the menu. The value will remain in the range from Min to less than Max.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : Selects the quantization method to use:",
                "type": "Par",
                "name": "quantvalue"
            },
            {
                "text": "Menu : Selects whether to quantize the index relative to the sample 0, or the start index of the CHOP.",
                "type": "Par",
                "name": "quantindex"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Limit CHOP can limit the values of the input channels to be between a minimum and maximum, and can quantize the input channels in time and/or value such that the value steps over time.\t\t\n\t\t\t\nLimiting a channel causes all its values to lie within a range. Several different methods are for limiting are listed under the Type parameter description.\t\t\t\n\t\t\t\nQuantizing a channel value snaps its values to the closest allowable value (the \"quantized values\"). Quantizing methods are: Floor, Ceiling, and Round.\t\t\t\n\t\t\t\nQuantizing a channel index is like quantizing in time, and acts as a sample and hold mechanism. The channel is sampled at a quantized index, and held at that value until the next quantized index at which time the value takes on the input value at that point.",
        "opLicense": "Non-Commercial",
        "opClass": "limitCHOP_Class",
        "opLabel": "Limit",
        "opFamily": "CHOP",
        "opType": "limit",
        "short": "The Limit CHOP can limit the values of the input channels to be between a minimum and maximum, and can quantize the input channels in time and/or value such that the value steps over time.",
        "opCategories": ""
    },
    "logicCHOP": {
        "label": "logicCHOP",
        "members": [
            {
                "text": "Menu : This menu determines the method to convert inputs to binary:",
                "type": "Par",
                "name": "convert"
            },
            {
                "text": "Menu : Once converted by the Convert Input stage, Channel Pre OP defines a unary operation on each input sample:",
                "type": "Par",
                "name": "preop"
            },
            {
                "text": "Menu : Takes the first input and combines its channels, then the second input and combines its channels, and so on.",
                "type": "Par",
                "name": "chanop"
            },
            {
                "text": "Menu : Combine CHOPs combines the first channels of each CHOP, the second channels of each CHOP, etc.. Channels between inputs can be combined by number or name. Combining (Logic) Operations are:",
                "type": "Par",
                "name": "chopop"
            },
            {
                "text": "Menu : Channels are matched between inputs by Channel Name or Channel Number.",
                "type": "Par",
                "name": "match"
            },
            {
                "text": "Menu : Inputs that don't start at the same frame can be aligned. Se the section, Align Options.",
                "type": "Par",
                "name": "align"
            },
            {
                "text": "Set lower and upper bounds for when Convert Input is set to '''Off When Outside Bounds'''.",
                "type": "Par",
                "name": "boundmin"
            },
            {
                "text": "Set lower and upper bounds for when Convert Input is set to '''Off When Outside Bounds'''.",
                "type": "Par",
                "name": "boundmax"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Logic CHOP first converts channels of all its input CHOPs into binary (0 = off, 1 = on) channels and then combines the channels using a variety of logic operations.\t\t\n\t\t\t\n'''NOTE:''' The Logic CHOP is superceded by more convenient operators like the [[CHOP Execute DAT]] or the [[Text DAT]] which will run their scripts when CHOP channels change.\t\t\t\n\t\t\t\nThe Logic CHOP performs logic operations on the samples in CHOP channels. The channels of a CHOP can be combined into one channel, and several CHOPs can be combined into one CHOP.\t\t\t\n\t\t\t\nWith one input CHOP, you can invert the values of each sample. You can also do logic operations on the samples of one channel by the samples in the other channels, reducing N channels down to one. You can combine by applying an \"or\", \"and\", etc..\t\t\t\n\t\t\t\nWith two or more CHOP inputs, you can combine the channels in one CHOP with the channels in all the other CHOPs, reducing N CHOPs to 1.\t\t\t\n\t\t\t\nTo do math operations (add, multiply, ...) between channels or CHOPs, use the [[Math CHOP]].",
        "opLicense": "Non-Commercial",
        "opClass": "logicCHOP_Class",
        "opLabel": "Logic",
        "opFamily": "CHOP",
        "opType": "logic",
        "short": "The Logic CHOP first converts channels of all its input CHOPs into binary (0 = off, 1 = on) channels and then combines the channels using a variety of logic operations.",
        "opCategories": ""
    },
    "lookupCHOP": {
        "label": "lookupCHOP",
        "members": [
            {
                "text": "The Index Range maps the index channel's values to the lookup table's start and end and defaults to 0 and 1. The first parameter represents the start of the lookup table. When the index channel has this value, it will index the start of the lookup table. The second parameter represents the end of the lookup table and behaves in the same way.",
                "type": "Par",
                "name": "index1"
            },
            {
                "text": "The Index Range maps the index channel's values to the lookup table's start and end and defaults to 0 and 1. The first parameter represents the start of the lookup table. When the index channel has this value, it will index the start of the lookup table. The second parameter represents the end of the lookup table and behaves in the same way.",
                "type": "Par",
                "name": "index2"
            },
            {
                "text": "Menu : Adapts the range of the Lookup Table (2nd input) for cyclic or non-cyclic input indices. When using a cyclic input index (1st input), the lookup value for index 0.0 and 1.0 result in the same value. To avoid this, set Cyclic Range to Yes and the lookup will cycle smoothly.",
                "type": "Par",
                "name": "cyclic"
            },
            {
                "text": "Menu : Determines how index channels are mapped to lookup Channel tables.",
                "type": "Par",
                "name": "chanmatch"
            },
            {
                "text": "Menu : Determines how index channels are matched with a lookup channel in 'One Lookup Table Channel' mode.",
                "type": "Par",
                "name": "match"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Lookup CHOP outputs values from a lookup table. The first input (the Index Channel) is an index into the second input (the Lookup Table). Lookup outputs interpolated values from the lookup table.\t\t\n\t\t\t\nBoth the Index and Lookup Tables can contain any number of channels.\t\t\t\n\t\t\t\nAn Index sample with value 0 maps to the beginning (first sample) of the lookup table, and an index sample with value of 1 maps to the end (last sample) of the lookup table.\t\t\t\n\t\t\t\nThe output CHOP is the same length as the Index input. It is the same number of channels as the Lookup Table input, and has the same channel names as the Lookup Table input. The output is filled with the data extracted from the lookup tables. Indexes that fall between two lookup table samples are interpolated. The lookup table can be sampled outside its range. \n\nNOTE: The Extend Conditions of the lookup table are used in this case where the index is less than 0 or greater than 1.\t\t\t\n\t\t\t\nThe sample rate of the output is the sample rate of the Index input.\t\t\t\n\t\t\t\nThe Lookup CHOP can be used to fetch values from a color lookup table, where a single index produces red, green and blue channels. It can also be used for rolloff or decay tables, where it specifies how much a parameter drops with distance.",
        "opLicense": "Non-Commercial",
        "opClass": "lookupCHOP_Class",
        "opLabel": "Lookup",
        "opFamily": "CHOP",
        "opType": "lookup",
        "short": "The Lookup CHOP outputs values from a lookup table.",
        "opCategories": ""
    },
    "ltcinCHOP": {
        "label": "ltcinCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The LTC In CHOP reads SMPTE timecode data encoded into an audio signal. Read the overview [http://en.wikipedia.org/wiki/Linear_timecode Linear Timecode].\t\n\t\t\nFirst bring the audio signal into CHOPs using an [[Audio Device In CHOP]]. This can then be input into the LTC In CHOP.\t\t\n\t\t\nSee also: [[LTC Out CHOP]]",
        "opLicense": "Non-Commercial",
        "opClass": "ltcinCHOP_Class",
        "opLabel": "LTC In",
        "opFamily": "CHOP",
        "opType": "ltcin",
        "short": "The LTC In CHOP reads SMPTE timecode data encoded into an audio signal.",
        "opCategories": ""
    },
    "ltcoutCHOP": {
        "label": "ltcoutCHOP",
        "members": [
            {
                "text": "Menu : Specifies the method used to output LTC, there are 2 options.",
                "type": "Par",
                "name": "playmode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The LTC Out CHOP outputs \"linear timecode\" which is a SMPTE timecode data encoded into an audio signal. See also [http://en.wikipedia.org/wiki/Linear_timecode Linear Timecode].\t\n\t\t\nUse an [[Info CHOP]] to determine which values are currently being output.\t\t\n\t\t\nThe output of this CHOP can be sent to an [[Audio Device Out CHOP]].\t\t\n\t\t\nSee also: [[LTC In CHOP]]",
        "opLicense": "Non-Commercial",
        "opClass": "ltcoutCHOP_Class",
        "opLabel": "LTC Out",
        "opFamily": "CHOP",
        "opType": "ltcout",
        "short": "The LTC Out CHOP outputs \"linear timecode\" which is a SMPTE timecode data encoded into an audio signal. See also [http://en.wikipedia.org/wiki/Linear_timecode Linear Timecode].",
        "opCategories": ""
    },
    "mathCHOP": {
        "label": "mathCHOP",
        "members": [
            {
                "text": "Menu : Unary operations can be performed on individual channels. A menu of unary operations (as described above) that are performed on each channel as it comes in to the Math CHOP include:",
                "type": "Par",
                "name": "preop"
            },
            {
                "text": "Menu : A choice of operations is performed between the channels of an input CHOP, for each input. The Nth sample of one channel is combined with the Nth sample of other channels:",
                "type": "Par",
                "name": "chanop"
            },
            {
                "text": "Menu : A menu of operations that is performed between the input CHOPs, combining several CHOPs into one.",
                "type": "Par",
                "name": "chopop"
            },
            {
                "text": "Menu : A menu (same as Channel Pre OP) is performed as the finale stage upon the channels resulting from the above operations.",
                "type": "Par",
                "name": "postop"
            },
            {
                "text": "Menu : Match channels between inputs by name or index.",
                "type": "Par",
                "name": "match"
            },
            {
                "text": "Menu : This menu handles cases where multiple input CHOPs have different start or end times. All channels output from a CHOP share the same start/end interval, so the inputs must be treated with the Align Options:",
                "type": "Par",
                "name": "align"
            },
            {
                "text": "Menu : The resulting values can be converted to integer.",
                "type": "Par",
                "name": "integer"
            },
            {
                "text": "Another way to multiply/add. Converts from one low-high range to another range.",
                "type": "Par",
                "name": "fromrange1"
            },
            {
                "text": "Another way to multiply/add. Converts from one low-high range to another range.",
                "type": "Par",
                "name": "fromrange2"
            },
            {
                "text": "Another way to multiply/add. Converts from one low-high range to another range.",
                "type": "Par",
                "name": "torange1"
            },
            {
                "text": "Another way to multiply/add. Converts from one low-high range to another range.",
                "type": "Par",
                "name": "torange2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Math CHOP performs arithmetic operations on channels. The channels of a CHOP can be combined into one channel, and several CHOPs can be combined into one CHOP.\t\t\n\t\t\t\nThe OP page lets you pre-operate on each sample, like making all samples positive or taking the square  of each sample.\t\t\t\n\t\t\t\nUsing '''Combine Channels''', for an input CHOP with multi-channels, you can multiply the samples of one channel by the samples in the other channels, reducing N channels down to one. You can combine them by multiplying, adding, finding the maximum, etc..  \t\t\t\n\t\t\t\nUsing '''Combine CHOPs''', where there are two or more CHOP inputs, you can multiply (or add, etc.) the channels in one CHOP with the channels in all the other CHOPs, reducing N CHOPs to 1. (otherwise channels of multi-inputs are just merged)\t\t\t\n\t\t\t\nYou can then post-operate on the resulting samples - negate, square root, etc.\t\t\t\n\t\t\t\nThen using the Mult-Add page it can offset and scale the values of each sample.\t\t\t\n\t\t\t\nMore conveniently you can use the Range page to do linear scaling as well by setting an output low-high range for a certain input low-high range.\t\t\t\n\t\t\t\nFinally, you can round the resulting values off to an integer.\n\n'''Tip''': You can affect only certain channels of your input by using the Scope parameter on the Common page.\n\t\t\t\n'''Note''': To do logic operations (and, or, ...) between channels or CHOPs, use the [[Logic CHOP]].\n\n'''Tip: Customizing each channel:''': You can use the local member <code>chanIndex</code> in a parameter like Post-Add, for example, <code>me.chanIndex*2</code> to give a different post-add value for each channel. <code>chanIndex</code> is available in numerous CHOPs like the [[Pattern CHOP]]. (expressions are non-optimized)",
        "opLicense": "Non-Commercial",
        "opClass": "mathCHOP_Class",
        "opLabel": "Math",
        "opFamily": "CHOP",
        "opType": "math",
        "short": "The Math CHOP performs arithmetic operations on channels. The channels of a CHOP can be combined into one channel, and several CHOPs can be combined into one CHOP.",
        "opCategories": ""
    },
    "mergeCHOP": {
        "label": "mergeCHOP",
        "members": [
            {
                "text": "Menu : This menu handles cases where multiple input CHOPs have different start or end times. All channels output from a CHOP share the same start/end interval, so the inputs must be treated with the Align Options:",
                "type": "Par",
                "name": "align"
            },
            {
                "text": "Menu : When channels of the input CHOPs have the same name, this menu determines what to do.",
                "type": "Par",
                "name": "duplicate"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Merge CHOP takes multiple inputs and merges them into the output. All the channels of the input appear in the output. The channel order is the channels of the first input followed by the channels of the second input, and so on.\t\t\n\t\t\t\nChannel names may conflict, but a channel is renamed according to the Duplicate Names menu. The CHOP appends or increments the digits of the channel name until an unused name is found.\t\t\t\n\t\t\t\nWhen the Time Slice flag on the Common parameter page is on, the Merge CHOP will merge only the current [[Time Slice]] of a channel, not the entire length of all the channels.",
        "opLicense": "Non-Commercial",
        "opClass": "mergeCHOP_Class",
        "opLabel": "Merge",
        "opFamily": "CHOP",
        "opType": "merge",
        "short": "The Merge CHOP takes multiple inputs and merges them into the output.",
        "opCategories": ""
    },
    "midiinCHOP": {
        "label": "midiinCHOP",
        "members": [
            {
                "text": "Menu : Get MIDI input from a device or a file.",
                "type": "Par",
                "name": "source"
            },
            {
                "text": "Menu : Determine what to record.",
                "type": "Par",
                "name": "recordtype"
            },
            {
                "text": "Menu : Describes how multiple notes are handled. (As one channel, or individual).",
                "type": "Par",
                "name": "notemeth"
            },
            {
                "text": "Menu : Describes how multiple velocity events are recorded. (Separate channels or combined in one channel as separate samples).",
                "type": "Par",
                "name": "velocity"
            },
            {
                "text": "Menu : Note values can be normalized for convenience:",
                "type": "Par",
                "name": "notenorm"
            },
            {
                "text": "Menu : There are 128 different controllers available. By choosing By Index Only, you can specify any number of controllers in the Control Index parameter. Otherwise, you can select a controller from the list from this menu. Some controllers have multiple instances, such as Sound Controllers 1-10. Selecting a controller with multiple instances allows you to use the Control Index parameter to select which instances you want. Any invalid control indices will be ignored.",
                "type": "Par",
                "name": "controltype"
            },
            {
                "text": "Menu : Some controllers can be paired together to form 14 bit controllers, rather than the normal 7 bit controllers (controller indices 0-31, 98 and 100). Selecting 14 bit Controllers interprets a pair as one 14 bit controller. Otherwise, they are interpreted as separate 7 bit Controllers.",
                "type": "Par",
                "name": "format"
            },
            {
                "text": "Menu : Controller values can be normalized for convenience:",
                "type": "Par",
                "name": "norm"
            },
            {
                "text": "Menu : Select the units to use for this parameter, Samples, Frames, or Seconds.",
                "type": "Par",
                "name": "startunit"
            },
            {
                "text": "Menu : Select the units to use for this parameter, Samples, Frames, or Seconds.",
                "type": "Par",
                "name": "endunit"
            },
            {
                "text": "Menu : The left extend conditions (before range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The MIDI In CHOP reads Note events, Controller events, Program Change events, System Exclusive messages and Timing events from both MIDI devices and files. See also [[MIDI In Map CHOP]].\t\t\n\t\t\t\nThe MIDI In CHOP receives [[MIDI]] events from MIDI devices connected to the serial port, reads MIDI events internal to the workstation (i.e. the built-in software synth), and interprets musical scores in MIDI files. Supported MIDI events are:\t\t\t\n\t\t\t\n: Note On, Note Off\t\t\t\n: Polyphonic Aftertouch\t\t\t\n: Channel Pressure\t\t\t\n: Program Change\t\t\t\n: Control Change (MIDI controller devices)\t\t\t\n: Pitch Wheel\t\t\t\n: Timer Events including beat pulses\t\t\t\n: Bar Messages\t\t\t\n: Start, Stop, Continue\t\t\t\n: Song Position Pointer\t\t\t\n: System Exclusive Messages\t\t\t\n\t\t\t\nMIDI events arriving on separate MIDI channels may be recorded on separate CHOP channels. Also, any number of MIDI CHOPs can read from the same or different sources. TouchDesigner can be configured such that MIDI Start, Stop, or Continue events can control the [[Timeline]] and [[Beat Dialog]].\t\t\t\n\t\t\t\nThe 'Simplified Output' option creates a channel for every type of MIDI event received, so number of channels expands while the devices is being used. No need to specify name, channel and index patterns.\t\t\t\n\t\t\t\n'''Note''': The values of the MIDI inputs are saved into the TouchDesigner .toe file, and are restored when the file is reloaded. The physical controllers may be in a different position when the .toe is restarted, causing the values to jump when the controllers are moved. This is unavoidable. \t\t\t\n\t\t\t\nSee also the [[MIDI In DAT]], [[MIDI Event DAT]], [[MIDI In Map CHOP]], [[MIDI Out CHOP]].",
        "opLicense": "Non-Commercial",
        "opClass": "midiinCHOP_Class",
        "opLabel": "MIDI In",
        "opFamily": "CHOP",
        "opType": "midiin",
        "short": "The MIDI In CHOP reads Note events, Controller events, Program Change events, System Exclusive messages and Timing events from both MIDI devices and files.",
        "opCategories": ""
    },
    "midiinmapCHOP": {
        "label": "midiinmapCHOP",
        "members": [
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "See first the [[MIDI In DAT]]. The MIDI In Map CHOP reads in specified channels from the [[MIDI Device Mapper Dialog]] which prepares slider channels starting from s1, s2, etc. and button channels starting with b1, b2 and so on. The MIDI In Map CHOP selects from these channels.\t\t\n\t\t\t\n'''NOTE''': (Apr 12 09) This page needs to be updated with the info in the release notes.\n\t\t\t\nAnother CHOP, the [[MIDI In CHOP]] retrieves [[MIDI]] data more directly but it is less portable as it addresses the MIDI channel numbers, note numbers and controller numbers in the CHOP, so in order to change the MIDI mapping, you need to change the settings in TouchDesigner, whereas with the MIDI In Map CHOP, users need only set the mapping in the Dialogs -&gt; MIDI Device Mapper.\t\t\t\n\t\t\t\nSee also the [[MIDI In DAT]], [[MIDI Event DAT]], [[MIDI In CHOP]], [[MIDI Out CHOP]], <code>midi</code> command, [[MIDI Device Mapper Dialog]].",
        "opLicense": "Non-Commercial",
        "opClass": "midiinmapCHOP_Class",
        "opLabel": "MIDI In Map",
        "opFamily": "CHOP",
        "opType": "midiinmap",
        "short": "See first the [[MIDI In DAT]]. The MIDI In Map CHOP reads in specified channels from the [[MIDI Device Mapper Dialog|MIDI Device Mapper]] which prepares slider channels starting from s1, s2, etc.",
        "opCategories": ""
    },
    "midioutCHOP": {
        "label": "midioutCHOP",
        "members": [
            {
                "text": "Menu : Where the MIDI events are sent to. MIDI Mapper is the default destination.",
                "type": "Par",
                "name": "destination"
            },
            {
                "text": "Menu : A MIDI 'All Note Off' event can be sent upon the start and/or end of the output.",
                "type": "Par",
                "name": "autonoteoff"
            },
            {
                "text": "Menu : Values in the range 0-1 are mapped to MIDI value 0-127.",
                "type": "Par",
                "name": "notenorm"
            },
            {
                "text": "Menu : Sends 7 or 14 bit controller events.",
                "type": "Par",
                "name": "controlformat"
            },
            {
                "text": "Menu : Maps channel values from different ranges to 0-127.",
                "type": "Par",
                "name": "controlnorm"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The MIDI Out CHOP sends [[MIDI]] events to any available MIDI devices when its input channels change. More flexibly, the Python [[midioutCHOP Class]] can be used to send any type of MIDI event to a MIDI device via an existing MIDI Out CHOP. In [[Tscript]], the <code>midi</code> command can output MIDI events.\t\t\n\t\t\t\nThe MIDI devices can be other software programs (such as midisynth) or devices attached to the serial ports. Channels are used to control the sending of the MIDI events. The channels are evaluated over the last time slice (from the last [[Timeline]] position to the current).\t\t\t\n\t\t\t\nThe MIDI Out CHOP sends MIDI events based on any changes to its input channels. The channels have to be named appropriately, like <code>ch3c14</code> and <code>ch7n60</code>.\t\t\t\n\t\t\t\nAn event is sent every time a channel changes its value during this slice. All timing is preserved, as long as the [[Timeline]] is running in realtime (the \"Realtime\" flag is in the top menu bar). \t\t\t\n\t\t\t\nNaming the CHOP channels: Channels are mapped to events by their name. Events like notes, controllers and velocities must be followed by the note/controller number (n65, c7). If the number is left off a note event, the note number is the value of the channel. Other events, which are sent to the entire channel, do not need a trailing number (pc, pw). The channel prefix can be used to identify the MIDI channel the event should be sent on (i.e. \"ch1n45\" assigns that TouchDesigner channel to note 45 messages on MIDI channel 1).  Channels can always be renamed with a [[Rename CHOP]] before entering the [[MIDI Out CHOP]].\t\t\t\n\t\t\t\nThe MIDI Out CHOP sends MIDI velocity as well. The values of the channels entering the MIDI Out CHOPs are sent as the velocity of the note. If Normalize is \"None\", the channel needs to be 0 to 127. If Normalize is \"0 to 1\", channel values between 0 and 1 are scaled to be MIDI 0 to 127.\t\t\t\n\t\t\t\nThe \"Cook Every Frame\" option cooks the CHOP every frame, even if the CHOP isn't being displayed. All Volume Off and All Volume On flags are new and emit events for Controller 7 of all 16 channels. MIDI output go in a separate thread to allow output that slows TouchDesigner less. It now works in Time Slice mode for note events and controller events. (Not for Program Change or Sysex messages yet) Note channels only trigger anew Note On when the input channel goes from 0 or less to a value greater than zero. Similar for Note Off events.The channel name determines how it is interpreted.\t\t\t\n\t\t\t\nFor example,\t\t\t\n\t\t\t\n: ch3n60 - this channel is interpreted as channel3 note 60. A Note On event is sent when the value goes from 0 or less to greater than zero\t\t\t\n: ch5n - This channel will contain note numbers.\u00ac\u2020 The value quantized to an integer, and when the integer value changes, the note of the old value goes off and the note of the new value goes on. If the channel steps from 53 to 78, it sends a Note Off event for note 53, and a Note On event for note 78.\t\t\t\n: ch14c7 - the value of the channel is sent to controller 7 (volume) of channel 14. By default, the values 0 to 1 are mapped to MIDI value 0 to 127.\t\t\t\n\t\t\t\nThese features work in Time Slice mode:\t\t\t\n\t\t\t\n: By default, channels are to start with \"ch\" followed by the channel number (1-16). In the case of notes, it is followed by \"n\" for notes, then digits for the note number. In the case of controllers, it is followed by \"c\" and a controller number. These prefixes can be altered. MIDI Out now interprets aftertouch, pressure, pitchwheel channels, and outputs these events to the MIDI stream. Note-normalization is added allowing 0 to 127 and 0 to 1 ranges. MIDI Out reads a bar ramp channel to output MIDI clock events\u00ac\u2020 (with a channel popup menu to the parameter to select the channel name). Program change events are implemented through the \"pc\" channels.both 7 and 14 bit controller events can be output. You can capture a MIDI stream and output it to a file.\t\t\t\n\t\t\t\nSee also the [[MIDI In DAT]], [[MIDI Event DAT]], [[MIDI In Map CHOP]], [[MIDI In CHOP]], <code>midi</code> command.",
        "opLicense": "Non-Commercial",
        "opClass": "midioutCHOP_Class",
        "opLabel": "MIDI Out",
        "opFamily": "CHOP",
        "opType": "midiout",
        "short": "The MIDI Out CHOP sends MIDI events to any available MIDI devices when its input channels change.",
        "opCategories": ""
    },
    "mosysCHOP": {
        "label": "mosysCHOP",
        "members": [
            {
                "text": "Menu : The network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "mosysCHOP",
        "opLabel": "MoSys",
        "opClass": "mosysCHOP_Class",
        "opFilter": "False",
        "opLicense": "Pro",
        "opCategories": "",
        "short": "The MoSys CHOP receives data from a MoSys camera tracking system.",
        "long": "The MoSys CHOP receives data from a MoSys camera tracking system. The channels can be used to control a virtual [[Camera COMP|camera]] and to implement lens distortion via the [[MoSys TOP]] as part of a virtual production system."
    },
    "mouseinCHOP": {
        "label": "mouseinCHOP",
        "members": [
            {
                "text": "Menu : While '''On''', the mouse movement will be output from and the CHOP will cook every frame. When set to '''Off''' it will not cook and the current mouse X or Y values will not be output. '''While Playing''' will capture mouse events only when the [[Timeline]] is playing forward.",
                "type": "Par",
                "name": "active"
            },
            {
                "text": "Menu : Controls the range of the mouse Position X and Position Y.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : The left extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Mouse In CHOP outputs X and Y screen values for the mouse device and monitors the up/down state of the three mouse buttons.\t\t\n\t\t\t\nWhen the Active flag is on, the Mouse X and Y positions are output through the channels named in the Position X and Y parameters and the button states are output through the channels named in the Left, Right and Middle Button parameters.\t\t\t\n\t\t\t\nThe button values are 0 for Button Up and 1 for Button Down.\t\t\t\n\t\t\t\nThe Mouse In CHOP and [[Keyboard In CHOP]]s are sometimes connected to the Position and Active inputs respectively of the [[Record CHOP]] to enable the recording of channels.",
        "opLicense": "Non-Commercial",
        "opClass": "mouseinCHOP_Class",
        "opLabel": "Mouse In",
        "opFamily": "CHOP",
        "opType": "mousein",
        "short": "The Mouse In CHOP outputs X and Y screen values for the mouse device and monitors the up/down state of the three mouse buttons.",
        "opCategories": ""
    },
    "mouseoutCHOP": {
        "label": "mouseoutCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Mouse Out CHOP forces the mouse position and button status to be driven from TouchDesigner using the incoming CHOP channels. The <code>tx</code> and <code>ty</code> channels works in normalized coordinates, ranging from 0 to 1 for the left-to-right and bottom-to-top of the full desktop. If the Desktop is spread over two monitors, tx == 1 is the right of the second monitor.\t\n\t\t\nWARNING: If the incoming channels are changing every frame, it may be difficult to regain control of the mouse without using the keyboard or some other means to kill or suspend the process. However the Mouse Out CHOP does not control the mouse while the incoming channels are constant.",
        "opLicense": "Non-Commercial",
        "opClass": "mouseoutCHOP_Class",
        "opLabel": "Mouse Out",
        "opFamily": "CHOP",
        "opType": "mouseout",
        "short": "The Mouse Out CHOP forces the mouse position and button status to be driven from TouchDesigner using the incoming CHOP channels.",
        "opCategories": ""
    },
    "natnetinCHOP": {
        "label": "natnetinCHOP",
        "members": [
            {
                "text": "Menu : Set this to the connection mode the server is set to.",
                "type": "Par",
                "name": "connectiontype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The NatNet In CHOP is used to receive tracking data over the network data from [http://www.optitrack.com OptiTrack] systems. Currently the only data that is received is Rigid Body data.",
        "opLicense": "Non-Commercial",
        "opClass": "natnetinCHOP_Class",
        "opLabel": "NatNet In",
        "opFamily": "CHOP",
        "opType": "natnetin",
        "os": "Microsoft Windows",
        "short": "The NatNet In CHOP is used to receive tracking data over the network data from [http://www.optitrack.com OptiTrack] systems.",
        "opCategories": ""
    },
    "ncamCHOP": {
        "label": "ncamCHOP",
        "members": [
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Select how the camera's orientation and position are outputted.",
                "type": "Par",
                "name": "cameraview"
            },
            {
                "text": "Menu : Select how the camera's projection settings are outputted.",
                "type": "Par",
                "name": "cameraproj"
            },
            {
                "text": "Menu : Controls the output of additional camera properties like zoom and focus. These properties can either be normalized (0 to 1) or in their native physical units.",
                "type": "Par",
                "name": "cameraprops"
            },
            {
                "text": "Menu : Select whether the embedded timecode is presented as a single counter or in separate hour, minute, second and frame channels.",
                "type": "Par",
                "name": "timecode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "ncamCHOP",
        "opLabel": "Ncam",
        "opClass": "ncamCHOP_Class",
        "opFilter": "False",
        "opLicense": "Pro",
        "short": "The Ncam CHOP receives camera tracking data from an external Ncam Reality system for use in virtual production.",
        "long": "The Ncam CHOP receives camera tracking data from an external [https://www.ncam-tech.com/ Ncam Reality system] for use in virtual production. The data is received over a network using the TCP protocol and includes information on the camera's position, orientation and optical properties. This data can be used in a [[Camera COMP]] to render content from a virtual environment that is synced to the movement of a physical camera. An [[Ncam TOP]] can also be used to receive image data from the camera and to composite it with the rendered content.\n    \nFor additional tracking solutions, see the [[Stype CHOP]] and [[FreeD CHOP]].",
        "opCategories": ""
    },
    "noiseCHOP": {
        "label": "noiseCHOP",
        "members": [
            {
                "text": "Menu : The noise function used to generate noise. The functions available are:",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : Changing the Transform Order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block. In matrix math terms, if we use the 'multiply vector on the right' (column vector) convention, a transform order of Scale, Rotate, Translate would be written as T * R * S * Position",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : As with transform order (above), changing the order in which the rotations take place will alter the final position and orientation. A Rotation order of Rx Ry Rz would create the final rotation matrix as follows R = Rz * Ry * Rx",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "pz"
            },
            {
                "text": "Menu : Constraint and its parameters allows the noise curve to start and/or end at selected values. The mean value may also be enforced. '''Note:''' This only works when Time Slice is Off because time slicing has no pre-determined start/end.",
                "type": "Par",
                "name": "constraint"
            },
            {
                "text": "Menu : The left extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Noise CHOP makes an irregular wave that never repeats, with values approximately in the range -1 to +1.\t\t\n\t\t\t\nIt generates both smooth curves and noise that is random each sample. It uses the same math as the [[Noise SOP]].\t\t\t\n\t\t\t\nYou can create several curves with different shapes, and you can adjust period, amplitude, harmonics and more.\t\t\t\n\t\t\t\nOptionally, an input can be connected. It is assumed that the input contains 1 to 3 channels representing X, Y and Z coordinates of points in space, and are used to sample anywhere in 3D noise space. One index in the input produces one sample in the output.\t\t\t\n\t\t\t\nAll noise functions work identically with [[Time Slicing]] on and off, with the exception of Harmonic Summation and Brownian whose methods cannot be limited to 1 in Time Slice mode. When the [[Timeline]] wraps around to frame 1, the noise functions will continue uninterrupted.",
        "opLicense": "Non-Commercial",
        "opClass": "noiseCHOP_Class",
        "opLabel": "Noise",
        "opFamily": "CHOP",
        "opType": "noise",
        "short": "The Noise CHOP makes an irregular wave that never repeats, with values approximately in the range -1 to +1.",
        "opCategories": ""
    },
    "nullCHOP": {
        "label": "nullCHOP",
        "members": [
            {
                "text": "Menu : This controls how nodes downstream from the Null CHOP are triggered for recooking when the Null CHOP output changes. See also: [[Cook]]",
                "type": "Par",
                "name": "cooktype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opClass": "nullCHOP_Class",
        "opFamily": "CHOP",
        "long": "The Null CHOP is used as a place-holder and does not alter the data coming in.\t\t\n\t\t\t\nIt is often used to [[Export]] channels to parameters, which allows you to experiment with the CHOPs that feed into the Null without having to un-export from one CHOP and re-export from another.\t\t\t\n\t\t\t\nThe Null CHOP also has options to force-cook nodes downstream from it, or the opposite, to stop cooking nodes downstream if its inputs are not changing.\t\t\t\n\t\t\t\n[[Image:NullCHOP.jpg]]",
        "short": "The Null CHOP is used as a place-holder and does not alter the data coming in.",
        "opFilter": "True",
        "opType": "null",
        "opLabel": "Null",
        "opCategories": ""
    },
    "oakdeviceCHOP": {
        "label": "oakdeviceCHOP",
        "members": [
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "outtimercount"
            },
            {
                "text": "Menu : Outputs the \"wall-clock\" time since Start occurred, no matter if the device's <code>Play</code> parameter was turned off or not. Will stop counting when the <code>Done</code> state has been reached.",
                "type": "Par",
                "name": "outrunningcount"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "oakdeviceCHOP",
        "opLabel": "OAK Device",
        "opClass": "oakdeviceCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "The OAK Device CHOP serves as the main interface to an OAK camera.",
        "long": "The OAK Device CHOP serves as the main interface to an OAK camera. It also implements many of the features of the Timer CHOP such as timer counters, pulses, and custom Python callbacks.<!--\n-->{{OPSubSection\n|opFamily=CHOP\n|sectionName=Basic Usage\n|sectionSummary=Before starting TouchDesigner, connect any OAK Devices to the computer via USB or Power over Ethernet (PoE). If you connect any devices while TouchDesigner is running, you should pulse the Refresh Device List parameter on the OAK Device CHOP. Next, customize the Python createPipeline callback and pulse the start parameter to start the camera. It's ok if you save a project while a camera is running. The camera will know to automatically start when the project opens next time.}}<!--\n-->{{OPSubSection\n|opFamily=CHOP\n|sectionName=Resolution and ISP Scale\n|sectionSummary=The <code>depthai</code> python module has an enum for RGB resolution: [https://docs.luxonis.com/projects/api/en/latest/references/python/?highlight=dai.ColorCameraProperties.SensorResolution#depthai.ColorCameraProperties.SensorResolution dai.ColorCameraProperties.SensorResolution]. This enum currently includes THE_1080_P, THE_1200_P, THE_4_K, and many others. These options may not necessarily be compatible with your OAK hardware. The most commonly available RGB resolution is 1080p. You can save on bandwidth by selecting a lower resolution via the ISP scale. Selecting (2, 3) with THE_1080_P will result in a 1280x720 image.}}<!--\n-->{{OPSubSection\n|opFamily=CHOP\n|sectionName=Configs\n|sectionSummary=The DepthaiTestSuite.toe project includes several base components which help control settings of an OAK camera by sending messages via an OAK Device CHOP. For example, the oakDeviceConfig base enables the user to set the XLinkChunkSize, logging level, and infrared laser settings of a device. The oakCameraControl base helps control RGB camera settings. The oakStereoDepthConfig base helps control stereo depth settings. It is possible to use these configs while the camera is running.}}<!--\n-->{{OPSubSection\n|opFamily=CHOP\n|sectionName=Optimizing Latency and FPS\n|sectionSummary=Luxonis has a tutorial on [https://docs.luxonis.com/projects/api/en/latest/tutorials/low-latency/ low latency]. In some cases such as streaming 4K video, you'll want to set [https://docs.luxonis.com/projects/api/en/latest/references/python/?highlight=xlinkchunksize#depthai.GlobalProperties.xlinkChunkSize:~:text=disables%20consistent%20timesyncing-,setXLinkChunkSize,-(self%3A XLinkChunkSize] to zero. This can be done with the oakDeviceConfig.\n\nWhen creating <code>depthai</code> pipelines, it's possible to set FPS targets for various nodes such as the [https://docs.luxonis.com/projects/api/en/latest/components/nodes/color_camera/ ColorCamera] node. In general, the FPS cannot be changed after the pipeline has been loaded on the camera. You should pick high FPS values, but keep in mind that if you push these numbers too high, you may see the effective FPS as shown by an Info CHOP begin to fall.}}\nSee Also: [[OAK-D]], [[OAK Select CHOP]], [[OAK Select TOP]]"
    },
    "oakselectCHOP": {
        "label": "oakselectCHOP",
        "members": [
            {
                "text": "Menu : The default option \"Items As Separate Channels\" enables time-slicing while \"Items as Separate Samples\" does not. If the stream is one which automatically fills in the CHOP, then \"Items as Separate Samples\" is a useful way to make the CHOP output '''Max Items''' samples consistently.",
                "type": "Par",
                "name": "outputformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "oakselectCHOP",
        "opLabel": "OAK Select",
        "opClass": "oakselectCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "Access a stream of the [[OAK Device CHOP]]",
        "long": "The OAK Select CHOP is like a [[Script CHOP]] combined with a [[Select CHOP]], and any of the other hardware-specific CHOPs. The basic operation involves providing an [[OAK Device CHOP]] and a stream name. In the simplest case, the stream's data will show up as well-named channels. For example, [https://docs.luxonis.com/projects/api/en/latest/components/messages/img_detections/ ImgDetections] messages indicating the 2D coordinates and labels of detected objects will show up as CHOP channels without any manual coding. In more complex cases such as hand landmark tracking, the stream may be of [https://docs.luxonis.com/projects/api/en/latest/components/messages/nn_data/ NNData] or [https://docs.luxonis.com/projects/api/en/latest/components/messages/buffer/ Buffer] type, requiring the user to implement a callback and parse the data."
    },
    "objectCHOP": {
        "label": "objectCHOP",
        "members": [
            {
                "text": "Menu : Specify the information to output from the objects as described in the parameters below. Except for 'measurements', these match the standard transform formats as described by the [[Transform CHOP]].",
                "type": "Par",
                "name": "compute"
            },
            {
                "text": "Menu : The transform order to use for Rotation, Scale, Transform, Bearing, or Single Bearing Angle <span class=\"tipTextCHOP\">Compute</span> modes.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : The rotation order to use for Rotation, Scale, Transform, Bearing, or Single Bearing Angle <span class=\"tipTextCHOP\">Compute</span> modes.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "Menu : Bearing requires a direction to use as a reference base.",
                "type": "Par",
                "name": "bearingref"
            },
            {
                "text": "An arbitrary base direction for the bearing calculation.",
                "type": "Par",
                "name": "bearingx"
            },
            {
                "text": "An arbitrary base direction for the bearing calculation.",
                "type": "Par",
                "name": "bearingy"
            },
            {
                "text": "An arbitrary base direction for the bearing calculation.",
                "type": "Par",
                "name": "bearingz"
            },
            {
                "text": "Menu : Sets how the created channels are named.",
                "type": "Par",
                "name": "nameformat"
            },
            {
                "text": "Menu : The start and end time of the desired interval of the object path.",
                "type": "Par",
                "name": "outputrange"
            },
            {
                "text": "Menu : The extend condition before the CHOP interval. They are:",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : Extend condition after the interval. Same options as Extend Left.",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opClass": "objectCHOP_Class",
        "opFamily": "CHOP",
        "long": "The Object CHOP compares two objects and outputs channels containing their raw or relative positions and orientations. The information that can be output is:\t\t\n\t\t\t\n* Position of one object relative to another\t\t\t\n* Rotation of one object relative to another\t\t\t\n* Bearing of one object relative to another\t\t\t\n* Single Bearing Angle between two objects\t\t\t\n* Distance between the origin of two objects\t\t\t\n* Inverse Square of the Distance between two objects\t\t\t\n\t\t\t\nThe optional two inputs allow you to compare X,Y,Z points in world space with objects or each other. The inputs are expected to have three channels containing XYZ points (three channels with the suffix x, y and z). Alternatively, they can be in the standard transform formats as described by the [[Transform CHOP]] help. These inputs replace the target and/or reference objects. Object and points can be compared with each other, but \"Rotation\" mode will always return zero.\t\t\t\n\t\t\t\nSee also the [[SOP to CHOP]] and the [[Parameter CHOP]]. They retrieve other information from [[object]]s and [[SOP]]s.",
        "short": "The Object CHOP compares two objects and outputs channels containing their raw or relative positions and orientations.",
        "opFilter": "False",
        "opType": "object",
        "opLabel": "Object",
        "opCategories": ""
    },
    "oculusaudioCHOP": {
        "label": "oculusaudioCHOP",
        "members": [
            {
                "text": "Menu : If the audio source content is known, this parameter can be set to improve overall sound quality.",
                "type": "Par",
                "name": "bandhint"
            },
            {
                "text": "Menu : Select attentuation calculation between the audio source and listener (head).",
                "type": "Par",
                "name": "attenuation"
            },
            {
                "text": "Sets the size of the box room.",
                "type": "Par",
                "name": "roomsizex"
            },
            {
                "text": "Sets the size of the box room.",
                "type": "Par",
                "name": "roomsizey"
            },
            {
                "text": "Sets the size of the box room.",
                "type": "Par",
                "name": "roomsizez"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Oculus Audio CHOP uses the Oculus Audio SDK to take a mono sound channel and create a spatialized stereo pair or channels for that sound.\n\nSee also: [[Audio Render CHOP]]",
        "opLicense": "Non-Commercial",
        "opClass": "oculusaudioCHOP_Class",
        "opLabel": "Oculus Audio",
        "opFamily": "CHOP",
        "opType": "oculusaudio",
        "os": "Microsoft Windows",
        "short": "The Oculus Audio CHOP uses the Oculus Audio SDK to take a mono sound channel and create a spatialized stereo pair or channels for that sound.",
        "opCategories": ""
    },
    "oculusriftCHOP": {
        "label": "oculusriftCHOP",
        "members": [
            {
                "text": "Menu : Switches between three different output modes.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Oculus Rift CHOP connects to an [[Oculus Rift]] device and outputs several useful sets of channels that can be used to integrate the Oculus Rift into projects.\t\t\n\t\t\t\nYou can view the detected orientation of the device and put the rotation values directly into other operators. To help decrease latency, prediction can be used to guess what the orientation will be at some point in the future.\t\t\t\n\t\t\t\nThe raw sensor data is also available, with options for both sensor acceleration and angular velocity.\t\t\t\n\t\t\t\nThe devices calibration parameters are another option. These can be used to generate the projection matrices and distortion shaders, although both of these are already available (see below and [[Oculus Rift TOP]]). This data is constant, but may differ on future devices.\t\t\t\n\t\t\t\nThe last two things the Oculus Rift CHOP can output are the left and right eye projection matrices. These can be (and will need to be) passed into a camera's \"Custom Projection\" parameter in order to provide a proper 3D experience with the Oculus Rift. For convenience, the channels are aligned to be passed in directly by reference.\t\t\t\n\t\t\t\nWithout an Oculus Rift device connected the CHOP uses default values and will output channels corresponding to the Oculus Rift Developer Kit device. This allows you to design something for the Oculus Rift without actually having one.\t\t\t\n\t\t\t\nSee also [[Oculus Rift]]",
        "opLicense": "Non-Commercial",
        "opClass": "oculusriftCHOP_Class",
        "opLabel": "Oculus Rift",
        "opFamily": "CHOP",
        "opType": "oculusrift",
        "os": "Microsoft Windows",
        "short": "The Oculus Rift CHOP connects to an [[Oculus Rift]] device and outputs several useful sets of channels that can be used to integrate the Oculus Rift into projects.",
        "opCategories": ""
    },
    "openvrCHOP": {
        "label": "openvrCHOP",
        "members": [
            {
                "text": "Menu : Controls what kind of category of data will be output from this node.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : Controls the range of motion of the skeleton values.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The OpenVR CHOP receives positional data, frame rendering info, and action data from the [[OpenVR]] SDK. Each CHOP can output in one of 5 modes: Sensors, Projection Matrices, Trackers, Frame Timings, Actions and Skeletons.\n\n=== Actions ===\n\nActions are described in more details in [[OpenVR Actions]].\n\t\t\t\n=== Getting Sensor Data at Higher Rates ===\t\t\t\n\t\t\t\nBy default when running a VR system the file will be throttled to the speed of the VR devices refresh rate by the OpenVR SDK. This helps ensure the low latency output required for a good VR experience. If only controllers/Vive trackers are being used for tracking in a non-VR situation, the file can run and sample those devices at a higher sample rate as long as no [[OpenVR TOP]] in the project. If an [[OpenVR TOP]] is present anywhere in the project, then playback will be throttled to the VR devices refresh rate.\t\t\t\n\t\t\t\nSee also [[OpenVR]], [[OpenVR TOP]], [[OpenVR SOP]], [[Audio Render CHOP]]",
        "opLicense": "Non-Commercial",
        "opClass": "openvrCHOP_Class",
        "opLabel": "OpenVR",
        "opFamily": "CHOP",
        "opType": "openvr",
        "os": "Microsoft Windows",
        "short": "The OpenVR CHOP receives positional data from the [[OpenVR]] SDK.",
        "opCategories": ""
    },
    "oscinCHOP": {
        "label": "oscinCHOP",
        "members": [
            {
                "text": "Menu : The network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The OSC In CHOP is used to accept Open Sound Control Messages. OSC In can be used to accept messages from either a 3rd party application which adheres to the Open Sound Control specification (http://www.cnmat.berkeley.edu/OpenSoundControl/). OSC In is based on a connection-less system, meaning that it can accept multiple messages for any number of sources at the same time. The user must specify a port number which OSC In will look for incoming messages. This port must not have anything running on it before OSC In attempts to use it. OSC CHOPs in TouchDesigner use the UDP transport protocol.\t\t\n\t\t\t\nSee also [[OSC_In_DAT|OSC In DAT]], [[OSC Out CHOP]], [[iOS and OSC]], [[Touch In CHOP]].\t\t\t\n\t\t\t\nThere are options which allow the user to adjust the default message queuing system to optimize it for their specific network conditions and usage needs. The Min/Max Target size specifies a range which the queue attempts to keep the buffer size at in seconds. Increasing the Queue Adjust Time will determine how long the queue can be outside that range before it tries to correct it.\t\t\t\n\t\t\t\nIf the user wishes to use OSC In to detect when messages are arriving, there is a Pulse Mode toggle which will read a single sample of any incoming message when it arrives and displays the pulse reset values any other time. This is useful for syncing beats between TouchDesigner and another applications.\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opLicense": "Non-Commercial",
        "opClass": "oscinCHOP_Class",
        "opLabel": "OSC In",
        "opFamily": "CHOP",
        "opType": "oscin",
        "short": "The OSC In CHOP is used to accept Open Sound Control Messages.",
        "opCategories": ""
    },
    "oscoutCHOP": {
        "label": "oscoutCHOP",
        "members": [
            {
                "text": "Menu : Selects the network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Choose the data format to send data between 32-bit integer, 32-bit float, or 64-bit double.",
                "type": "Par",
                "name": "numericformat"
            },
            {
                "text": "Menu : Specify how to format the outgoing messages.",
                "type": "Par",
                "name": "format"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "TheOSC Out CHOP sends all input channels to a specified network address and port. Each channel name and associated data is transmitted together to the specified location. TouchDesigner time stamps all outgoing Open Sound Control messages with the time of the outgoing frame relative to the system time when the first message was sent. OSC CHOPs in TouchDesigner use the UDP transport protocol.\t\t\n\t\t\t\nOSC Out will either send all the channels each cook or it will only send each channel depending on if it has changed at all since the last time it was sent. This is determined by the <span class=\"tipTextCHOP\">Send Events Every Cook</span> flag.\n\nOSC bundles allows you to send a group of messages in a single command rather than as separate, individual messages. The[[OSC Out DAT]] has a <code>sendOSC()</code> function that will accept a list of messages and send as a bundle. \n\t\nSee also [[OSC In CHOP]], [[OSC Out DAT]], [[OSC In DAT]], [[iOS and OSC]], [[Touch Out CHOP]], [[UDP Out DAT]], [[TCP/IP DAT]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opLicense": "Non-Commercial",
        "opClass": "oscoutCHOP_Class",
        "opLabel": "OSC Out",
        "opFamily": "CHOP",
        "opType": "oscout",
        "short": "The OSC Out CHOP sends all input channels to a specified network address and port.",
        "opCategories": ""
    },
    "outCHOP": {
        "label": "outCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Out CHOP sends CHOP data from inside a components to other components or CHOPs.\t\n\t\t\nIt sends channels to one of the outputs of the component. For each Out CHOP, there is one output connector on the Out CHOP's parent component.",
        "opLicense": "Non-Commercial",
        "opClass": "outCHOP_Class",
        "opLabel": "Out",
        "opFamily": "CHOP",
        "opType": "out",
        "short": "The Out CHOP sends CHOP data from inside a components to other components or CHOPs.",
        "opCategories": ""
    },
    "overrideCHOP": {
        "label": "overrideCHOP",
        "members": [
            {
                "text": "Menu : Monitors the channels in each input and matches them according to this menu.",
                "type": "Par",
                "name": "match"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Override CHOP lets you take inputs from several CHOP sources, and uses the most-recently changed input channels to determine the output. For example, if a 16-channel CHOP comes from one MIDI device, and another 16-channel CHOP comes from another place like another device or a preset, then Override selects the most recently-changed channels and outputs those values.\t\t\n\t\t\t\nThe Override CHOP outputs the same channels as the first input. If subsequent inputs have more or less channels than the first input, the missing/extra channels are ignored. The output defaults to the channel values of the first input, but when a value changes in any monitored channel, that value will become the new output for the corresponding channel name or number. If the same channel name or number is changing in two or more inputs at the same time, precedence is given by input order.\t\t\t\n\t\t\t\nThe Override CHOP output is reset to the default each time the number of inputs to the CHOP changes or the method of matching (by number or by name) changes.\t\t\t\n\t\t\t\nThe CHOP length is the length of the first input. From frame to frame, if all values are the same, the output is unchanged.\t\t\t\n\t\t\t\nAn optional channel can be created that will tell you which input has the most recently changed channel.",
        "opLicense": "Non-Commercial",
        "opClass": "overrideCHOP_Class",
        "opLabel": "Override",
        "opFamily": "CHOP",
        "opType": "override",
        "short": "The Override CHOP lets you take inputs from several CHOP sources, and uses the most-recently changed input channels to determine the output.",
        "opCategories": ""
    },
    "panelCHOP": {
        "label": "panelCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Panel CHOP reads [[Panel Value]]s from [[Panel Component]]s into CHOP channels. Panel values can also be accessed by using the <code>panel</code> Member of the [[PanelCOMP Class]].",
        "opLicense": "Non-Commercial",
        "opClass": "panelCHOP_Class",
        "opLabel": "Panel",
        "opFamily": "CHOP",
        "opType": "panel",
        "short": "The Panel CHOP reads [[Panel Value]]s from [[Panel Component]]s into CHOP channels.",
        "opCategories": ""
    },
    "pangolinCHOP": {
        "label": "pangolinCHOP",
        "members": [
            {
                "text": "Menu : Select the source operator.",
                "type": "Par",
                "name": "source"
            },
            {
                "text": "Menu : Select the mode for calculating the rate of the image in Beyond. Note: this is not the rate of the CHOP.",
                "type": "Par",
                "name": "ratemode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "pangolinCHOP",
        "opLabel": "Pangolin",
        "opClass": "pangolinCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "short": "The Pangolin CHOP interfaces with Pangolin's Beyond.",
        "long": "The Pangolin CHOP interfaces with Pangolin's [https://pangolin.com/collections/beyond-software Beyond]. Beyond is a professional laser and multimedia show control application. When Beyond is running, the Pangolin CHOP will send laser image frames to it. The image frames are created from either a SOP input or CHOP input.\n    \nThe Pangolin CHOP should work with any version of Beyond but it is recommended to use at least Beyond v5.1.\n    \n'''TouchDesigner Non-commercial will only work with the demo version of Beyond. TouchDesigner Commercial or Pro is required to interface with licensed versions of Beyond.'''\n    \nSee also: [[Laser CHOP]].",
        "opCategories": ""
    },
    "parameterCHOP": {
        "label": "parameterCHOP",
        "members": [
            {
                "text": " : Channels can be named suitably for multi-exporting. See [[CHOP_Export]].",
                "type": "Par",
                "name": "nameformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Parameter CHOP gets parameter values, including custom parameters, from all OP types.\t\t\n\t\t\t\n(This replaces the Fetch CHOP.)\t\t\t\n \t\t\t\nRetrieve from parameters alternatively using a <code>node.par.Customname</code> expression of the [[Par Class]], or the [[Parameter Execute DAT]].\t\t\t\n\t\t\t\nSee the [[Select CHOP]] for retrieving channels from the output of other CHOPs.",
        "opLicense": "Non-Commercial",
        "opClass": "parameterCHOP_Class",
        "opLabel": "Parameter",
        "opFamily": "CHOP",
        "opType": "par",
        "short": "The Parameter CHOP gets parameter values, including custom parameters, from all OP types."
    },
    "patternCHOP": {
        "label": "patternCHOP",
        "members": [
            {
                "text": "Menu : The shape of one cycle of the pattern.",
                "type": "Par",
                "name": "wavetype"
            },
            {
                "text": "Two parameters to multiply by a line from <code>taper1</code> at the start to <code>taper2</code> at the end. The default of (<code>1 1</code>) has no effect.",
                "type": "Par",
                "name": "taper1"
            },
            {
                "text": "Two parameters to multiply by a line from <code>taper1</code> at the start to <code>taper2</code> at the end. The default of (<code>1 1</code>) has no effect.",
                "type": "Par",
                "name": "taper2"
            },
            {
                "text": "A value at each From Range will become its corresponding To Range value.",
                "type": "Par",
                "name": "fromrange1"
            },
            {
                "text": "A value at each From Range will become its corresponding To Range value.",
                "type": "Par",
                "name": "fromrange2"
            },
            {
                "text": "A value at each From Range will become its corresponding To Range value.",
                "type": "Par",
                "name": "torange1"
            },
            {
                "text": "A value at each From Range will become its corresponding To Range value.",
                "type": "Par",
                "name": "torange2"
            },
            {
                "text": "Menu : A round-off menu to convert all numbers to integers.",
                "type": "Par",
                "name": "integer"
            },
            {
                "text": "Menu : If an input CHOP is attached, it adopts the length and sample rate of the input CHOP, and",
                "type": "Par",
                "name": "combine"
            },
            {
                "text": "Menu : The left right extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            },
            {
                "text": "Menu : The shape of one cycle of the pattern.",
                "type": "Par",
                "name": "wavetype"
            },
            {
                "text": "Two parameters to multiply by a line from <code>taper1</code> at the start to <code>taper2</code> at the end. The default of (<code>1 1</code>) has no effect.",
                "type": "Par",
                "name": "taper1"
            },
            {
                "text": "Two parameters to multiply by a line from <code>taper1</code> at the start to <code>taper2</code> at the end. The default of (<code>1 1</code>) has no effect.",
                "type": "Par",
                "name": "taper2"
            },
            {
                "text": "A value at each From Range will become its corresponding To Range value.",
                "type": "Par",
                "name": "fromrange1"
            },
            {
                "text": "A value at each From Range will become its corresponding To Range value.",
                "type": "Par",
                "name": "fromrange2"
            },
            {
                "text": "A value at each From Range will become its corresponding To Range value.",
                "type": "Par",
                "name": "torange1"
            },
            {
                "text": "A value at each From Range will become its corresponding To Range value.",
                "type": "Par",
                "name": "torange2"
            },
            {
                "text": "Menu : A round-off menu to convert all numbers to integers.",
                "type": "Par",
                "name": "integer"
            },
            {
                "text": "Menu : If an input CHOP is attached, it adopts the length and sample rate of the input CHOP, and",
                "type": "Par",
                "name": "combine"
            },
            {
                "text": "Menu : The left right extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Pattern CHOP generates a sequence of samples in a channel. Unlike the [[Wave CHOP]] its purpose is generating arrays of samples that have no reference to time (seconds or frames).\t\t\n \t\t\t\nIt is useful for curve generation like lookup tables, simple shapes that can be converted to SOPs, generating channels that are passed to the [[Geometry COMP]] to generate instances, and other non-time-based curve-generation, with as little need to make expressions in Python.\t\t\t\n\t\t\t\nAll defaults are in samples, not seconds or frames (though like all CHOPs, it carries with it a sample rate). There is no start-end, just Length in samples.\t\t\t\n\t\t\t\n'''Tip''': To display a CHOP viewer in the units of samples, make the [[Viewer Active]] and change [[Mouse Click|RMB]] -> Units to be Samples.\t\t\t\n \t\t\t\nThe Pattern CHOP optionally takes one input CHOP to match the length and sample rate, and, choosing via the Combine Channels menu, Appends or Inserts the new channel(s), Replaces the incoming channels, Adds to the incoming channels or Multiplies the incoming channels.\t\t\t\n\t\t\t\nThe Pattern CHOP defaults to one cycle of the curve over the length of the CHOP, no matter how many samples long.\t\t\t\n \t\t\t\n'''Tip: Customizing each channel:''' The python object for the Pattern CHOP has a <code>chanIndex</code> member, so if Pattern generates three channels you can put something like <code>[1, 3, 7][me.chanIndex]</code> in any parameter to customize its value for each channel. For example, in the Type parameter, put the expression <code>['sin', 'cos', 'ramp'][me.chanIndex]</code> to get 3 different curve types.",
        "opLicense": "Non-Commercial",
        "opClass": "patternCHOP_Class",
        "opLabel": "Pattern",
        "opFamily": "CHOP",
        "opType": "pattern",
        "short": "The Pattern CHOP generates a sequence of samples in a channel.",
        "opCategories": ""
    },
    "performCHOP": {
        "label": "performCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Perform CHOP outputs many channels like frames-per-second, describing the current state of the TouchDesigner process. As channels they can be manipulated into user interfaces and calculations to adjust real-time self-tuning of the process. \t\n\t\t\nIt outputs the \"cook time\" of the prior frame that was drawn, which is a reflection of how many frames TouchDesigner cooked in the prior second. The <code>cook</code>\n\n'''Tip''': Put a Trail CHOP after the Perform CHOP to watch its progress.\n\nchannel, when sent to a Trail CHOP shows which frames were cooked and which were skipped, useful in optimizing your work to reach a desired frame rate.\t\t\n\t\t\nThe Built-in Variables found on Dialogs -> Variables -> Built-in include more useful data on your running system. See also the Built-in Variables section of the [[Variables]] page.",
        "opLicense": "Non-Commercial",
        "opClass": "performCHOP_Class",
        "opLabel": "Perform",
        "opFamily": "CHOP",
        "opType": "perform",
        "short": "The Perform CHOP outputs many channels like frames-per-second, describing the current state of the TouchDesigner process.",
        "opCategories": ""
    },
    "phaserCHOP": {
        "label": "phaserCHOP",
        "members": [
            {
                "text": "Menu : Specifies the format of the output.",
                "type": "Par",
                "name": "outputformat"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "phaserCHOP",
        "opLabel": "Phaser",
        "opClass": "phaserCHOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Phaser CHOP does staggered (time-offset) animation interpolation. Phaser outputs one channel with multi-samples. Each sample animates from 0 to 1 over a cycle, but each sample value rises from 0 and arrives at 1 at different times.",
        "long": "The Phaser CHOP does staggered (time-offset) animation interpolation. Phaser outputs one channel with multi-samples. Each sample animates from 0 to 1 over a cycle, but each sample value rises from 0 and arrives at 1 at different times.\n    \nFor example, you may have a set of N objects that you want to animate from a start position to an end position. You set Num Samples to N, which will make the Phaser CHOP output one channel with N samples that will animate the samples from 0 to 1 and be interpolated with an easing function. In the Phaser CHOP the start-to-end cycle is controlled by the first input of the CHOP, which is expected to be one channel with value between 0 to 1. \n\nThe 0-1 values can be used with the [[Lookup CHOP]] to animate groups of channels.\n\nBy default the timing is staggered uniformly.  If you want to stagger their transitions irregularly, you use the second input, a set of values in one CHOP channel (typically N samples) that are between 0 and 1. The phase value specifies the object's timing relationship with the rest of those in the CHOP. A phase value of 1 corresponds to an animated object thats \"ahead of the pack\" (ie. it will start animating before the others). A value of 0 corresponds to an object that is late (ie. it will be the last to start easing/animating). If a phase input is not provided then the phase will simply be i/N where N is the total number of objects (ie. samples), and i is the index of the current sample.\n    \nThere is also a notion of an \"Edge\" in the Phaser, which describes the cohesiveness of the group of animated objects and how fast the samples rise. A small value will cause the objects to go through the animation very quickly or at high value, very slowly and in unison with other samples.\n\nLook at David Braun's '''[https://www.youtube.com/watch?v=S4PQW4f34c8 TouchDesigner Summit Talk]''' to see the background of the Phaser CHOP. Its functionality draws heavily from David's research and development in quantitative easing. \n\nSee also the [[OP Snippets]].",
        "opCategories": ""
    },
    "pipeinCHOP": {
        "label": "pipeinCHOP",
        "members": [
            {
                "text": "Menu : Set operation as server or client.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : Print all incoming commands (not channel data) to the Console which can be opened from the Dialogs menu. A good way to test a connection is to put \"<code>echo X</code>\" commands in the incoming stream.",
                "type": "Par",
                "name": "echo"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Pipe In CHOP allows users to input from custom devices into CHOPs. It is implemented as a TCP/IP network connection.",
        "opType": "pipein",
        "opFilter": "False",
        "opClass": "pipeinCHOP_Class",
        "opLabel": "Pipe In",
        "long": "The Pipe In CHOP allows users to input from custom devices into CHOPs. It is implemented as a TCP/IP network connection.\t\t\n\t\t\t\nThe connection can be from a user-written program that outputs to the Pipe In CHOP's port, or from another TouchDesigner process, where the data is coming from a [[Pipe Out CHOP]].\t\t\t\n\t\t\t\nRegular channel data sent to Pipe In outputs has CHOP channels (channel names with floating point values every frame). Mixed with it can be TouchDesigner scripting commands that get executed when they arrive. \t\t\t\n\t\t\t\n'''TIP:''' The [[TCP/IP DAT]] or [[UDP In DAT]] is the preferred way to send script commands and other data packets over the network.\t\t\t\n\t\t\t\nThis node differs from the [[Touch In CHOP]] as it functions using a stream of commands, instead of a simple stream of channel data like the [[Touch In CHOP]]. Information comes in in various commands which are documented in the files located in your installation directory\t\t\t\n<code>C:/Program Files/Derivative/TouchDesigner*/touch/docs/pipe</code>.\t\t\t\n\t\t\t\nTo receive network data from another \"server\" computer (e.g. from a TouchDesigner Pipe Out CHOP running remotely), a connection must be established between the server and the Pipe In CHOP before data is sent. You must supply the Server Address and Port from which to receive incoming data to a channel. The server should be listening for connections on the port that this CHOP is using.\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''\t\t\n\t\t\t\nSee also [[Shared Mem In CHOP]].",
        "opCategories": ""
    },
    "pipeoutCHOP": {
        "label": "pipeoutCHOP",
        "members": [
            {
                "text": "Menu : Set operation as server or client.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : In single sample mode, this parameter determines which sample to send; the sample at frame 1 or the current sample.",
                "type": "Par",
                "name": "sample"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Pipe Out CHOP can be used to transmit data out of TouchDesigner to other processes running on a remote machine using a network connection.",
        "opType": "pipeout",
        "opFilter": "True",
        "opClass": "pipeoutCHOP_Class",
        "opLabel": "Pipe Out",
        "long": "The Pipe Out CHOP can be used to transmit data out of TouchDesigner to other processes running on a remote machine using a network connection. If the other process is another TouchDesigner process, a [[Pipe In CHOP]] in that process can be used to receive the data. Multiple PipeIn CHOPs can connect to a PipeOut CHOP.\n\nFor more information on how to connect two TouchDesigner processes running on different machines with a Pipe In and Pipe Out CHOP, see the [[Pipe In CHOP]].\t\n\t\t\t\n'''NOTE:''' For TouchDesigner-to-TouchDesigner communication of channel data, see the [[Touch In CHOP]] and [[Touch Out CHOP]] which offer optimized and [[Time Slice]]d data transfer.\t\t\t\n\t\t\t\n'''TIP:''' The [[TCP/IP DAT]] or [[UDP Out DAT]] is the preferred way to send script commands and other data packets over the network.\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''\t\t\t\t\t\n\t\t\t\nSee also [[OSC Out CHOP]], [[Shared Mem Out CHOP]].",
        "opCategories": ""
    },
    "posistagenetCHOP": {
        "label": "posistagenetCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "This operator decodes [http://www.posistage.net/ PosiStageNet] protocol data into CHOP channels. PosiStageNet will track any number of objects and output their position, orientation, speed, acceleration, or the objects' target position.\n\nPosiStageNet is a data exchange protocol created by [http://www.vyv.ca/ VYV] and [http://www.malighting.com MA Lighting], and has applications in on-stage lighting, sound, and projection mapping.\n\nSee also [[BlackTrax CHOP]].",
        "opLabel": "PosiStageNet",
        "opClass": "posistagenetCHOP_Class",
        "opType": "posistagenet",
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "This operator decodes PosiStageNet protocol data into CHOP channels.",
        "opCategories": ""
    },
    "pulseCHOP": {
        "label": "pulseCHOP",
        "members": [
            {
                "text": "Menu : You can interpolate the values between pulses using the following function curves:",
                "type": "Par",
                "name": "interp"
            },
            {
                "text": "Menu : Select the units to use for this parameter, Samples, Frames, or Seconds.",
                "type": "Par",
                "name": "widthunit"
            },
            {
                "text": "Menu : Enable the Minimum and Maximum clamping values below with this menu.",
                "type": "Par",
                "name": "limit"
            },
            {
                "text": "Menu : Select the units to use for this parameter, Samples, Frames, or Seconds.",
                "type": "Par",
                "name": "startunit"
            },
            {
                "text": "Menu : Select the units to use for this parameter, Samples, Frames, or Seconds.",
                "type": "Par",
                "name": "endunit"
            },
            {
                "text": "Menu : The left extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Pulse CHOP generates pulses in one channel at regular intervals.",
        "opType": "pulse",
        "opFilter": "False",
        "opClass": "pulseCHOP_Class",
        "opLabel": "Pulse",
        "long": "The Pulse CHOP generates pulses in one channel at regular intervals. The amplitude of each pulse can be edited with the CHOP sliders or with handles on the graph.\t\t\n\t\t\t\nThe Pulse CHOP gives a set of pulses in a static channel of a specifiable length. \t\t\t\n\t\t\t\nSee also the [[LFO CHOP]] to get an endless stream of pulses that is [[Time Slice]]d, and the [[Pattern CHOP]] for a string of static pulses.\t\t\t\n\t\t\t\nThe Pulse CHOP can be used as triggers to the [[Copy CHOP]], and can represent regularly-timed events.\t\t\t\n\t\t\t\nBy default, the pulses are a single sample long, but you can increase the Pulse Width so that the pulses are steps to the next pulse. You can also interpolate the values between pulses, as Linear, Ease In Ease Out, Cubic or other curves.\t\t\t\n\t\t\t\nThe pulses can be restricted to a minimum / maximum limit. If the Limit Type is Clamp, the graph has additional convenient handles at the minimum and maximum for each pulse.\t\t\t\n\t\t\t\nThe Pulse CHOP generates a single channel of up to 32 pulses, and you can merge several Pulse CHOPs into a multi-channel CHOP.\t\t\t\n\t\t\t\nThe Pulse CHOP uses its optional first input as a start/end reference, so a number of Pulse CHOPs can be stretched to the same interval.\t\t\t\n\t\t\t\nIn order to set the value at the last sample, the option, Last Pulse at Last Sample is provided. Otherwise, the last pulse is prior to the last sample.",
        "opCategories": ""
    },
    "realsenseCHOP": {
        "label": "realsenseCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The RealSense CHOP references a [[RealSense TOP]] camera and fetches tracking data from it.",
        "opType": "realsense",
        "opFilter": "False",
        "opClass": "realsenseCHOP_Class",
        "opLabel": "RealSense",
        "long": "[[RealSense]] is a tracking device from Intel. The RealSense CHOP references a [[RealSense TOP]] camera and fetches tracking data from it. The RealSense CHOP supports skeleton tracking through the [https://www.intelrealsense.com/skeleton-tracking/ Cubemos Skeleton Tracking API]. [[Cubemos]] is Windows only. A Cubemos license is required to use the skeleton tracking.\n    \n==== Skeleton Tracking Setup ====\nThe [[RealSense CHOP]] supports skeleton tracking through the [https://www.intelrealsense.com/skeleton-tracking/ Cubemos RealSense Skeleton Tracking API]. The Cubemos API requires a license to use in TouchDesigner. A full license can be purchased [https://www.intelrealsense.com/skeleton-tracking here]; a trial license is also available. Installing their SDK is required to setup the license file. After installation of the SDK, the license can be setup with the <code>post_installation.bat</code> script in the <code>C:/Program Files/Cubemos/SkeletonTracking/scripts</code> folder. A model file (<code>.cubemos</code>) is also required for the skeleton tracking, two of which are packaged with the Cubemos Skeleton Tracking SDK, located in their <code>Cubemos/SkeletonTracking/models/skeleton-tracking</code> folder.\n\n'''NOTE:''' The [https://github.com/IntelRealSense/librealsense/releases librealsense SDK v2.50.0] does not look like it will be updated for Apple Silicon, so it is not an option to add to these builds.\n\nSee also: [[RealSense]], [[RealSense TOP]]",
        "opCategories": ""
    },
    "recordCHOP": {
        "label": "recordCHOP",
        "members": [
            {
                "text": "Menu : When and how much to record:",
                "type": "Par",
                "name": "record"
            },
            {
                "text": "Menu : Determines whether record should sample the time slice or the current frame. You would generally want to use Current Time Slice, for audio, as all frames will be evaluated.\t\n\t\t\t\nIf the interval is set to be the Current Frame, it will always cook (only look at) the current frame (things downstream still cook regardless of this setting however). Thus, it should generally not be used for audio, but rather fro things like device input, because it interpolates the values between the captured frames.",
                "type": "Par",
                "name": "sample"
            },
            {
                "text": "Menu : Determines how to compute missed input samples using interpolation. Using Hold Previous Value does just that; Linear and Cubic interpolation will create a mathematical blend of values in a linear (straight line between values in time), or cubic (smooth round-off curve between beginning and ending values).",
                "type": "Par",
                "name": "interp"
            },
            {
                "text": "Menu : Determines the frame range that gets output from the CHOP.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "The data gets recorded in a fixed-range interval and the most recent data gets recorded at the end of the interval and the remaining samples get shifted toward the start of the interval. This is useful for making snakes.",
                "type": "Par",
                "name": "segment1"
            },
            {
                "text": "The data gets recorded in a fixed-range interval and the most recent data gets recorded at the end of the interval and the remaining samples get shifted toward the start of the interval. This is useful for making snakes.",
                "type": "Par",
                "name": "segment2"
            },
            {
                "text": "Menu : Enabled when a CHOP is connected to the Record CHOP's 3rd input (ie. Input 2). Determines what condition is required to trigger a reset using this input.",
                "type": "Par",
                "name": "resetcondition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Record CHOP takes the channels coming in the first (Position) input, converts and records them internally, and outputs the stored channels as the CHOP output.",
        "opType": "record",
        "opFilter": "True",
        "opClass": "recordCHOP_Class",
        "opLabel": "Record",
        "long": "The Record CHOP takes the channels coming in the first (Position) input, converts and records them internally, and outputs the stored channels as the CHOP output. The optional second (Active) input is used to enable and disable the recording.\t\t\n\t\t\t\nDuring recording, the Record CHOP uses only the values of the first input at the current frame. The Type determines how the input values are converted.\t\t\t\n\t\t\t\n'''Tip''': The [[Trail CHOP]] also records the last window of samples, and more powerfully, the gestureCapture component in the Palette gives more control over multi-captures and smoothing channel data.\t\t\t\n\t\t\t\nIf Record is set to Auto Range, and the Active input goes on, and TouchDesigner is playing, then any existing storage array is cleared, and the channels are recorded in a new storage array until Active goes off. This behaves like a sampler.\t\t\t\n\t\t\t\nThe [[Mouse In CHOP]] and [[Keyboard In CHOP]] are often attached to the Position and Active inputs respectively of the Record CHOP to perform the recording of channels from mouse movements, enabled by pressing a keyboard key (see the [[Keyboard In CHOP]]).\t\t\t\n\t\t\t\nRecord Segment is useful for recording trails, snakes, and other models that use a time-history of motion.\t\t\t\n\t\t\t\nSee the [[Time Slice CHOP]] for input smoothing.",
        "opCategories": ""
    },
    "renameCHOP": {
        "label": "renameCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Rename CHOP renames channels. Channels names from the input CHOP are matched using the From pattern, and are renamed to the corresponding name in the To pattern.",
        "opType": "rename",
        "opFilter": "True",
        "opClass": "renameCHOP_Class",
        "opLabel": "Rename",
        "long": "The Rename CHOP renames channels. Channels names from the input CHOP are matched using the From pattern, and are renamed to the corresponding name in the To pattern. Channels that do not match the From pattern are not affected.\t\n \nIt uses [[Pattern Matching]] on the From string, and [[Pattern Replacement]] on the To string.\n\t\t\nThe channel values and the channel order are not affected, only their names change.\t\t\n\t\t\n(Note that the [[Constant CHOP]] (containing channel values of 0) added to another CHOP in a [[Math CHOP]] can also be used to rename channels.)\t\t\n\t\t\nSee also [[Select CHOP]]",
        "opCategories": ""
    },
    "renderpickCHOP": {
        "label": "renderpickCHOP",
        "members": [
            {
                "text": "Menu : Decides when to update values based on pick interactions.",
                "type": "Par",
                "name": "strategy"
            },
            {
                "text": "Menu : Determines when the values are updated.",
                "type": "Par",
                "name": "responsetime"
            },
            {
                "text": "Menu : Determines how the pick location is set.",
                "type": "Par",
                "name": "pickingby"
            },
            {
                "text": "Menu : Returns the position of the point picked on the geometry. Channels ''tx, ty, tz''.",
                "type": "Par",
                "name": "position"
            },
            {
                "text": "Menu : Returns the normals of the point picked on the geometry. Channels ''nx, ny, nz''.",
                "type": "Par",
                "name": "normal"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Render Pick CHOP samples a rendering (from a [[Render TOP]] or a [[Render Pass TOP]]) and returns 3D information from the geometry at that particular pick location.",
        "opType": "renderpick",
        "opFilter": "False",
        "opClass": "renderpickCHOP_Class",
        "opLabel": "Render Pick",
        "long": "The Render Pick CHOP samples a rendering (from a [[Render TOP]] or a [[Render Pass TOP]]) and returns 3D information from the geometry at that particular pick location. Values sampled can include position, normals, point color, texture coordinates, depth and the object's path.\tAn [[Info DAT]] should be used to retrieve the object's path.\n\t\t\t\nThe pick location is specified through uv coordinates of the rendering. These uv coordinates can be selected by clicking on a [[Panel Component]] or explicitly setting them in the U and V parameters in the Render Pick CHOP.\n\nAlong with the geometric data returned, this node has two channels 'picked' and 'trigger' that inform the picked status. 'picked' will be 1 when an object has been found at the search location. 'trigger' will be 1 when both an object has been found, and the 'Picking By' condition has been met. That is, either the 'Panel Value' is 1, or the 'Select' parmeter is 'On.\n\t\t\t\nSee also the multi-sample [[Render Pick DAT]].",
        "opCategories": ""
    },
    "renderstreaminCHOP": {
        "label": "renderstreaminCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "renderstreaminCHOP",
        "opLabel": "RenderStream In",
        "opClass": "renderstreaminCHOP_Class",
        "opFilter": "True",
        "opLicense": "Pro",
        "opCategories": "",
        "short": "=This node is the primary node to control and configure a connection with the [[RenderStream]] protocol from [https://www.disguise.one/en/products/renderstream/ Disguise].",
        "long": "This node is the primary node to control and configure a connection with the [[RenderStream]] protocol from [https://www.disguise.one/en/products/renderstream/ Disguise]. Along with being the sync-point for when a frame starts rendering, it also brings in all of the control channels, and also takes a DAT with schema information to create controllable parameters within Disguise.\n\nUsually you want to have the 'Real-Time' flag on the top of the TouchDesigner UI turned off when using this node, so that this node is what drives frame advancement, not the default TouchDesigner time advancement.\n\nSee also [[RenderStream Out TOP]], [[RenderStream In TOP]], [[RenderStream]]."
    },
    "reorderCHOP": {
        "label": "reorderCHOP",
        "members": [
            {
                "text": "Menu : There are three different reordering methods. You can enter a Numeric Pattern, a Character Pattern, or use an optional second input CHOP as an order reference.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : Only enabled if a second input is present. Specifies the format of that input.",
                "type": "Par",
                "name": "orderref"
            },
            {
                "text": "Menu : Channels that do not match are called \"remaining\" and can also be ordered: they can be placed at the At Beginning or At Ending (in reference to the position of the matched channels).",
                "type": "Par",
                "name": "rempos"
            },
            {
                "text": "Menu : The channels that did not match can have the Same as Input order, or can be sorted AlphaNumerically.",
                "type": "Par",
                "name": "remorder"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Reorder CHOP re-orders the first input CHOP's channels by numeric or alphabetic patterns.",
        "opType": "reorder",
        "opFilter": "True",
        "opClass": "reorderCHOP_Class",
        "opLabel": "Reorder",
        "long": "The Reorder CHOP re-orders the first input CHOP's channels by numeric or alphabetic patterns. Either a channel pattern specifies the new order, or a number sequence specifies the new order.\t\t\n\t\t\t\nIf the second input, the Order Reference is present, the Numeric Pattern and Character Pattern are ignored, and the first input CHOP's channels are reordered to match as well as possible the reference CHOP's. In this case, Method is not used.\t\t\t\n\t\t\t\nChannel values are never affected.",
        "opCategories": ""
    },
    "replaceCHOP": {
        "label": "replaceCHOP",
        "members": [
            {
                "text": "Menu : Determines the start/end range of the output.",
                "type": "Par",
                "name": "length"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Replace CHOP can be used to replace channels very quickly.",
        "opType": "replace",
        "opFilter": "True",
        "opClass": "replaceCHOP_Class",
        "opLabel": "Replace",
        "long": "The Replace CHOP can be used to replace channels very quickly. The output of channels in <span class=\"tipTextCHOP\">Input1</span> will be replaced by channels found in <span class=\"tipTextCHOP\">Input2</span> if a matching channel exists in Input2. Any channels that are in Input1 and not in Input2 will be output without being replaced.\t\t\n\t\t\t\nYou can also use this to quickly delete channels (this method can be faster than the [[Delete CHOP]]). To do this send all the channels to Input2, then send the channels you want to keep to Input1.",
        "opCategories": ""
    },
    "resampleCHOP": {
        "label": "resampleCHOP",
        "members": [
            {
                "text": "Menu : The resample method to apply to the channels:",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : Determines how the Start/End parameters are interpreted.",
                "type": "Par",
                "name": "relative"
            },
            {
                "text": "Menu : The interpolation method to use when resampling:",
                "type": "Par",
                "name": "interp"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Resample CHOP resamples an input's channels to a new sample rate and/or start/end interval.",
        "opType": "resample",
        "opFilter": "True",
        "opClass": "resampleCHOP_Class",
        "opLabel": "Resample",
        "long": "The Resample CHOP resamples an input's channels to a new sample rate and/or start/end interval. In all cases, the entire input interval is resampled to match the output interval.\t\t\n\t\t\t\nResample does a simple linear interpolation of the Time Slice in [[Time Slicing]] mode. Only the sample rate can be changed.",
        "opCategories": ""
    },
    "scurveCHOP": {
        "label": "scurveCHOP",
        "members": [
            {
                "text": "Menu : What Curve Type to Generate.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Specify the low and high range of the input index.",
                "type": "Par",
                "name": "fromrange1"
            },
            {
                "text": "Specify the low and high range of the input index.",
                "type": "Par",
                "name": "fromrange2"
            },
            {
                "text": "Specify the low and high range of the curve.",
                "type": "Par",
                "name": "torange1"
            },
            {
                "text": "Specify the low and high range of the curve.",
                "type": "Par",
                "name": "torange2"
            },
            {
                "text": "Menu : The left extend condition (before range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "scurve",
        "opLabel": "S Curve",
        "opLicense": "Non-Commercial",
        "opClass": "scurveCHOP_Class",
        "opFilter": "False",
        "short": "This CHOP generates S curves.",
        "long": "This CHOP generates S curves.",
        "opCategories": ""
    },
    "scanCHOP": {
        "label": "scanCHOP",
        "members": [
            {
                "text": " : Choose the source node family.",
                "type": "Par",
                "name": "source"
            },
            {
                "text": " : Controls the order in which rows are output to minimize flicker.",
                "type": "Par",
                "name": "interleave"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Scan CHOP converts a [[SOP]] or [[TOP]] to oscilloscope or laser friendly control waves.",
        "opType": "scan",
        "opFilter": "False",
        "opClass": "scanCHOP_Class",
        "opLabel": "Scan",
        "long": "The Scan CHOP converts a [[SOP]] or [[TOP]] to oscilloscope or laser friendly control waves.  The output is usually in the audible range and can be heard directly via an [[Audio Device Out CHOP]], or used to drive the X and Y deflector inputs of an oscilloscope, or a laser projector recreating the imagery.\nThe output can also be visualized through use of a [[Limit SOP]].\t\t\n\t\t\t\nA sample component found at: [http://www.derivative.ca/Forum/viewtopic.php?f=22&t=1201 Op to Audio CHOP example]\t\t\t\n\t\t\t\nA sample video can be found at: [http://vimeo.com/channels/touchdesigner#3750626 Total Internal Reflection]\t\t\t\n\t\t\t\nSee also: [[EtherDream CHOP]], [[EtherDream DAT]]"
    },
    "scriptCHOP": {
        "label": "scriptCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Script CHOP runs a script each time the Script CHOP cooks.",
        "opType": "script",
        "opFilter": "False",
        "opClass": "scriptCHOP_Class",
        "opLabel": "Script",
        "long": "The Script CHOP runs a script each time the Script CHOP cooks. By default, the Script CHOP is created with a docked DAT that contains three Python methods: <code>cook</code>, <code>onPulse</code>, and <code>setupParameters</code>. The <code>cook</code> method is run each time the Script CHOP cooks. The <code>setupParameters</code> method is run whenever the Setup Parameter button on the Script page is pressed. The <code>onPulse</code> method is run whenever a custom pulse parameter is pushed.\t\n\t\t\nRefer to Help -> Python Examples, and Help -> [[OP Snippets|Operator Snippets]].\t\t\n\t\t\nNote: Because the Script CHOP can get data from anywhere, it's difficult to determine what it procedurally depends on. So every time that any Script OP runs it will make a list of operators, parameters, nodes etc that it depends upon, and when they change, the Script OP will re-cook.\t\n\nThe [[Script CHOP]] enables numPy arrays to be converted into the CHOP's channels.  Also any CHOP can get its channels converted into numPy arrays. (May 2021) See <code>numPyArray()</code> in [[CHOP Class]].\n\t\nSee also: [[Script DAT]], [[Script SOP]], [[Script TOP]]",
        "opCategories": ""
    },
    "selectCHOP": {
        "label": "selectCHOP",
        "members": [
            {
                "text": "Menu : This menu handles cases where multiple input CHOPs have different start or end times. All channels output from a CHOP share the same start/end interval, so the inputs must be treated with the Align Options:",
                "type": "Par",
                "name": "align"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Select CHOP selects and renames channels from other CHOPs of any CHOP network.",
        "opType": "select",
        "opFilter": "False",
        "opClass": "selectCHOP_Class",
        "opLabel": "Select",
        "long": "The Select CHOP selects and renames channels from other CHOPs of any CHOP network. You can select the channels from control panel gadgets like sliders and buttons. It retrieves channels from one or more CHOPs.\t\t\n\t\t\t\nIt selects only the channels you specify. Example: \"<code>c2 c5 c3 c3</code>\" will result in 4 channels, the last two identical, all in the specified order.\t\t\t\n\t\t\t\nThere are two ways of getting channels - through the CHOP and Channel Name parameters or directly from a CHOP connected to its input. All extract and renaming options apply when using the CHOP and Channel Name parameters instead of the wired input. \t\t\t\n\t\t\t\nSee [[Pattern Matching]] for selecting CHOPs and channels. \t\t\t\n\t\t\t\nIt can also rename channels by generating new channel names. See [[Pattern Replacement]] and [[Pattern Expansion]] for patterns you can use. \t\t\t\n\t\t\t\nSee [[Rename_CHOP#Channel_Naming_Patterns|Channel Naming Patterns]] for more ways to manipulate existing channel names into new ones.\t\t\t\n\t\t\t\n(The Select CHOP gets channels from any CHOP, the [[Parameter CHOP]] gets parameters of any OP.)\t\t\t\n\t\t\t\nSee also the [[Rename CHOP]] (Select CHOP does most of the same things and more.)",
        "opCategories": ""
    },
    "sequencerCHOP": {
        "label": "sequencerCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "'''NOTE''': '''The [[Timer CHOP]] replaces the Sequencer CHOP'''.",
        "opType": "sequencer",
        "opFilter": "False",
        "opClass": "sequencerCHOP_Class",
        "opLabel": "Sequencer",
        "long": "'''NOTE''': '''The [[Timer CHOP]] replaces the Sequencer CHOP'''. Sequencer CHOP has been removed (it will still work in existing files). See the [[Timer CHOP]] examples in the OP Snippets (Help -> Operator Snippets). The Timer CHOP is an engine for running timed processes. It outputs channels such as timing fractions, counters, pulses and timer states, and it calls python functions (callbacks) on various timing events.",
        "opCategories": ""
    },
    "serialCHOP": {
        "label": "serialCHOP",
        "members": [
            {
                "text": "Menu : The type of input transition to monitor.",
                "type": "Par",
                "name": "state"
            },
            {
                "text": "StrMenu : Selects the COM port that the serial connection will use.",
                "type": "Par",
                "name": "port"
            },
            {
                "text": "Pulse : Use this menu to select from some commonly used baud rates.",
                "type": "Par",
                "name": "baudrate"
            },
            {
                "text": "Menu : This parameter sets the number of data bits sent in each. Data bits are transmitted \"backwards\". Backwards refers to the order of transmission, which is from least significant bit (LSB) to most significant bit (MSB). To interpret the data bits, you must read from right to left.",
                "type": "Par",
                "name": "databits"
            },
            {
                "text": "Menu : This parameter can be set to none, even, or odd. The optional parity bit follows the data bits and is included as a simple means of error checking. Parity bits work by specifying ahead of time whether the parity of the transmission is to be even or odd. If the parity is set to be odd, the transmitter will then set the parity bit in such a way as to make an odd number of 1's among the data bits and the parity bit.",
                "type": "Par",
                "name": "parity"
            },
            {
                "text": "Menu : The last part of transmission packet consists of 1 or 2 Stop bits. The connection will now wait for the next Start bit.",
                "type": "Par",
                "name": "stopbits"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Serial CHOP is used for serial communication through an external port, using the RS-232 protocol.",
        "opType": "serial",
        "opFilter": "True",
        "opClass": "serialCHOP_Class",
        "opLabel": "Serial",
        "long": "The Serial CHOP is used for serial communication through an external port, using the RS-232 protocol. These ports are usually a 9 pin connector, or a USB port on new machines. (Using a USB port requires a USB-to-serial adaptor and driver.) All of a computer's available serial ports can be found in the Device Manager under the Windows operating system. Their names begin with 'COM'. Example: COM1, COM2, COM3, etc.\t\t\n\t\t\t\nThis CHOP monitors changes in its input channels, and sends the corresponding script through the serial connection.\t\t\t\nAny ASCII numeric digits '0'..'9' that are received, are stored and reflected in the output channel named 'return'.\t\t\t\n\t\t\t\nWhen you need to receive more complex data, other than simple ASCII numbers use the [[Serial DAT]].\t\t\t\n\t\t\t\nSee also [[Serial DAT]], [[serialDAT_Class]], [[Arduino]].",
        "opCategories": ""
    },
    "sharedmeminCHOP": {
        "label": "sharedmeminCHOP",
        "members": [
            {
                "text": "Menu : Reads from a Local or a Global memory location.",
                "type": "Par",
                "name": "memtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Commercial",
        "opFamily": "CHOP",
        "short": "The Shared Mem In CHOP receives CHOPs from a shared memory segment that is attached to a [[Shared Mem Out CHOP]] in another process or the same process.",
        "opType": "sharedmemin",
        "opFilter": "False",
        "opClass": "sharedmeminCHOP_Class",
        "opLabel": "Shared Mem In",
        "long": "The Shared Mem In CHOP receives CHOPs from a shared memory segment that is attached to a [[Shared Mem Out CHOP]] in another process or the same process.\t\t\t\n\t\t\t\nSee [[Using Shared Memory in TouchDesigner]], [[Write a Shared Memory CHOP]] and the [[Pipe In CHOP]].",
        "opCategories": ""
    },
    "sharedmemoutCHOP": {
        "label": "sharedmemoutCHOP",
        "members": [
            {
                "text": "Menu : Writes to a Local or a Global memory location.",
                "type": "Par",
                "name": "memtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Commercial",
        "opFamily": "CHOP",
        "short": "The Shared Mem Out CHOP sends CHOPs to a shared memory segment that is attached to a [[Shared Mem In CHOP]] in another process or the same process.",
        "opType": "sharedmemout",
        "opFilter": "True",
        "opClass": "sharedmemoutCHOP_Class",
        "opLabel": "Shared Mem Out",
        "long": "The Shared Mem Out TOP is only available in TouchDesigner Commercial and Pro.\t\t\n\t\t\t\nThe Shared Mem Out CHOP sends CHOPs to a shared memory segment that is attached to a [[Shared Mem In CHOP]] in another process or the same process.\t\t\t\n\t\t\t\nSee [[Using Shared Memory in TouchDesigner]], [[Write a Shared Memory CHOP]] and [[Pipe Out CHOP]].",
        "opCategories": ""
    },
    "shiftCHOP": {
        "label": "shiftCHOP",
        "members": [
            {
                "text": "Menu : The start or the end of the channels can be used as the reference position. The channels are shifted by altering the reference position.",
                "type": "Par",
                "name": "reference"
            },
            {
                "text": "Menu : Determines how the Start and End parameters are to be interpreted:",
                "type": "Par",
                "name": "relative"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Shift CHOP time-shifts a CHOP, changing the start and end of the CHOP's interval. However, the contents of the channels remain the same.",
        "opType": "shift",
        "opFilter": "True",
        "opClass": "shiftCHOP_Class",
        "opLabel": "Shift",
        "long": "The Shift CHOP time-shifts a CHOP, changing the start and end of the CHOP's interval. However, the contents of the channels remain the same.\t\t\n\t\t\t\nEach channel can be shifted a different amount by using the $C variable in the Scroll parameter or the Start/End parameters.\t\t\t\n\t\t\t\nAn optional second input, the Start/End Reference, is used to align the first input CHOP relative to another reference CHOP. This outputs the channels of the first CHOP only, and the shifts are based on the interval of the second CHOP. It is useful for making several CHOPs match up to the same time.",
        "opCategories": ""
    },
    "shuffleCHOP": {
        "label": "shuffleCHOP",
        "members": [
            {
                "text": "Menu : Chooses the operation \"shuffle\" performs:",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Shuffle CHOP reorganizes the samples in a set of channels.",
        "opType": "shuffle",
        "opFilter": "True",
        "opClass": "shuffleCHOP_Class",
        "opLabel": "Shuffle",
        "long": "The Shuffle CHOP reorganizes the samples in a set of channels.\t\t\n\t\t\t\nIt is useful for transforming data received by the [[SOP to CHOP]] and [[TOP to CHOP]]s into channels containing only one row or column. Data can be easily manipulated, then transformed back if needed.",
        "opCategories": ""
    },
    "slopeCHOP": {
        "label": "slopeCHOP",
        "members": [
            {
                "text": "Menu : The type of slope to calculate.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : The sample pairs used to calculate the slope.",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Slope CHOP calculates the slope (or \"derivative\" in math-speak) of the input channels.",
        "opType": "slope",
        "opFilter": "True",
        "opClass": "slopeCHOP_Class",
        "opLabel": "Slope",
        "long": "The Slope CHOP calculates the slope (or \"derivative\" in math-speak) of the input channels.\t\t\n\t\t\t\nIf the input CHOP represents position, the slope can be interpreted as speed. By default, the Slope CHOP converts position to speed.\t\t\t\n\t\t\t\nIn mathematical terms, the slope is the first derivative of the channel curve. The second and third derivatives can also be calculated. The second derivative can be interpreted as acceleration (and the third derivative could be interpreted as the rate of change in acceleration).\t\t\t\n\t\t\t\nThis CHOP can be used in conjunction with the [[Speed CHOP]] to manipulate speed or acceleration directly. You can calculate the speed or acceleration of a moving object with a Slope CHOP and manipulate it with other CHOPs. Then you can convert the new speed or acceleration curve back to position data with a Speed CHOP. You may need to adjust the starting position, since the Slope CHOP removes this information. This can be done with the use of the Constant parameters in the Speed CHOP.\t\t\t\n\t\t\t\nThe Units option causes the output to be expressed as a change in value per sample, value per frame, or value per second.",
        "opCategories": ""
    },
    "soptoCHOP": {
        "label": "soptoCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The SOP to CHOP uses a [[Geometry COMP|geometry object]] to choose a [[SOP]] from which the channels will be created.",
        "opType": "sopto",
        "opFilter": "False",
        "opClass": "soptoCHOP_Class",
        "opLabel": "SOP to",
        "long": "The SOP to CHOP uses a [[Geometry COMP|geometry object]] to choose a [[SOP]] from which the channels will be created. The channels are created from the point attributes of a SOP, such as the X, Y and Z of the point position.\t\t\n\t\t\t\nFrom the SOP you can select a subset of the points using Point Groups. The set of attributes that are converted to channels are chosen using the names of the attributes seen on the Info popup of SOP tiles (middle mouse click on a SOP in a SOP network pane).\t\t\t\n\t\t\t\nFor data going the opposite direction, see the [[CHOP to SOP|Channel SOP]].\t\t\t\n\t\t\t\n'''Note:''' This CHOP works in tandem with the [[CHOP to SOP|Channel SOP]]. Point data is modified in CHOPs as regular channel data (samples) and then fed back to geometry as point attributes through the Channel SOP.",
        "opCategories": ""
    },
    "sortCHOP": {
        "label": "sortCHOP",
        "members": [
            {
                "text": "Menu : There are three different sorting methods. CHOP samples can be reordered by increasing values, decreasing values or in random order.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : Specify if the channels to be sorted will be specified by index or name.",
                "type": "Par",
                "name": "select"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Sort CHOP re-orders the inputs channels samples by value or by random.",
        "opType": "sort",
        "opFilter": "True",
        "opClass": "sortCHOP_Class",
        "opLabel": "Sort",
        "long": "The Sort CHOP re-orders the inputs channels samples by value or by random. Specifying a channel to be sorted will reorder all channels samples according to the new order. This node does not change the order of the channels relative to each other. To sort the channels relative to each other use a [[Reorder CHOP]].\n\t\t\t\nAdditionally an index channel can be created which holds the former sample index before sorting.",
        "opCategories": ""
    },
    "speedCHOP": {
        "label": "speedCHOP",
        "members": [
            {
                "text": "Menu : Determines the order of the integral to use. If the input is a velocity, a First Order integral will return the position. If the input is an acceleration, a Second Order integral will return the position, and a First Order integral will return the velocity.",
                "type": "Par",
                "name": "order"
            },
            {
                "text": "Menu : Select limit options such as loop, clamp, or zigzag from the menu. The value will remain in the range from Min to less than Max.",
                "type": "Par",
                "name": "limittype"
            },
            {
                "text": "Menu : This menu determines how the Reset input triggers a reset of the channel(s).",
                "type": "Par",
                "name": "resetcondition"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Speed CHOP converts speed (units per second) to distance (units) over a time range.",
        "opType": "speed",
        "opFilter": "True",
        "opClass": "speedCHOP_Class",
        "opLabel": "Speed",
        "long": "The Speed CHOP converts speed (units per second) to distance (units) over a time range. More generally, you give it a rate (the CHOP input) and it outputs a cumulative value. For example, the Speed CHOP converts rotation rate (rotations per second) into the number of rotation turns. ( Math-heads recognize this as an 'integral', which calculates the area under a curve. The curve is the incoming channel values over a time range, the output is the area.)\t\t\n\t\t\t\nIf you send a Constant CHOP channel that has value 1 into the Speed CHOP, then the Speed CHOP output will increase by 1 every second. If you feed it -2, it will decrease by 2 every second, and if you feed it 0, the output will not change. Use a Trail CHOP to see its results. You can reset the Speed CHOP to 0 by pressing the Reset parameter, or by sending in a channel (whose value is greater than 0) into the second input.\t\t\t\n\t\t\t\nThe first input contains the channels to be 'integrated'. By default, the Speed CHOP is time-sliced, so it keeps adding/subtracting to the output each frame it cooks. If you turn off its Time Slice parameter and send it a CHOP with a fixed frame range (like a default Noise CHOP), you can see the cumulative value starting from 0.\t\t\t\n\t\t\t\nThe output is calculated by adding the input's channel values for every sample, divided by the [[CHOP#Parts_of_a_CHOP|samples per second]] of the Speed CHOP (typically 60), starting with the sample at the Start index. Negative input values reduce the output, positive values increase it. The cumulative values are put in the output channels.\t\t\t\n\t\t\t\nWhen the CHOP is reset, its output can be set to any value via the <span class=\"tipTextCHOP\">Reset Value</span> parameter.\t\t\t\n\t\t\t\nWhen the second input is used to reset the output, where the second input is greater than 0, the area is reset and held to the reset value. For example, a [[Wave CHOP]] (which is negative half the time) when passed into the second input causes the output to be reset for half a cycle.\t\t\t\n\t\t\t\nSee also: [[Lookup CHOP]], [[Timer CHOP]], [[Count CHOP]], [[Event CHOP]]",
        "opCategories": ""
    },
    "spliceCHOP": {
        "label": "spliceCHOP",
        "members": [
            {
                "text": "Menu : Specify which direction the Start and Trim parameters below work.",
                "type": "Par",
                "name": "direction"
            },
            {
                "text": "Menu : Gives options for how to set the trim length.",
                "type": "Par",
                "name": "trimmethod"
            },
            {
                "text": "Menu : Handles how the 2nd input is spliced into the channel.",
                "type": "Par",
                "name": "insertmethod"
            },
            {
                "text": "Menu : Choose interpolation method for stretched insert channel.",
                "type": "Par",
                "name": "insertinterp"
            },
            {
                "text": "Menu : Match channels between inputs by name or number.",
                "type": "Par",
                "name": "match"
            },
            {
                "text": "Menu : Choose interpolation method for any channels that are unmatched using \"Match Channels\".",
                "type": "Par",
                "name": "unmatchedinterp"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opFamily": "CHOP",
        "short": "The Splice CHOP inserts CHOP channels connected to the second input into the channels of the first input.",
        "opType": "splice",
        "opFilter": "True",
        "opClass": "spliceCHOP_Class",
        "opLabel": "Splice",
        "long": "The Splice CHOP inserts CHOP channels connected to the second input into the channels of the first input. You can specify the start sample and length of where to remove samples.\t\t\n\t\t\t\nThen the inserted data from the second input can be stretched in various ways, then spliced into the trimmed point in the channels.\t\t\t\n\t\t\t\nYou can match by channel number or channel name. Un-matched channels will have the samples in their gaps interpolate in one of three selectable ways.\t\t\t\n\t\t\t\nTo extract a sample from a CHOP, modify it and replace it at its original index, connect a Splice CHOP to the original, set Start and Trim Length where you want, turn on Output Trimmed Section, modify the result, then send that as second input to another Splice CHOP with first input from the the original CHOP, and with Start set to <syntaxhighlight lang=python inline>op('splice1').par.start</syntaxhighlight> and Trim Length set to <syntaxhighlight lang=python inline>op('splice1').par.trimlength</syntaxhighlight>.\t\t\t\n\t\t\t\nThe Splice CHOP can also smooth a section of a CHOP: Set the Start and Trim Length to that section. Give it a second input with no matching channels. Set Insert Method to Set to Trim Length, and adjust the Insert Interpolate menu.\t\t\t\n\t\t\t\nCheck [[OP Snippets]] for these and other tricks.\t\t\t\n\t\t\t\nSee also [[Delete CHOP]], [[Trim CHOP]], [[Select CHOP]]",
        "opCategories": ""
    },
    "springCHOP": {
        "label": "springCHOP",
        "members": [
            {
                "text": "Menu : Determines whether the input channel(s) represents a position or a force.",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Spring",
        "short": "The Spring CHOP creates vibrations influenced by the input channels, as if a mass was attached to a spring.",
        "opFilter": "True",
        "long": "The Spring CHOP creates vibrations influenced by the input channels, as if a mass was attached to a spring.\t\t\n\t\t\t\nIt acts as if, for every channel, there is a mass at the end of a spring, affected by a distance from the actual position (the output of the channel at the previous frame) to the desired position (the input channel at the current frame). When the distance (output - input) is zero, there is no force and therefore no movement.\t\t\t\n\t\t\t\nAlternately, when Input Effect is force, the input is used as a force on the spring/mass, and the CHOP reacts to this force plus the force of the spring/mass. In this case, the mass would always stabilize at value 0 if the input is a force of 0.\t\t\t\n\t\t\t\nThe damping acts to make the spring system lose energy, so that higher damping makes everything come to rest sooner.\t\t\t\n\t\t\t\nIts behavior is best understood by feeding it a chop that steps from one constant value to another in sequence, then playing with the constants.",
        "opType": "spring",
        "opClass": "springCHOP_Class",
        "opCategories": ""
    },
    "stretchCHOP": {
        "label": "stretchCHOP",
        "members": [
            {
                "text": "Menu : The interpolation method to use when resampling.",
                "type": "Par",
                "name": "interp"
            },
            {
                "text": "Menu : Determines how Start/End parameters are interpreted:",
                "type": "Par",
                "name": "relative"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Stretch",
        "short": "The Stretch CHOP preserves the shape of channels and the sampling rate, but resamples the channels into a new interval.",
        "opFilter": "True",
        "long": "The Stretch CHOP preserves the shape of channels and the sampling rate, but resamples the channels into a new interval. All data in the range is stretched or compressed to the new start and end positions.\t\t\n\t\t\t\nA Reverse Interval parameter reverses the order of the samples of each channel.",
        "opType": "stretch",
        "opClass": "stretchCHOP_Class",
        "opCategories": ""
    },
    "stypeCHOP": {
        "label": "stypeCHOP",
        "members": [
            {
                "text": "Menu : The network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The Stype CHOP reads camera tracking information sent from a [[Stype]] ('''RedSpy''') device using the Stype HF protocol. The CHOP outputs channels that can be used to control a virtual camera and implement lens distortion via the [[Stype TOP]].\t\t\n\nThe channels exported by the Stype CHOP are:\n:''connected'' - 1 or 0, indicating whether the CHOP has received valid Stype messages within the last 500ms\n:''recording'' - 1 or 0, indicating the recording status on the Stype Kit (see Stype protocol for more information)\n:''focus_distance'' - 1 or 0, indicating how the focus field is used (see Stype protocol for more information)\n:''hours, minutes, seconds, frames'' - timecode, may be zero if time information is not present\n:''tx, ty, tz'' - camera position, can be connected to the [[Camera COMP]] Translate parameters\n:''rx, ry, rz'' - camera rotation, can be connected to the [[Camera COMP]] Rotate parameters\n:''fov'' - camera field of view, can be connected to the [[Camera COMP]] FOV Angle parameter\n:''padded_fov'' - field of view expanded by the padding parameter, can be used in [[Camera COMP]] FOV Angle parameter \n:''aspect'' - aspect ratio of the camera\n:''focus'' - camera focus from 0 (closest) to 1 (infinite), can be used to simulate depth of field\n:''zoom'' - camera zoom from 0 (wide) to 1 (tele)\n:''centerx, centery'' - offset of the camera sensor in mm, used by the [[Stype TOP]] for calculating lens correction\n:''k1, k2'' - radial lens distortion parameters, used by the [[Stype TOP]] for calculating lens correction\n:''pawidth, paheight'' - size of the sensor in mm, used by the [[Stype TOP]] for calculating lens correction\n\nFor more information or to diagnose connection problems, an [[Info CHOP]] can be connected to see if any packets have been dropped or skipped.\n\n'''NOTE:''' This CHOP works with [https://www.stype.tv Stype] hardware.\t\nFor more information refer to the [[Stype]] article.\n\nSee also [[Stype TOP]].",
        "opLicense": "Pro",
        "opClass": "stypeCHOP_Class",
        "opLabel": "Stype",
        "opFamily": "CHOP",
        "opType": "stype",
        "short": "The Stype CHOP reads camera tracking information sent from a Stype device.",
        "opCategories": ""
    },
    "stypeoutCHOP": {
        "label": "stypeoutCHOP",
        "members": [
            {
                "text": "Menu : Selects the network protocol to use. Refer to the Network Protocols article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Determine how the packet number field is generated. The packet number generally increments by 1 each frame and loops from 255 to 0.",
                "type": "Par",
                "name": "packetnumber"
            },
            {
                "text": "Menu : Selects the network protocol to use. Refer to the Network Protocols article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Determine how the packet number field is generated. The packet number generally increments by 1 each frame and loops from 255 to 0.",
                "type": "Par",
                "name": "packetnumber"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "stypeoutCHOP",
        "opLabel": "Stype Out",
        "opClass": "stypeoutCHOP_Class",
        "opFilter": "True",
        "opLicense": "Pro",
        "opCategories": "",
        "short": "",
        "long": "The Stype Out CHOP sends camera tracking information, including position, orientation and lens information, to an external device or program over the network using the Stype HF protocol. This can be used to emulate a physical [https://www.stype.tv Stype] camera or to send data to another program/device that can process Stype tracking data. Data packets are sent out once per frame based on the current data in the CHOP channels. If one of the expected channels is not found in the input, then a default value will be sent.\n    \nThe channels used by the Stype Out CHOP are:\n:''recording'' - 1 or 0, indicating the recording status on the Stype Kit (see Stype protocol for more information)\n:''focus_distance'' - 1 or 0, indicating how the focus field is used (see Stype protocol for more information)\n:''packet_number'' - a looping number from 0-255 indicating the packet number. By default the number is incremented each frame, but can also be generated manually (see Stype protocol for more information)\n:''hours, minutes, seconds, frames'' - timecode, may be zero if time information is not present\n:''tx, ty, tz'' - camera position, can be connected to the [[Camera COMP]] Translate parameters\n:''rx, ry, rz'' - camera rotation, can be connected to the [[Camera COMP]] Rotate parameters\n:''fov'' - camera field of view, can be connected to the [[Camera COMP]] FOV Angle parameter\n:''padded_fov'' - field of view expanded by the padding parameter, can be used in [[Camera COMP]] FOV Angle parameter \n:''aspect'' - aspect ratio of the camera\n:''focus'' - camera focus from 0 (closest) to 1 (infinite), can be used to simulate depth of field\n:''zoom'' - camera zoom from 0 (wide) to 1 (tele)\n:''centerx, centery'' - offset of the camera sensor in mm, used by the [[Stype TOP]] for calculating lens correction\n:''k1, k2'' - radial lens distortion parameters, used by the [[Stype TOP]] for calculating lens correction\n:''pawidth, paheight'' - size of the sensor in mm, used by the [[Stype TOP]] for calculating lens correction"
    },
    "switchCHOP": {
        "label": "switchCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Switch",
        "short": "The Switch CHOP allows you to control the flow of channels through a CHOPnet.",
        "opFilter": "True",
        "long": "The Switch CHOP allows you to control the flow of channels through a CHOPnet. It selects one of the input CHOPs by index and copies it exactly. This is useful for selecting one of several \"gestures\" or actions. Only one input chop can be selected at a time.\t\n\t\t\nInputs are indexed starting at 0, so that the first input is 0, the second is 1, and so on.\t\t\n\t\t\nIf the First Input Is Index parameter is enabled, the first input is used as the \"switch\" and the remaining inputs will be selection choices. In this case, the second input will be indexed as 0, the third as 1, the fourth as 2, and so on (the Switch input chop is not indexed). The index value is determined by evaluating the first channel in the first input at the current frame. Only integer indices are used; fractional indices will be rounded down to the closest integer.\t\t\n\t\t\nIf the index is less than 0, then the index will be interpreted to be 0. If the index is greater than the number of input chops, the last input chop is selected.\t\t\n\t\t\nIf you wish to blend between inputs use the [[Cross CHOP]] or the [[Blend CHOP]].",
        "opType": "switch",
        "opClass": "switchCHOP_Class",
        "opCategories": ""
    },
    "syncinCHOP": {
        "label": "syncinCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Pro",
        "opLabel": "Sync In",
        "short": "The [[Sync In CHOP]] and [[Sync Out CHOP]] are used to keep timelines in two or more TouchDesigner processes within a single frame of each other.",
        "opFilter": "False",
        "long": "The [[Sync In CHOP]] and [[Sync Out CHOP]] are used to keep timelines in two or more TouchDesigner processes within a single frame of each other. One process will contain a [[Sync Out CHOP]] while one or more other processes contain [[Sync In CHOP]]s. The processes with [[Sync In CHOP]]s should have their '''Realtime flag checked off''', as their frame rates will be determined by the [[Sync Out CHOP]].  Also note, all monitors (including all clients and server) should be set to the '''same rate'''.  Note that unplugging or re-adding monitors may sometime change previously configured settings.\n\n\nThe CHOPs synchronize by pausing their own timeline until all Sync In/Out CHOPs have cooked. The [[Sync Out CHOP]] will be ahead of the [[Sync In CHOP]]s. If any CHOPs fail to communicate, the others will timeout, causing all processes to run slowly. \n\nClient machines may come online at any point, or be switched off as desired, as the [[Sync Out CHOP]] will adjust accordingly, either timing out, temporarily or permanently banning individual clients as specified.\n\nIn addition any extra CHOP channels sent through the [[Sync Out CHOP]] is received by the [[Sync In CHOP]]s. \n\t\t\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''\n\t\t\nAn [[Info DAT]], pointing to the [[Sync Out CHOP]], provides a detailed list of all clients:\t\t\n\t\t\nThe columns are:\t\t\n* <code>pid</code>: process id of the client\t\t\n* <code>address</code>: ip and port number\t\t\n* <code>machine_name</code>: client machine name\t\t\n* <code>filename</code>: name of the <code>.toe</code> file the client resides in\t\t\n* <code>op_path</code>: full operator path to the client\t\t\n* <code>include</code>:  when 1, the Sync Out CHOPs waits for a reply, when 0, it is ignored.\t\t\n* <code>timeout_total</code>:  The total number of times the Sync Out CHOP stalled waiting for this client\t\t\n* <code>timeout_consecutive</code>:  The running number of times the Sync Out CHOP stalled waiting for this client.\t\t\n* <code>steady_total</code>: The total number of times the Sync Out CHOP received a reply in time.\t\t\n* <code>steady_consecutive</code>: The running number of times the Sync Out CHOP received a reply in time:\t\t\n* <code>reply</code>:  The last reply from the client, all clients should have the same increasing value.\t\t\n\t\t\n<br>\t\t\n\t\t\nSimilarly, an [[Info CHOP]] will reveal further information: [[#Info_CHOP_Channels|Info CHOP Channels]]\t\n\t\t\n==Intermittent Connections==\t\t\nWhenever a client replies, it is immediately assumed reliable, and waited upon, by the [[Sync Out CHOP]] each frame thereafter.\t\t\nWhen a client times-out a number of times in a row, however, it is continuously ignored by the [[Sync Out CHOP]], until it replies on time again. \t\t\nThis also applies to clients that have stopped communicating altogether.\t\t\nThe number of consecutive timeouts is controlled by the <code>Client Timeouts (consecutive)</code> parameter and is reflected by the <code>timeout_consecutive</code> [[Info DAT]] column.\t\t\n\t\t\n==Fixing Dropped frames on Client==\t        \nIf a particular client is dropping frames, inspect the Sync Out CHOP on the server side with an info DAT.  Look at the column for timeout_consecutive. As well take note of the info chop channel for the sync in CHOP called sync_incompletes.  If one or both of these attributes are increasing, try adjusting the TimeOut parameter on the sync CHOP.  Increasing this value has been known to remedy this issue.\n\n\n==Banning==\t\t\nIf a client produces unreliable communication, sometimes steady, sometimes timing out, then it can be permanently ignored by enabling <code>Ban Clients</code> and setting the <code>Total Timeouts</code> accordingly.  Once a client timeouts a certain number of times, its Info DAT <code>include</code> column reports <code>banned</code> and it will always be ignored, even if it starts responding in time again.\t\t\n\t\t\n==Resetting==\t\t\nWhenever the Sync Out CHOP first starts any and all clients are accepted, and nothing is banned.  Pressing <code>Clear Stats</code> in the [[Sync Out CHOP]] also returns to this state, clearing all banned lists, and totals, even in the remote client [[Info CHOP|Info CHOPs]].\t\t\n<br>\t\t\n<br>\t\t\nSee also [[Syncing Multiple Computers]] and [[Hardware Frame Lock]].",
        "opType": "syncin",
        "opClass": "syncinCHOP_Class",
        "opCategories": ""
    },
    "syncoutCHOP": {
        "label": "syncoutCHOP",
        "members": [
            {
                "text": "Menu : Choose between automatically or manually selecting local port to use.",
                "type": "Par",
                "name": "localportmode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Pro",
        "opLabel": "Sync Out",
        "short": "The [[Sync In CHOP]] and [[Sync Out CHOP]] are used to keep timelines in two or more TouchDesigner processes within a single frame of each other. One process will contain a [[Sync Out CHOP]] while one or more other processes contain [[Sync In CHOP]]s.",
        "opFilter": "True",
        "long": "The [[Sync In CHOP]] and [[Sync Out CHOP]] are used to keep timelines in two or more TouchDesigner processes within a single frame of each other. One process will contain a [[Sync Out CHOP]] while one or more other processes contain [[Sync In CHOP]]s. The processes with [[Sync In CHOP]]s should have their '''Realtime flag checked off''', as their frame rates will be determined by the [[Sync Out CHOP]]. Also note, all monitors (including all clients and server) should be set to the '''same rate'''.  Note that unplugging or re-adding monitors may sometime change previously configured settings.\n\nThe CHOPs synchronize by pausing their own timeline until all Sync In/Out CHOPs have cooked. The [[Sync Out CHOP]] will be ahead of the [[Sync In CHOP]]s. If any CHOPs fail to communicate, the others will timeout, causing all processes to run slowly. \n\nClient machines may come online at any point, or be switched off as desired, as the [[Sync Out CHOP]] will adjust accordingly, either timing out, temporarily or permanently banning individual clients as specified.\n\nIn addition any extra CHOP channels sent through the [[Sync Out CHOP]] is received by the [[Sync In CHOP]]s. \n\t\t\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''\n\nAn [[Info DAT]], pointing to the [[Sync Out CHOP]], provides a detailed list of all clients:\t\t\n\n\nThe columns are:\t\t\n* <code>pid</code>: process id of the client\t\t\n* <code>address</code>: ip and port number\t\t\n* <code>machine_name</code>: client machine name\t\t\n* <code>filename</code>: name of the <code>.toe</code> file the client resides in\t\t\n* <code>op_path</code>: full operator path to the client\t\t\n* <code>include</code>:  when 1, the Sync Out CHOPs waits for a reply, when 0, it is ignored.\t\t\n* <code>timeout_total</code>:  The total number of times the Sync Out CHOP stalled waiting for this client\t\t\n* <code>timeout_consecutive</code>:  The running number of times the Sync Out CHOP stalled waiting for this client.\t\t\n* <code>steady_total</code>: The total number of times the Sync Out CHOP received a reply in time.\t\t\n* <code>steady_consecutive</code>: The running number of times the Sync Out CHOP received a reply in time:\t\t\n* <code>reply</code>:  The last reply from the client, all clients should have the same increasing value.\t\t\t\t\n<br>\nSimilarly, an [[Info CHOP]] will reveal further information: [[#Info_CHOP_Channels|Info CHOP Channels]]\t\n\n==Intermittent Connections==\t\t\nWhenever a client replies, it is immediately assumed reliable, and waited upon, by the [[Sync Out CHOP]] each frame thereafter.\t\t\nWhen a client times-out a number of times in a row, however, it is continuously ignored by the [[Sync Out CHOP]], until it replies on time again. \t\t\nThis also applies to clients that have stopped communicating altogether.\t\t\nThe number of consecutive timeouts is controlled by the <code>Client Timeouts (consecutive)</code> parameter and is reflected by the <code>timeout_consecutive</code> [[Info DAT]] column.\t\n==Banning==\t\t\nIf a client produces unreliable communication, sometimes steady, sometimes timing out, then it can be permanently ignored by enabling <code>Ban Clients</code> and setting the <code>Total Timeouts</code> accordingly. Once a client timeouts a certain number of times, its Info DAT <code>include</code> column reports <code>banned</code> and it will always be ignored, even if it starts responding in time again.\t\t\t\n==Resetting==\t\t\nWhenever the Sync Out CHOP first starts any and all clients are accepted, and nothing is banned.  Pressing <code>Clear Stats</code> in the [[Sync Out CHOP]] also returns to this state, clearing all banned lists, and totals, even in the remote client [[Info CHOP|Info CHOPs]].\t\t\n\t\nSee also [[Syncing Multiple Computers]] and [[Hardware Frame Lock]].",
        "opType": "syncout",
        "opClass": "syncoutCHOP_Class",
        "opCategories": ""
    },
    "tabletCHOP": {
        "label": "tabletCHOP",
        "members": [
            {
                "text": "Menu : While '''On''', the pen movement will be output from and the CHOP will cook every frame. When set to '''Off''' it will not cook and the values will not be updated. '''While Playing''' will capture pen events only when the [[Timeline]] is playing forward.",
                "type": "Par",
                "name": "active"
            },
            {
                "text": "Menu : The left extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Tablet",
        "short": "The Tablet CHOP gets the [http://www.wacom.com Wacom] tablet X and Y values, and also gets pen tip pressure, X tilt and Y tilt, and the various pen buttons.",
        "opFilter": "False",
        "long": "The Tablet CHOP gets the [http://www.wacom.com Wacom] tablet X and Y values, and also gets pen tip pressure, X tilt and Y tilt, and the various pen buttons. Two pens can be used to output one set of channels for each pen. The Tablet CHOP will initialize/install when the CHOP is created. \t\t\n\t\t\t\nIt supports the simultaneous use of two devices (Stylus Pen, Airbrush or 4D Mouse) on the same tablet, with the \"1st Pen\" folder controlling the parameters of the primary device (the first one activated), and the \"2nd Pen\" folder controlling the parameters of the other device.\t\t\t\n\t\t\t\nPut a channel name in a parameter to create that channel.\t\t\t\n\t\t\t\nThe range of all axes is -1.0 to 1.0. The values of the Button parameters are 0 for Button Up and 1 for Button Down. All axis and button channels are active when the Active state is On.\t\t\t\n\t\t\t\nIn most parameter fields of this CHOP, if you put a channel name in the parameter, it will attempt to read that parameter and output the channel. Otherwise no channel is created.\t\t\t\n\t\t\t\nFor advice on setting up the tablet and tuning the sensitivity of the pen and tablet, please read the [[Wacom_Intuos_Tablet|Wacom Intuos]] article.",
        "opType": "tablet",
        "opClass": "tabletCHOP_Class",
        "opCategories": ""
    },
    "timesliceCHOP": {
        "label": "timesliceCHOP",
        "members": [
            {
                "text": "Menu : How to sample the input CHOP to create the output time slice. If the input CHOP is not time sliced and lies outside the current time slice region, its extend regions will be sampled.",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Time Slice",
        "short": "The Time Slice CHOP outputs a time slice of samples.",
        "opFilter": "True",
        "long": "The Time Slice CHOP outputs a time slice of samples. It is used to generate smooth in-betweens when TouchDesigner cannot cook/draw fast enough and keep up with the animation's frames per second. When you send it to a [[Record CHOP]] or [[Gesture CHOP]], you will see the channels recorded and playing back more smoothly.\t\t\n\t\t\t\nThe number and names of channels does not change between input and output, but the output's frame range is a time slice: it goes from the previous frame that TouchDesigner cooked plus one, to the current frame.\t\t\t\n\t\t\t\nFor example, assume the TouchDesigner frames per second is four frames to remain realtime. Say the input to the Time Slice CHOP is a slider which only gets sampled when TouchDesigner draws. We will have slider values for frames 231 and 235, but there are no slider values for frames 232, 233 and 234, the current frame is 235, and the previous frame that TouchDesigner cooked and drew was frame 231. It had to skip.\t\t\t\n\t\t\t\nWhen the Method is set to Linear in this example, the Time Slice CHOP will output a \"time slice\" which is a 4-sample CHOP for frames 232 to 235, and the values at frames 232 to 234 will be the values interpolated between the slider at frames 231 and 235.\t\t\t\n\t\t\t\nTherefore any CHOPs after the Time Slice CHOP, like Gesture, Record or [[Lag CHOP]] will get smooth data going into it, even though TouchDesigner isn't cooking every frame.",
        "opType": "timeslice",
        "opClass": "timesliceCHOP_Class",
        "opCategories": ""
    },
    "timecodeCHOP": {
        "label": "timecodeCHOP",
        "members": [
            {
                "text": "Menu : The source used for generating the timecode",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : Specify how to calculate [https://en.wikipedia.org/wiki/SMPTE_timecode#Drop-frame_timecode drop-frames]. Drop frames are used when the FPS is fractional. FPS cannot increment a fractional amount per frame so FPS is rounded to the next whole number and the accumulation of error is accommodated for by adding drop frames.",
                "type": "Par",
                "name": "dropframe"
            },
            {
                "text": "Menu : The index value units.",
                "type": "Par",
                "name": "indexunit"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "timecodeCHOP",
        "opLabel": "Timecode",
        "opClass": "timecodeCHOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "",
        "long": "The Timecode CHOP generates timecode data, supporting a variety of different modes for doing so: including from a timecode string, sequentially, and more. The timecode data is output as both channel data in the CHOP, and as a [[Timecode_Class|timecode object]] via its [[TimecodeCHOP_Class#timecode|timecode member]] in Python.\n    \nThe timecode can follow the SMPTE standard (ie. non-negative, loops at 24 hours), or a more general format (ie. negative timecode allowed, loops at 100 hours).\n    \nOptionally, an input with negative, hour, minute, second, or frame channels can be provided that is added to the Timecode CHOP's output.\n\nSee also: [[Timecode]], [[Timecode Class]]."
    },
    "timelineCHOP": {
        "label": "timelineCHOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Timeline",
        "short": "The Timeline CHOP outputs time-based CHOP channels for a specific component.",
        "opFilter": "False",
        "long": "The Timeline CHOP outputs time-based CHOP channels for a specific component. The time channels are defined by a [[Time COMP|Time Component]] whose [[Network Path|Path]] can be determined using the python expression <code>me.time</code>. When a '''Reference Node''' is specified, the time defined at that node is used.  When the Reference Node is not specified, then the time defined at the Timeline CHOP's location is used (ie. time defined at <code>me.time</code>).",
        "opType": "timeline",
        "opClass": "timelineCHOP_Class",
        "opCategories": ""
    },
    "timerCHOP": {
        "label": "timerCHOP",
        "members": [
            {
                "text": "Menu : '''Sequential''' (timeline-independent) or '''Locked to Timeline'''. In Locked to Timeline, non-deterministic features are disabled. '''External CHOP Channel''' lets you drive the master time (<code>.masterSeconds</code> etc) using a CHOP channel defined by the parameters on the External page.",
                "type": "Par",
                "name": "timecontrol"
            },
            {
                "text": "Menu : Describes how the length is defined.",
                "type": "Par",
                "name": "lengthtype"
            },
            {
                "text": "Menu : Choose between using Samples, Frames, or Seconds as the units for this parameter.",
                "type": "Par",
                "name": "lengthunits"
            },
            {
                "text": "Menu : Choose between using Samples, Frames, or Seconds as the units for this parameter.",
                "type": "Par",
                "name": "delayunits"
            },
            {
                "text": "Menu : Choose between using Samples, Frames, Seconds, Fraction(0-1) as the units for this parameter.",
                "type": "Par",
                "name": "cueunits"
            },
            {
                "text": "Menu : Choose between using Samples, Frames, or Seconds as the units for this parameter.",
                "type": "Par",
                "name": "notifyunits"
            },
            {
                "text": "Menu : Determines which action to take when the timer gets to the end, ie \"is done\" or finished. Note there is also a onDone callback that can be used for customizing behavior.",
                "type": "Par",
                "name": "ondone"
            },
            {
                "text": "Menu : If the Segment Method is '''Serial Timers''', the timers will be played back-to-back. If the Segment Method is '''Parallel Timers''', the timers can be played at the same time, and a set of channels will be output for each timer.",
                "type": "Par",
                "name": "segmethod"
            },
            {
                "text": "Menu : For the columns <code>delay</code>, <code>begin</code>, <code>length</code> and <code>cycleendalert</code>, you specify whether it\u2019s seconds, frames or samples with this menu.",
                "type": "Par",
                "name": "segunits"
            },
            {
                "text": "Menu : Describes how the end time is calculated.",
                "type": "Par",
                "name": "segsendtime"
            },
            {
                "text": "Menu : By default, custom channels step to their new value at the begin of the segment. This menu lets you interpolate to the new value linearly, or any combination of ease-in and ease-out.",
                "type": "Par",
                "name": "interpolation"
            },
            {
                "text": "Menu : Choose between using Samples, Frames, or Seconds as the units for this parameter.",
                "type": "Par",
                "name": "substartunits"
            },
            {
                "text": "Menu : Choose between using Samples, Frames, or Seconds as the units for this parameter.",
                "type": "Par",
                "name": "subendunits"
            },
            {
                "text": "Menu : Controls the behavior once the sub range end point is reached: Loop at End, or Pause at End.",
                "type": "Par",
                "name": "subendaction"
            },
            {
                "text": "Menu : Outputs the elapsed Seconds channel as <code>timer_seconds</code>, Frames outputs channel as <code>timer_frames</code>, or Samples outputs channel as <code>timer_samples</code>. Because this is elapsed time, <code>timer_frames</code> starts at 0, as do the others.",
                "type": "Par",
                "name": "outtimercount"
            },
            {
                "text": "Menu : Outputs the delay count in seconds, frames or samples.",
                "type": "Par",
                "name": "outdelaycount"
            },
            {
                "text": "Menu : Outputs channel <code>length</code>, starting with 0 for first segment ending at #segments at end.",
                "type": "Par",
                "name": "outlength"
            },
            {
                "text": "Menu : Outputs <code>cumulative_seconds</code>, <code>cumulative_frames</code> or <code>cumulative_samples</code>. It is a time count that adds up all the Timer Active times for all segments since Start: it is affected by \"Speed\", and counts up only while <code>timer_active</code> (Play) is on.   See the python member <code>.cumulativeSeconds</code>.",
                "type": "Par",
                "name": "outcumulativecount"
            },
            {
                "text": "Menu : Outputs <code>playing_seconds</code>, <code>playing_frames</code> or <code>playing_samples</code>. It is a time count that adds up all the Timer Active times for all segments since Start: it is not affected by \"Speed\", and counts up only while <code>timer_active</code> and <code>play</code> is on.  See the python member <code>.playingSeconds</code>.",
                "type": "Par",
                "name": "outplayingcount"
            },
            {
                "text": "Menu : Outputs the \"wall-clock\" time since Start occurred, no matter what are the delays, speeds, cycles or pre-mature clicking of Go To Segment End, etc. It stops counting when Done has been reached. <code>running_seconds</code>, <code>running_frames</code>, or <code>running_samples</code>. When CHOP is set to Parallel Timers, this will output a channel per segment plus one global running time channel.   See the python member <code>.runningSeconds</code>.",
                "type": "Par",
                "name": "outrunningcount"
            },
            {
                "text": "Menu : Outputs <code>master_seconds</code>, <code>master_frames</code> or <code>master_samples</code>. It is a time count that adds up all the Timer Active times for all segments since Start: it is affected by \"Speed\", and counts up only while <code>timer_active</code> and <code>play</code> is on. It also includes any delay times.   See the python member <code>.masterSeconds</code>.",
                "type": "Par",
                "name": "outmastercount"
            },
            {
                "text": "Menu : Choose between using Samples, Frames, or Seconds as the units for this parameter.",
                "type": "Par",
                "name": "extunits"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Timer",
        "short": "The Timer CHOP is an engine for running timed processes. It outputs channels such as timing fractions, counters, pulses and timer states, and it calls python functions (callbacks) when various timing events occur.",
        "opFilter": "False",
        "long": "The Timer CHOP is an engine for running timed processes. It outputs channels such as timing fractions, counters, pulses and timer states, and it calls python functions (callbacks) when various timing events occur.\t\t\n\t\t\t\nExamples using the Timer CHOP include triggering multiple timed cues, running playlists, timelines, state machines, and driving pre-animated animation components in 3D scenes. See Help -> Operator Snippets for numerous examples.\t\t\t\n\t\t\t\nYou set a timer to a number of seconds, frames or samples, and trigger it to start via the Start parameter or the second input CHOP. The Timer CHOP outputs in seconds, frames, samples, fraction and on-off states as it\u2019s counting, including a <code>done</code> channel that goes on when it is complete.  When it reaches certain states like end-of-cycles or when it\u2019s done, various python callbacks are called allowing you to customize its behavior.\t\t\t\n \t\t\t\nThe Timer CHOP gets triggered by events (via pulsing its parameters or driving its two inputs). It takes events in, counts time, changes state. Via its python callback functions, you can send events out to other nodes, set parameters, get/set values in DATs, CHOPs and storage, restart itself, or trigger other nodes. As such, it can operate as a state machine.\t\t\t\n\t\t\t\nIt has play/pause, plus a speed control to slow down or speed up the timer.\t\t\t\n \t\t\t\nIt can also cycle indefinitely and then can be signaled to end immediately or at the end of the current cycle.\t\t\t\n\t\t\t\nOne Timer CHOP can also have multiple timers within it. By attaching a Table DAT you can define one timer (segment) per row. In Serial Timers mode it allows for one time segment followed by another. In Parallel Timers mode, the timers all run in parallel, each with its own begin time and length, and its own set of output channels.\t\t\t\n\t\t\t\n[[image:Timer CHOP.2.png]]\t\t\t\n\t\t\t\nThe Timer CHOP can be Locked to Timeline in a deterministic way, or run more freely in Sequential Mode. When run independently from the timeline, you can jump ahead, break out of cycles, pause, <code>goTo()</code> exact position or timecode in the timer, and dynamically adjust the speed.\n\nThe Timer CHOPs can be chained together, so that when one ends, the next can begin. They just need to all be Initialized together, where the <code>ready_pulse</code> channel of one Timer CHOP is exported to the Initialize parameter of the next Timer CHOP. Then they can be run in sequence, where the output of one Timer CHOP\u2019s <code>done_pulse</code> channel is wired to the Start input (or exported to the Start parameter) of the next Timer CHOP.  You start the chain of timers by starting the first Timer CHOP. By using some Timer CHOPs to loop awaiting input or response, or by adding logic to decide which CHOP to start next, state machines can be implemented.\t\t\t\n\nAttach an Info DAT to see the timecodes, or use the <code>.timecode</code> members. Custom text strings can be placed in the Info DAT for each segment, and custom animated channels can be created.\t\t\t\n\t\t\t\nTo make the entire CHOP loop after the last segment, set the On Done menu to Re-Start.\t\n\n'''Recommended''': the '''OP Snippets for Timer CHOP'''.  See the channel descriptions in [[Initialize Start]].\t\t\n\t\t\t\n===Callbacks===\nThe callbacks are called at different moments during the timer progression.\n\n<code>onInitialize()</code> gets called when you pulse the Initialize parameter. Here you can prepare any part of your setup prior to starting. At the end of Initialize the timer goes into a \"ready\" state.\n\n<code>onStart()</code> gets called on the frame that the Start parameter is pulsed. The timer then goes into a \"running\" state.\n\n<code>onTimerActive()</code> gets called every frame that the timer is running and there is no Delay or Play is off.\n\n<code>onCycleStart()</code> gets called if the timer is set to cycle via the Cycle parameters.\n\t\t\t\nBefore a cycle or segment ends, an <code>onCycleEndAlert()</code> callback based on the Cycle End Alert parameter can be called to allow you to prepare for the next cycle, segment or Timer CHOP.\n\n<code>onSegmentEnter()</code> and <code>onSegmentExit()</code> get called if the timer is being driven by a Segments DAT which acts like several timers in one.  The argument <code>segment</code> in these callbacks is actually an object with useful members including any custom columns you have in your segment table: In <code>onSegmentEnter()</code>, put the code <code>print(help(segment))</code>\n\n<code>onDone()</code> gets called when the timer reaches its finished state.\n\nYou can initialize at a specific time by using <code>.masterSeconds</code> in <code>onInitialize()</code>.\n\t\t\t\n'''See also''': [[Trigger CHOP]], [[Event CHOP]], [[Speed CHOP]], [[Count CHOP]], [[Beat CHOP]], [[Event CHOP]], [[Clock CHOP]], [[Delay CHOP]], [[CHOP Execute DAT]], [[LFO CHOP]]. \t\ntime measurements\n{{{!}} class=\"wikitable\"\n{{!}}+ Time Measurements and what affects them\n{{!}}-\n! Name !! Speed !! Play !! Cycles !! Go To and Cueing !! Subrange !! Delay Between Segments\n{{!}}-\n{{!}} Cumulative Time Count {{!}}{{!}} slows if speed<1 {{!}}{{!}} pauses when off {{!}}{{!}} jumps back {{!}}{{!}} jumps {{!}}{{!}} jumps {{!}}{{!}} pauses\n{{!}}-\n{{!}} Playing Time Count {{!}}{{!}} unaffected {{!}}{{!}} pauses when off {{!}}{{!}} keeps counting {{!}}{{!}} keeps counting {{!}}{{!}} keeps counting {{!}}{{!}} keeps counting\n{{!}}-\n{{!}} Running Time Count {{!}}{{!}} unaffected {{!}}{{!}} unaffected {{!}}{{!}} keeps counting {{!}}{{!}} keeps counting {{!}}{{!}} keeps counting {{!}}{{!}} keeps counting\n{{!}}-\n{{!}} Master Time Count {{!}}{{!}} slows if speed<1 {{!}}{{!}} pauses when off {{!}}{{!}} jumps back {{!}}{{!}} jumps {{!}}{{!}} jumps {{!}}{{!}} keeps counting\n{{!}}-\n{{!}} Segment + Fraction {{!}}{{!}} 0 to 1 per-segment {{!}}{{!}} pauses when off {{!}}{{!}} jumps back {{!}}{{!}} jumps {{!}}{{!}} jumps {{!}}{{!}} pauses\n{{!}}}",
        "opType": "timer",
        "opClass": "timerCHOP_Class",
        "opCategories": ""
    },
    "toptoCHOP": {
        "label": "toptoCHOP",
        "members": [
            {
                "text": "Menu : Gives the option for a delayed data download from the GPU, which is much faster and does not stall the render.",
                "type": "Par",
                "name": "downloadtype"
            },
            {
                "text": "Menu : When enabled, only pixels that have a non-zero value in the selected active channel will be added to the CHOP channel.",
                "type": "Par",
                "name": "activechannel"
            },
            {
                "text": "Menu : Scales the output to lie in the range 0-1, 0-255 or 0-65535.",
                "type": "Par",
                "name": "rgbaunit"
            },
            {
                "text": "Menu : Specifies what to extract from the image.",
                "type": "Par",
                "name": "crop"
            },
            {
                "text": "Menu : Specifies the units for the following 4 parameters. The parameters can use the local variables <code>$NR</code> and <code>$NC</code> for the number of rows and columns.",
                "type": "Par",
                "name": "uvunits"
            },
            {
                "text": "Menu : Determines the interpolation method when UV sampling with an input CHOP.",
                "type": "Par",
                "name": "interp"
            },
            {
                "text": "Menu : The image extend conditions when sampling the image with U less than 0.",
                "type": "Par",
                "name": "imageleft"
            },
            {
                "text": "Menu : The image extend conditions for U greater than 1.",
                "type": "Par",
                "name": "imageright"
            },
            {
                "text": "Menu : The image extend conditions for V less than 0.",
                "type": "Par",
                "name": "imagebottom"
            },
            {
                "text": "Menu : The image extend conditions for V greater than 1.\t\n\t\t\t\nThe extend conditions are:",
                "type": "Par",
                "name": "imagetop"
            },
            {
                "text": "The color to use when outside the bounds of the image, and the Default Color extend condition is set.",
                "type": "Par",
                "name": "defcolorr"
            },
            {
                "text": "The color to use when outside the bounds of the image, and the Default Color extend condition is set.",
                "type": "Par",
                "name": "defcolorg"
            },
            {
                "text": "The color to use when outside the bounds of the image, and the Default Color extend condition is set.",
                "type": "Par",
                "name": "defcolorb"
            },
            {
                "text": "The color to use when outside the bounds of the image, and the Default Color extend condition is set.",
                "type": "Par",
                "name": "defcolora"
            },
            {
                "text": "Menu : Select the units to use for this parameter, Samples, Frames, or Seconds.",
                "type": "Par",
                "name": "startunit"
            },
            {
                "text": "Menu : The left extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "TOP to",
        "short": "The TOP to CHOP converts pixels in a [[TOP]] image to [[CHOP]] channels.",
        "opFilter": "False",
        "long": "The TOP to CHOP converts pixels in a [[TOP]] image to [[CHOP]] channels. Each pixel color element (RGBA) is placed in a separate channel. Depending on the parameter options, the node will either create a single set of channels for the whole image or it can create a separate set of channels for each scanline (row).\n\t\t\t\nA single pixel, rows of pixels, columns of pixels or rectangular regions can be extracted from the image. It is therefore important to be aware of how many pixels your source image is composed of.\n\nThe Exclude NaN and Active Mask parameters can be used to skip certain pixels so they are not included in the chop channels.\n\t\t\t\nThere is an optional input which supplies UV coordinates to sample the image. The input CHOP must contain 2 channels, for U and V. The first channel is always assumed to be U. The channels produced (red, green, blue and alpha) will be exactly as long as the input channel's length, with a value for each UV coordinate.\t\t\t\n\t\t\t\nIf you are grabbing pixels from a [[Depth TOP]], you will only get a single channel (the depth). This will be placed in the R channel.",
        "opType": "topto",
        "opClass": "toptoCHOP_Class"
    },
    "touchinCHOP": {
        "label": "touchinCHOP",
        "members": [
            {
                "text": "Menu : Selects which network protocol to use to transfer data. Different protocol's have methods of connecting and using the address parameter. For more information refer to the [[Network Protocols]] article.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : This parameter lets you send the the data in a single global pipe if required. This can be important if various data streams must be sent in frame sync.",
                "type": "Par",
                "name": "syncports"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Touch In",
        "short": "The Touch In CHOP can be used to create a high speed connection between two TouchDesigner processes via CHOPs.",
        "opFilter": "False",
        "long": "The Touch In CHOP can be used to create a high speed connection between two TouchDesigner processes via CHOPs.\t\t\n\t\t\t\nData is sent over TCP/IP. The Touch In CHOP (client) receives its data from a [[Touch Out CHOP]] (server). The Touch In CHOP is similar to a [[Pipe In CHOP]] but highly optimized for TouchDesigner-to-TouchDesigner communication. For interfacing with other software or devices, see the [[Pipe In CHOP]] or the [[TCP/IP DAT]].\t\t\t\n\t\t\t\nTo receive network data from another \"server\" computer (e.g. from a Touch Out CHOP running remotely), a connection must be established between the server and the Touch In CHOP before data is sent.\t\t\t\n\t\t\t\nThe data is received as time slices, and can be used to eliminate frame dropping if the sender or receiver is not running at its target frame rate. See [[Time Slicing]] and the [[Time Slice CHOP]].\t\t\t\n\t\t\t\nTo analyze the timing of the messages coming in, attach an [[Info CHOP]] to the Touch In CHOP. It will show the internal queue size and whether it is dropping or missing data (<code>queue_advanced_total</code> and <code>queue_retarded_total</code> should not be increasing, and <code>queue_length</code> should not be zero).\n\n'''NOTE for Windows OS - If experiencing connection issues, confirm Windows Firewall is disabled for TouchDesigner.'''\t\t\n\t\t\t\nSee also: [[OSC In CHOP]]",
        "opType": "touchin",
        "opClass": "touchinCHOP_Class",
        "opCategories": ""
    },
    "touchoutCHOP": {
        "label": "touchoutCHOP",
        "members": [
            {
                "text": "Menu : Selects which network protocol to use to transfer data. Different protocol's have methods of connecting and using the address parameter. For more information refer to the [[Network Protocols]] article.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : This parameter lets you send the the data in a single global pipe if required. This can be important if various data streams must be sent in frame sync.",
                "type": "Par",
                "name": "syncports"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Touch Out",
        "short": "The Touch Out CHOP can be used to create high speed connection between two TouchDesigner processes.",
        "opFilter": "True",
        "long": "The Touch Out CHOP can be used to create high speed connection between two TouchDesigner processes. Data is sent over TCP/IP. The Touch Out CHOP (server) sends it's data to a [[Touch In CHOP]] (client). The Touch Out CHOP is similar to a [[Pipe Out CHOP]] but highly optimized for TouchDesigner-to-TouchDesigner communication. For interfacing with other software or devices, see the [[Pipe Out CHOP]].\t\t\n\t\t\t\nTo receive network data from another \"server\" computer (e.g. from a TouchDesigner Touch Out CHOP running remotely), a connection must be established between the server and the Touch In CHOP before data is sent. You must supply the Server Address and Port from which to receive incoming data to a channel. The server should be listening for connections on the port that this CHOP is using. Multiple Touch In CHOPs (clients) can receive data from a single Touch Out CHOP (server).\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opType": "touchout",
        "opClass": "touchoutCHOP_Class",
        "opCategories": ""
    },
    "trailCHOP": {
        "label": "trailCHOP",
        "members": [
            {
                "text": "Menu : Determines when to capture values.",
                "type": "Par",
                "name": "capture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Trail",
        "short": "The Trail CHOP displays a history of its input channels back in time.",
        "opFilter": "True",
        "long": "The Trail CHOP displays a history of its input channels back in time. A window of time is displayed from the current frame back in time, the size of this window is set by the Window Length parameter. The last sample in the Trail CHOP is a sample of the input at the current frame. <br><br>'''Note:''' If the input channels change in number or names, the Trail CHOP clears its trails and begins anew.  You can use a [[Replace CHOP]] in this case to create stand in values.<br>",
        "opType": "trail",
        "opClass": "trailCHOP_Class",
        "opCategories": ""
    },
    "transformCHOP": {
        "label": "transformCHOP",
        "members": [
            {
                "text": "Menu : Changing the Transform order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block. In matrix math terms, if we use the 'multiply vector on the right' (column vector) convention, a transform order of Scale, Rotate, Translate would be written as T * R * S * Position",
                "type": "Par",
                "name": "inxord"
            },
            {
                "text": "Menu : As with transform order (above), changing the order in which the rotations take place will alter the final position and orientation. A Rotation order of Rx Ry Rz would create the final rotation matrix as follows R = Rz * Ry * Rx",
                "type": "Par",
                "name": "inrord"
            },
            {
                "text": "Menu : Operation(s) to apply on the transforms on Input 0, before they are combined with other transforms.",
                "type": "Par",
                "name": "input0preop"
            },
            {
                "text": "Menu : Operation(s) to apply on the transforms on Input 1, before they are combined with other transforms.",
                "type": "Par",
                "name": "input1preop"
            },
            {
                "text": "Menu : The operation that should be applied between transforms coming from Input 0 and Input 1. Refer to the main description of this node for an explanation of how multiple samples and/or transform sets are combined between the two inputs.",
                "type": "Par",
                "name": "inputoperation"
            },
            {
                "text": "Menu : See description from earlier Transform Order parameter.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : See description from earlier Rotate Order parameter.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "pz"
            },
            {
                "text": "Menu : Operation(s) to apply on the transforms generated by the above parameters, before it is combined with other transforms.",
                "type": "Par",
                "name": "preop"
            },
            {
                "text": "Menu : Controls how the input transform(s) are combined with the transform specified on this page. The below two descriptions use a multiply \"vector on the right\" convention (column vectors).",
                "type": "Par",
                "name": "multiplyorder"
            },
            {
                "text": "Menu : Optionally applied one last operation to the final generated transform before it is output.",
                "type": "Par",
                "name": "postop"
            },
            {
                "text": "Menu : Specify the format the transform will be output in.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : Controls how channels that don't match the naming convention for the various transform format are treated.",
                "type": "Par",
                "name": "unmatchedchans"
            },
            {
                "text": "Menu : See description from earlier Transform Order parameter.",
                "type": "Par",
                "name": "outxord"
            },
            {
                "text": "Menu : See description from earlier Rotate Order parameter.",
                "type": "Par",
                "name": "outrord"
            },
            {
                "text": "Specify approximate starting values for the rotation channels produced.",
                "type": "Par",
                "name": "hintx"
            },
            {
                "text": "Specify approximate starting values for the rotation channels produced.",
                "type": "Par",
                "name": "hinty"
            },
            {
                "text": "Specify approximate starting values for the rotation channels produced.",
                "type": "Par",
                "name": "hintz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Transform",
        "short": "The Transform CHOP takes transformations in various formats, applied operations to them, and outputs them in various formats.",
        "opFilter": "True",
        "long": "The Transform CHOP takes transformations in various formats, applied operations to them, and outputs them in various formats. It can be used to:\t\t\n\t\t\t\n* Change the position and orientation of an object.\t\t\t\n* Convertion transforms one format to another format.\n* Convert a set of transform channels with a certain transform order into an equivalent set of channels with a different transform order.\t\n* Change the direction, starting point and scale of motion capture data or other data being calibrated to match other reference frames.\t\t\t\n\t\n( See also the [[Transform XYZ CHOP]] for fdoing transforms on XYZ positions and vectors. )\n\nThree transform formats exists:\n* Transform with Euler angles for rotation. These are defined by channels with suffixes: <code>tx ty tz, rx ry rz, sx sy sz</code> and an optional transform and rotate order <code>xord and rord</code>.\n* Transform with Quaternion for rotation. These are defined by channels with suffixes: <code>tx ty tz, qx qy qx qw, sx sy sz</code> and an optional transform order <code>xord</code>.\n* A 4x4 or 3x3 matrix. These are defined by channels with suffixes: <code>m00, m10, m20, m30, m01, m11... m33</code>. Where the notation is <code>m[''row''][''col'']</code>. The matrix should be be in column-major order, that is to say, the translate portion should be in <code>m03, m13, m23</code>. The 4th row and column can be omitted to use a 3x3 matrix instead. Unlike the other formats, this format can not have arbitrary missing channels. Either 9 channels for 3x3 or 16 channels for 4x4 matrices must be provided.\n\nThe first two transform formats can be specified with missing channels, in which case default values will be used. 0s for translates and rotates, 1s for scale, and (0,0,0,1) for quaternion.\n\nFrequently the input channels come from an [[Object CHOP]] or [[Parameter CHOP]]. Examples are: \t\t\t\n\t\t\t\n* geo1:tx geo1:ty geo1:tz geo1:rx ...\t\t\t\n* headtx headty headtz headrx\t\t\t\n* tx ty tz rx ... (what you would get from a Parameter CHOP)\n* cam1:m00 cam1:m10 cam1:m20 .... cam1:m33\n\t\t\t\n===Multiple Transform Sets===\nAny of the above defines a transformation matrix. Multiple transform 'sets' can be specified by channels having different prefixes. Different sets using different formats can be all in the same CHOP. Formats can not be mixed within a set though. Each set will be combined with sets from the other input, and the transform on the 'Transform' page to create final transforms for each set.\n\nIf no inputs are connected to the CHOP, it will output the transform generated from the 'Transform' page.\n\nIf inputs are connected, the output will contain the same number of samples as the first input. Samples will be combined between the inputs 1:1, that is, the start/end range and the sample rate of the inputs are ignored. If the second input contains less samples than the first one, the extend conditions for that CHOP will be used to determine values for the samples coming from the 2nd CHOP that are out of range.\n\nIf multiple sets are provided, they will be matched 1st-to-1st set, 2nd-to-2nd set. If there are less sets in the second input than the first one, then it will loop over the sets. E.g if the first input as 5 sets and the second input as 2 sets, the matching will be 1st-to-1st, 2nd-to-2nd, 3rd-to-1st, 4th-to-2nd and 5th-to-1st.\n\n===Order of Operation===\nThe inputs will be combined together first, then the result from that will be combined with the transform defined on the 'Transform' page.\n\nThe channels of a Transform CHOP are frequently exported back to objects.",
        "opType": "transform",
        "opClass": "transformCHOP_Class",
        "opCategories": ""
    },
    "transformxyzCHOP": {
        "label": "transformxyzCHOP",
        "members": [
            {
                "text": "Menu : Choose if the input 0 values should be treated as a position or a vectors. Vectors will not have the translation portion of the transform applied to them, and can be normalized before and/or after the transformation is applied.",
                "type": "Par",
                "name": "input0type"
            },
            {
                "text": "Menu : Changing the Transform order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block. In matrix math terms, if we use the 'multiply vector on the right' (column vector) convention, a transform order of Scale, Rotate, Translate would be written as T * R * S * Position",
                "type": "Par",
                "name": "inxord"
            },
            {
                "text": "Menu : As with transform order (above), changing the order in which the rotations take place will alter the final position and orientation. A Rotation order of Rx Ry Rz would create the final rotation matrix as follows R = Rz * Ry * Rx",
                "type": "Par",
                "name": "inrord"
            },
            {
                "text": "Menu : Operation(s) to apply on the transforms on Input 1, before they are combined with other transforms.",
                "type": "Par",
                "name": "input1preop"
            },
            {
                "text": "Menu : See description from earlier Transform Order parameter.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : See description from earlier Rotate Order parameter.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "XYZ translation values.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "XYZ rotation, in degrees.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "XYZ scale to shrink or enlarge the transform.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "XYZ pivot to apply the above operations around.",
                "type": "Par",
                "name": "pz"
            },
            {
                "text": "Menu : Controls how the input transform(s) are combined with the transform specified on this page. The below two descriptions use a multiply \"vector on the right\" convention (column vectors).",
                "type": "Par",
                "name": "multiplyorder"
            },
            {
                "text": "Menu : Controls how channels that don't match the naming convention for the various transform format are treated.",
                "type": "Par",
                "name": "unmatchedchans"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "transformxyzCHOP",
        "opLabel": "Transform XYZ",
        "opClass": "transformxyzCHOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "Transforms positions and vectors.",
        "long": "The Transform XYZ CHOP is used to transform positions and vector. The difference between transforming a position vs. a vector is that a vector won't have the translation portion of the transformation applied to it.<br><br>The Transform XYZ CHOP first groups the channels from the first input by looking for '<code>x</code>', '<code>y</code>' and '<code>z</code>' as the last character in the channel names. Then it treats each of the sets created as either a Position or a Vector depending on the parameter choice. The second input can be connected, and must describe a transform in the same format of channels that the [[Transform CHOP]] supports. The second input is combined with the 'Transform' page parameters, and the resulting transform is applied to the input positions and vectors.<br><br>CHOPs with multiple-samples can be provided, which allows for larger amount of positional data to be transformed in a single CHOP.\n    \nSee also the [[Transform CHOP]].",
        "opCategories": ""
    },
    "triggerCHOP": {
        "label": "triggerCHOP",
        "members": [
            {
                "text": "Menu : Determines whether a trigger occurs on an increasing slope or decreasing slope when passing the trigger threshold. A release will occur on the opposite slope.",
                "type": "Par",
                "name": "triggeron"
            },
            {
                "text": "Menu : The shape of the attack ramp.",
                "type": "Par",
                "name": "ashape"
            },
            {
                "text": "Menu : The shape of the decay ramp.",
                "type": "Par",
                "name": "dshape"
            },
            {
                "text": "Menu : The shape of the release ramp.",
                "type": "Par",
                "name": "rshape"
            },
            {
                "text": "Menu : See Remainder Options. What to do with remaining samples at end of the interval:",
                "type": "Par",
                "name": "remainder"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Trigger",
        "short": "The Trigger CHOP starts an audio-style attack/decay/sustain/release (ADSR) envelope to all trigger pulses in the input channels.",
        "opFilter": "True",
        "long": "The Trigger CHOP starts an audio-style attack/decay/sustain/release (ADSR) envelope to all trigger pulses in the input channels. A trigger point occurs whenever the first input's channel increases across the trigger threshold value. Most commonly, an ADSR starts when the input goes from 0 to 1.\t\t\n\t\t\t\nThe envelope consists of six major sections: delay, attack, peak, decay, sustain and release.\t\t\t\n\t\t\t\nFrom the time the threshold is reached and while the channel's value is above the release threshold, the envelope is in its sustain phase during which it will delay, attack, peak-hold, decay and then maintain its sustain value.\t\t\t\n\t\t\t\nAfter the inputs drops below the release threshold, the envelope start its release phase and will drop to 0.\t\t\t\n\t\t\t\nThe peak and sustain levels can be set independently, but peak value can never be less than sustain.\t\t\t\n\t\t\t\nIf you don't connect an input to the Trigger CHOP and you set it to Time Slice off, a single full envelope is generated. \t\t\t\n\t\t\t\nThis CHOP works with both time-sliced inputs or with static input channels.\n\nFor jittery inputs, if you don't want it to trigger until its input has been On for some period, see the [[OP Snippets]] for the Trigger CHOP, example \"trigger after a time threshold\", which uses the Count CHOP.\n\t\t\t\n'''Note''': See examples in OP Snippets.\t\t\t\n\t\t\t\nSee also: [[Timer CHOP]], [[Count CHOP]], [[Speed CHOP]], [[Event CHOP]]",
        "opType": "trigger",
        "opClass": "triggerCHOP_Class",
        "opCategories": ""
    },
    "trimCHOP": {
        "label": "trimCHOP",
        "members": [
            {
                "text": "Menu : Determines whether the Start/End parameters are expressed as absolute numbers (relative to time 0) or numbers that are relative to the start and end of the input channels.",
                "type": "Par",
                "name": "relative"
            },
            {
                "text": "Menu : Which part of the channel to discard:",
                "type": "Par",
                "name": "discard"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Trim",
        "short": "The Trim CHOP shortens or lengthens the input's channels.",
        "opFilter": "True",
        "long": "The Trim CHOP shortens or lengthens the input's channels. A part of the interval can be preserved or removed. If the channels are being lengthened, the extend conditions of the channel will be used to get the new values.\t\t\n\t\t\t\nThe Trim CHOP is sometimes used to get a 1-sample value at the current frame, where the inputs are channels at frame 0 or channels at some other frame range.\t\t\t\n\t\t\t\nThe handles on the Trim CHOP in the graph can interactively adjust its length.\t\t\t\n\t\t\t\nSee also [[Splice CHOP]], [[Delete CHOP]], [[Select CHOP]]",
        "opType": "trim",
        "opClass": "trimCHOP_Class",
        "opCategories": ""
    },
    "warpCHOP": {
        "label": "warpCHOP",
        "members": [
            {
                "text": "Menu : The warping method to use: <span class=\"tipTextCHOP\">Rate</span> or <span class=\"tipTextCHOP\">Index Control</span>.",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Warp",
        "short": "The Warp CHOP time-warps the channels of the first input (the Pre-Warp Channels) using one warping channel in the second input (the Warp Curve).",
        "opFilter": "True",
        "long": "The Warp CHOP time-warps the channels of the first input (the Pre-Warp Channels) using one warping channel in the second input (the Warp Curve). The Warp Curve acts as either a rate control or an index control, as explained below. The Warp CHOP usually works on non-time-sliced channels, like pre-key-framed channels of motion. See also the [[Lookup CHOP]], the [[Speed CHOP]] and the [[Audio Oscillator CHOP]].\t\t\n\t\t\t\nIn the Rate Control Method, feeding the Warp CHOP a Warp Curve with a constant value of 1 makes the output identical to the Pre-Warp Channels, assuming the two inputs have the same start-end interval. That is, where the rate is 1, the Pre-Warp Channels are not warped.\t\t\t\n\t\t\t\nWhere the Warp Curve is above 1, it causes a speed-up in the animation. Where the Warp Curve is below 1, it causes a slow-down in the animation. Rates less than 0 cause the animation to go in reverse.\t\t\t\n\t\t\t\nIn the Index Control Method, the Warp Curve acts as an index into the first input. If the Warp Curve is a straight ramp with a slope of 1 (in Units), it produces unwarped output channels. If Units is set to Seconds, a Warp Curve value of 0 gets the Pre-Warp Channels' values at time 0 seconds. A Warp Curve value of 2 gets the Pre-Warp Channels' values at time 2 seconds.\t\t\t\n\t\t\t\nThe Warp CHOP will output the same number of channels and channel names as the Pre-Warp Channels input, and the sample rate will be the same as that of the Pre-Warp input. However, the CHOP will output the same start-end time interval as the Warp Curve input.\t\t\t\n\t\t\t\nIf you take a Warp Curve and pass it directly to a Warp CHOP with the Rate Control Method, it is equivalent to passing the same curve to an Speed CHOP and then passing it to the Warp CHOP with the Index Control Method.",
        "opType": "warp",
        "opClass": "warpCHOP_Class",
        "opCategories": ""
    },
    "waveCHOP": {
        "label": "waveCHOP",
        "members": [
            {
                "text": "Menu : There is a choice of waveforms shapes:",
                "type": "Par",
                "name": "wavetype"
            },
            {
                "text": "Menu : The left extend conditions (before/after range).",
                "type": "Par",
                "name": "left"
            },
            {
                "text": "Menu : The right extend conditions (before/after range).",
                "type": "Par",
                "name": "right"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opLicense": "Non-Commercial",
        "opLabel": "Wave",
        "short": "The Wave CHOP makes repeating waves with a variety of shapes.",
        "opFilter": "False",
        "long": "The Wave CHOP makes repeating waves with a variety of shapes. It is by default 10-seconds of 1-second sine waves, a total of 600 frames. You can adjust period (frequency), phase, shape, amplitude and offset.\t\t\n\t\t\t\nThe Wave CHOP gives a set of waves in channels of a specifiable time-range. It is superceded by the [[LFO CHOP]] which gives an endless stream of waves that is [[Time Slice]]d, and the [[Pattern CHOP]] that has more control over shaping waveform samples (and is time-independent). The [[Audio Oscillator CHOP]] also creates waveforms that are continually repeated, but its defaults are for higher-frequency waves at higher (audio) sample rates. \t\t\t\n\t\t\t\nBecause the Extend Conditions of the Wave CHOP are set to Repeat, the wave will repeat outside the 10-second range.\t\t\t\n\t\t\t\nApplied to the actual waveform can be an offset, decay and ramp.\n\t\t\t\nMultiple channels can be generated in the Channel Name parameter using [[Pattern Expansion]]. A few examples of name pattern name expansion:\t\t\t\n\t\t\t\n* <code>tx ty tz</code>\t\t\t\n* <code>t[xyz]</code> - expands to <code>tx ty tz</code>\t\t\t\n* <code>chan[1-4]</code> - expands to <code>chan1 chan2 chan3 chan4</code>\t\t\t\n* <code>c[xyz][1-5:2]</code> - expands to <code>cx1 cx3 cx5 cy1 cy3 cy5 cz1 cz3 cz5</code>\t\t\t\n\t\t\t\nSee also: [[LFO CHOP]], [[Pattern CHOP]], [[Audio Oscillator CHOP]].",
        "opType": "wave",
        "opClass": "waveCHOP_Class",
        "opCategories": ""
    },
    "wrnchaiCHOP": {
        "label": "wrnchaiCHOP",
        "members": [
            {
                "text": "Menu : A menu of available GPU(s) to run wrnchAI on. Selecting 'Default' uses the same GPU TouchDesigner is currently running on.",
                "type": "Par",
                "name": "gpu"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "CHOP",
        "opType": "wrnchaiCHOP",
        "opLabel": "wrnchAI",
        "opClass": "wrnchaiCHOP_Class",
        "opFilter": "False",
        "opLicense": "Pro",
        "short": "Uses the wrnchAI engine to track human motion in any video stream.",
        "long": "'''Note: Wrnch has be acquired by another company and it is no longer possible to obtain a license to use it anymore. This CHOP has been removed in 2022.20000+ builds.'''\n\nUsing the [[wrnchAI]] engine to track human motion in any video stream, this CHOP will output channels for Body, Face and Hand positions. Multiple people can be tracked at the same time with low-latency, and the system compatible with all cameras and video feeds. TouchDesigner used the wrnchAI Edge SDK and all computation is done locally in realtime utilizing Nvidia GPUs and the NVIDIA CUDA\u00ae Deep Neural Network library ([https://developer.nvidia.com/cudnn cuDNN]). This can offer skeletal tracking of multiple people at 60fps or higher (90-120fps etc).\n    \n '''Requires a separate license from wrnchAI''' to run in TouchDesigner. Requires '''Nvidia GPU on Windows OS''' and TouchDesigner Pro. \n Make sure to install TouchDesigner from the Full Installer, the Lite Installer does not include wrnchAI libraries.\n\n===== Quickstart Guide =====\nOnce you have a wrnchAI license (purchased or trial), you will have access to your '''wrnchAI licenses''' page and the '''wrnchAI Edge Releases''' page.\n\n# Go to your [https://devportal.wrnch.ai/licenses wrnchAI licenses page]. Click on the 'key' icon and copy the '''Edge License Key''' into the CHOP's 'wrnchAI License' parameter.\n# Go to [https://devportal.wrnch.ai/wrnchai_edge/releases wrnchAI Edge Releases page] and download the '''wrnchAI Engine for Win10'''. The file will be something like <code>wrnchAI-Engine-1.17.0-GPU-Win10.zip</code>\n# Once downloaded, extract the .zip file and locate the '''wrnchAI trained models folder''' for use in the CHOP's 'Model Folder' parameter. It should be located here: <code>wrnchAI-engine-GPU-1.17.0-Windows-amd64/bin/wrModels</code>\nThe wrnchAI CHOP will take a few moments to initialize and then will be ready for tracking. Initializing is only required when a new Model Folder is introduced, it will not need to re-initialize each time the project is started.",
        "opCategories": ""
    },
    "zedCHOP": {
        "label": "zedCHOP",
        "members": [
            {
                "text": " : Selects the reference frame for plane position.",
                "type": "Par",
                "name": "referenceframe"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "long": "The ZED CHOP reads positional and plane tracking from the ZED camera. It can additionally use a UV to find plane in the room, and return information about that plane such as it's size/orientation either relative to the camera, or the room itself.\n\t\t\t\n'''NOTE:''' This CHOP works with the [https://www.stereolabs.com/zed/ Stereolabs ZED] hardware.\t\nFor more information and to know what ZED SDK to install refer to the [[ZED]] article.\n\nSee also [[ZED TOP]] and [[ZED SOP]].",
        "opLicense": "Non-Commercial",
        "opClass": "zedCHOP_Class",
        "opLabel": "ZED",
        "opFamily": "CHOP",
        "os": "Microsoft Windows",
        "opType": "zed",
        "short": "The ZED CHOP reads positional tracking data from the ZED camera.",
        "opCategories": ""
    },
    "alignSOP": {
        "label": "alignSOP",
        "members": [
            {
                "text": "Menu : Can optionally align subgroups of ''n'' primitives or every ''n''th primitive in a cyclical manner.",
                "type": "Par",
                "name": "align"
            },
            {
                "text": "Pivot Location for each \"left\" primitive.",
                "type": "Par",
                "name": "leftuv1"
            },
            {
                "text": "Pivot Location for each \"left\" primitive.",
                "type": "Par",
                "name": "leftuv2"
            },
            {
                "text": "Pivot location for each \"right\" primitive.",
                "type": "Par",
                "name": "rightuv1"
            },
            {
                "text": "Pivot location for each \"right\" primitive.",
                "type": "Par",
                "name": "rightuv2"
            },
            {
                "text": "If an auxiliary input is used, this location specifies an end point for the alignment. Left primitives are then distributed uniformly between the <code>Right UV</code> and the <code>Right UV End</code>.",
                "type": "Par",
                "name": "rightuvend1"
            },
            {
                "text": "If an auxiliary input is used, this location specifies an end point for the alignment. Left primitives are then distributed uniformly between the <code>Right UV</code> and the <code>Right UV End</code>.",
                "type": "Par",
                "name": "rightuvend2"
            },
            {
                "text": "Menu : Sets the overall transform and rotation order for the transformations. The transform and rotation order determines the order in which transformations take place. Depending on the order, you can achieve different results using the exact same values.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : Sets the overall transform and rotation order for the transformations. The transform and rotation order determines the order in which transformations take place. Depending on the order, you can achieve different results using the exact same values.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of translation about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of translation about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of translation about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of rotation about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of rotation about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of rotation about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of scaling about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of scaling about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of scaling about the local <code>xyz</code> axes.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of translation / rotation / scaling about the local <code>xyz</code> axes",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of translation / rotation / scaling about the local <code>xyz</code> axes",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "Allows you to perform a post-alignment transformation. Specify the amount of translation / rotation / scaling about the local <code>xyz</code> axes",
                "type": "Par",
                "name": "pz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "alignSOP_Class",
        "opType": "align",
        "short": "The Align SOP aligns a group of primitives to each other or to an auxiliary input, by translating or rotating each primitive along any pivot point.",
        "opFilter": "True",
        "opLabel": "Align",
        "long": "The Align SOP aligns a group of primitives to each other or to an auxiliary input, by translating or rotating each primitive along any pivot point.\t\t\n\t\t\t\n'''Left and Right Primitives''' - The notions of \"left\" and \"right\" which follow depend on context. If an auxiliary input is used, it is always the right primitive and the primary input geometry are all left primitives. If only one input is used, then for each pair being aligned, there is a left and a right primitive. This means that relative to neighbouring primitives, one primitive can be both left and right.\t\t\t\n\t\t\t\n<div><center>[[Image:TouchGeometry72.gif]]</center></div>",
        "opFamily": "SOP",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "armSOP": {
        "label": "armSOP",
        "members": [
            {
                "text": "Menu : You can use either '''Ellipses''' or '''Capture Regions''' as deformation geometry. Ellipses are for use with the Skeleton SOP. Capture Regions are for use with the Capture SOP.",
                "type": "Par",
                "name": "capttype"
            },
            {
                "text": "Menu : Position the model along the +X or -X axis.",
                "type": "Par",
                "name": "axis"
            },
            {
                "text": "The X, Z position of the first shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder1tx"
            },
            {
                "text": "The X, Z position of the first shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder1ty"
            },
            {
                "text": "The X, Z position of the first shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder1tz"
            },
            {
                "text": "The X, Z position of the second shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder2tx"
            },
            {
                "text": "The X, Z position of the second shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder2ty"
            },
            {
                "text": "The X, Z position of the second shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder2tz"
            },
            {
                "text": "The X, Z position of the third shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder3tx"
            },
            {
                "text": "The X, Z position of the third shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder3ty"
            },
            {
                "text": "The X, Z position of the third shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder3tz"
            },
            {
                "text": "The X, Z position of the fourth shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder4tx"
            },
            {
                "text": "The X, Z position of the fourth shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder4ty"
            },
            {
                "text": "The X, Z position of the fourth shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder4tz"
            },
            {
                "text": "The X, Z position of the fifth shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder5tx"
            },
            {
                "text": "The X, Z position of the fifth shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder5ty"
            },
            {
                "text": "The X, Z position of the fifth shoulder circle, as well as its overall scale.",
                "type": "Par",
                "name": "shoulder5tz"
            },
            {
                "text": "The X, Z position of the first elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow1tx"
            },
            {
                "text": "The X, Z position of the first elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow1ty"
            },
            {
                "text": "The X, Z position of the first elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow1tz"
            },
            {
                "text": "The X, Z position of the second elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow2tx"
            },
            {
                "text": "The X, Z position of the second elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow2ty"
            },
            {
                "text": "The X, Z position of the second elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow2tz"
            },
            {
                "text": "The X, Z position of the third elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow3tx"
            },
            {
                "text": "The X, Z position of the third elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow3ty"
            },
            {
                "text": "The X, Z position of the third elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow3tz"
            },
            {
                "text": "The X, Z position of the fourth elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow4tx"
            },
            {
                "text": "The X, Z position of the fourth elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow4ty"
            },
            {
                "text": "The X, Z position of the fourth elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow4tz"
            },
            {
                "text": "The X, Z position of the fifth elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow5tx"
            },
            {
                "text": "The X, Z position of the fifth elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow5ty"
            },
            {
                "text": "The X, Z position of the fifth elbow circle, as well as its overall scale.",
                "type": "Par",
                "name": "elbow5tz"
            },
            {
                "text": "The X, Z position of the first wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist1tx"
            },
            {
                "text": "The X, Z position of the first wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist1ty"
            },
            {
                "text": "The X, Z position of the first wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist1tz"
            },
            {
                "text": "The X, Z position of the second wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist2tx"
            },
            {
                "text": "The X, Z position of the second wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist2ty"
            },
            {
                "text": "The X, Z position of the second wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist2tz"
            },
            {
                "text": "The X, Z position of the third wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist3tx"
            },
            {
                "text": "The X, Z position of the third wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist3ty"
            },
            {
                "text": "The X, Z position of the third wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist3tz"
            },
            {
                "text": "The X, Z position of the fourth wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist4tx"
            },
            {
                "text": "The X, Z position of the fourth wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist4ty"
            },
            {
                "text": "The X, Z position of the fourth wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist4tz"
            },
            {
                "text": "The X, Z position of the fifth wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist5tx"
            },
            {
                "text": "The X, Z position of the fifth wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist5ty"
            },
            {
                "text": "The X, Z position of the fifth wrist circle, as well as its overall scale.",
                "type": "Par",
                "name": "wrist5tz"
            },
            {
                "text": "End Affector Translation. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "End Affector Translation. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "End Affector Translation. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "End Affector Rotation. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "End Affector Rotation. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "End Affector Rotation. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "End Affector Scale. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "End Affector Scale. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "End Affector Scale. For a full explanation of transforms, see the [[Transform SOP]].",
                "type": "Par",
                "name": "sz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opLicense": "Non-Commercial",
        "opClass": "armSOP_Class",
        "opFamily": "SOP",
        "long": "The Arm SOP creates all the necessary geometry for an arm, and provides a smooth, untwisted skin that connects the arm to the body. It is controlled through inverse kinematics linked to a handprint.",
        "short": "The Arm SOP creates all the necessary geometry for an arm, and provides a smooth, untwisted skin that connects the arm to the body.",
        "opFilter": "False",
        "opType": "arm",
        "opLabel": "Arm",
        "opCategories": ""
    },
    "basisSOP": {
        "label": "basisSOP",
        "members": [
            {
                "text": "Menu : Select the method of parameterization in u from the options below.",
                "type": "Par",
                "name": "uparmtype"
            },
            {
                "text": "Range specifies the domain interval to be shifted. All the knots captured in this range are shifted by the same amount as far as the closest neighbouring knot on either side.",
                "type": "Par",
                "name": "urange1"
            },
            {
                "text": "Range specifies the domain interval to be shifted. All the knots captured in this range are shifted by the same amount as far as the closest neighbouring knot on either side.",
                "type": "Par",
                "name": "urange2"
            },
            {
                "text": "Menu : Select the method of parameterization in v from the options below.",
                "type": "Par",
                "name": "vparmtype"
            },
            {
                "text": "Range specifies the domain interval to be shifted. All the knots captured in this range are shifted by the same amount as far as the closest neighbouring knot on either side.",
                "type": "Par",
                "name": "vrange1"
            },
            {
                "text": "Range specifies the domain interval to be shifted. All the knots captured in this range are shifted by the same amount as far as the closest neighbouring knot on either side.",
                "type": "Par",
                "name": "vrange2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "basisSOP_Class",
        "opType": "basis",
        "short": "The Basis SOP provides a set of operations applicable to the parametric space of spline curves and surfaces.",
        "opFilter": "True",
        "opLabel": "Basis",
        "long": "The Basis SOP provides a set of operations applicable to the parametric space of spline curves and surfaces. The parametric space, also known as the \"domain\" of a NURBS or Bzier primitive, is defined by one basis in the U direction and, if the primitive is a surface, another basis in the V direction. The size of the domain is given by the values of the knots that make up the basis.\t\t\n\t\t\t\n<div><center>[[Image:BasisSOP.gif]]</center></div>\t\t\t\n\t\t\t\nThe Basis SOP contains both ratio-preserving and non ratio-preserving operations.\t\t\t\n\t\t\t\nIf the basis reparameterization does not change the distance ratios between knots, the shape of a NURBS primitive is not affected. If the ratios are not preserved, however, a NURBS primitive will change shape in the area influenced by the modified knots; furthermore, if the primitive is a NURBS or Bzier surface, any profiles it may contain will be affected as well.\t\t\t\n\t\t\t\nFor more information about bases and knots see Breakpoints, Knots, and Spline Basis in the Geometry Types Guide.",
        "opFamily": "SOP",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "blendSOP": {
        "label": "blendSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "blendSOP_Class",
        "opType": "blend",
        "short": "The Blend SOP provides 3D metamorphosis between shapes with the same topology. It can blend",
        "opFilter": "True",
        "opLabel": "Blend",
        "long": "The Blend SOP provides 3D metamorphosis between shapes with the same topology. It can blend between sixteen input SOPs using the average weight of each input's respective channel. It will also interpolate point colors and/or texture co-ordinates between shapes.\t\n\t\t\nFor best results, there should be the same number of points / CVs (and faces) in the geometry of each SOP. The points should have a similar order; if point 17 in one source is on the left side, and point 17 in another Source is on the right side, it will move across the object during the blend, which may create distorted and twisted shapes. To ensure that this doesn't happen, you can make all the pieces to be blended by editing point positions of one common base shape. Each of the pieces to be morphed must be in different SOPs.\t\t\n\t\t\nFor example, when editing the shapes in the Model Editor, each particular geometry can be saved and then read in, or input the Model SOP directly into the Blend SOP. You would then have the base model geometry entering the Blend SOP in the first Blend, then up to 15 Model SOPs feeding from the SOP containing the base model geometry, which in turn would feed into the Blend SOP. Remember that Model SOPs cannot be unlocked and, therefore, are a safe way to store data without using a File In SOP.\t\t\n\t\t\nThe Blend SOP now only cooks non-zero-weighted inputs.\t\t\n\t\t\nSee also [[Sequence Blend SOP]].",
        "opFamily": "SOP",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "booleanSOP": {
        "label": "booleanSOP",
        "members": [
            {
                "text": "Menu : Some of the operations below produce guide geometry to give you visual feedback on the results of the operation being performed. The appearance of the geometry is context sensitive - if you are performing an intersect operation, or either of the edge operations the guide will be both inputs; if you are doing A minus B then the guide will be B and if B minus A then the guide will be A. If you are doing union then there will be no guide geometry.\t\n\t\t\nIf the guide geometry is too distracting, you can disable it by entering the Viewport options dialog and clicking on the Guide geometry button so that it no longer appears indented. This procedure is global and will disable the guide geometry of other SOPs as well.\n\nThe Boolean SOP will automatically orient polygons so they face the same way. This may not be enough in some cases because Boolean results in some unshared edges where the intersection cut took place. If the shading is still not good enough, you are best to follow Boolean with a Facet SOP. In it, Consolidate Points, Orient Polygons and finally Cusp.\t\t\n\t\t\nIf you have really strange shaped polygons, you can first triangulate one or both of the inputs with the Divide SOP.",
                "type": "Par",
                "name": "booleanop"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "booleanSOP_Class",
        "opType": "boolean",
        "short": "The Boolean SOP takes two closed polygonal sets, A and B. Set these Sources to the SOPs with the 3D shapes that you wish to operate on.",
        "opFilter": "True",
        "opLabel": "Boolean",
        "long": "The Boolean SOP takes two closed polygonal sets, A and B. Set these Sources to the SOPs with the 3D shapes that you wish to operate on. There are two important requirements for input geometry:\t\n\t\t\n* Shapes must be completely closed. A tube with open ends is not an acceptable input. You can close Tube ends with an end-cap. An extruded letter with no back polygons output is also unacceptable (even with backs output it can be unacceptable because of the second requirement).\t\t\n* All polygons must be convex and coplanar. In the case of the Extrude SOP, you must select Output Convex Faces for front and back faces. It will now be a usable input for Boolean. The Divide SOP also offers a convexing function for geometry not created with the Extrude SOP.\t\t\n\t\t\nOther caveats for Boolean are the following:\t\t\n\t\t\n* Point colors and texture UV coordinates are not interpolated correctly.\t\t\n* In some cases polygons can be reversed so that all normals point outwards. The polygon reversal should not usually present much of a problem (use a Primitive SOP &gt; Face/Hull page &gt; Vertex &gt; Reverse to reverse them if necessary).\t\t\n\n* A [[Facet SOP]] can be used to prepare inputs when the Boolean SOP complaints they are not closed. In that case, use both the Consolidate Points and Orient Polygons options.\n\t\t\nThis SOP is quite visual and intuitive; you can experiment with the different combinations on screen to see the effects.\t\t\n\t\t\n'''Note:''' The Boolean SOP handles polygonal geometry types. For boolean-type operations with nurbs and Bezier surfaces - see [[Surfsect SOP]].",
        "opFamily": "SOP",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "bridgeSOP": {
        "label": "bridgeSOP",
        "members": [
            {
                "text": "Menu : Allows bridging of subgroups of N primitives or patterns of primitives.",
                "type": "Par",
                "name": "bridge"
            },
            {
                "text": "Specifies the type of normal to use for computing direction:",
                "type": "Par",
                "name": "frenet"
            },
            {
                "text": "Menu : Specifies the type of normal to use for computing direction:",
                "type": "Par",
                "name": "frenet"
            },
            {
                "text": "The scaling and rotation parameters contain three fields. The rotation fields (degrees) apply further rotation to the tangents, while the scale parameter further scales the tangents.",
                "type": "Par",
                "name": "rotatet1"
            },
            {
                "text": "The scaling and rotation parameters contain three fields. The rotation fields (degrees) apply further rotation to the tangents, while the scale parameter further scales the tangents.",
                "type": "Par",
                "name": "rotatet2"
            },
            {
                "text": "The scaling and rotation parameters contain three fields. The rotation fields (degrees) apply further rotation to the tangents, while the scale parameter further scales the tangents.",
                "type": "Par",
                "name": "rotatet3"
            },
            {
                "text": "The scaling and rotation parameters contain three fields. The rotation fields (degrees) apply further rotation to the tangents, while the scale parameter further scales the tangents.",
                "type": "Par",
                "name": "scalet1"
            },
            {
                "text": "The scaling and rotation parameters contain three fields. The rotation fields (degrees) apply further rotation to the tangents, while the scale parameter further scales the tangents.",
                "type": "Par",
                "name": "scalet2"
            },
            {
                "text": "The scaling and rotation parameters contain three fields. The rotation fields (degrees) apply further rotation to the tangents, while the scale parameter further scales the tangents.",
                "type": "Par",
                "name": "scalet3"
            },
            {
                "text": "Further scaling of the curvature.\t\n\t\t\t\n'''Note:''' If the resulting skin bulges too greatly, you can achieve a smooth resulting transition between surfaces by disabling the <span class=\"tipTextSOP\">Preserve Tangent</span> &amp; <span class=\"tipTextSOP\">Preserve Curvature Magnitude</span> parameters, and manually tweaking the Tangent Scales and the Curvature Scales. In general, avoid tweaking the Rotations of the Tangents unless you wish to deform the resulting surface.\t\t\t\n\t\t\t\nIf the bridge bulges on one side but not the other, try increasing the <span class=\"tipTextSOP\">Min. Number of Cross sections</span> in the bridge.",
                "type": "Par",
                "name": "scalec1"
            },
            {
                "text": "Further scaling of the curvature.\t\n\t\t\t\n'''Note:''' If the resulting skin bulges too greatly, you can achieve a smooth resulting transition between surfaces by disabling the <span class=\"tipTextSOP\">Preserve Tangent</span> &amp; <span class=\"tipTextSOP\">Preserve Curvature Magnitude</span> parameters, and manually tweaking the Tangent Scales and the Curvature Scales. In general, avoid tweaking the Rotations of the Tangents unless you wish to deform the resulting surface.\t\t\t\n\t\t\t\nIf the bridge bulges on one side but not the other, try increasing the <span class=\"tipTextSOP\">Min. Number of Cross sections</span> in the bridge.",
                "type": "Par",
                "name": "scalec2"
            },
            {
                "text": "Further scaling of the curvature.\t\n\t\t\t\n'''Note:''' If the resulting skin bulges too greatly, you can achieve a smooth resulting transition between surfaces by disabling the <span class=\"tipTextSOP\">Preserve Tangent</span> &amp; <span class=\"tipTextSOP\">Preserve Curvature Magnitude</span> parameters, and manually tweaking the Tangent Scales and the Curvature Scales. In general, avoid tweaking the Rotations of the Tangents unless you wish to deform the resulting surface.\t\t\t\n\t\t\t\nIf the bridge bulges on one side but not the other, try increasing the <span class=\"tipTextSOP\">Min. Number of Cross sections</span> in the bridge.",
                "type": "Par",
                "name": "scalec3"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "bridgeSOP_Class",
        "opType": "bridge",
        "short": "The Bridge SOP is useful for skinning trimmed surfaces, holes, creating highly controllable joins between arms and body, branches or tube intersections.",
        "opFilter": "True",
        "opLabel": "Bridge",
        "long": "The Bridge SOP is useful for skinning trimmed surfaces, holes, creating highly controllable joins between arms and body, branches or tube intersections.\t\t\n\t\t\t\nThe Bridge SOP is similar to the Skin SOP but with much greater control over the resulting surface. Given a set of profiles (i.e. curves on surface) and/or spatial faces, the Bridge SOP builds a NURBS skin with specified tangent and curvature characteristics. The precision of the resulting surface is highly dependent on the number of required cross-sections and on the quality of the profile extraction. High precisions will generate a very dense surface with, potentially, many multiple knots.\t\t\t\n\t\t\t\nIn general, the higher the order of the curve, the better the fit the Bridge SOP will be able to provide. However, it is generally better to stick to cubics (order 4) curves, as the software is optimized for cubics.\t\t\t\n\t\t\t\nBecause the Bridge SOP can join both a set of spatial curves and trim curves, it can be used much like the Skin SOP and/or the Fillet <span>SOP</span>. However, bridging trimmed surfaces is more expensive than bridging carved surfaces.\t\t\t\n\t\t\t\nYou will usually need a Trim, Bridge, or Profile SOP after a Project SOP.\t\t\t\n\t\t\t\n* Use a Trim SOP to cut a hole in the projected surface\t\t\t\n* Use a Bridge SOPto skin the profile curve to another profile curve.\t\t\t\n* Use a Profile SOP to extract the curve on surface or remap it's position.\t\t\t\n\t\t\t\n'''Note:''' To texture-map the resulting skin, use an Orthographic projection rather than a Spline-based projection. This results in better continuity across the surfaces.",
        "opFamily": "SOP",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "cacheSOP": {
        "label": "cacheSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "cacheSOP_Class",
        "opType": "cache",
        "short": "The Cache SOP collects its input geometry in a cache for faster random-access playback of multiple SOPs.",
        "opFilter": "True",
        "opLabel": "Cache",
        "long": "The Cache SOP collects its input geometry in a cache for faster random-access playback of multiple SOPs. It should be used when cook times for a chain of <span>SOP</span>s is long and a quicker playback is needed.\n\t\nOnce cached, the geometries can be accessed in any order. This is advantageous to a 2D flipbook or scene render since the geometry is still fully 3-Dimensional. The upshot being that you can scrub otherwise sluggish animations in real time because things are precomputed and stored in a cache.",
        "opFamily": "SOP",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "captureregionSOP": {
        "label": "captureregionSOP",
        "members": [
            {
                "text": "Menu : Defines the direction axis of the region. Use Z axis when the region is inside a bone object.\t\n\t\t\t\n[[Image:TouchGeometry46.gif]]",
                "type": "Par",
                "name": "orient"
            },
            {
                "text": "Position of the center of the region.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Position of the center of the region.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Position of the center of the region.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "tcapx"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "tcapy"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "tcapz"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "bcapx"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "bcapy"
            },
            {
                "text": "The X, Y, Z radii of the top/bottom hemisphere.",
                "type": "Par",
                "name": "bcapz"
            },
            {
                "text": "Defines the weight of a point exactly on the centre line and edge of the region respectively. Point weights in-between are blended.",
                "type": "Par",
                "name": "weight1"
            },
            {
                "text": "Defines the weight of a point exactly on the centre line and edge of the region respectively. Point weights in-between are blended.",
                "type": "Par",
                "name": "weight2"
            },
            {
                "text": "The Capture Region SOP<uses region colors for helpful feedback.\t\n\t\t\t\nBy default the region inherits the color of its containing object (via an expression).",
                "type": "Par",
                "name": "colorr"
            },
            {
                "text": "The Capture Region SOP<uses region colors for helpful feedback.\t\n\t\t\t\nBy default the region inherits the color of its containing object (via an expression).",
                "type": "Par",
                "name": "colorg"
            },
            {
                "text": "The Capture Region SOP<uses region colors for helpful feedback.\t\n\t\t\t\nBy default the region inherits the color of its containing object (via an expression).",
                "type": "Par",
                "name": "colorb"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Capture Region SOP defines capture region (cregion), which is a type of primitive which can be thought of as a modified tube primitive (a tube with half a sphere on either end). The hemispheres on the ends of the tubes are called \"caps\". Like any other primitive, each Capture Region has a primitive number and can be assigned primitive attributes. A Capture Region is simply a volume which is used to define the point capture weighting for a geometry. It is then animated to deform the geometry.\t\t\n\t\t\t\nCapture Regions are always shown in wireframe (even in shaded mode) so that you can focus on the geometry for which the region will act on.",
        "opLabel": "Capture Region",
        "opLicense": "Non-Commercial",
        "opFamily": "SOP",
        "short": "The Capture Region SOP defines capture region (cregion), which is a type of primitive which can be thought of as a modified tube primitive (a tube with half a sphere on either end).",
        "opType": "cregion",
        "opFilter": "False",
        "opClass": "captureregionSOP_Class",
        "opCategories": ""
    },
    "captureSOP": {
        "label": "captureSOP",
        "members": [
            {
                "text": "Menu : Use this menu to specify where to get the weight from.",
                "type": "Par",
                "name": "weightfrom"
            },
            {
                "text": "Menu : This option colors each point by capture region (using point attributes) according to its capture weight. The points inherit their colors from the Capture Region(s) in which they lie. For example, if a point falls within a blue capture region and also a yellow capture region, the point will be colored green (more blue near if the blue weighting dominates, and more yellow if the yellow weight dominates). In addition, the points become darker as the weighting gets lighter. For example, near the edge of a blue region, a caught point will appear dark blue. Near the centre, it will appear bright blue. If a point is not caught by any region, it is colored bright red.",
                "type": "Par",
                "name": "color"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "capture",
        "opFilter": "True",
        "short": "The Capture SOP is used to weight points in a geometry to capture regions.",
        "opLicense": "Non-Commercial",
        "opClass": "captureSOP_Class",
        "opLabel": "Capture",
        "long": "The Capture SOP is used to weight points in a geometry to capture regions. The weighting scheme is described in the next section, [[Capture Region SOP]].\t\t\n\t\t\t\nThe weights and the regions they correspond to are transferred down the SOP chain as point and detail attributes.\t\t\t\n\t\t\t\nThe Capture SOP can take an optional second input to specify extra capture regions to use in the capture process. Any capture regions that are in this second input are processed after the capture regions that are in the object hierarchy specified by the <span class=\"tipTextSOP\">Hierarchy</span> parameter. You can also specify a second input and not specify a Parent Object at all.",
        "opFamily": "SOP",
        "opCategories": ""
    },
    "choptoSOP": {
        "label": "choptoSOP",
        "members": [
            {
                "text": "Sets the bounds for positions that are not defined by a channel, ie. a channel is not set to one of the P attributes.",
                "type": "Par",
                "name": "startposx"
            },
            {
                "text": "Sets the bounds for positions that are not defined by a channel, ie. a channel is not set to one of the P attributes.",
                "type": "Par",
                "name": "startposy"
            },
            {
                "text": "Sets the bounds for positions that are not defined by a channel, ie. a channel is not set to one of the P attributes.",
                "type": "Par",
                "name": "startposz"
            },
            {
                "text": "Sets the bounds for positions that are not defined by a channel, ie. a channel is not set to one of the P attributes.",
                "type": "Par",
                "name": "endposx"
            },
            {
                "text": "Sets the bounds for positions that are not defined by a channel, ie. a channel is not set to one of the P attributes.",
                "type": "Par",
                "name": "endposy"
            },
            {
                "text": "Sets the bounds for positions that are not defined by a channel, ie. a channel is not set to one of the P attributes.",
                "type": "Par",
                "name": "endposz"
            },
            {
                "text": " : The sample data fetch method:",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : Determines how the CHOP samples are mapped to the geometry points.",
                "type": "Par",
                "name": "mapping"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "chopto",
        "opFilter": "False",
        "short": "The CHOP to SOP takes CHOP channels and generates 3D polygons in a SOP.",
        "opLicense": "Non-Commercial",
        "opClass": "choptoSOP_Class",
        "opLabel": "CHOP to",
        "long": "The CHOP to SOP takes CHOP channels and generates 3D polygons in a SOP. It reads sample data from a [[CHOP]] and converts it into point positions and point attributes. This makes it complementary to the [[SOP to CHOP]]. The Channels created by the [[SOP to CHOP]] can be modified and then re-inserted into the SOP network via a CHOP to SOP.\t\n\t\t\nBy default, the SOP is a line from (<code>-1 0 0</code>) to (<code>1 0 0</code>) containing one point for every sample in the CHOP.\t\t\n \t\t\nIt matches the input channels to the Channel Scope (<code>tx ty tz</code>) where possible. If <code>tx</code> or <code>ty</code> or <code>tz</code> don\u2019t match anything, it just uses the value from the default line, and it only shows a Warning.\t\t\n\t\t\nThe simplest thing to do is to send it a channel named <code>ty</code>, which will make a 3D curve that looks like the CHOP curve.\t\t\n\t\t\nThis does what a [[Point SOP]] with a <code>op('wave1')['chan1'].eval(0)</code> function can do, but is much faster.\t\t\n\t\t\nBy using point groups from the incoming SOP, the channels can be inserted only into the group's points.\t\t\n\t\t\nThe CHOP to SOP also supports custom attributes. If the user maps a channel to an attribute that is not found, that attribute is added to the points.  Currently, all custom attributes are floats and of size = 1. \t\t\n\t\t\nIn its default state it will attempt to replace the point positions (<code>P(0) P(1) P(2)</code>) with the channels named <code>tx ty</code> and <code>tz</code>.\t\t\n\t\t\nThe channel and attribute scope are first expanded into individual names and matched on a 1 to 1 basis. If you are filling P it doesn't matter if you specify <code>t[xyz]</code> or <code>tx ty tz</code>, both will replace <code>P(0) P(1) P(2)</code>, which can be collapsed to <code>P</code>.\t\t\n\t\t\nFor example: Add custom attributes \"Scale\", \"Twist\" or \"Roll\" to the backbone's points with a CHOP to SOP.\t\t\n\t\t\nIf you connect a SOP to its input, it will use the SOP as a starting geometry versus the default line.",
        "opFamily": "SOP",
        "opCategories": ""
    },
    "circleSOP": {
        "label": "circleSOP",
        "members": [
            {
                "text": "Menu : For information on the different types, see the [http://www.derivativeinc.com/Tools/Touch000/Manual/Guides/GeoTypesGuide/GeometryTypes.pdf Geometry Types Guide]. Depending on the primitive type chosen, some SOP options may not apply.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : The plane on which the circle lies.",
                "type": "Par",
                "name": "orient"
            },
            {
                "text": "The Radius of the Circle in the X and Y directions.",
                "type": "Par",
                "name": "radx"
            },
            {
                "text": "The Radius of the Circle in the X and Y directions.",
                "type": "Par",
                "name": "rady"
            },
            {
                "text": "The Center of the Circle in X, Y and Z.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "The Center of the Circle in X, Y and Z.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "The Center of the Circle in X, Y and Z.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Menu : Determines how the circle should be drawn. Applies to polygons and imperfect splines only.",
                "type": "Par",
                "name": "arc"
            },
            {
                "text": "Float : The beginning and ending angles of the arc. An arc will start at the beginning angle, and proceed towards the ending angle. If beginning=0 and end=360 it will be a full circle. As a reference:\t\n\t\t\n<div><center>[[Image:TouchGeometry222.gif]]</center></div>\t\t\n\t\t\n'''Note:''' The total angle can exceed 360, making multiple wraps of the circle.",
                "type": "Par",
                "name": "angle"
            },
            {
                "text": "Menu : Option to include texture cooordinates or not.",
                "type": "Par",
                "name": "texture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "circle",
        "opFilter": "False",
        "short": "The Circle SOP creates open or closed arcs, circles and ellipses.",
        "opLicense": "Non-Commercial",
        "opClass": "circleSOP_Class",
        "opLabel": "Circle",
        "long": "The Circle SOP creates open or closed arcs, circles and ellipses.\t\n\t\t\nIf two NURBS circles that are non-rational (i.e. their X and Y radii are unequal) are skinned, more isoparms may be generated than expected. This is because non-rational NURBS circles parameterise their knots based on chord length, and the Skin SOP must consolidate the total number of knots between the two circles before skinning.\t\t\n\t\t\nTo remedy this, you may want to use a Refine SOP, and unrefine the resulting skin, or better yet - before unrefining, start with the same circle and use a Primitive or Transform SOP to deform the second copy before skinning.",
        "opFamily": "SOP",
        "opCategories": ""
    },
    "claySOP": {
        "label": "claySOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "clay",
        "opFilter": "True",
        "short": "The Clay SOP deforms faces and surfaces by pulling points that lie directly on them.",
        "opLicense": "Non-Commercial",
        "opClass": "claySOP_Class",
        "opLabel": "Clay",
        "long": "The Clay SOP deforms faces and surfaces by pulling points that lie directly on them. As opposed to the Point SOP or other SOPs that manipulate control points (CVs), the Clay SOP operates on the primitive contours themselves, providing a direct, intuitive, and unconstrained way of reshaping geometry. Thus, rather than translating CVs to change the aspect of the primitive, the Clay SOP takes the inverse approach of manipulating the primitive's skin to reposition the CVs.\t\t\n\t\t\t\nThe point that defines the area to be modified is called a \"target point\" or \"target\" for short. It is expressed as a (u,v) pair in the parametric space of the primitive and ranges between 0 and 1 in both U and V. The image of the target point on the primitive is a 3D point which Clay can displace in several ways. Furthermore, if the primitive is a surface, there is are options to pull only the point or a whole isoparametric curve in either U or V.\t\t\t\n\t\t\t\nClay does not refine the faces and surfaces unless asked to, so the complexity of the geometry does not increase. The area affected by the change varies with each primitive type and topology. In all cases it is possible to reduce to amount of change by inserting a Refine SOP before the Clay SOP and inserting detail around the target point. For other ways to increase the locality of the deformation as well as its sharpness, see U and V Sharpness below.\t\t\t\n\t\t\t\nIf a second input is present, it is possible to snap the target (u,v) point to an (s,t) point on the first primitive of the second input. Without a second input, the primitives can be made to snap to themselves. Moreover, the Clay SOP is able to snap the target to arbitrary points in space.\t\t\t\n\t\t\t\nBoth this SOP and the Align SOP can be used effectively as snapping tools and building blocks for curve networks. The main difference between the two SOPs is that Clay deforms the inputs partially, while Align translates and/or rotates the whole primitive.\t\t\t\n\t\t\t\nThe Clay SOP accepts a mix of any combination of face and surface types.",
        "opFamily": "SOP",
        "opCategories": ""
    },
    "clipSOP": {
        "label": "clipSOP",
        "members": [
            {
                "text": "Menu : Options controlling what part of the clip to keep:",
                "type": "Par",
                "name": "clipop"
            },
            {
                "text": "The default values of <code>0 1 0</code> creates a Normal vector straight up in Y, which is perpendicular to the XZ plane, which becomes the clipping plane. <code>1 0 0</code> points the normal in positive X, giving a clipping plane in YZ. The plane may be positioned at an angle by using values typed in (<code>1 1 0</code> gives a 45 angle plane) or interactively by using the direction vector jack.",
                "type": "Par",
                "name": "dirx"
            },
            {
                "text": "The default values of <code>0 1 0</code> creates a Normal vector straight up in Y, which is perpendicular to the XZ plane, which becomes the clipping plane. <code>1 0 0</code> points the normal in positive X, giving a clipping plane in YZ. The plane may be positioned at an angle by using values typed in (<code>1 1 0</code> gives a 45 angle plane) or interactively by using the direction vector jack.",
                "type": "Par",
                "name": "diry"
            },
            {
                "text": "The default values of <code>0 1 0</code> creates a Normal vector straight up in Y, which is perpendicular to the XZ plane, which becomes the clipping plane. <code>1 0 0</code> points the normal in positive X, giving a clipping plane in YZ. The plane may be positioned at an angle by using values typed in (<code>1 1 0</code> gives a 45 angle plane) or interactively by using the direction vector jack.",
                "type": "Par",
                "name": "dirz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "clip",
        "opFilter": "True",
        "short": "The Clip SOP cuts and creases source geometry with a plane.",
        "opLicense": "Non-Commercial",
        "opClass": "clipSOP_Class",
        "opLabel": "Clip",
        "long": "The Clip SOP cuts and creases source geometry with a plane.",
        "opFamily": "SOP",
        "opCategories": ""
    },
    "convertSOP": {
        "label": "convertSOP",
        "members": [
            {
                "text": "Menu : Determines which geometry by type will be converted. The default is All Types:",
                "type": "Par",
                "name": "fromtype"
            },
            {
                "text": "Menu : Determines what the above From Type geometry will be converted to. Conversion to Polygons is the default:\t\n\t\t\n\t\t\n'''Notes''':\t\t\nNot all geometry can be converted to specific types. For example, a triangulated polygon surface to a single NURBS surface, or a Mesh sphere into a primitive sphere. Also, certain conversions will preserve shapes. For example, converting a Bzier curve to a NURBS curve or a polygonal mesh to a NURBS Surface.\t\t\n\t\t\n'''Circle Notes''': Converting to primitive circles is available for action users who are used to working with polygon circles so that you can convert them to primitive circles for the TouchDesigner Skeleton, Arm, and Limb SOPs.\t\t\n\t\t\n'''Trimmed Surface Notes''': If the primitive to be converted is a curve (NURBS or Bezier) and is flat, a trimmed surface will be generated such that the visible piece coincides with the curve. If the curve is not flat, it will be converted to a non-trimmed surface. The advantage of the trimmed solution is that it yields a very clean surface and handles concave curves perfectly.",
                "type": "Par",
                "name": "totype"
            },
            {
                "text": "Menu : This option is used to select how the points of the created surface are connected.",
                "type": "Par",
                "name": "surftype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "convert",
        "opFilter": "True",
        "short": "The Convert SOP converts geometry from one geometry type to another type.",
        "opLicense": "Non-Commercial",
        "opClass": "convertSOP_Class",
        "opLabel": "Convert",
        "long": "The Convert SOP converts geometry from one geometry type to another type. Types include polygon, mesh, Bezier patche, particle and sphere primitive.",
        "opFamily": "SOP",
        "opCategories": ""
    },
    "copySOP": {
        "label": "copySOP",
        "members": [
            {
                "text": "Menu : Sets the overall transform order for the transformations. The <span class=\"tipTextSOP\">Transform Order</span> determines the order in which transformations take place. Depending on the order, you can achieve different results using the exact same values. Choose the appropriate order from the menu.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : Sets the order of the rotations within the overall transform order.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "These allow you to specify the Translation (how much it moves over in a given direction), Rotation, and the Scale between each copy. Three columns are given for X, Y, and Z coordinates. Guide geometry is provided for the Pivot's translations. The Pivot is represented by a single red dot in the Viewport. Changing the Pivot parameters moves this point of reference.",
                "type": "Par",
                "name": "pz"
            },
            {
                "text": "When specifying a Look At, it is possible to specify an up vector for the lookat. Without using an up vector, it is possible to get poor animation when the lookat object passes through the Y axis of the target object.",
                "type": "Par",
                "name": "upvectorx"
            },
            {
                "text": "When specifying a Look At, it is possible to specify an up vector for the lookat. Without using an up vector, it is possible to get poor animation when the lookat object passes through the Y axis of the target object.",
                "type": "Par",
                "name": "upvectory"
            },
            {
                "text": "When specifying a Look At, it is possible to specify an up vector for the lookat. Without using an up vector, it is possible to get poor animation when the lookat object passes through the Y axis of the target object.",
                "type": "Par",
                "name": "upvectorz"
            },
            {
                "text": "StrMenu : Copy the attributes to the source geometry's points.",
                "type": "Par",
                "name": "setpt"
            },
            {
                "text": "StrMenu : Copy the attributes to the source geometry's primitives.",
                "type": "Par",
                "name": "setprim"
            },
            {
                "text": "StrMenu : Copy the attributes to the source geometry's vertices.",
                "type": "Par",
                "name": "setvtx"
            },
            {
                "text": "StrMenu : Multiply the attributes with the source geometry's point attributes.",
                "type": "Par",
                "name": "mulpt"
            },
            {
                "text": "StrMenu : Multiply the attributes with the source geometry's primitive attributes.",
                "type": "Par",
                "name": "mulprim"
            },
            {
                "text": "StrMenu : Multiply the attributes with the source geometry's vertex attributes.",
                "type": "Par",
                "name": "mulvtx"
            },
            {
                "text": "StrMenu : Add the attributes to the source geometry's point attributes.",
                "type": "Par",
                "name": "addpt"
            },
            {
                "text": "StrMenu : Add the attributes to the source geometry's primitive attributes.",
                "type": "Par",
                "name": "addprim"
            },
            {
                "text": "StrMenu : Add the attributes to the source geometry's vertex attributes.",
                "type": "Par",
                "name": "addvtx"
            },
            {
                "text": "StrMenu : Subtract the attributes from the source geometry's point attributes.",
                "type": "Par",
                "name": "subpt"
            },
            {
                "text": "StrMenu : Subtract the attributes from the source geometry's primitive attributes.",
                "type": "Par",
                "name": "subprim"
            },
            {
                "text": "StrMenu : Subtract the attributes from the source geometry's vertex attributes.",
                "type": "Par",
                "name": "subvtx"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opFilter": "True",
        "opType": "copy",
        "opLicense": "Non-Commercial",
        "opClass": "copySOP_Class",
        "short": "The Copy SOP lets you make copies of the geometry of other SOPs and apply a transformation to each copy.",
        "long": "The Copy SOP lets you make copies of the geometry of other SOPs and apply a transformation to each copy.\t\t\n\t\t\t\nIt also allows you to copy geometry to points on an input template.",
        "opLabel": "Copy",
        "opCategories": ""
    },
    "cplusplusSOP": {
        "label": "cplusplusSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opType": "cplusplus",
        "opLabel": "CPlusPlus",
        "opLicense": "Non-Commercial",
        "opClass": "cplusplusSOP_Class",
        "opFilter": "False",
        "short": "The CPlusPlus SOP allows you to make custom SOP operators by writing your own plugin using C++.",
        "long": "The CPlusPlus SOP allows you to make custom SOP operators by writing your own plugin using C++.\n\nSee [[Write a CPlusPlus Plugin]] and the other articles in the [[:Category:C++|C++ category]] for more detailed information on how to make .dll for use with this SOP.\n \nThe C++ code can be written for GPU or CPU loading. The ease of developing C++ code for either of these two options are fairly similar. Nevertheless, by setting the \u201c<code>directToGPU</code>\u201d flag within the C++ code, only one of these modes is recognized as a valid mode. Different classes are dedicated for each of these two modes, so bear in mind that setting the \u201c<code>directToGPU</code>\u201d flag to \u201c<code>true</code>\u201d or \u201c<code>false</code>\u201d requires different classes and functions to be called within either of <code>execute()</code> or <code>executeVBO()</code>.\n\nIn CPU mode, the geometry data can be added one at a time or all at once. As well, in CPU mode the CPlusPlus SOP can use wired SOP inputs and SOP to DAT, SOP to CHOP, or SOP output OPs as well. Additionally DAT, CHOP, and TOP 'non-wired' input operators can be used as custom parameters. In this case, the custom parameters must be first handled in the C++ code to be able to accept any input from the other operators. \n\nThe GPU direct mode is similar to CPU mode, but it cannot use any output SOPs downstream or be accessed by SOP to DAT or SOP to CHOP operators. In GPU direct mode the data is added to the VBO buffers immediately which improves the performance through faster updating, however the size of the vertices and face array indices must be known prior to filling the buffers. \n\nExample for CPlusPlus SOP as a Visual Studio project in Windows are available in <code>C:/Program Files/Derivative/TouchDesigner/Samples/CPlusPlus/SimpleShapesSOP</code> or your custom TouchDesigner installation folder. (NOTE: On macOS it is here: <code>TouchDesigner.app/Contents/Resources/tfs/Samples/CPlusPlus/SimpleShapesSOP</code>)\n\n'''Custom Parameters''' - Custom Parameters can be automatically created by the C++ SOP <code>.dll</code>. This custom parameter page can be removed, edited, or appended to from within the <code>setupParameters()</code> function in SimpleShapes.cpp. The defined custom parameters can be enabled or disabled depending on whether they are valid for a specific task or not. \n\n'''Geometry Data''' - Geometry within the C++ SOP code can be defined by any algorithm or even imported from external files. The possible geometries are triangular meshes and particle systems. Note that if your original geometry has polygons with more than 3 vertices, they must be converted to triangles with known and valid vertex indices, before being added to the list of triangles.\n\nThe geometry data for exporting to TouchDesigner can have point, normal, and texture coordinates, RGBA colors, triangle information in case of meshes and/or particle systems, as well as custom attributes with an arbitrary name, float or integer type, and up to 4 components (ie. Cd0, Cd1, Cd2, Cd3).",
        "opCategories": ""
    },
    "creepSOP": {
        "label": "creepSOP",
        "members": [
            {
                "text": "Menu : The Source Input is Translated, Rotated and Scaled so as to complete the given options listed below.",
                "type": "Par",
                "name": "resetmethod"
            },
            {
                "text": "Translate the Source Input Creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translate the Source Input Creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Translate the Source Input Creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Rotate the Source Input creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "Rotate the Source Input creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "Rotate the Source Input creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "Scale the Source Input creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scale the Source Input creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Scale the Source Input creep geometry on the surface of the Path Input.",
                "type": "Par",
                "name": "sz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opFilter": "True",
        "opType": "creep",
        "opLicense": "Non-Commercial",
        "opClass": "creepSOP_Class",
        "short": "The Creep SOP lets you deform and animate Source Input geometry along the surface of the Path Input geometry.",
        "long": "The Creep SOP lets you deform and animate Source Input (input0) geometry along the surface of the Path Input (input1) geometry.",
        "opLabel": "Creep",
        "opCategories": ""
    },
    "curveclaySOP": {
        "label": "curveclaySOP",
        "members": [
            {
                "text": "Menu : Choice of several projection axes:",
                "type": "Par",
                "name": "projop"
            },
            {
                "text": "Specify the direction vector of the projection.",
                "type": "Par",
                "name": "projdir1"
            },
            {
                "text": "Specify the direction vector of the projection.",
                "type": "Par",
                "name": "projdir2"
            },
            {
                "text": "Specify the direction vector of the projection.",
                "type": "Par",
                "name": "projdir3"
            },
            {
                "text": "Menu : Choice of several projection axes:",
                "type": "Par",
                "name": "deformop"
            },
            {
                "text": "Specify the direction vector of the displacement.",
                "type": "Par",
                "name": "deformdir1"
            },
            {
                "text": "Specify the direction vector of the displacement.",
                "type": "Par",
                "name": "deformdir2"
            },
            {
                "text": "Specify the direction vector of the displacement.",
                "type": "Par",
                "name": "deformdir3"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opFilter": "True",
        "opType": "curveclay",
        "opLicense": "Non-Commercial",
        "opClass": "curveclaySOP_Class",
        "short": "The Curveclay SOP is similar to the Clay SOP in that you deform a spline surface not by modifying the CVs but by directly manipulating the surface.",
        "long": "The Curveclay SOP is similar to the Clay SOP in that you deform a spline surface not by modifying the CVs but by directly manipulating the surface. However, instead of using a point on the surface, you use one or more faces to deform that surface. Also, CurveClay does not yet support polygonal meshes. <br><br>\t\t\nThe combination of inputs will determine the modes of transformation. For any combination of inputs, the following parameters modify the following behaviors of the SOP.",
        "opLabel": "Curveclay",
        "opCategories": ""
    },
    "dattoSOP": {
        "label": "dattoSOP",
        "members": [
            {
                "text": "Menu : Specify whether to merge point data or primitive data. This parameter is only enabled when there is an input connected to the SOP.",
                "type": "Par",
                "name": "merge"
            },
            {
                "text": "Menu : Specifies how to build geometry.",
                "type": "Par",
                "name": "build"
            },
            {
                "text": "Menu : Connectivity of polygons.",
                "type": "Par",
                "name": "connect"
            },
            {
                "text": "Menu : When creating a particle system, specify to render the particles as lines or point sprites.",
                "type": "Par",
                "name": "prtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The DAT to SOP can be used to create geometry from DAT tables, or if a SOP input is specified, to modify attributes on existing geometry.",
        "opLicense": "Non-Commercial",
        "opClass": "dattoSOP_Class",
        "opLabel": "DAT to",
        "long": "The DAT to SOP can be used to create geometry from DAT tables, or if a SOP input is specified, to modify attributes on existing geometry. See also the [[Add SOP]].\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nWithout a SOP input, the output is created entirely from the DAT, one SOP point per row of the DAT, except for an optional top row with column headings. The common columns headings include the point number <code>index</code>, point position <code>P(0) P(1) P(2)</code>, point weight <code>Pw</code>, the color and alpha <code>Cd(0) Cd(1) Cd(2) Cd(3)</code>, texture coordinates <code>uv(0) uv(1) uv(2)</code>, and point normal <code>N(0) N(1) N(2)</code>. If no index column is specified, row number is used as the point number. If there is no heading for the Point DAT, the list of attributes is assumed to be in order <code>P(0) P(1) P(2) Pw Cd(0) Cd(1) Cd(2) Cd(3) N(0) N(1) N(2) uv(0) uv(1) uv(2)</code> for the first 14 columns.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nIf an input is used, attributes are read in and replace the ones in the existing geometry. The <span class=\"tipTextSOP\">Merge</span> parameter will be enabled when an input is connected. Depending on the Merge menu setting, either the  <span class=\"tipTextSOP\">Points DAT</span> or  <span class=\"tipTextSOP\">Primitive DAT</span> parameter used for the merge data. If an input is used, the Points or Primitives DAT must have a column named <code>''index''</code>. This column is used to match the point or primitive to the incoming geometry by point or primitive number.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nAttributes in the columns headings should have column name ''<code>attrib</code>'' if it is a single value attribute, or have multiple columns named <code>''attrib''(0)</code>, <code>''attrib''(1)</code>, <code>''attrib''(2)</code> etc if it is a multiple-value attribute.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nData can also be converted into a form that can be rendered as particles.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n'''Example File :''' [[File:SOPtoDATtoSOP.tox]]",
        "opType": "datto",
        "opCategories": ""
    },
    "extrudeSOP": {
        "label": "extrudeSOP",
        "members": [
            {
                "text": "Menu : This should almost always be turned on when cross-sections are used. It consolidates points of polygons that would otherwise cross or overlap when the bevel takes place.",
                "type": "Par",
                "name": "dofuse"
            },
            {
                "text": "Menu : Control how the front face of the extrusion should be built. You may wish to have a \"No Output\" because some faces are never actually seen when doing animation and, therefore, would only take up additional overhead if left on.",
                "type": "Par",
                "name": "fronttype"
            },
            {
                "text": "Menu : This value controls whether or not the back of the extruded object will have a face or not. The options are the same as the Front Face options above.",
                "type": "Par",
                "name": "backtype"
            },
            {
                "text": "Menu : Controls how the cross-section(s) will be extruded. If the input cross-section is a Bzier or NURBS curve, the surface will be constructed with a patch of the same geometry type.",
                "type": "Par",
                "name": "sidetype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "extrudeSOP_Class",
        "opType": "extrude",
        "opLicense": "Non-Commercial",
        "opLabel": "Extrude",
        "long": "The Extrude SOP can be used for:\t\t\n* Extruding and bevelling Text and other geometry\t\t\t\n* Cusping the bevelled edges to get sharp edges\t\t\t\n* Making primitives thicker or thinner'''\t\t\t\n\t\nThe default is a 1 unit extrusion directly backwards from the input geometry's normals.\n\nIt uses the normal of the surface to determine the direction of extrusion. In the case of planar or open polygons, the normal is difficult to determine, and may not always provide the result that you expect. Turn on the Primitive Normals display in the [[Viewer]] display options to see the normals.\n\nThe extrusion is created by extending surfaces from the vertices of the input geometry along the cross-section curve given in the second input (Input 1). The first vertex of the cross-section curve is placed by default at the vertices of the input geometry and aligned so that the curve's positive Y axis extends opposite to the input geometry's normal. The cross-section's positive X axis by default extends outwards from center of the input geometry.\n\nIf no cross-section curve is given, a vertical line going from (0,0,0) to (0,1,0) is used. This results in a 1 unit extrusion directly backwards from the input geometry's normals. As another example, using a straight line from (0,0,0) to (.1,.1,0) will result in an extrusion that extends 1 unit backwards from the input and flares .1 unit outwards on all sides. The Thickness and Depth parameters can be used to shift and scale the cross-section without directly changing the curve.\n\n'''Note:''' The shape of the cross-section is always relative to its first vertex, so shifting the entire cross-section curve will have no effect. Also, only the X and Y axes of the curve are used i.e. Z position values are ignored.\n\nAfter the new geometry is created, normals are computed by default.\n\n'''Warning:''' If you take a default output from a [[Text SOP]] and Extrude it, it may have bad rendering artifacts (and too many polygons) as it's extruding each of the triangles of the triangulated letters. You need to change the Output parameter of the Text SOP to Closed Polygons. See [[OP Snippets]].",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Extrude SOP can be used for extruding and bevelling Text and other geometry, cusping the bevelled edges to get sharp edges, and making primitives thicker or thinner.",
        "opCategories": ""
    },
    "facetrackSOP": {
        "label": "facetrackSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opType": "facetrackSOP",
        "opLabel": "Face Track",
        "opClass": "facetrackSOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "os": "Microsoft Windows",
        "hardware": "This operator uses the Augmented Reality (AR) SDK of the Nvidia Maxine system and requires a 20 or 30 series Nvidia RTX card to operate. 40 series cards are supported in 2023 and newer releases.",
        "short": "Provides accesses to the fitted face mesh generated by the Face Track CHOP.",
        "long": "The Face Track SOP provides accesses to the fitted face mesh generated by the Face Track CHOP. It can either be uploaded directly to the GPU for rendering or passed along to other SOPs for further modification. By default, the mesh is pre-transformed to align with the source face of the input image (x, y positions equal image u,v positions). However, you can also disable the pre-transform which will leave the fitted mesh at the origin in the original scale. The mesh can still be aligned with the image using the tx, ty, rx, etc channels of the [[Face Track CHOP]].\n    \n'''Note: ''' To use this feature you will need to provide a compatible 3D morphable face mesh file in Nvidia 'nvf' format to the 'Mesh File' parameter of the [[Face Track CHOP]]. This file does not ship with TouchDesigner, but instructions on creating one are provided on the [[Face Track CHOP]] page.",
        "opCategories": ""
    },
    "facetSOP": {
        "label": "facetSOP",
        "members": [
            {
                "text": "Menu : Consolidate eliminates the redundancy of having many points that are close to each other, by merging them together to form a fewer set of common points. Consolidate is useful for cleaning up an edge that may appear between adjacent polygons that have been merged.",
                "type": "Par",
                "name": "cons"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "facetSOP_Class",
        "opType": "facet",
        "opLicense": "Non-Commercial",
        "opLabel": "Facet",
        "long": "The Facet SOP lets you control the smoothness of faceting of a given object. It also lets you consolidate points or surface normals.\t\n\t\t\nThe Facet SOP, like [[Divide SOP]], works as a pipeline to change geometry in stages. For this reason, Compute Normals appears twice. For example, you can compute surface normals before making vertices (the points of each polygon) unique, which gives you the unusual result of smooth shading and unique point, as the normals get computed while the points are still shared.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Facet SOP lets you control the smoothness of faceting of a given object.",
        "opCategories": ""
    },
    "fileinSOP": {
        "label": "fileinSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "fileinSOP_Class",
        "opType": "filein",
        "opLicense": "Non-Commercial",
        "opLabel": "File In",
        "long": "The File In SOP allows you to read a geometry file that may have been previously created in the Model Editor, output geometry from a SOP, or generated from other software such as [http://www.sidefx.com Houdini]. The geometry file can be read in from disk or from the web. Use http:// when specifying a URL.",
        "opFilter": "False",
        "opFamily": "SOP",
        "short": "The File In SOP allows you to read a geometry file that may have been previously created in the Model Editor, output geometry from a SOP, or generated from other software such as [http://www.sidefx.com Houdini].",
        "opCategories": ""
    },
    "fitSOP": {
        "label": "fitSOP",
        "members": [
            {
                "text": "Menu : Specifies one of two fitting styles: approximation or interpolation. Each style has a number of parameters that are accessible from the respective folder. For more information see the Approximation and Interpolation pages below.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : The output of the Fit SOP is a NURBS or Bzier primitive. All input faces are fitted to Spline curves, and all input surfaces are fitted to spline surfaces. The resulting shapes are identical whether created as NURBS or as Bzier primitives.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : This option is used to select the type of surface, when using a Mesh Primitive Type.",
                "type": "Par",
                "name": "surftype"
            },
            {
                "text": "Menu : Scope establishes the interpolation method.",
                "type": "Par",
                "name": "scope"
            },
            {
                "text": "Menu : Specifies the parameterization of the data in the U direction (the only direction if the input is a curve). The data parameterization can be uniform, chord length, or centripetal.\t\n\t\t\t\n: Uniform Uniform parameterization uses equally spaced parameter values. It works best when the geometry is very regular. When the data is unevenly spaced, this approach can produce very unintuitive shapes, and is not recommended.\t\t\t\n: Chord Length Chord length computes the parameterization of the data based on the relative distances between successive data points. It is the most commonly used approach because is tends to produce the most accurate results.\t\t\t\n: Centripetal Centripetal parameterization is similar to chord length, but yields better results when the data has very sharp corners.",
                "type": "Par",
                "name": "dataparmu"
            },
            {
                "text": "Menu : V data parameterization is identical to U data parameterization, but it affects the V direction when the input is a surface. It is not used when the input is a face.",
                "type": "Par",
                "name": "dataparmv"
            },
            {
                "text": "Menu : This menu determines whether the fitted curve should be closed, or whether the fitted surface should be wrapped in the U parametric direction. The options are to open (Off), close (On), or inherit the closure type from the input primitive.",
                "type": "Par",
                "name": "closeu"
            },
            {
                "text": "Menu : This menu determines whether the fitted surface should be wrapped in the V parametric direction. The options are to open (Off), close (On), or inherit the closure type from the input primitive. V Wrap is ignored when the input is a face.",
                "type": "Par",
                "name": "closev"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "fitSOP_Class",
        "opType": "fit",
        "opLicense": "Non-Commercial",
        "opLabel": "Fit",
        "long": "The Fit SOP fits a Spline curve to a sequence of points or a Spline surface to an m X n mesh of points.\t\t\n\t\t\t\nAny type of face or surface represents a valid input. The Fit SOP looks only at the control vertices (CVs) of the primitives, treating the CVs as data points to run the fit through. For example, if a cubic NURBS surface and a mesh have the same number of rows and columns and identical points, they will yield an identical fit because the Spline bases of the input NURBS surface are ignored.\t\t\t\n\t\t\t\nThe Fit SOP generates two types of outputs: primitives that roughly follow the path of the data points without necessarily going through the data points; and primitives that touch all the data points. The first type, known as \"approximation\", is used primarily to extract a lean, smooth shape from a heavy data set, lending itself well to data reduction. The second type, known as \"interpolation\", often serves as a smoothing tool for paths that must go through specified target positions.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Fit SOP fits a Spline curve to a sequence of points or a Spline surface to an m X n mesh of points.",
        "opCategories": ""
    },
    "fontSOP": {
        "label": "fontSOP",
        "members": [
            {
                "text": " : Select from the following types. For information on the different types, see the Geometry Types section. Bzier Curves and Polygons provide the most efficient use of memory, because they use polygons for letters containing straight segments, and Bzier curves for all others.\t\n\t\t\n'''Note:''' Due to an Open GL bug, holes in Bzier fonts may shade incorrectly.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Translates the geometry in x, y and z.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translates the geometry in x, y and z.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Translates the geometry in x, y and z.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Scales the text in the X and Y axis.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scales the text in the X and Y axis.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Letter spacing in the X direction. Line spacing in the Y direction if there are multiple lines. If you need manual character-by-character, you can do it in Model mode.",
                "type": "Par",
                "name": "kernx"
            },
            {
                "text": "Letter spacing in the X direction. Line spacing in the Y direction if there are multiple lines. If you need manual character-by-character, you can do it in Model mode.",
                "type": "Par",
                "name": "kerny"
            },
            {
                "text": " : This adds uv coordinates to the geometry created by the Font SOP.",
                "type": "Par",
                "name": "texture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "fontSOP_Class",
        "opType": "font",
        "opLicense": "Non-Commercial",
        "opLabel": "Font",
        "long": "'''Note''': Font SOP deprecated build 2019.14650, use [[Text TOP]]. \n    \nThe Font SOP allows you to create text in your model from Adobe Type 1 Postscript Fonts.\t\n\t\t\nTo install fonts, copy the font files to the <code>$TFS/touch/fonts</code> directory of your installation path. They will be ready to be used in the Font SOP after restarting TouchDesigner.\t\t\n\t\t\nThe fonts located in <code>$TFS/touch/fonts_g</code>l are not for the Font SOP, they are for the TouchDesigner UI only.",
        "opFilter": "False",
        "opFamily": "SOP",
        "short": "'''Note''': Font SOP deprecated build 2019.14650, use [[Text TOP]]. The Font SOP allows you to create text in your model from Adobe Type 1 Postscript Fonts."
    },
    "fractalSOP": {
        "label": "fractalSOP",
        "members": [
            {
                "text": "The direction of the Fractalisation. The default values of <code>0, 0, 1</code> make the fractal deviations point in the Z direction. Can be overridden by: Use Vertex Normals.",
                "type": "Par",
                "name": "dirx"
            },
            {
                "text": "The direction of the Fractalisation. The default values of <code>0, 0, 1</code> make the fractal deviations point in the Z direction. Can be overridden by: Use Vertex Normals.",
                "type": "Par",
                "name": "diry"
            },
            {
                "text": "The direction of the Fractalisation. The default values of <code>0, 0, 1</code> make the fractal deviations point in the Z direction. Can be overridden by: Use Vertex Normals.",
                "type": "Par",
                "name": "dirz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "fractalSOP_Class",
        "opType": "fractal",
        "opLicense": "Non-Commercial",
        "opLabel": "Fractal",
        "long": "The Fractal SOP allows you created jagged mountain-like divisions of the input geometry. It will create random-looking deviations and sub-divisions along either a specified normal vector (the Direction xyz fields) or the vertex normals of the input geometry. This is great for the creation of terrains and landscapes.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Fractal SOP allows you created jagged mountain-like divisions of the input geometry.",
        "opCategories": ""
    },
    "gridSOP": {
        "label": "gridSOP",
        "members": [
            {
                "text": "Menu : Select from the following types. For information on the different types, see the Geometry Types section. Depending on the primitive type chosen, some SOP options may not apply.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : (Results only viewable for polygons and meshes).",
                "type": "Par",
                "name": "surftype"
            },
            {
                "text": "Menu : Specifies on which plane the Grid is built.",
                "type": "Par",
                "name": "orient"
            },
            {
                "text": "The X and Y scale of the grid.",
                "type": "Par",
                "name": "sizex"
            },
            {
                "text": "The X and Y scale of the grid.",
                "type": "Par",
                "name": "sizey"
            },
            {
                "text": "Center of grid in X, Y, and Z.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Center of grid in X, Y, and Z.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Center of grid in X, Y, and Z.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Menu : This adds uv coordinates to the geometry created by the Grid SOP.",
                "type": "Par",
                "name": "texture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "gridSOP_Class",
        "opType": "grid",
        "opLicense": "Non-Commercial",
        "opLabel": "Grid",
        "long": "The Grid SOP allows you to create grids and rectangles using polygons, a mesh, Bzier and NURBS surfaces, or multiple lines using open polygons.",
        "opFilter": "False",
        "opFamily": "SOP",
        "short": "The Grid SOP allows you to create grids and rectangles using polygons, a mesh, Bzier and NURBS surfaces, or multiple lines using open polygons.",
        "opCategories": ""
    },
    "holeSOP": {
        "label": "holeSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "holeSOP_Class",
        "opType": "hole",
        "opLicense": "Non-Commercial",
        "opLabel": "Hole",
        "long": "The Hole SOP is for making holes where faces are enclosed, even if they are not in the same plane. It can also remove existing holes from the input geometry.\n\t\nThe holes are made by searching for faces which are enclosed by other faces and creating bridges to the interior faces. It offers more flexibility than either the [[Extrude SOP]] or [[Divide SOP]]'s hole-making capabilities because it can deal with interior faces which are not exactly in the same orientation as the exterior ones. It can also remove existing bridges that it finds in the input geometry if needed.\t\n\t\n'''Note:''' This SOP works with Polygonal and Bezier geometry types only. NURBS surfaces will be converted internally to Beziers.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Hole SOP is for making holes where faces are enclosed, even if they are not in the same plane. It can also remove existing holes from the input geometry.",
        "opCategories": ""
    },
    "inSOP": {
        "label": "inSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "inSOP_Class",
        "opType": "in",
        "opLicense": "Non-Commercial",
        "opLabel": "In",
        "long": "The In SOP creates a SOP input in a Component. Component inputs are positioned alphanumerically on the left side of the node.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The In SOP creates a SOP input in a Component. Component inputs are positioned alphanumerically on the left side of the node.",
        "opCategories": ""
    },
    "isosurfaceSOP": {
        "label": "isosurfaceSOP",
        "members": [
            {
                "text": "Determines the minimum clipping plane boundary for display of iso surface.",
                "type": "Par",
                "name": "minx"
            },
            {
                "text": "Determines the minimum clipping plane boundary for display of iso surface.",
                "type": "Par",
                "name": "miny"
            },
            {
                "text": "Determines the minimum clipping plane boundary for display of iso surface.",
                "type": "Par",
                "name": "minz"
            },
            {
                "text": "Determines maximum clipping plane boundary for display of iso surfaces.",
                "type": "Par",
                "name": "maxx"
            },
            {
                "text": "Determines maximum clipping plane boundary for display of iso surfaces.",
                "type": "Par",
                "name": "maxy"
            },
            {
                "text": "Determines maximum clipping plane boundary for display of iso surfaces.",
                "type": "Par",
                "name": "maxz"
            },
            {
                "text": "The density, or resolution of the iso surface polygons in X, Y and Z.",
                "type": "Par",
                "name": "divsx"
            },
            {
                "text": "The density, or resolution of the iso surface polygons in X, Y and Z.",
                "type": "Par",
                "name": "divsy"
            },
            {
                "text": "The density, or resolution of the iso surface polygons in X, Y and Z.",
                "type": "Par",
                "name": "divsz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "isosurfaceSOP_Class",
        "opType": "iso",
        "opLicense": "Non-Commercial",
        "opLabel": "Iso Surface",
        "long": "The Iso Surface SOP uses implicit functions to create 3D visualizations of isometric surfaces found in Grade 12 Functions and Relations textbooks.\t\n\t\t\nAn implicit function is defined so that it = 0. For example with:\t\t\n<syntaxhighlight lang=python>x2 + y2 = r2</syntaxhighlight>\t\n\t\t\nthe implicit function is:\t\t\n\t\t\n<syntaxhighlight lang=python>f(x, y) = x2 + y2 - r2 = 0</syntaxhighlight>",
        "opFilter": "False",
        "opFamily": "SOP",
        "short": "The Iso Surface SOP uses implicit functions to create 3D visualizations of isometric surfaces found in Grade 12 Functions and Relations textbooks.",
        "opCategories": ""
    },
    "joinSOP": {
        "label": "joinSOP",
        "members": [
            {
                "text": "Menu : This menu determines the parametric direction of the joining operation, which can be in U or in V, and is meaningful only when the inputs are surfaces. The U direction is associated with columns; the V direction refers to rows. For example, joining two surfaces in U will generate a surface with more columns than either input. The number of rows might be higher too, but only if the two inputs have a different number of rows or a different V basis.",
                "type": "Par",
                "name": "dir"
            },
            {
                "text": "Menu : Can optionally join subgroups of n primitives or every nth primitive in a cyclical manner.\t\n\t\t\n'''For Example'''; assume there are six primitives numbered for 0 - 5, and N = 2. Then, \t\t\n\t\t\n# Groups will generate 0-1 2-3 4-5\t\t\n# Skipping will generate 0-2-6 and 1-3-5.",
                "type": "Par",
                "name": "joinop"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "joinSOP_Class",
        "opType": "join",
        "opLicense": "Non-Commercial",
        "opLabel": "Join",
        "long": "The Join SOP connects a sequence of faces or surfaces into a single primitive that inherits their attributes. Faces of different types can be joined together, and so can surfaces. Mixed face-surface types are not allowed. The surfaces do not have to have the same number of rows or columns in the side being joined. Spline types of different orders and parameterization are all valid inputs. The Join SOP converts simpler primitives such as polygons into Bziers and NURBS if necessary.\t\n\t\t\nJoining is different from filleting (see [[Fillet SOP]]) or stitching (see [[Stitch SOP]]) because it takes n primitives and converts them into one after possibly changing the connected ends of the primitives. Filleting creates a new primitive between each input pair and never affects the original shapes. Stitching changes the original shapes but does not change the number of resulting primitives.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Join SOP connects a sequence of faces or surfaces into a single primitive that inherits their attributes.",
        "opCategories": ""
    },
    "jointSOP": {
        "label": "jointSOP",
        "members": [
            {
                "text": "These parameters control the shape of the smooth path, varying the shape of the implied curve from the left or right. If the Orient Circles option is on, the sign of the scale has no effect. For a discussion of the relative terms right and left, see [[Align SOP]].",
                "type": "Par",
                "name": "lrscale1"
            },
            {
                "text": "These parameters control the shape of the smooth path, varying the shape of the implied curve from the left or right. If the Orient Circles option is on, the sign of the scale has no effect. For a discussion of the relative terms right and left, see [[Align SOP]].",
                "type": "Par",
                "name": "lrscale2"
            },
            {
                "text": "These parameters allow you to override the distance between circles, thereby affecting the shape of the joint.",
                "type": "Par",
                "name": "lroffset1"
            },
            {
                "text": "These parameters allow you to override the distance between circles, thereby affecting the shape of the joint.",
                "type": "Par",
                "name": "lroffset2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "long": "The Joint SOP will aid in the creation of circle-based skeletons by creating a series of circles between each pair of input circles. This SOP requires at least a pair of circles in order to work correctly.",
        "opLicense": "Non-Commercial",
        "opClass": "jointSOP_Class",
        "opLabel": "Joint",
        "opFamily": "SOP",
        "opType": "joint",
        "short": "The Joint SOP will aid in the creation of circle-based skeletons by creating a series of circles between each pair of input circles.",
        "opCategories": ""
    },
    "kinectSOP": {
        "label": "kinectSOP",
        "members": [
            {
                "text": "Menu : Only Kinect v1 sensors supported at this time.",
                "type": "Par",
                "name": "hwversion"
            },
            {
                "text": "Menu : Only used for Kinect 1 devices. Specify whether to track full skeleton or seated skeleton.",
                "type": "Par",
                "name": "skeleton"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "kinectSOP_Class",
        "opType": "kinect",
        "opLicense": "Non-Commercial",
        "opLabel": "Kinect",
        "long": "The Kinect SOP uses the Kinect v1 sensor to scan and create geometry.",
        "opFilter": "False",
        "opFamily": "SOP",
        "short": "The Kinect SOP uses the Kinect v1 sensor to scan and create geometry.",
        "opCategories": ""
    },
    "latticeSOP": {
        "label": "latticeSOP",
        "members": [
            {
                "text": "Menu : Choose if deformation should be done using a regularly spaced lattice or an arbitary point cloud.",
                "type": "Par",
                "name": "deformtype"
            },
            {
                "text": "Must be set to match the number of divisions in the lattice grid object(s).",
                "type": "Par",
                "name": "divsx"
            },
            {
                "text": "Must be set to match the number of divisions in the lattice grid object(s).",
                "type": "Par",
                "name": "divsy"
            },
            {
                "text": "Must be set to match the number of divisions in the lattice grid object(s).",
                "type": "Par",
                "name": "divsz"
            },
            {
                "text": "StrMenu : Deformation by specifying a Kernal Function and Points makes it easier to deform arbitrary clouds of points, as this makes the topology of the lattice behave more like a metaball rather than as a fixed lattice. ''Kernel Function'' determines which meta kernel to use to determine the influence of a point. For more information on kernel types check here: [[Metaball#Metaball_Model_Types|Metaball Model Types]]",
                "type": "Par",
                "name": "kernel"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "latticeSOP_Class",
        "opType": "lattice",
        "opLicense": "Non-Commercial",
        "opLabel": "Lattice",
        "long": "The Lattice SOP allows you to create animated deformations of its input geometry by manipulating grids or a subdivided box that encloses the input source's geometry.\t\t\n\t\t\t\nIt is much easier to deform an object by moving a few grids than trying to animate every single point of an object.\t\t\t\n\t\t\t\nThis SOP has very few buttons and looks simple, but it is important to understand how it works. The first input, called '''Geometry to Deform''', is for the geometry you wish to deform. The second input, called '''Rest Geometry''', must be an evenly spaced grid which fully encloses the geometry to deform. The third input, called '''Deformed Geometry''', is a copy of the initial grid that is altered in some way, either by moving parts of it with animation channels, dragging its points in the Model Editor, or by running it through a [[Spring SOP]] which distorts it with the forces which simulate the laws of physics. Lattice computes a deformation based on the difference between the Rest Geometry and the Deformed Geometry, and applies it to the input geometry. The output of the SOP is the deformation of the geometry in the input source. If the Deformed Geometry is being animated, the output will also bend, twist and stretch every frame.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Lattice SOP allows you to create animated deformations of its input geometry by manipulating grids or a subdivided box that encloses the input source's geometry.",
        "opCategories": ""
    },
    "lineSOP": {
        "label": "lineSOP",
        "members": [
            {
                "text": "These X,Y, and Z values set the position of the beginning of the line.",
                "type": "Par",
                "name": "pax"
            },
            {
                "text": "These X,Y, and Z values set the position of the beginning of the line.",
                "type": "Par",
                "name": "pay"
            },
            {
                "text": "These X,Y, and Z values set the position of the beginning of the line.",
                "type": "Par",
                "name": "paz"
            },
            {
                "text": "These X,Y, and Z values set the position of the end of the line.",
                "type": "Par",
                "name": "pbx"
            },
            {
                "text": "These X,Y, and Z values set the position of the end of the line.",
                "type": "Par",
                "name": "pby"
            },
            {
                "text": "These X,Y, and Z values set the position of the end of the line.",
                "type": "Par",
                "name": "pbz"
            },
            {
                "text": "Menu : Texture adds (0,1) coordinates to the vertices when set to Unit. Creates a rectangle without uv attributes when set to Off.",
                "type": "Par",
                "name": "texture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "lineSOP_Class",
        "opType": "line",
        "opLicense": "Non-Commercial",
        "opLabel": "Line",
        "long": "The Line SOP creates straight lines.",
        "opFilter": "False",
        "opFamily": "SOP",
        "short": "The Line SOP creates straight lines.",
        "opCategories": ""
    },
    "linethickSOP": {
        "label": "linethickSOP",
        "members": [
            {
                "text": "Controls the width of the surface created at the start of the line. Startwidth1 adjusts the width on the inside of the curve, Startwidth2 adjusts the width on the outside of the curve.",
                "type": "Par",
                "name": "startwidth1"
            },
            {
                "text": "Controls the width of the surface created at the start of the line. Startwidth1 adjusts the width on the inside of the curve, Startwidth2 adjusts the width on the outside of the curve.",
                "type": "Par",
                "name": "startwidth2"
            },
            {
                "text": "Controls the width of the surface created at the end of the line. Endwidth1 adjusts the width on the inside of the curve, Endwidth2 adjusts the width on the outside of the curve.",
                "type": "Par",
                "name": "endwidth1"
            },
            {
                "text": "Controls the width of the surface created at the end of the line. Endwidth1 adjusts the width on the inside of the curve, Endwidth2 adjusts the width on the outside of the curve.",
                "type": "Par",
                "name": "endwidth2"
            },
            {
                "text": "Fraction of the input curve that is used to create the new surface geometry. Domain1 sets position on the curve for Startwidth, Domain2 sets position on the curve for Endwidth.",
                "type": "Par",
                "name": "domain1"
            },
            {
                "text": "Fraction of the input curve that is used to create the new surface geometry. Domain1 sets position on the curve for Startwidth, Domain2 sets position on the curve for Endwidth.",
                "type": "Par",
                "name": "domain2"
            },
            {
                "text": "Menu : This menu selects the type of interpolation used between Startwidth and Endwidth.",
                "type": "Par",
                "name": "shape"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "linethickSOP_Class",
        "opType": "linethick",
        "opLicense": "Non-Commercial",
        "opLabel": "Line Thick",
        "long": "The Line Thick SOP extrudes a surface from a curved line. The line can be of polygon, NURBS, or Bezier geometry type.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Line Thick SOP extrudes a surface from a curved line.",
        "opCategories": ""
    },
    "lsystemSOP": {
        "label": "lsystemSOP",
        "members": [
            {
                "text": "Menu : Provides two options for output geometry:",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Defines the default color U, V index increments when the turtle symbols ` or # are used.",
                "type": "Par",
                "name": "incu"
            },
            {
                "text": "Defines the default color U, V index increments when the turtle symbols ` or # are used.",
                "type": "Par",
                "name": "incv"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "lsystemSOP_Class",
        "opType": "lsystem",
        "opLicense": "Non-Commercial",
        "opLabel": "LSystem",
        "long": "The Lsystem SOP implements L-systems (Lindenmayer-systems, named after Aristid Lindenmayer (1925-1989)), allow definition of complex shapes through the use of iteration. They use a mathematical language in which an initial string of characters is evaluated repeatedly, and the results are used to generate geometry. The result of each evaluation becomes the basis for the next iteration of geometry, giving the illusion of growth.\t\t\n\t\t\t\nYou begin building an L-system by defining a sequence of rules which are evaluated to produce a new string of characters. Each character of the new string represents one command which affects an imaginary stylus, or \"turtle\". Repeating this process will grow your geometry.\t\t\t\n\t\t\t\nYou can use L-systems to create things such as:\t\t\t\n* Create organic objects such as trees, plants, flowers over time.\t\t\t\n* Create animated branching objects such as lightning and snowflakes.\t\t\t\n\t\t\t\nThe file can be read in from disk or from the web. Use http:// when specifying a URL.\t\t\t\n\t\t\t\n===<div class=\"subSectionLineSOP\">The Algorithmic Beauty of Plants</div>===\t\t\t\n\t\t\t\nThe descriptions located here should be enough to get you started in writing your own L-system rules, however, if you have any serious interests in creating L-systems, you should obtain the book:\t\t\t\n\t\t\t\n The Algorithmic Beauty of Plants\t\t\t\n Przemyslaw Prusinkiewicz &amp; Aristid Lindenmayer\t\t\t\n Springer-Verlag, New York, Phone: 212.460.1500\t\t\t\n ISBN: 0-387-94676-4, 1996.\t\t\t\n\t\t\t\nwhich is the definitive reference on the subject. It contains a multitude of L-systems examples complete with descriptions of the ideas and theories behind modelling realistic plant growth.",
        "opFilter": "False",
        "opFamily": "SOP",
        "short": "The Lsystem SOP implements L-systems (Lindenmayer-systems, named after Aristid Lindenmayer (1925-1989)), allow definition of complex shapes through the use of iteration.",
        "opCategories": ""
    },
    "magnetSOP": {
        "label": "magnetSOP",
        "members": [
            {
                "text": "Menu : Sets the overall transform order for the transformations. The transform order determines the order in which transformations take place. Depending on the order, you can achieve different results using the exact same values. Choose the appropriate order from the menu.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : Sets the order of the rotations within the overall transform order.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "These three fields move the Source geometry in the three axes. The Translates of the metaball only affect the position of the area of influence. The influence itself is provided by an imaginary magnet within the Magnet SOP itself, and the attitude of this influence is determined by the Translates of the Magnet SOP.\t\n\t\t\t\n'''Note:''' If the '''Translate''' values of the Magnet SOP are all zero, the magnet will have no deforming influence. The weight of the [[Metaball SOP]] scales the influence of the Magnet SOP's Translates.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "These three fields move the Source geometry in the three axes. The Translates of the metaball only affect the position of the area of influence. The influence itself is provided by an imaginary magnet within the Magnet SOP itself, and the attitude of this influence is determined by the Translates of the Magnet SOP.\t\n\t\t\t\n'''Note:''' If the '''Translate''' values of the Magnet SOP are all zero, the magnet will have no deforming influence. The weight of the [[Metaball SOP]] scales the influence of the Magnet SOP's Translates.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "These three fields move the Source geometry in the three axes. The Translates of the metaball only affect the position of the area of influence. The influence itself is provided by an imaginary magnet within the Magnet SOP itself, and the attitude of this influence is determined by the Translates of the Magnet SOP.\t\n\t\t\t\n'''Note:''' If the '''Translate''' values of the Magnet SOP are all zero, the magnet will have no deforming influence. The weight of the [[Metaball SOP]] scales the influence of the Magnet SOP's Translates.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "These three fields rotate the Source geometry in the three axes.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "These three fields rotate the Source geometry in the three axes.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "These three fields rotate the Source geometry in the three axes.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "These three fields scale the input geometry in the three axes.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "These three fields scale the input geometry in the three axes.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "These three fields scale the input geometry in the three axes.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "The pivot point for the transformations. Not the same as the pivot point in the pivot channels.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "The pivot point for the transformations. Not the same as the pivot point in the pivot channels.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "The pivot point for the transformations. Not the same as the pivot point in the pivot channels.",
                "type": "Par",
                "name": "pz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "magnetSOP_Class",
        "opType": "magnet",
        "opLicense": "Non-Commercial",
        "opLabel": "Magnet",
        "long": "The Magnet SOP allows you to affect deformations of the input geometry with another object using a \"magnetic field\" of influence, defined by a metaball field. It allows the creation of animated bumps and dents within objects, and other special effects.\t\t\n\t\t\t\nIt is important to note that the actual deformation comes from the <span class=\"tipTextSOP\">Translate</span> parameters of the Magnet SOP, and not from the metaball. The metaball defines the area of effect for the <span class=\"tipTextSOP\">Translate</span> parameters of the Magnet SOP. The weight of the metaball determines the effectiveness of the <span class=\"tipTextSOP\">Translate</span> within the Magnet SOP.\t\t\t\n\t\t\t\nThe power of the magnet is greatest at the centre of a metaball field and diminishes to nothing at the edge of the field.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Magnet SOP allows you to affect deformations of the input geometry with another object using a \"magnetic field\" of influence, defined by a metaball field.",
        "opCategories": ""
    },
    "mergeSOP": {
        "label": "mergeSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "mergeSOP_Class",
        "opType": "merge",
        "opLicense": "Non-Commercial",
        "opLabel": "Merge",
        "long": "The Merge SOP merges geometry from multiple SOPs. You can merge SOPs by wiring them into the Merge SOP, and/or you can specify the names in the SOPs parameter, where you can include wildcard [[Pattern Matching]] to merge large sets of SOPs with similar names.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Merge SOP merges geometry from multiple SOPs.",
        "opCategories": ""
    },
    "metaballSOP": {
        "label": "metaballSOP",
        "members": [
            {
                "text": "Controls the radius of the metaball field.",
                "type": "Par",
                "name": "radx"
            },
            {
                "text": "Controls the radius of the metaball field.",
                "type": "Par",
                "name": "rady"
            },
            {
                "text": "Controls the radius of the metaball field.",
                "type": "Par",
                "name": "radz"
            },
            {
                "text": "Metaball center in X, Y and Z.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Metaball center in X, Y and Z.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Metaball center in X, Y and Z.",
                "type": "Par",
                "name": "tz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "The Metaball SOP creates metaballs and meta-superquadric surfaces. Metaballs can be thought of as spherical force fields whose surface is an implicit function defined at any point where the density of the force field equals a certain threshold. Because the density of the force field can be increased by the proximity of other metaball force fields, metaballs have the unique property that they change their shape to adapt and fuse with surrounding metaballs. This makes them very effective for modeling organic surfaces. For example, below we have a metaball. The surface of the metaball exists whenever the density of the metaball's field reaches a certain threshold:\t\n\t\t\n[[Image:MetaExample1.jpg]]\t\t\n\t\t\nWhen two or more metaball force fields are combined, as in the illustration below, the resulting density of the force fields is added, and the surface extends to include that area where the force fields intersect and create density values with a value of one. For more information on metaballs, see [[Metaball]]s.\t\t\n\t\t\n[[Image:MetaExample2.jpg]]\t\t\n{{OPSubSection\n|opFamily=SOP\n|sectionName=Level of Detail for Metaball Display\n|sectionSummary=You can change the level of detail of the metaball and NURBS display by adjusting the Level of Detail parameter in the Display Option Dialog &gt; Viewport page &gt; <span class=\"tipTextSOP\">Level of Detail</span> option. To open the Display Options Dialog, press \"p\" in a SOP viewport.\n}}\n{{OPSubSection\n|opFamily=SOP\n|sectionName=Better Metaball Shading Tip\n|sectionSummary=Accurate metaball normals will be computed if the normal attribute exists when conversion to polygons is done. Thus, to get improved shading on polygonized metaballs, it's a good idea to add the normal attribute (i.e. use a [[Facet SOP]]) before converting the metaballs.\n}}",
        "opLabel": "Metaball",
        "opLicense": "Non-Commercial",
        "opFamily": "SOP",
        "short": "The Metaball SOP creates metaballs and meta-superquadric surfaces.",
        "opType": "metaball",
        "opFilter": "False",
        "opClass": "metaballSOP_Class",
        "opCategories": ""
    },
    "modelSOP": {
        "label": "modelSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "modelSOP_Class",
        "opType": "model",
        "opLicense": "Non-Commercial",
        "opLabel": "Model",
        "long": "The Model SOP holds the surface modeler in TouchDesigner. It is designed to hold raw model geometry constructed using the SOP Editor (aka Modeler). It holds modeled data and cannot be unlocked - protecting you from losing your model data.\n\t\nAny SOP can be [[Lock Flag|locked]] and modified with the modeler.",
        "opFilter": "False",
        "opFamily": "SOP",
        "short": "The Model SOP holds the surface modeler in TouchDesigner.",
        "opCategories": ""
    },
    "noiseSOP": {
        "label": "noiseSOP",
        "members": [
            {
                "text": "Menu : This menu sets which attribute of the geometry the Noise SOP acts on.",
                "type": "Par",
                "name": "attribute"
            },
            {
                "text": "Menu : The noise function used to generate noise. The functions available are:",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : The menu attached to this parameter allows you to specify the order in which the transforms will take place. Changing the Transform order will change where things go much the same way as going a block and turning east gets you to a different place than turning east and then going a block.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : The rotational matrix presented when you click on this option allows you to set the transform order for the rotations. As with transform order (above), changing the order in which the rotations take place will alter the final position.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "Translate the sampling plane through the noise space.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Translate the sampling plane through the noise space.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Translate the sampling plane through the noise space.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Rotate the sampling plane in the noise space.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "Rotate the sampling plane in the noise space.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "Rotate the sampling plane in the noise space.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "Scale the sampling plane.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "Scale the sampling plane.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "Scale the sampling plane.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "Control the pivot for the transform of the sampling plane.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "Control the pivot for the transform of the sampling plane.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "Control the pivot for the transform of the sampling plane.",
                "type": "Par",
                "name": "pz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "noiseSOP_Class",
        "opType": "noise",
        "opLicense": "Non-Commercial",
        "opLabel": "Noise",
        "long": "The Noise SOP displaces geometry points using noise patterns. It uses the same math as the [[Noise CHOP]].",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Noise SOP displaces geometry points using noise patterns.",
        "opCategories": ""
    },
    "nullSOP": {
        "label": "nullSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "nullSOP_Class",
        "opType": "null",
        "opLicense": "Non-Commercial",
        "opLabel": "Null",
        "long": "The Null SOP has no effect on the geometry. It is an instance of the SOP connected to its input. The Null SOP is often used when making reference to a SOP network, allowing new SOPs to be added to the network (upstream) without the need to update the reference.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Null SOP has no effect on the geometry. It is an instance of the SOP connected to its input.",
        "opCategories": ""
    },
    "oculusriftSOP": {
        "label": "oculusriftSOP",
        "members": [
            {
                "text": "Menu : Select which controller model to load.",
                "type": "Par",
                "name": "model"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opType": "oculusrift",
        "opLabel": "Oculus Rift",
        "opLicense": "Non-Commercial",
        "opClass": "oculusriftSOP_Class",
        "opFilter": "False",
        "short": "Loads geometry for the Oculus Rift Touch controllers.",
        "os": "Microsoft Windows",
        "long": "Loads geometry for the Oculus Rift Touch controllers.",
        "opCategories": ""
    },
    "outSOP": {
        "label": "NotSet",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": []
    },
    "particleSOP": {
        "label": "particleSOP",
        "members": [
            {
                "text": "Menu : Selects how the particles are rendered.",
                "type": "Par",
                "name": "prtype"
            },
            {
                "text": "Menu : Select between emitting particles from the geometry's points or deforming the original geometry using the Particle SOP's behavior.",
                "type": "Par",
                "name": "behave"
            },
            {
                "text": "Menu : Decide how the internal memory for points is reused when a point needs to be created or when a point dies.",
                "type": "Par",
                "name": "ptreuse"
            },
            {
                "text": "Menu : Select which mode of attraction to use for Surface Attractors.",
                "type": "Par",
                "name": "attractmode"
            },
            {
                "text": "Forces of gravity acting on the particles. When drag is zero, the particles can accelerate with no limit on their speed.",
                "type": "Par",
                "name": "externalx"
            },
            {
                "text": "Forces of gravity acting on the particles. When drag is zero, the particles can accelerate with no limit on their speed.",
                "type": "Par",
                "name": "externaly"
            },
            {
                "text": "Forces of gravity acting on the particles. When drag is zero, the particles can accelerate with no limit on their speed.",
                "type": "Par",
                "name": "externalz"
            },
            {
                "text": "Wind forces acting on the particles. Similar to <span class=\"tipTextSOP\">External Force</span>. Using <span class=\"tipTextSOP\">Wind</span> (and no other forces, such as <span class=\"tipTextSOP\">Turbulence</span>), the particles will not exceed the wind velocity.\t\n\t\t\t\n====Discussion - Wind vs External Force====\t\t\t\n\t\t\t\nThe application of <span class=\"tipTextSOP\">External Force</span> directly affects a particles' acceleration, the rate of which is determined by the mass (F = Mass  Acceleration). <span class=\"tipTextSOP\">Wind</span> is an additional force, but one that is velocity sensitive. If a particle is already travelling at wind velocity, then it shouldn't receive any extra force from it. This implies a maximum velocity when using <span class=\"tipTextSOP\">Wind</span> on its own.\t\t\t\n\t\t\t\nAn increase in mass impedes acceleration for a given constant force. <span class=\"tipTextSOP\">Drag</span> is a force opposing the direction of motion which is velocity sensitive, i.e. the larger the velocity, the greater the effect of drag. Its useful for limiting the velocity of particles.",
                "type": "Par",
                "name": "windx"
            },
            {
                "text": "Wind forces acting on the particles. Similar to <span class=\"tipTextSOP\">External Force</span>. Using <span class=\"tipTextSOP\">Wind</span> (and no other forces, such as <span class=\"tipTextSOP\">Turbulence</span>), the particles will not exceed the wind velocity.\t\n\t\t\t\n====Discussion - Wind vs External Force====\t\t\t\n\t\t\t\nThe application of <span class=\"tipTextSOP\">External Force</span> directly affects a particles' acceleration, the rate of which is determined by the mass (F = Mass  Acceleration). <span class=\"tipTextSOP\">Wind</span> is an additional force, but one that is velocity sensitive. If a particle is already travelling at wind velocity, then it shouldn't receive any extra force from it. This implies a maximum velocity when using <span class=\"tipTextSOP\">Wind</span> on its own.\t\t\t\n\t\t\t\nAn increase in mass impedes acceleration for a given constant force. <span class=\"tipTextSOP\">Drag</span> is a force opposing the direction of motion which is velocity sensitive, i.e. the larger the velocity, the greater the effect of drag. Its useful for limiting the velocity of particles.",
                "type": "Par",
                "name": "windy"
            },
            {
                "text": "Wind forces acting on the particles. Similar to <span class=\"tipTextSOP\">External Force</span>. Using <span class=\"tipTextSOP\">Wind</span> (and no other forces, such as <span class=\"tipTextSOP\">Turbulence</span>), the particles will not exceed the wind velocity.\t\n\t\t\t\n====Discussion - Wind vs External Force====\t\t\t\n\t\t\t\nThe application of <span class=\"tipTextSOP\">External Force</span> directly affects a particles' acceleration, the rate of which is determined by the mass (F = Mass  Acceleration). <span class=\"tipTextSOP\">Wind</span> is an additional force, but one that is velocity sensitive. If a particle is already travelling at wind velocity, then it shouldn't receive any extra force from it. This implies a maximum velocity when using <span class=\"tipTextSOP\">Wind</span> on its own.\t\t\t\n\t\t\t\nAn increase in mass impedes acceleration for a given constant force. <span class=\"tipTextSOP\">Drag</span> is a force opposing the direction of motion which is velocity sensitive, i.e. the larger the velocity, the greater the effect of drag. Its useful for limiting the velocity of particles.",
                "type": "Par",
                "name": "windz"
            },
            {
                "text": "The amplitude of turbulent (chaotic) forces along each axis. Use positive values, if any.",
                "type": "Par",
                "name": "turbx"
            },
            {
                "text": "The amplitude of turbulent (chaotic) forces along each axis. Use positive values, if any.",
                "type": "Par",
                "name": "turby"
            },
            {
                "text": "The amplitude of turbulent (chaotic) forces along each axis. Use positive values, if any.",
                "type": "Par",
                "name": "turbz"
            },
            {
                "text": "The particles will die or bounce off the limit planes when it reaches them. The six limit plane fields define a bounding cube. The default settings are <code>1000</code> units away, which is very large. Reduce the values to about one to see the effect.",
                "type": "Par",
                "name": "limitposx"
            },
            {
                "text": "The particles will die or bounce off the limit planes when it reaches them. The six limit plane fields define a bounding cube. The default settings are <code>1000</code> units away, which is very large. Reduce the values to about one to see the effect.",
                "type": "Par",
                "name": "limitposy"
            },
            {
                "text": "The particles will die or bounce off the limit planes when it reaches them. The six limit plane fields define a bounding cube. The default settings are <code>1000</code> units away, which is very large. Reduce the values to about one to see the effect.",
                "type": "Par",
                "name": "limitposz"
            },
            {
                "text": "The particles will die or bounce off the limit planes when it reaches them. The six limit plane fields define a bounding cube. The default settings are <code>1000</code> units away, which is very large. Reduce the values to about one to see the effect.",
                "type": "Par",
                "name": "limitnegx"
            },
            {
                "text": "The particles will die or bounce off the limit planes when it reaches them. The six limit plane fields define a bounding cube. The default settings are <code>1000</code> units away, which is very large. Reduce the values to about one to see the effect.",
                "type": "Par",
                "name": "limitnegy"
            },
            {
                "text": "The particles will die or bounce off the limit planes when it reaches them. The six limit plane fields define a bounding cube. The default settings are <code>1000</code> units away, which is very large. Reduce the values to about one to see the effect.",
                "type": "Par",
                "name": "limitnegz"
            },
            {
                "text": "Menu : Control over what happens when a particle hits either the six collision planes or the collide object. The options are:",
                "type": "Par",
                "name": "hit"
            },
            {
                "text": "Menu : Select if the particle will split and under what conditions.",
                "type": "Par",
                "name": "splittype"
            },
            {
                "text": "When a particle splits, it splits into a number of other particles. The number of particles is randomly set between this range.",
                "type": "Par",
                "name": "splitmin"
            },
            {
                "text": "When a particle splits, it splits into a number of other particles. The number of particles is randomly set between this range.",
                "type": "Par",
                "name": "splitmax"
            },
            {
                "text": "Each split particle is given this base velocity.",
                "type": "Par",
                "name": "splitvelx"
            },
            {
                "text": "Each split particle is given this base velocity.",
                "type": "Par",
                "name": "splitvely"
            },
            {
                "text": "Each split particle is given this base velocity.",
                "type": "Par",
                "name": "splitvelz"
            },
            {
                "text": "This is a random amount that is added to the split velocity. When creating fireworks, the variance is large while the velocity is low. When rendering raindrops splashing, the split velocity is large in Y, and the variance in X and Z causes the particles to bounce up - but randomly - in the XZ plane.",
                "type": "Par",
                "name": "splitvarx"
            },
            {
                "text": "This is a random amount that is added to the split velocity. When creating fireworks, the variance is large while the velocity is low. When rendering raindrops splashing, the split velocity is large in Y, and the variance in X and Z causes the particles to bounce up - but randomly - in the XZ plane.",
                "type": "Par",
                "name": "splitvary"
            },
            {
                "text": "This is a random amount that is added to the split velocity. When creating fireworks, the variance is large while the velocity is low. When rendering raindrops splashing, the split velocity is large in Y, and the variance in X and Z causes the particles to bounce up - but randomly - in the XZ plane.",
                "type": "Par",
                "name": "splitvarz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "particleSOP_Class",
        "opType": "particle",
        "opLicense": "Non-Commercial",
        "opLabel": "Particle",
        "long": "The Particle SOP is used for creating and controlling motion of \"particles\" for particle systems simulations. Particle systems are often used to create simulations of natural events such as rain and snow, or effects such as fireworks and sparks. In Touch, the points of the input geometry are used as the starting positions of the particles. Each point of the input can be affected by external force (gravity) and wind. Particles can collide and bounce off another object, set by the <span class=\"tipTextSOP\">Collision Source</span>. They can also bounce off, or die at, limit planes set in X, Y and Z.\t\n    \nParticles are created with an initial velocity/direction that comes from the source geometry\u2019s point normals, and that velocity can be controlled by modifying the normals using, for instance, a [[Point SOP]], [[Facet SOP]] or [[Script SOP]]. A point with a Normal of magnitude 1 emit bear particles with a velocity of 1 unit per second in the direction of the normal. \n\t\t\t\nParticles have various [[Attribute]]s that regular geometry do not have, such as velocity, life expectancy and age. These attributes must be carried with each point in order to carry out the simulation.\t\t\t\n\t\t\t\nThe fourth input is Surface Attractors that cause the particles to be attached to areas of a surface. Each particle's id is used to determine a random target primitive, and random u,v on that primitive.  That target position is used to modify the current velocity.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Particle SOP is used for creating and controlling motion of \"particles\" for particle systems simulations.",
        "opCategories": ""
    },
    "pointSOP": {
        "label": "pointSOP",
        "members": [
            {
                "text": "Expressions to translate the XYZ coordinates of a given point can be entered here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.x</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.y</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.z</syntaxhighlight>.\t\n\t\t\t\nSimply entering <syntaxhighlight lang=python inline>me.inputPoint.x</syntaxhighlight> into the Position X field means that the X coordinate of each point that comes in is passed straight through with no modification.\t\t\t\n\t\t\t\nChanging this entry to <syntaxhighlight lang=python inline>me.inputPoint.x+5</syntaxhighlight> means that the X coordinate of each point that comes in will be displaced by 5 units. This expression can be expanded to produce many useful effects. Transformations can also be effected in the Y and Z fields.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Expressions to translate the XYZ coordinates of a given point can be entered here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.x</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.y</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.z</syntaxhighlight>.\t\n\t\t\t\nSimply entering <syntaxhighlight lang=python inline>me.inputPoint.x</syntaxhighlight> into the Position X field means that the X coordinate of each point that comes in is passed straight through with no modification.\t\t\t\n\t\t\t\nChanging this entry to <syntaxhighlight lang=python inline>me.inputPoint.x+5</syntaxhighlight> means that the X coordinate of each point that comes in will be displaced by 5 units. This expression can be expanded to produce many useful effects. Transformations can also be effected in the Y and Z fields.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Expressions to translate the XYZ coordinates of a given point can be entered here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.x</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.y</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.z</syntaxhighlight>.\t\n\t\t\t\nSimply entering <syntaxhighlight lang=python inline>me.inputPoint.x</syntaxhighlight> into the Position X field means that the X coordinate of each point that comes in is passed straight through with no modification.\t\t\t\n\t\t\t\nChanging this entry to <syntaxhighlight lang=python inline>me.inputPoint.x+5</syntaxhighlight> means that the X coordinate of each point that comes in will be displaced by 5 units. This expression can be expanded to produce many useful effects. Transformations can also be effected in the Y and Z fields.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Menu : Select between keeping the weight or adding a new weight.",
                "type": "Par",
                "name": "doweight"
            },
            {
                "text": "Menu : Select between keeping the color, adding new color, or using no color.",
                "type": "Par",
                "name": "doclr"
            },
            {
                "text": "If you select 'Add Color' from the menu above, Cd color attributes will be added/modified in the SOP. Enter expressions below to control the values of the point colors. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputColor[0]</syntaxhighlight> for red, <syntaxhighlight lang=python inline>me.inputColor[1]</syntaxhighlight> for green, <syntaxhighlight lang=python inline>me.inputColor[2]</syntaxhighlight> for blue, and <syntaxhighlight lang=python inline>me.inputColor[3]</syntaxhighlight> for alpha.\nIf you select 'No Color' from the menu above, the Cd color attribute will be removed from the SOP.",
                "type": "Par",
                "name": "diffr"
            },
            {
                "text": "If you select 'Add Color' from the menu above, Cd color attributes will be added/modified in the SOP. Enter expressions below to control the values of the point colors. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputColor[0]</syntaxhighlight> for red, <syntaxhighlight lang=python inline>me.inputColor[1]</syntaxhighlight> for green, <syntaxhighlight lang=python inline>me.inputColor[2]</syntaxhighlight> for blue, and <syntaxhighlight lang=python inline>me.inputColor[3]</syntaxhighlight> for alpha.\nIf you select 'No Color' from the menu above, the Cd color attribute will be removed from the SOP.",
                "type": "Par",
                "name": "diffg"
            },
            {
                "text": "If you select 'Add Color' from the menu above, Cd color attributes will be added/modified in the SOP. Enter expressions below to control the values of the point colors. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputColor[0]</syntaxhighlight> for red, <syntaxhighlight lang=python inline>me.inputColor[1]</syntaxhighlight> for green, <syntaxhighlight lang=python inline>me.inputColor[2]</syntaxhighlight> for blue, and <syntaxhighlight lang=python inline>me.inputColor[3]</syntaxhighlight> for alpha.\nIf you select 'No Color' from the menu above, the Cd color attribute will be removed from the SOP.",
                "type": "Par",
                "name": "diffb"
            },
            {
                "text": "Menu : Select between keeping the normals, adding new normals, or using no normals.",
                "type": "Par",
                "name": "donml"
            },
            {
                "text": "If you select 'Add Normal' from the menu above, N normal attributes will be added/modified in the SOP. Enter expressions to change a given point normal here. Point normals are directional vectors used by other SOPs, such as Turbulence, Facet and Copy. See [[Attributes]] article for detailed information. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputNormal[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputNormal[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputNormal[2]</syntaxhighlight>.\nIf you select 'No Normal' from the menu above, the N normal attribute will be removed from the SOP.",
                "type": "Par",
                "name": "nx"
            },
            {
                "text": "If you select 'Add Normal' from the menu above, N normal attributes will be added/modified in the SOP. Enter expressions to change a given point normal here. Point normals are directional vectors used by other SOPs, such as Turbulence, Facet and Copy. See [[Attributes]] article for detailed information. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputNormal[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputNormal[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputNormal[2]</syntaxhighlight>.\nIf you select 'No Normal' from the menu above, the N normal attribute will be removed from the SOP.",
                "type": "Par",
                "name": "ny"
            },
            {
                "text": "If you select 'Add Normal' from the menu above, N normal attributes will be added/modified in the SOP. Enter expressions to change a given point normal here. Point normals are directional vectors used by other SOPs, such as Turbulence, Facet and Copy. See [[Attributes]] article for detailed information. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputNormal[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputNormal[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputNormal[2]</syntaxhighlight>.\nIf you select 'No Normal' from the menu above, the N normal attribute will be removed from the SOP.",
                "type": "Par",
                "name": "nz"
            },
            {
                "text": "Menu : Select between keeping the texture coordinates, adding new texture coordinates, or using no texture coordinates.",
                "type": "Par",
                "name": "douvw"
            },
            {
                "text": "If you select 'Add Texture' from the menu above, uv texture coordinate attributes will be added/modified in the SOP. Enter expressions here to control the values of the texture coordinates here. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputTexture[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputTexture[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputTexture[2]</syntaxhighlight>.\nIf you select 'No Texture' from the menu above, the uv texture coordinate attribute will be removed from the SOP.",
                "type": "Par",
                "name": "mapu"
            },
            {
                "text": "If you select 'Add Texture' from the menu above, uv texture coordinate attributes will be added/modified in the SOP. Enter expressions here to control the values of the texture coordinates here. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputTexture[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputTexture[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputTexture[2]</syntaxhighlight>.\nIf you select 'No Texture' from the menu above, the uv texture coordinate attribute will be removed from the SOP.",
                "type": "Par",
                "name": "mapv"
            },
            {
                "text": "If you select 'Add Texture' from the menu above, uv texture coordinate attributes will be added/modified in the SOP. Enter expressions here to control the values of the texture coordinates here. The attributes to modify are: <syntaxhighlight lang=python inline>me.inputTexture[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputTexture[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputTexture[2]</syntaxhighlight>.\nIf you select 'No Texture' from the menu above, the uv texture coordinate attribute will be removed from the SOP.",
                "type": "Par",
                "name": "mapw"
            },
            {
                "text": "Menu : Select between keeping the width attribute or adding a new width. This Width (width) attribute is used exclusively with [[Line MAT]] to control line width when the material is rendered.",
                "type": "Par",
                "name": "dowidth"
            },
            {
                "text": "Menu : Select between keeping the scale attribute, adding new scale, or using no scale. This scale (pscale) attribute is used with the [[Particle SOP]] and acts as a multiplier for the size of particles. The value of this attribute is multiplied by the size specified in the [[Particle SOP]]'s render attributes to scale each particle. This attribute is used by the [[Point Sprite MAT]] when rendering point sprites.",
                "type": "Par",
                "name": "dopscale"
            },
            {
                "text": "Menu : The type of attribute created can be selected from this menu.",
                "type": "Par",
                "name": "custom1type"
            },
            {
                "text": "Set the values of the Custom Attrib using these parameters.",
                "type": "Par",
                "name": "custom1val1"
            },
            {
                "text": "Set the values of the Custom Attrib using these parameters.",
                "type": "Par",
                "name": "custom1val2"
            },
            {
                "text": "Set the values of the Custom Attrib using these parameters.",
                "type": "Par",
                "name": "custom1val3"
            },
            {
                "text": "Set the values of the Custom Attrib using these parameters.",
                "type": "Par",
                "name": "custom1val4"
            },
            {
                "text": "Menu : Retains, adds, or removes mass and drag attributes for points.",
                "type": "Par",
                "name": "domass"
            },
            {
                "text": "Menu : Retains, adds, or removes spring constant attributes for points. The Spring Constant is a well known physical property affecting each point.",
                "type": "Par",
                "name": "dospringk"
            },
            {
                "text": "Menu : Retains, adds, or removes the velocity of points. Defines the magnitude of the particle's velocity in the X, Y and Z directions.",
                "type": "Par",
                "name": "dovel"
            },
            {
                "text": "If you select 'Add Velocity' from the menu above, v velocity attributes will be added/modified in the SOP. Enter expressions to change a given point velocity here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.v[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.v[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.v[2]</syntaxhighlight>. If you select 'No Velocity' from the menu above, the v velocity attribute will be removed from the SOP.",
                "type": "Par",
                "name": "vx"
            },
            {
                "text": "If you select 'Add Velocity' from the menu above, v velocity attributes will be added/modified in the SOP. Enter expressions to change a given point velocity here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.v[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.v[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.v[2]</syntaxhighlight>. If you select 'No Velocity' from the menu above, the v velocity attribute will be removed from the SOP.",
                "type": "Par",
                "name": "vy"
            },
            {
                "text": "If you select 'Add Velocity' from the menu above, v velocity attributes will be added/modified in the SOP. Enter expressions to change a given point velocity here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.v[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.v[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.v[2]</syntaxhighlight>. If you select 'No Velocity' from the menu above, the v velocity attribute will be removed from the SOP.",
                "type": "Par",
                "name": "vz"
            },
            {
                "text": "Menu : Creates/Removes the \"up\" attribute for points. This attribute defines an up vector which is used to fully define the space around a point (for particle instancing or copying geometry). The up vector can be used in conjunction with the copy template's normals to control the orientation of the copies in the [[Copy SOP]].",
                "type": "Par",
                "name": "doup"
            },
            {
                "text": "If you select 'Add Up Vector' from the menu above, up attributes will be added/modified in the SOP. Enter expressions to change a given point up vector here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.up[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.up[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.up[2]</syntaxhighlight>. If you select 'No Up Vector' from the menu above, the up attribute will be removed from the SOP.",
                "type": "Par",
                "name": "upx"
            },
            {
                "text": "If you select 'Add Up Vector' from the menu above, up attributes will be added/modified in the SOP. Enter expressions to change a given point up vector here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.up[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.up[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.up[2]</syntaxhighlight>. If you select 'No Up Vector' from the menu above, the up attribute will be removed from the SOP.",
                "type": "Par",
                "name": "upy"
            },
            {
                "text": "If you select 'Add Up Vector' from the menu above, up attributes will be added/modified in the SOP. Enter expressions to change a given point up vector here. The attributes to modify here are: <syntaxhighlight lang=python inline>me.inputPoint.up[0]</syntaxhighlight>, <syntaxhighlight lang=python inline>me.inputPoint.up[1]</syntaxhighlight> and <syntaxhighlight lang=python inline>me.inputPoint.up[2]</syntaxhighlight>. If you select 'No Up Vector' from the menu above, the up attribute will be removed from the SOP.",
                "type": "Par",
                "name": "upz"
            },
            {
                "text": "Menu : Retains, adds, or removes radiusf attributes for points, used to modify the distance roll-off effect. The roll-off is: <code>r /(r+d^2)</code> Where <code>r</code> is radius, and <code>d</code> is distance from attractor point. If no radius is set, no attenuation is performed.",
                "type": "Par",
                "name": "doradius"
            },
            {
                "text": "Menu : Retains, adds, or removes scalef attributes for points, a multiplier for total force associated with this attractor point.\t\n\t\t\t\nBoth Radius and Force Scale will default to 1 if not created as point attributes.\t\t\t\n\t\t\t\n'''Radial / Normal / Edge / Directional Force''' - These four parameters introduce a type of force when created and each has a corresponding multiplier associated with it.",
                "type": "Par",
                "name": "doscale"
            },
            {
                "text": "Menu : Retains, adds, or removes radialf attributes for points, the force directed towards the attractor point. Positive multipliers are towards while negative are away.",
                "type": "Par",
                "name": "doradialf"
            },
            {
                "text": "Menu : Retains, adds, or removes normalf attributes for points, the force directed along the point normal direction.",
                "type": "Par",
                "name": "donormalf"
            },
            {
                "text": "Menu : Retains, adds, or removes edgef attributes for points, which only works on primitive face types. The force is directed in the direction of the edge leading from that point. If multiple vertices reference the same point, then the direction is the edge direction of the last primitive referencing the point.\t\n\t\t\t\nIf the face open, then the end point has an edge direction equal to that of the preceding point in that primitive.\t\t\t\n\t\t\t\n'''Note:''' When edge forces are added using the Point SOP, the force directions are computed in the Point SOP itself. Thus, any following transformations do not effect these. If you wish for the edge directions to be transformed as well, all transformations must be done before the Point SOP. Only the edge forces function like this.",
                "type": "Par",
                "name": "doedgef"
            },
            {
                "text": "Menu : Retains, adds, or removes dirf attributes for points, an arbitrary directional force still affected by the distance roll-off function.",
                "type": "Par",
                "name": "dodirf"
            },
            {
                "text": "If you select 'Add Dir. F' from the menu above, dirf attribute will be added/modified in the SOP. Enter expressions here to control the values of the force in the arbitrary direction here. If you select 'No Dir. F' from the menu above, the dirf attribute will be removed from the SOP.",
                "type": "Par",
                "name": "dirfx"
            },
            {
                "text": "If you select 'Add Dir. F' from the menu above, dirf attribute will be added/modified in the SOP. Enter expressions here to control the values of the force in the arbitrary direction here. If you select 'No Dir. F' from the menu above, the dirf attribute will be removed from the SOP.",
                "type": "Par",
                "name": "dirfy"
            },
            {
                "text": "If you select 'Add Dir. F' from the menu above, dirf attribute will be added/modified in the SOP. Enter expressions here to control the values of the force in the arbitrary direction here. If you select 'No Dir. F' from the menu above, the dirf attribute will be removed from the SOP.",
                "type": "Par",
                "name": "dirfz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "pointSOP_Class",
        "opType": "point",
        "opLicense": "Non-Commercial",
        "opLabel": "Point",
        "long": "The Point SOP allows you to get right into the geometry and manipulate the position, color, texture coordinates, and normals of the points in the Source, and other attributes. The Point SOP also lets you create custom point attributes. It is the complement to the [[Primitive SOP]]. Using a second input allows for combining of two SOPs using their respective expressions (see: [[PointSOP Class]]). If the second input has less points than the first input, the points in the second input will be cycled.\t\t\n\t\t\t\nFor example, you can create point coloring, or flip the normals of incoming geometry. Using expressions in Position X, Y and Z, you can move any given input point to a new place as defined by the expression with any standard attributes. \t\t\n\nThe Width (width) attribute affects the line width in the [[Line MAT]].  The Scale attribute (pscale) affects particle size, and in the [[Line MAT]] it affects the dot size at each point.\n\n'''Tip''': For greater flexibility, use the [[Script SOP]].",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Point SOP allows you to get right down into the geometry and manipulate the position, color, texture coordinates, and normals of the points in the Source, and other attributes.",
        "opCategories": ""
    },
    "polypatchSOP": {
        "label": "polypatchSOP",
        "members": [
            {
                "text": "Menu : Select spline type: <span class=\"tipTextSOP\">Cardinal</span> or <span class=\"tipTextSOP\">BSpline</span>.",
                "type": "Par",
                "name": "basis"
            },
            {
                "text": "Menu : This option is used to select how the points of the created surface are connected.",
                "type": "Par",
                "name": "connecttype"
            },
            {
                "text": "Menu : Settings for wrapping in U direction.",
                "type": "Par",
                "name": "closeu"
            },
            {
                "text": "Menu : Settings for wrapping in V direction.",
                "type": "Par",
                "name": "closev"
            },
            {
                "text": "Settings for clamping first end in U.",
                "type": "Par",
                "name": "firstuclampoff"
            },
            {
                "text": "Settings for clamping first end in U.",
                "type": "Par",
                "name": "firstuclampon"
            },
            {
                "text": "Settings for clamping first end in U.",
                "type": "Par",
                "name": "firstuclampifprim"
            },
            {
                "text": "Settings for clamping last end in U.",
                "type": "Par",
                "name": "lastuclampoff"
            },
            {
                "text": "Settings for clamping last end in U.",
                "type": "Par",
                "name": "lastuclampon"
            },
            {
                "text": "Settings for clamping last end in U.",
                "type": "Par",
                "name": "lastuclampifprim"
            },
            {
                "text": "Settings for clamping first end in V.",
                "type": "Par",
                "name": "firstvclampoff"
            },
            {
                "text": "Settings for clamping first end in V.",
                "type": "Par",
                "name": "firstvclampon"
            },
            {
                "text": "Settings for clamping first end in V.",
                "type": "Par",
                "name": "firstvclampifprim"
            },
            {
                "text": "Settings for clamping last end in V.",
                "type": "Par",
                "name": "lastvclampoff"
            },
            {
                "text": "Settings for clamping last end in V.",
                "type": "Par",
                "name": "lastvclampon"
            },
            {
                "text": "Settings for clamping last end in V.",
                "type": "Par",
                "name": "lastvclampifprim"
            },
            {
                "text": "The number of divisions in the output surface. Use more divisions for a smoother surface.",
                "type": "Par",
                "name": "divisionsx"
            },
            {
                "text": "The number of divisions in the output surface. Use more divisions for a smoother surface.",
                "type": "Par",
                "name": "divisionsy"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "polypatchSOP_Class",
        "opType": "polypatch",
        "opLicense": "Non-Commercial",
        "opLabel": "Polypatch",
        "long": "The Polypatch SOP creates a smooth polygonal patch from a mesh primitive or a set of faces (polygons, NURBS or Bezier curves).",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Polypatch SOP creates a smooth polygonal patch from a mesh primitive or a set of faces (polygons, NURBS or Bezier curves).",
        "opCategories": ""
    },
    "polyreduceSOP": {
        "label": "polyreduceSOP",
        "members": [
            {
                "text": "Menu : Select how to reduce the number of polygons from the following methods.",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opType": "polyreduceSOP",
        "opLabel": "Polyreduce",
        "opClass": "polyreduceSOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Polyreduce SOP reduces a high detail polygonal model into one consisting of fewer polygons.",
        "long": "The Polyreduce SOP reduces a high detail polygonal model into one consisting of fewer polygons. The second input's polygons represent feature edges. They are matched to the input mesh by point numbers.\t\n\t\t\nThe methods to reduce polygonal models are:\t\t\n\t\t\n* A percentage of their former size\t\t\n* A specfic number of polys (within a few)\t\t\n* According to distance from a camera\t\t\n\t\t\nNote that as it requires (and outputs) a triangular mesh, the polygon count may increase as a result of this operation.\t\t\n\t\t\nA second input for feature edges is provided.",
        "opCategories": ""
    },
    "polysplineSOP": {
        "label": "polysplineSOP",
        "members": [
            {
                "text": "Menu : Spline type to use. There are seven choices:",
                "type": "Par",
                "name": "basis"
            },
            {
                "text": "Menu : Determines if the output spline is open or closed.",
                "type": "Par",
                "name": "closure"
            },
            {
                "text": "Menu : Settings for refining the spline by adding extra divisions.",
                "type": "Par",
                "name": "divide"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "polysplineSOP_Class",
        "opType": "polyspline",
        "opLicense": "Non-Commercial",
        "opLabel": "Polyspline",
        "long": "The Polyspline SOP fits a spline curve to a polygon or hull and outputs a polygonal approximation of that spline. You can choose either to create divisions between the original points, or to ignore the position of the original points and divide the shape into segments of equal lengths.\t\n\t\t\nPolyspline can optionally resample the output curve, providing control over the length and number of its segments.\t\t\n\t\t\n'''Tip:''' When using this SOP, it is useful to enable Points display in the Viewport options dialog. This way you can see exactly what effect the SOP is having.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Polyspline SOP fits a spline curve to a polygon or hull and outputs a polygonal approximation of that spline.",
        "opCategories": ""
    },
    "polystitchSOP": {
        "label": "polystitchSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "polystitchSOP_Class",
        "opType": "polystitch",
        "opLicense": "Non-Commercial",
        "opLabel": "Polystitch",
        "long": "The Polystitch SOP attempts to stitch polygonal surfaces together, thereby eliminating cracks that result from evaluating the surfaces at differing levels of detail.\n\t\nFirst, the boundaries of all the polygons to be stitched are found. An edge is a boundary edge if it is shared by no other polygon. The uniqueness of edges is determined by point numbers, and not by spatial positioning. Each boundary is then split at each \"corner\" into a number of pieces. A list of corner points can be manually specified, or any point at which the boundary changes direction by a certain amount can be flagged as a corner.\t\n\t\nFinally, any two boundary pieces that are within the tolerance of each other are stitched together. This is performed by snapping the points of the high detail edge to those of the low detail edge.",
        "opFilter": "True",
        "opFamily": "SOP",
        "short": "The Polystitch SOP attempts to stitch polygonal surfaces together, thereby eliminating cracks that result from evaluating the surfaces at differing levels of detail.",
        "opCategories": ""
    },
    "profileSOP": {
        "label": "profileSOP",
        "members": [
            {
                "text": "Menu : This menu allows you to extract a stand-alone 3D curve as the world or parametric image of the profile. The non-parametric option will yield a curve whose shape and position in space are identical or very similar to those of the chosen profile. The parametric option will produce a planar, XY face whose vertices and type will be identical to those of the profile in 2D; also, if the profile is a spline it will have the same basis as the extracted curve.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : Select how to reposition and scale an existing profile to fit within the specified domain range. It is a good means of bringing an invisible profile into view by setting the mapping range between 0 and 1 in the U and V parametric directions. A profile mapped outside the unit domain becomes invisible but is not removed from the surface. Other ways to change a profile are available through the [[Primitive SOP]].",
                "type": "Par",
                "name": "maptype"
            },
            {
                "text": "Indicates in percentages what part of the U surface domain is the mapping area. A full range of 0-1 will cause the profiles to be mapped to the entire domain in the U parametric direction. The range is not restricted to the 0-1 interval.",
                "type": "Par",
                "name": "urange1"
            },
            {
                "text": "Indicates in percentages what part of the U surface domain is the mapping area. A full range of 0-1 will cause the profiles to be mapped to the entire domain in the U parametric direction. The range is not restricted to the 0-1 interval.",
                "type": "Par",
                "name": "urange2"
            },
            {
                "text": "Indicates in percentages what part of the V surface domain is the mapping area. A full range of 0-1 will cause the profiles to be mapped to the entire domain in the V parametric direction. The range is not restricted to the 0-1 interval.",
                "type": "Par",
                "name": "vrange1"
            },
            {
                "text": "Indicates in percentages what part of the V surface domain is the mapping area. A full range of 0-1 will cause the profiles to be mapped to the entire domain in the V parametric direction. The range is not restricted to the 0-1 interval.",
                "type": "Par",
                "name": "vrange2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "profile",
        "opLabel": "Profile",
        "short": "The Profile SOP enables the extraction and manipulation of profiles.",
        "opClass": "profileSOP_Class",
        "opFamily": "SOP",
        "long": "The Profile SOP enables the extraction and manipulation of profiles.\t\t\n\t\t\t\nYou will usually need a [[Trim SOP]], [[Bridge SOP]], or Profile SOP after a [[Project SOP]]. Use a Trim SOP to cut a hole in the projected surface. Use a Bridge SOP to skin the profile curve to another profile curve.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "railsSOP": {
        "label": "railsSOP",
        "members": [
            {
                "text": "Menu : Select how the cross=section is applied along the rails.",
                "type": "Par",
                "name": "cycle"
            },
            {
                "text": "The vertices at which the cross-section is connected to the rails.",
                "type": "Par",
                "name": "vertex1"
            },
            {
                "text": "The vertices at which the cross-section is connected to the rails.",
                "type": "Par",
                "name": "vertex2"
            },
            {
                "text": "The direction vector to use.",
                "type": "Par",
                "name": "dirx"
            },
            {
                "text": "The direction vector to use.",
                "type": "Par",
                "name": "diry"
            },
            {
                "text": "The direction vector to use.",
                "type": "Par",
                "name": "dirz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "rails",
        "opLabel": "Rails",
        "short": "The Rails SOP generates surfaces by stretching cross-sections between two rails.",
        "opClass": "railsSOP_Class",
        "opFamily": "SOP",
        "long": "The Rails SOP generates surfaces by stretching cross-sections between two rails. This is similar to the [[Sweep SOP]], but it gives more control over the orientation and scaling of the cross-sections. The first SOP input is the cross-section which will be replicated, and is typically placed in the XY plane. The second input SOP source is the rails along which the cross-section is replicated.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "rasterSOP": {
        "label": "rasterSOP",
        "members": [
            {
                "text": "Menu : Determines the direction of rasterization. Depending on the image horizontal or vertical might work better.",
                "type": "Par",
                "name": "direction"
            },
            {
                "text": "Menu : Gives the option for a delayed data download from the GPU, which is much faster and does not stall the render.",
                "type": "Par",
                "name": "downloadtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opType": "rasterSOP",
        "opLabel": "Raster",
        "opClass": "rasterSOP_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Raster SOP converts a field of pixels into a field of colored geometry points suitable for laster devices.",
        "long": "The Raster SOP converts TOP image data to geometry by scanning left to right, top to bottom, outputting a geometry point at each pixel. This output can be used to display image data on laser devices, oscilloscopes or similar devices using the [[Laser CHOP]]. This is different from the [[Trace SOP]] which only outputs contour shapes from an image.",
        "opCategories": ""
    },
    "raySOP": {
        "label": "raySOP",
        "members": [
            {
                "text": "Menu : Select the method of projection for the Ray SOP.",
                "type": "Par",
                "name": "method"
            },
            {
                "text": "Menu : If selected, updates each point in the source geometry with the normal at the collision surface it intersects with. If the point doesn't intersect at the collision surface, a normal of (0,0,0) is used.",
                "type": "Par",
                "name": "normal"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "ray",
        "opLabel": "Ray",
        "short": "The Ray SOP is used to project one surface onto another.",
        "opClass": "raySOP_Class",
        "opFamily": "SOP",
        "long": "The Ray SOP is used to project one surface onto another. Rays are projected from each point of the input geometry in the direction of its normal. This can be used to drape clothes over surfaces, shrink-wrap one object with another, and other similar effects.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "rectangleSOP": {
        "label": "rectangleSOP",
        "members": [
            {
                "text": "Menu : Picks the major plane the rectangle's y-axis orients itself with. Set it to <span class=\"Heading4\">camera</span> if it is to point towards a camera.",
                "type": "Par",
                "name": "orient"
            },
            {
                "text": "Specify the aspect ratio of the camera with this parameter and the Restangle SOP's aspect ratio will match. This makes it easy to apply a texture on the rectangle which matches the camera's viewport without any further adjustments.",
                "type": "Par",
                "name": "cameraaspectx"
            },
            {
                "text": "Specify the aspect ratio of the camera with this parameter and the Restangle SOP's aspect ratio will match. This makes it easy to apply a texture on the rectangle which matches the camera's viewport without any further adjustments.",
                "type": "Par",
                "name": "cameraaspecty"
            },
            {
                "text": "Adjusts the size of the rectangle in X and Y. If the size of the rectangle is being chosen from a Camera, or from a connected input SOP, then this parameter behaves as a scale. Otherwise it will set the size of the rectangle for all other modes.",
                "type": "Par",
                "name": "sizex"
            },
            {
                "text": "Adjusts the size of the rectangle in X and Y. If the size of the rectangle is being chosen from a Camera, or from a connected input SOP, then this parameter behaves as a scale. Otherwise it will set the size of the rectangle for all other modes.",
                "type": "Par",
                "name": "sizey"
            },
            {
                "text": "These X, Y, and Z Values determine where the center of the Rectangle is located. If the position of the rectangle is being chosen from a Camera, or from a connected input SOP, then this parameter behaves as an offset. Otherwise it will set the center of the rectangle for all other modes.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "These X, Y, and Z Values determine where the center of the Rectangle is located. If the position of the rectangle is being chosen from a Camera, or from a connected input SOP, then this parameter behaves as an offset. Otherwise it will set the center of the rectangle for all other modes.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "These X, Y, and Z Values determine where the center of the Rectangle is located. If the position of the rectangle is being chosen from a Camera, or from a connected input SOP, then this parameter behaves as an offset. Otherwise it will set the center of the rectangle for all other modes.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Menu : Texture addes (0,1) coordinates to the vertices when set to <span class=\"tipTextSOP\">Face</span>. Creates a rectangle without uv attributes when set to <span class=\"tipTextSOP\">Off</span>.",
                "type": "Par",
                "name": "texture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "rectangle",
        "opLabel": "Rectangle",
        "short": "The Rectangle SOP creates a 4-sided polygon. It is a planar surface.",
        "opClass": "rectangleSOP_Class",
        "opFamily": "SOP",
        "long": "The Rectangle SOP creates a 4-sided polygon. It is a planar surface. The rectangle can be explicitly sized, or sized from other sources such as at the camera's view frustum, or the bounding box of a SOP connected to this node's input.",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "refineSOP": {
        "label": "refineSOP",
        "members": [
            {
                "text": "Menu : Specify how to measure along splines / curves.",
                "type": "Par",
                "name": "refinespace"
            },
            {
                "text": " : Subdivide refines a primitive such that the subdivision causes a sharp discontinuity if ever displaced. In essence subdivide is equivalent to refine for polygons and Bziers, since any refinement causes a potential discontinuity. In the case of a NURBS it is equivalent to a maximum refinement (i.e. count = primitive basis order - 1).",
                "type": "Par",
                "name": "subdivspace"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "refine",
        "opLabel": "Refine",
        "short": "The Refine SOP allows you to increase the number of CVs in any NURBS, Bzier, or polygonal surface or face without changing its shape.",
        "opClass": "refineSOP_Class",
        "opFamily": "SOP",
        "long": "The Refine SOP allows you to increase the number of CVs in any NURBS, Bzier, or polygonal surface or face without changing its shape. It is also used to decrease the number of CVs within a given tolerance (i.e. a simple but fast method of data reduction).\t\t\n{{OPSubSection\n|opFamily=SOP\n|sectionName=The Difference Between Refinement and Unrefinement\n|sectionSummary=Refinement and unrefinement work both on faces (polygons, Bzier curves and NURBS curves) and surfaces (primitive meshes, Bzier surfaces and NURBS surfaces). To unrefine a face or a surface you need to specify a parametric interval (not just a single value as in refinement). This allows you to unrefine primitives within arbitrary intervals, either locally or globally. For example, to unrefine the whole primitive choose 0 and 1 as the two parametric boundaries; [0,0.5] will unrefine only the first parametric half of the primitive.\t\t\t\n\t\t\t\nThe interval boundaries are given by the First/Second U/V fields. Since refinement does not need an interval, the Second U/V fields are disabled by default.\t\t\t\n\t\t\t\nThe Tolerance control is only available for unrefinement, and not for refinement. Refinement does not need tolerances because it generates a curve or a surface that is mathematically identical to the original. Unrefinement, however, may tend to smooth out (or \"melt\") the original in a given area. In short, unrefinement is lossy; refinement isn't.\t\n}}",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "revolveSOP": {
        "label": "revolveSOP",
        "members": [
            {
                "text": "Menu : This option is used to select the type of surface, when using a Mesh Primitive Type.",
                "type": "Par",
                "name": "surftype"
            },
            {
                "text": "Coordinates defining the origin of the revolution.",
                "type": "Par",
                "name": "originx"
            },
            {
                "text": "Coordinates defining the origin of the revolution.",
                "type": "Par",
                "name": "originy"
            },
            {
                "text": "Coordinates defining the origin of the revolution.",
                "type": "Par",
                "name": "originz"
            },
            {
                "text": "X, Y, and Z coordinates of the direction vector defining the direction of the revolve.",
                "type": "Par",
                "name": "dirx"
            },
            {
                "text": "X, Y, and Z coordinates of the direction vector defining the direction of the revolve.",
                "type": "Par",
                "name": "diry"
            },
            {
                "text": "X, Y, and Z coordinates of the direction vector defining the direction of the revolve.",
                "type": "Par",
                "name": "dirz"
            },
            {
                "text": "Menu : Determines how the revolve should be generated.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Float : The start and end angles of the revolve. A revolve will start at the beginning angle, and proceed towards the ending angle. If <span class=\"tipTextSOP\">Beginning</span> = <code>0</code> and <span class=\"tipTextSOP\">End</span> = <code>360</code> it will be fully revolved. Values greater than 360 are also valid.",
                "type": "Par",
                "name": "angle"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "revolve",
        "opLabel": "Revolve",
        "short": "The Revolve SOP revolves faces to create a surface of revolution.",
        "opClass": "revolveSOP_Class",
        "opFamily": "SOP",
        "long": "The Revolve SOP revolves faces to create a surface of revolution. The revolution's direction and origin are represented by guide geometry that resembles a thick line with a cross hair at the centre. The cross hair represents the origin of the revolve as entered in the dialog and the stick represents the direction. Changing any of these parameters will cause the guide to change appropriately.\t\t\n\t\t\t\nIf the guide geometry is too distracting, you can disable it by entering the Viewport options dialog and clicking on the Guide geometry button so that it no longer appears indented. This procedure is global and will disable the guide geometry of other SOPs as well.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "scriptSOP": {
        "label": "scriptSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "script",
        "opLabel": "Script",
        "short": "The Script SOP runs a script each time the Script SOP cooks.",
        "opClass": "scriptSOP_Class",
        "opFamily": "SOP",
        "long": "The Script SOP runs a python script each time the Script SOP cooks. It can create, delete and modify points, primitives and their vertices. It can create custom attributes or built-in attributes like <code>Cd</code> (color), <code>uv</code> and <code>N</code> (normals). It can add polygons, bezier curves and meshes among others. It can combine multiple inputs. By default, the Script SOP is created with a docked DAT that contains three Python methods: <code>cook()</code>, <code>onPulse()</code>, and <code>setupParameters()</code>. The <code>cook()</code> method is run each time the Script SOP cooks. The <code>setupParameters()</code> method is run whenever the Setup Parameter button on the Script page is pressed. The <code>onPulse()</code> method is run whenever a custom pulse parameter is pushed.\t\n\t\t\nRefer to Help -> Python Examples, and Help -> [[OP Snippets|Operator Snippets]].\t\n\t\t\nNote: Because the Script SOP can get data from anywhere, it's difficult to determine what it procedurally depends on. So every time that a Script OP runs it will make a list of operators, parameters, nodes etc that it depends upon, and when they change, the Script OP will re-cook.\t\t\n\nSee also: [[Geometry Detail]], [[Point]], [[Point List]], [[Point Class]], [[Primitive]], [[Prims Class]], [[Polygon]], [[Vertex]], [[SOP]], [[SOP Class]], [[SOP to DAT]], [[Point SOP]], [[Point Group]]s, [[Primitive Group]]s, [[Attributes]].\n\nSee also: [[Script CHOP]], [[Script DAT]], [[Script TOP]].",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "selectSOP": {
        "label": "selectSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "select",
        "opLabel": "Select",
        "short": "The Select SOP allows you to reference a SOP from any other location in TouchDesigner.",
        "opClass": "selectSOP_Class",
        "opFamily": "SOP",
        "long": "The Select SOP allows you to reference a SOP from any other location in TouchDesigner. If only one other SOP is referenced, its memory is shared instead of re-created in this SOP.",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "sequenceblendSOP": {
        "label": "sequenceblendSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "sblend",
        "opLabel": "Sequence Blend",
        "short": "The Sequence Blend SOP allows you do 3D Metamorphosis between shapes and Interpolate point position, colors, point normals, and texture coordinates between shapes.",
        "opClass": "sequenceblendSOP_Class",
        "opFamily": "SOP",
        "long": "The Sequence Blend SOP allows you do 3D Metamorphosis between shapes and Interpolate point position, colors, point normals, and texture coordinates between shapes.\n\t\nSee also [[Blend SOP]] and [[Switch SOP]].",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "skinSOP": {
        "label": "skinSOP",
        "members": [
            {
                "text": "Menu : (Results only viewable for polygons and meshes).",
                "type": "Par",
                "name": "surftype"
            },
            {
                "text": "Menu : This menu (menu: Off, On, If primitive does) setting determines whether the surface should be wrapped in the V parametric direction. The options are to open (Off), close (On), or inherit the closure type from the cross-sections. V Wrap is ignored when doing bilinear skinning.",
                "type": "Par",
                "name": "closev"
            },
            {
                "text": "Menu : Can optionally skin subgroups of n primitives or every nth primitive in a cyclical manner.\t\n\t\t\n'''For example'''; assume there are six primitives numbered for 0 - 5, and <span class=\"tipTextSOP\">N</span> = 2. Then,\t\t\n\t\t\n* Groups will generate 0-1 2-3 4-5\t\t\n* Skipping will generate 0-2-6 and 1-3-5.",
                "type": "Par",
                "name": "skinops"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "skin",
        "opLabel": "Skin",
        "short": "The Skin SOP takes any number of faces and builds a skin surface over them.",
        "opClass": "skinSOP_Class",
        "opFamily": "SOP",
        "long": "The Skin SOP takes any number of faces and builds a skin surface over them. If given two or more surfaces, however, the SOP builds four skins, one for each set of boundary curves.\t\n\t\t\nAll face and surface types are valid as long as the input(s) contain only faces or only surfaces. Different face types can be skinned together into one surface. For example, it is possible to skin a cubic open NURBS curve with a polygon and a quintic closed Bzier curve even if the three faces have a different number of control vertices. Similarly, this SOP can skin the boundary curves of surfaces of different types, number of rows, columns, etc.\t\t\n\t\t\nWhen face types are input, the number of input SOPs and the number of faces in each input establish the skinning method. If only one input exists, a \"linear-skinning\" operation is performed by running a skin across the cross-sections. The result is the classic ruled or skinned surface. If a second input exists, a \"bi-linear skinning\" is performed which computes a cross-skin between the faces in the first input (U cross-sections) and the faces in the second input (V cross-sections). The result is a surface whose name derives from the number of cross-sections in each direction: triangular, square, or multiple boundary surface, as well as a special case of swept surfaces and N-rails. When possible, cross-sections are interpolated as isoparms.\t\t\n\t\t\nIf you need more control over tangency in the skin, try using the [[Bridge SOP]].\t\t\n\t\t\n'''Tip:''' If you have problems with the results being skinned in the wrong order, try inserting a Sort SOP ahead of the Skin SOP, and <span class=\"tipTextSOP\">Sort by Normals</span>.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "sortSOP": {
        "label": "sortSOP",
        "members": [
            {
                "text": "Menu : Sort the points in the input geometry, according to the following criteria:",
                "type": "Par",
                "name": "ptsort"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "pointproxx"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "pointproxy"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "pointproxz"
            },
            {
                "text": "Allows you to specify a unique vector along which points can be sorted.",
                "type": "Par",
                "name": "pointdirx"
            },
            {
                "text": "Allows you to specify a unique vector along which points can be sorted.",
                "type": "Par",
                "name": "pointdiry"
            },
            {
                "text": "Allows you to specify a unique vector along which points can be sorted.",
                "type": "Par",
                "name": "pointdirz"
            },
            {
                "text": "Menu : Sort the primitives according to the following criteria:",
                "type": "Par",
                "name": "primsort"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "primproxx"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "primproxy"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "primproxz"
            },
            {
                "text": "Allows you to specify a unique vector along which primitives can be sorted.",
                "type": "Par",
                "name": "primdirx"
            },
            {
                "text": "Allows you to specify a unique vector along which primitives can be sorted.",
                "type": "Par",
                "name": "primdiry"
            },
            {
                "text": "Allows you to specify a unique vector along which primitives can be sorted.",
                "type": "Par",
                "name": "primdirz"
            },
            {
                "text": "Menu : Sort the primitives according to the following criteria:",
                "type": "Par",
                "name": "partsort"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "partproxx"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "partproxy"
            },
            {
                "text": "The X, Y and Z coordinates to reference when sorting by <span class=\"tipTextSOP\">Proximity to Point</span>.",
                "type": "Par",
                "name": "partproxz"
            },
            {
                "text": "Allows you to specify a unique vector along which particles can be sorted.",
                "type": "Par",
                "name": "partdirx"
            },
            {
                "text": "Allows you to specify a unique vector along which particles can be sorted.",
                "type": "Par",
                "name": "partdiry"
            },
            {
                "text": "Allows you to specify a unique vector along which particles can be sorted.",
                "type": "Par",
                "name": "partdirz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "sort",
        "opLabel": "Sort",
        "short": "The Sort SOP allows you to sort points and primitives in different ways.",
        "opClass": "sortSOP_Class",
        "opFamily": "SOP",
        "long": "The Sort SOP allows you to sort points and primitives in different ways. Sometimes the primitives are arranged in the desired order, but the point order is not. There are many possible combinations. To sort vertices, use the [[Primitive SOP]].",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "sphereSOP": {
        "label": "sphereSOP",
        "members": [
            {
                "text": "Menu : Select from the following types. For information on the different types, see the [[:Category:Geometry|Geometry]] category articles. Depending on the primitive type chosen, some SOP options may not apply.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : This option is used to select the type of surface, when using a <span class=\"tipTextSOP\">Mesh Primitive Type</span>.",
                "type": "Par",
                "name": "surftype"
            },
            {
                "text": "The radius of the sphere in X, Y and Z.",
                "type": "Par",
                "name": "radx"
            },
            {
                "text": "The radius of the sphere in X, Y and Z.",
                "type": "Par",
                "name": "rady"
            },
            {
                "text": "The radius of the sphere in X, Y and Z.",
                "type": "Par",
                "name": "radz"
            },
            {
                "text": "Offset of sphere center from object center.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Offset of sphere center from object center.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Offset of sphere center from object center.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "These three fields rotate the Sphere along the X, Y, and Z axes.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "These three fields rotate the Sphere along the X, Y, and Z axes.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "These three fields rotate the Sphere along the X, Y, and Z axes.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "Menu : Determines axis for sphere. Poles of sphere align with orientation axis.",
                "type": "Par",
                "name": "orient"
            },
            {
                "text": "Menu : Adds UV texture coordinates to the sphere.",
                "type": "Par",
                "name": "texture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "sphere",
        "opLabel": "Sphere",
        "short": "The Sphere SOP generates spherical objects of different geometry types.",
        "opClass": "sphereSOP_Class",
        "opFamily": "SOP",
        "long": "The Sphere SOP generates spherical objects of different geometry types. It is capable of creating non-uniform scalable spheres of all geometry types.\t\n\t\t\nIf an input is provided, the sphere's radius is automatically determined as a function of the input's bounding geometry.",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "sprinkleSOP": {
        "label": "sprinkleSOP",
        "members": [
            {
                "text": "Menu : Describes where points are located.",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "SOP",
        "opType": "sprinkleSOP",
        "opLabel": "Sprinkle",
        "opClass": "sprinkleSOP_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Sprinkle SOP is used to add [[Point Class|points]] to either the surface or the volume of a SOP. You can create points on a surface, or within a closed volume based on the Method menu.",
        "long": "The Sprinkle SOP is used to add [[Point Class|points]] to either the surface or the volume of a SOP. You can create points on a surface, or within a closed volume based on the Method menu. The Surface method keeps the distribution of points constant per unit area of surface, whereas Per-Primitive gives each primitive, usually triangles, a constant number per primitive no matter their size.\n\nThe second input is used when you are scattering on a deforming surface. You generally don't want the distribution of points to jump while deforming, so you give the deformed surface as second input and the un-deformed surface as the first input. The Sprinkle SOP will then distribute points on the un-deformed surface, and then put them on their equivalent place on the deformed surface.",
        "opCategories": ""
    },
    "stitchSOP": {
        "label": "stitchSOP",
        "members": [
            {
                "text": "Menu : Stitches sub-groups of n primitives or patterns of primitives.",
                "type": "Par",
                "name": "stitchop"
            },
            {
                "text": "Menu : Allows stitching along either the U or V parametric direction.",
                "type": "Par",
                "name": "dir"
            },
            {
                "text": "Point on each left / right primitive at which to begin / end the stitch.",
                "type": "Par",
                "name": "leftuv1"
            },
            {
                "text": "Point on each left / right primitive at which to begin / end the stitch.",
                "type": "Par",
                "name": "leftuv2"
            },
            {
                "text": "Point on each left / right primitive at which to begin / end the stitch.",
                "type": "Par",
                "name": "rightuv1"
            },
            {
                "text": "Point on each left / right primitive at which to begin / end the stitch.",
                "type": "Par",
                "name": "rightuv2"
            },
            {
                "text": "The first value represents the width of the left stitch. The second value represents the width of the right stitch.",
                "type": "Par",
                "name": "lrwidth1"
            },
            {
                "text": "The first value represents the width of the left stitch. The second value represents the width of the right stitch.",
                "type": "Par",
                "name": "lrwidth2"
            },
            {
                "text": "Use this parameter to control the direction and position of the tangential slopes.",
                "type": "Par",
                "name": "lrscale1"
            },
            {
                "text": "Use this parameter to control the direction and position of the tangential slopes.",
                "type": "Par",
                "name": "lrscale2"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "stitch",
        "opLabel": "Stitch",
        "short": "The Stitch SOP is used to stretch two curves or surfaces to cover a smooth area.",
        "opClass": "stitchSOP_Class",
        "opFamily": "SOP",
        "long": "The Stitch SOP is used to stretch two curves or surfaces to cover a smooth area. It can also be used to create certain types of upholstered fabrics such as cushions and parachutes.\t\n\t\t\nIf a second input is given, it must contain one surface that the primitives in the first input can stitch to. The left input can contain either faces or surfaces; in either case, each primitive in the first input is stitched to a parametric area of the surface in the second input in such a way that the parametric area allocated to each primitive is the same and the size of all areas added together equals the parametric range specified in the R Width (see below).\t\t\n\t\t\nPlease refer to the [[Align SOP]] for a discussion of \"left\" and \"right\" primitives as well as the option of an auxiliary input.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "superquadSOP": {
        "label": "superquadSOP",
        "members": [
            {
                "text": "Menu : Select from the following types. For information on the different types, see the [http://www.derivativeinc.com/Tools/Touch000/Manual/Guides/GeoTypesGuide/GeometryTypes.pdf Geometry Types Guide]. Depending on the primitive type chosen, some SOP options may not apply.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : This option is used to select the type of surface, when using a <span class=\"tipTextSOP\">Mesh</span> primitive type.",
                "type": "Par",
                "name": "surftype"
            },
            {
                "text": "Determines overall radius.",
                "type": "Par",
                "name": "radx"
            },
            {
                "text": "Determines overall radius.",
                "type": "Par",
                "name": "rady"
            },
            {
                "text": "Determines overall radius.",
                "type": "Par",
                "name": "radz"
            },
            {
                "text": "Offset of superquad center from object center.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Offset of superquad center from object center.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Offset of superquad center from object center.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Menu : Determines pole axis for the iso surface.",
                "type": "Par",
                "name": "orient"
            },
            {
                "text": "Menu : Adds UV texture coordinates to the sphere.",
                "type": "Par",
                "name": "texture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "superquad",
        "opLabel": "Superquad",
        "short": "The Superquad SOP generates an isoquadric surface.",
        "opClass": "superquadSOP_Class",
        "opFamily": "SOP",
        "long": "The Superquad SOP generates an isoquadric surface. This produces a spherical shape that is similar to a metaball, with the difference that it doesn't change it's shape in response to what surrounds it. You can change the <span class=\"tipTextSOP\">XY Exponent</span> of an isoquadric surface to define it to be more \"squarish\" or \"starish\" in shape. Also, an isoquadric surface is always defined as a polygonal or mesh type geometry.",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "sweepSOP": {
        "label": "sweepSOP",
        "members": [
            {
                "text": "Menu : Determines the Cycle Type based on these menu options.",
                "type": "Par",
                "name": "cycle"
            },
            {
                "text": "Menu : Determines the output based on these menu options.",
                "type": "Par",
                "name": "skin"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "sweep",
        "opLabel": "Sweep",
        "short": "The Sweep SOP sweeps primitives in the Cross-section input along Backbone Source primitive(s), creating ribbon and tube-like shapes.",
        "opClass": "sweepSOP_Class",
        "opFamily": "SOP",
        "long": "The Sweep SOP sweeps primitives in the Cross-section input along Backbone Source primitive(s), creating ribbon and tube-like shapes. The cross-section primitives are placed at each point of the backbone perpendicular to it. The Backbone Source can have one or several primitives. If there is more than one, Sweep will sweep the cross section along each one.\t\t\n\t\t\t\nA backbone is a primitive curve that can be open or closed, but must have at least two points. The cross section input can also have multiple primitives, and can be assigned to the backbone in various ways. The origin of the cross section primitive is placed at a point on the backbone by default, but you can also choose a point number of the cross section to place. In most cases, it is best to build the cross section primitives in the XY plane; Sweep will automatically orient them properly along the backbone. If the backbone primitive(s) have point colors or texture coordinates, they will be maintained and applied to the cross section primitives.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "textSOP": {
        "label": "textSOP",
        "members": [
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : Use to set whether the language reads Left to Right or Right to Left.",
                "type": "Par",
                "name": "readingdirection"
            },
            {
                "text": "The amount of space to add between letters in X and Y. Kerning is way of adding an arbitrary offset between letters. There already is a default offset associated with each font so the letters are flush against each other. The <span class=\"tipTextSOP\">Kerning</span> parameter this adds to that and allows for a Y offset.",
                "type": "Par",
                "name": "kerning1"
            },
            {
                "text": "The amount of space to add between letters in X and Y. Kerning is way of adding an arbitrary offset between letters. There already is a default offset associated with each font so the letters are flush against each other. The <span class=\"tipTextSOP\">Kerning</span> parameter this adds to that and allows for a Y offset.",
                "type": "Par",
                "name": "kerning2"
            },
            {
                "text": "Menu : Sets the horizontal alignment.",
                "type": "Par",
                "name": "alignx"
            },
            {
                "text": "Menu : Sets the overall transform order for the transformations. The transform order determines the order in which transformations take place. Depending on the order, you can achieve different results using the exact same values. Choose the appropriate order from the menu.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : Sets the order of the rotations within the overall transform order.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "These three fields move the geometry in the three axes.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "These three fields move the geometry in the three axes.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "These three fields move the geometry in the three axes.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "These three fields rotate the geometry in the three axes.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "These three fields rotate the geometry in the three axes.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "These three fields rotate the geometry in the three axes.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "These three fields scale the geometry in the three axes.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "These three fields scale the geometry in the three axes.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "These three fields scale the geometry in the three axes.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which geometry scales and rotates. Altering the pivot point produces different results depending on the transformation performed on the object.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of an object is located at: <code>-1, -1, 0</code> and you wanted to scale the object by <code>0.5</code> (reduce its size by 50%) the object would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which geometry scales and rotates. Altering the pivot point produces different results depending on the transformation performed on the object.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of an object is located at: <code>-1, -1, 0</code> and you wanted to scale the object by <code>0.5</code> (reduce its size by 50%) the object would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which geometry scales and rotates. Altering the pivot point produces different results depending on the transformation performed on the object.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of an object is located at: <code>-1, -1, 0</code> and you wanted to scale the object by <code>0.5</code> (reduce its size by 50%) the object would scale toward the pivot point and appear to slide down and to the left.",
                "type": "Par",
                "name": "pz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "text",
        "opLabel": "Text",
        "short": "The Text SOP creates text geometry from any [http://en.wikipedia.org/wiki/TrueType TrueType] or [http://en.wikipedia.org/wiki/OpenType OpenType] font that is installed on the system, or any TrueType/OpenType font file on disk.",
        "opClass": "textSOP_Class",
        "opFamily": "SOP",
        "long": "The Text SOP creates text geometry from any [http://en.wikipedia.org/wiki/TrueType TrueType] or [http://en.wikipedia.org/wiki/OpenType OpenType] font that is installed on the system, or any TrueType/OpenType font file on disk. [[Unicode]] is supported.\t\n\nSee also: [[Text TOP]], [[Unicode]].",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "textureSOP": {
        "label": "textureSOP",
        "members": [
            {
                "text": "Menu : The <span class=\"tipTextSOP\">Face</span>, <span class=\"tipTextSOP\">Uniform Spline</span>, and <span class=\"tipTextSOP\">Arc-Length Spline</span> texturing methods accept spline curves as well as polygons.\t\n\t\t\t\nWhen using one of the spline-based methods, specifying a paste hierarchy in the <span class=\"tipTextSOP\">Group</span> field will propagate the computation of texture coordinates to all of its nodes. Projection methods will typically yield smoother texture continuity between pasted surfaces than any of the spline methods. Sometimes it helps ensuring that pasted features are Chord-length parameterized with the [[Basis SOP]].",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : Axis to project along, or projection method from splines. X, Y, or Z axes.",
                "type": "Par",
                "name": "axis"
            },
            {
                "text": "Menu : Select to apply texture coordinates to their Natural Location, Point textures, or Vertex textures.\t\n\t\t\t\nWhen <span class=\"tipTextSOP\">Natural location</span> is selected, the UV's will be applied to the verticies when using <span class=\"tipTextSOP\">Polar</span>, <span class=\"tipTextSOP\">Cylindrical</span>, <span class=\"tipTextSOP\">Rows and Columns</span>, and <span class=\"tipTextSOP\">Face</span> texture types.  <span class=\"tipTextSOP\">Orthographic</span>, <span class=\"tipTextSOP\">Uniform Spline</span>, <span class=\"tipTextSOP\">Average Spline</span> and <span class=\"tipTextSOP\">Arc Length Spline</span> will always generate point UV's when you choose <span class=\"tipTextSOP\">Natural</span>.\t\t\t\n\t\t\t\nNatural Location will also create vertex uvs when creating new texture layers, if a vertex uv already exists for layer 0.\t\t\t\n\t\t\t\nIIf the primitive is open in both directions like a grid or a surface (so that the ends do not touch), then the advantage of vertex UV's does not apply since there are no matched seams on the single surface to worry about.\t\t\t\n\t\t\t\nUsing vertex UVs gives you unique points at the closed seam whereas point UVs are shared at seams and are, by default given a value of 0 for either U or V depending on the closed direction of the surface. If you want to make a closed surface open, simply insert a [[Carve SOP]] in the chain and place a single carve in the surface of the direction that the surface is closed.",
                "type": "Par",
                "name": "coord"
            },
            {
                "text": "Scales the texture coordinates a specific amount.",
                "type": "Par",
                "name": "su"
            },
            {
                "text": "Scales the texture coordinates a specific amount.",
                "type": "Par",
                "name": "sv"
            },
            {
                "text": "Scales the texture coordinates a specific amount.",
                "type": "Par",
                "name": "sw"
            },
            {
                "text": "Offsets the texture coordinates a specific amount.",
                "type": "Par",
                "name": "offsetu"
            },
            {
                "text": "Offsets the texture coordinates a specific amount.",
                "type": "Par",
                "name": "offsetv"
            },
            {
                "text": "Offsets the texture coordinates a specific amount.",
                "type": "Par",
                "name": "offsetw"
            },
            {
                "text": "Menu : Sets the overall transform order for the transformations. The transform order determines the order in which transformations take place. Depending on the order, you can achieve different results using the exact same values. Choose the appropriate order from the menu.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : Sets the order of the rotations within the overall transform order.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "These three fields move the texture coordinates in the three axes.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "These three fields move the texture coordinates in the three axes.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "These three fields move the texture coordinates in the three axes.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "These three fields rotate the texture coordinates in the three axes.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "These three fields rotate the texture coordinates in the three axes.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "These three fields rotate the texture coordinates in the three axes.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "These three fields scale the texture coordinates in the three axes.",
                "type": "Par",
                "name": "scaletwox"
            },
            {
                "text": "These three fields scale the texture coordinates in the three axes.",
                "type": "Par",
                "name": "scaletwoy"
            },
            {
                "text": "These three fields scale the texture coordinates in the three axes.",
                "type": "Par",
                "name": "scaletwoz"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which the texture coordinates scale and rotate. Altering the pivot point produces different results depending on the transformation performed.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of the texture coordinates is located at: <code>-1, -1, 0</code> and you wanted to scale by <code>0.5</code> (reduce its size by 50%) the texture would scale toward the pivot point and appear to slide down and to the left.\t\t\t\n\t\t\t\n[[Image:TouchGeometry91.gif]]\t\t\t\n\t\t\t\nIn the example above, rotations performed on a texture coordinates with different pivot points produce very different results.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which the texture coordinates scale and rotate. Altering the pivot point produces different results depending on the transformation performed.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of the texture coordinates is located at: <code>-1, -1, 0</code> and you wanted to scale by <code>0.5</code> (reduce its size by 50%) the texture would scale toward the pivot point and appear to slide down and to the left.\t\t\t\n\t\t\t\n[[Image:TouchGeometry91.gif]]\t\t\t\n\t\t\t\nIn the example above, rotations performed on a texture coordinates with different pivot points produce very different results.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which the texture coordinates scale and rotate. Altering the pivot point produces different results depending on the transformation performed.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of the texture coordinates is located at: <code>-1, -1, 0</code> and you wanted to scale by <code>0.5</code> (reduce its size by 50%) the texture would scale toward the pivot point and appear to slide down and to the left.\t\t\t\n\t\t\t\n[[Image:TouchGeometry91.gif]]\t\t\t\n\t\t\t\nIn the example above, rotations performed on a texture coordinates with different pivot points produce very different results.",
                "type": "Par",
                "name": "pz"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "texture",
        "opLabel": "Texture",
        "short": "The Texture SOP assigns texture UV and W coordinates to the Source geometry for use in texture and bump mapping.",
        "opClass": "textureSOP_Class",
        "opFamily": "SOP",
        "long": "The Texture SOP assigns texture UV and W coordinates to the Source geometry for use in texture and bump mapping. It generates multi-layers of texture coordinates.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "torusSOP": {
        "label": "torusSOP",
        "members": [
            {
                "text": "Menu : Select from the following types. For information on the different types, see the [[:Category:Geometry|Geometry]] category articles.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : This option is used to select the type of surface, when using a <span class=\"tipTextSOP\">Mesh</span> primitive type.",
                "type": "Par",
                "name": "surftype"
            },
            {
                "text": "Menu : The axis along which the torus is constructed.",
                "type": "Par",
                "name": "orient"
            },
            {
                "text": "The first value (radx) defines the radius of the torus, the second value (rady) determines the radius of the inner ring.\t\n\t\t\t\n[[Image:TouchGeometry256.gif]]",
                "type": "Par",
                "name": "radx"
            },
            {
                "text": "The first value (radx) defines the radius of the torus, the second value (rady) determines the radius of the inner ring.\t\n\t\t\t\n[[Image:TouchGeometry256.gif]]",
                "type": "Par",
                "name": "rady"
            },
            {
                "text": "Offset of torus center from object origin.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Offset of torus center from object origin.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Offset of torus center from object origin.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "Float : The start and end sweep angles of the torus, if <span class=\"tipTextSOP\">U Wrap</span> is not enabled.",
                "type": "Par",
                "name": "angleu"
            },
            {
                "text": "Float : These are the start and end angles of the cross-section circle that is swept to make the torus, if <span class=\"tipTextSOP\">V Wrap</span> is not enabled.",
                "type": "Par",
                "name": "anglev"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "torus",
        "opLabel": "Torus",
        "short": "The Torus SOP generates complete or specific sections of torus shapes (like a doughnut).",
        "opClass": "torusSOP_Class",
        "opFamily": "SOP",
        "long": "The Torus SOP generates complete or specific sections of torus shapes (like a doughnut).",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "traceSOP": {
        "label": "traceSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "trace",
        "opLabel": "Trace",
        "short": "The Trace SOP reads an image file and automatically traces it, generating a set of faces around areas exceeding a certain brightness threshold.",
        "opClass": "traceSOP_Class",
        "opFamily": "SOP",
        "long": "The Trace SOP reads an image file and automatically traces it, generating a set of faces around areas exceeding a certain brightness threshold. You can control this threshold and the resolution of the resulting faces.",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "trailSOP": {
        "label": "trailSOP",
        "members": [
            {
                "text": "Menu : How to construct the trail geometry.",
                "type": "Par",
                "name": "result"
            },
            {
                "text": "Menu : This option is used to select the type of surface, when using a <span class=\"tipTextSOP\">Mesh Primitive Type</span>.",
                "type": "Par",
                "name": "surftype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "trail",
        "opLabel": "Trail",
        "short": "The Trail SOP takes an input SOP and makes a trail of each point of the input SOP over the past several frames, and connects the trails in different ways.",
        "opClass": "trailSOP_Class",
        "opFamily": "SOP",
        "long": "The Trail SOP takes an input SOP and makes a trail of each point of the input SOP over the past several frames, and connects the trails in different ways. It will generate trails of any input geometry, whether it is a cube translating, a deforming surface, or particles. This is useful for multi-frame ghosting effects and temporal modelling.\t\n\t\t\nWhen using a [[Particle SOP]] or [[Spring SOP]] as input, it is important to keep the trail increment to integer values. Otherwise, the trail will not work well.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "transformSOP": {
        "label": "transformSOP",
        "members": [
            {
                "text": "Menu : Sets the overall transform order for the transformations. The transform order determines the order in which transformations take place. Depending on the order, you can achieve different results using the exact same values. Choose the appropriate order from the menu.",
                "type": "Par",
                "name": "xord"
            },
            {
                "text": "Menu : Sets the order of the rotations within the overall transform order.",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "These three fields move the Source geometry in the three axes.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "These three fields move the Source geometry in the three axes.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "These three fields move the Source geometry in the three axes.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "These three fields rotate the Source geometry in the three axes.",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "These three fields rotate the Source geometry in the three axes.",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "These three fields rotate the Source geometry in the three axes.",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "These three fields scale the Source geometry in the three axes.",
                "type": "Par",
                "name": "sx"
            },
            {
                "text": "These three fields scale the Source geometry in the three axes.",
                "type": "Par",
                "name": "sy"
            },
            {
                "text": "These three fields scale the Source geometry in the three axes.",
                "type": "Par",
                "name": "sz"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which geometry scales and rotates. Altering the pivot point produces different results depending on the transformation performed on the object.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of an object is located at: <code>-1, -1, 0</code> and you wanted to scale the object by <code>0.5</code> (reduce its size by 50%) the object would scale toward the pivot point and appear to slide down and to the left.\t\t\t\n\t\t\t\n[[Image:TouchGeometry91.gif]]\t\t\t\n\t\t\t\nIn the example above, rotations performed on an object with different pivot points produce very different results.",
                "type": "Par",
                "name": "px"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which geometry scales and rotates. Altering the pivot point produces different results depending on the transformation performed on the object.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of an object is located at: <code>-1, -1, 0</code> and you wanted to scale the object by <code>0.5</code> (reduce its size by 50%) the object would scale toward the pivot point and appear to slide down and to the left.\t\t\t\n\t\t\t\n[[Image:TouchGeometry91.gif]]\t\t\t\n\t\t\t\nIn the example above, rotations performed on an object with different pivot points produce very different results.",
                "type": "Par",
                "name": "py"
            },
            {
                "text": "The pivot point for the transformations (not the same as the pivot point in the pivot channels). The pivot point parameters allow you to define the point about which geometry scales and rotates. Altering the pivot point produces different results depending on the transformation performed on the object.\t\n\t\t\t\nFor example, during a scaling operation, if the pivot point of an object is located at: <code>-1, -1, 0</code> and you wanted to scale the object by <code>0.5</code> (reduce its size by 50%) the object would scale toward the pivot point and appear to slide down and to the left.\t\t\t\n\t\t\t\n[[Image:TouchGeometry91.gif]]\t\t\t\n\t\t\t\nIn the example above, rotations performed on an object with different pivot points produce very different results.",
                "type": "Par",
                "name": "pz"
            },
            {
                "text": "When orienting an object, the <span class=\"tipTextSOP\">Up Vector</span> is used to determine where the positive Y axis points.",
                "type": "Par",
                "name": "upvectorx"
            },
            {
                "text": "When orienting an object, the <span class=\"tipTextSOP\">Up Vector</span> is used to determine where the positive Y axis points.",
                "type": "Par",
                "name": "upvectory"
            },
            {
                "text": "When orienting an object, the <span class=\"tipTextSOP\">Up Vector</span> is used to determine where the positive Y axis points.",
                "type": "Par",
                "name": "upvectorz"
            },
            {
                "text": "Menu : Sets the center of the geometry after the Transform page has been applied.",
                "type": "Par",
                "name": "posttx"
            },
            {
                "text": "Menu : Determines which part of the input geometry to align to the Origin or Reference Input as selected in Post Translate parameter above.",
                "type": "Par",
                "name": "fromx"
            },
            {
                "text": "Menu : When using Reference Input this determines which part of the Reference Input to align the geometry to.",
                "type": "Par",
                "name": "tox"
            },
            {
                "text": "Menu : Sets the center of the geometry after the Transform page has been applied.",
                "type": "Par",
                "name": "postty"
            },
            {
                "text": "Menu : Determines which part of the input geometry to align to the Origin or Reference Input as selected in Post Translate parameter above.",
                "type": "Par",
                "name": "fromy"
            },
            {
                "text": "Menu : When using Reference Input this determines which part of the Reference Input to align the geometry to.",
                "type": "Par",
                "name": "toy"
            },
            {
                "text": "Menu : Sets the center of the geometry after the Transform page has been applied.",
                "type": "Par",
                "name": "posttz"
            },
            {
                "text": "Menu : Determines which part of the input geometry to align to the Origin or Reference Input as selected in Post Translate parameter above.",
                "type": "Par",
                "name": "fromz"
            },
            {
                "text": "Menu : When using Reference Input this determines which part of the Reference Input to align the geometry to.",
                "type": "Par",
                "name": "toz"
            },
            {
                "text": "Menu : Sets the scale of the geometry after the Transform page has been applied.",
                "type": "Par",
                "name": "postscale"
            },
            {
                "text": "Menu : Sets the scale of the geometry after the Transform page has been applied to scale.",
                "type": "Par",
                "name": "postscalex"
            },
            {
                "text": "Menu : Sets the scale of the geometry after the Transform page has been applied to scale.",
                "type": "Par",
                "name": "postscaley"
            },
            {
                "text": "Menu : Sets the scale of the geometry after the Transform page has been applied to scale.",
                "type": "Par",
                "name": "postscalez"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "transform",
        "opLabel": "Transform",
        "short": "The Transform SOP translates, rotates and scales the input geometry in \"object space\" or local to the SOP.",
        "opClass": "transformSOP_Class",
        "opFamily": "SOP",
        "long": "The Transform SOP translates, rotates and scales the input geometry in \"object space\" or local to the SOP. The Model Editor and the Transform SOP both work in \"object space\", and change the X Y Z positions of the points. In contrast, animating the transformation channels of an object in the Geometry Viewer Pane moves/scales the entire object in \"world space\" and does not affect the XYZ point positions of the geometry.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "trimSOP": {
        "label": "trimSOP",
        "members": [
            {
                "text": "Menu : The types of trimming operations available.",
                "type": "Par",
                "name": "optype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "trim",
        "opLabel": "Trim",
        "short": "The Trim SOP cuts out parts of a spline surface, or uncuts previously cut pieces.",
        "opClass": "trimSOP_Class",
        "opFamily": "SOP",
        "long": "The Trim SOP cuts out parts of a spline surface, or uncuts previously cut pieces. When a portion of the surface is trimmed, it is not actually removed from the surface; instead, that part is made invisible. This means that you can still modify the surface (modify the position of its points, for instance) that is not displayed in order to affect the part that is displayed.\t\n\t\t\nThe surface can be trimmed by specifying open or closed profiles as inside or outside regions. The profiles need not be contained within the domain (UV space) of the surface; they can also be nested.\t\t\n\t\t\nOpen profiles are treated as follows: if both ends of the profile are inside the surface, the ends are connected to one another; if the profile's ends are outside the domain of the surface they are projected onto, that part of the surface appears to be cut away.\t\t\n\t\t\nYou will usually need a Trim SOP, [[Bridge SOP]], or [[Profile SOP]] after a [[Project SOP]].\t\t\n\t\t\n* Use a Trim SOP to cut a hole in the projected surface.\t\t\n* Use a [[Bridge SOP]] to skin the profile curve to another profile curve.\t\t\n* Use a [[Profile SOP]] to extract the curve on surface or remap it's position.\t\t\n{{OPSubSection\n|opFamily=SOP\n|sectionName=Selection Method - Winding Rule\n|sectionSummary=The selection method employed for clarifying overlapping trim loops is the winding rule, which executes overlapping commands instead of having them cancel each other out.\t\t\n\t\t\n'''Tip:''' Since only surfaces containing profile curves can be trimmed, you will always need a Project or [[Carve SOP]] in the chain above the Trim SOP.\n}}",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "tristripSOP": {
        "label": "tristripSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "tristrip",
        "opLabel": "Tristrip",
        "short": "The Tristrip SOP convert geometry into triangle strips.",
        "opClass": "tristripSOP_Class",
        "opFamily": "SOP",
        "long": "The Tristrip SOP convert geometry into triangle strips. Triangle strips are faster to render than regular triangles or quads.",
        "opLicense": "Non-Commercial",
        "opFilter": "True",
        "opCategories": ""
    },
    "tubeSOP": {
        "label": "tubeSOP",
        "members": [
            {
                "text": "Menu : Select from the following types. For information on the different types, see the [[:Category:Geometry|Geometry]] category articles.",
                "type": "Par",
                "name": "type"
            },
            {
                "text": "Menu : This option is used to select the type of surface, when using a Mesh Primitive Type.",
                "type": "Par",
                "name": "surftype"
            },
            {
                "text": "Menu : Primary axis of tube (long axis).",
                "type": "Par",
                "name": "orient"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rord"
            },
            {
                "text": "Location of the tube center from the object origin.",
                "type": "Par",
                "name": "tx"
            },
            {
                "text": "Location of the tube center from the object origin.",
                "type": "Par",
                "name": "ty"
            },
            {
                "text": "Location of the tube center from the object origin.",
                "type": "Par",
                "name": "tz"
            },
            {
                "text": "",
                "type": "Par",
                "name": "rx"
            },
            {
                "text": "",
                "type": "Par",
                "name": "ry"
            },
            {
                "text": "",
                "type": "Par",
                "name": "rz"
            },
            {
                "text": "The first field is the radius of the top of the tube and the second field represents the radius of the bottom of the tube.",
                "type": "Par",
                "name": "rad1"
            },
            {
                "text": "The first field is the radius of the top of the tube and the second field represents the radius of the bottom of the tube.",
                "type": "Par",
                "name": "rad2"
            },
            {
                "text": "Menu : Adds UV texture coordinates to the sphere.",
                "type": "Par",
                "name": "texture"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opType": "tube",
        "opLabel": "Tube",
        "short": "The Tube SOP generates open or closed tubes, cones, or pyramids along the X, Y or Z axes.",
        "opClass": "tubeSOP_Class",
        "opFamily": "SOP",
        "long": "The Tube SOP generates open or closed tubes, cones, or pyramids along the X, Y or Z axes. It outputs as meshes, polygons or simply a tube [[Primitive]].",
        "opLicense": "Non-Commercial",
        "opFilter": "False",
        "opCategories": ""
    },
    "vertexSOP": {
        "label": "vertexSOP",
        "members": [
            {
                "text": "Menu : Select between keeping the color, adding new color, or using no color for vertex color attributes from incoming geometry.",
                "type": "Par",
                "name": "doclr"
            },
            {
                "text": "If you select 'Add Color' from the menu above, Cd color vertex attributes will be added/modified in the SOP. Enter expressions below to control the values of the point colors. The attributes to modify are: <code>me.inputColor[0]</code> for red, <code>me.inputColor[1]</code> for green, <code>me.inputColor[2]</code> for blue, and <code>me.inputColor[3]</code> for alpha. If you select 'No Color' from the menu above, the Cd color vertex attribute will be removed from the SOP.",
                "type": "Par",
                "name": "diffr"
            },
            {
                "text": "If you select 'Add Color' from the menu above, Cd color vertex attributes will be added/modified in the SOP. Enter expressions below to control the values of the point colors. The attributes to modify are: <code>me.inputColor[0]</code> for red, <code>me.inputColor[1]</code> for green, <code>me.inputColor[2]</code> for blue, and <code>me.inputColor[3]</code> for alpha. If you select 'No Color' from the menu above, the Cd color vertex attribute will be removed from the SOP.",
                "type": "Par",
                "name": "diffg"
            },
            {
                "text": "If you select 'Add Color' from the menu above, Cd color vertex attributes will be added/modified in the SOP. Enter expressions below to control the values of the point colors. The attributes to modify are: <code>me.inputColor[0]</code> for red, <code>me.inputColor[1]</code> for green, <code>me.inputColor[2]</code> for blue, and <code>me.inputColor[3]</code> for alpha. If you select 'No Color' from the menu above, the Cd color vertex attribute will be removed from the SOP.",
                "type": "Par",
                "name": "diffb"
            },
            {
                "text": "Menu : Select between keeping the texture coordinates, adding new texture coordinates, or using no texture coordinates for the vertex texture attributes from incoming geometry.",
                "type": "Par",
                "name": "douvw"
            },
            {
                "text": "If you select 'Add Texture' from the menu above, uv texture coordinate vertex attributes will be added/modified in the SOP. Enter expressions here to control the values of the vertex texture coordinates here. The attributes to modify are: <code>me.inputTexture[0]</code>, <code>me.inputTexture[1]</code> and <code>me.inputTexture[2]</code>. If you select 'No Texture' from the menu above, the uv texture coordinates vertex attribute will be removed from the SOP.",
                "type": "Par",
                "name": "mapu"
            },
            {
                "text": "If you select 'Add Texture' from the menu above, uv texture coordinate vertex attributes will be added/modified in the SOP. Enter expressions here to control the values of the vertex texture coordinates here. The attributes to modify are: <code>me.inputTexture[0]</code>, <code>me.inputTexture[1]</code> and <code>me.inputTexture[2]</code>. If you select 'No Texture' from the menu above, the uv texture coordinates vertex attribute will be removed from the SOP.",
                "type": "Par",
                "name": "mapv"
            },
            {
                "text": "If you select 'Add Texture' from the menu above, uv texture coordinate vertex attributes will be added/modified in the SOP. Enter expressions here to control the values of the vertex texture coordinates here. The attributes to modify are: <code>me.inputTexture[0]</code>, <code>me.inputTexture[1]</code> and <code>me.inputTexture[2]</code>. If you select 'No Texture' from the menu above, the uv texture coordinates vertex attribute will be removed from the SOP.",
                "type": "Par",
                "name": "mapw"
            },
            {
                "text": "Menu : Select between keeping the crease, adding new crease, or using no crease for creaseweight attribute from incoming geometry.\t\n\t\t\nThe <code>Crease Weight</code> attribute can be used to set individual edge crease weights for sub-division surfaces (see [[Subdivide SOP]] ). This vertex attribute defines the weight for the edge which goes from that vertex to the next vertex in the polygon. For example, with a triangle (which has vertices 0, 1, 2), the attribute for vertex 1 defines the crease weight for the edge (1, 2). The attribute for vertex 2 defines the crease weight for edge (2, 0). The crease weight should be greater than 0. The larger the value for crease weights, the sharper the edge will be when sub-divided.\t\t\n\t\t\nCrease attributes can be visualized by passing them into a [[Subdivide SOP]].",
                "type": "Par",
                "name": "docrease"
            },
            {
                "text": "Menu : The type of attribute created can be selected from this menu.",
                "type": "Par",
                "name": "custom1type"
            },
            {
                "text": "Set the values of the Custom Attrib using these parameters.",
                "type": "Par",
                "name": "custom1val1"
            },
            {
                "text": "Set the values of the Custom Attrib using these parameters.",
                "type": "Par",
                "name": "custom1val2"
            },
            {
                "text": "Set the values of the Custom Attrib using these parameters.",
                "type": "Par",
                "name": "custom1val3"
            },
            {
                "text": "Set the values of the Custom Attrib using these parameters.",
                "type": "Par",
                "name": "custom1val4"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Vertex SOP allows you to edit/create attributes on a per-vertex (rather than per-point) basis.",
        "opClass": "vertexSOP_Class",
        "opFilter": "True",
        "long": "The Vertex SOP allows you to edit/create attributes on a per-vertex (rather than per-point) basis. It is similar to the [[Point SOP]] in this respect. It supports two inputs, and will inherit the first input source by default.  If the second input have less primitives than the first input, it will cycle through the primitives and match the vertices.  If the primitive in the first input has more vertices than the matching primitive in the second input, the extra vertices are ignored.\t\n\t\t\nThere are currently three vertex attributes supported:\t\t\n\t\t\n* Diffuse Color\t\t\n* Alpha\t\t\n* Texture Coordinates\t\t\n\t\t\nWhen the attribute is defined, it can only occur on either points or vertices, but not both. Thus, if the input geometry has a point attribute for diffuse color, the attribute will automatically be \"elevated\" to be a vertex attribute (if diffuse colors are added in the Vertex SOP).\t\t\n\t\t\nThe SOP processes every vertex of every primitive. For each vertex processed, there are variables which allow you to know the:\t\t\n\t\t\n* Vertex number of the primitive being processed\t\t\n* The number of vertices in the primitive being processed\t\t\n* The point which is referenced by the vertex\t\t\n* The primitive which contains the vertex\t\t\n* The total number of points\t\t\n* The total number of primitives \t\t\n\t\t\nThere are also local variables to find out the values of some point attributes (i.e. position, normal - if they exist), in addition to vertex attributes.  To access the attributes of the second input source, append a 2 to the variable.",
        "opLicense": "Non-Commercial",
        "opFamily": "SOP",
        "opType": "vertex",
        "opLabel": "Vertex",
        "opCategories": ""
    },
    "wireframeSOP": {
        "label": "wireframeSOP",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Wireframe SOP converts edges to tubes and points to spheres, creating the look of a wire frame structure in renderings.",
        "opClass": "wireframeSOP_Class",
        "opFilter": "True",
        "long": "The Wireframe SOP converts edges to tubes and points to spheres, creating the look of a wire frame structure in renderings. This is ideal for modelling tube structures and pipes.",
        "opLicense": "Non-Commercial",
        "opFamily": "SOP",
        "opType": "wire",
        "opLabel": "Wireframe",
        "opCategories": ""
    },
    "artnetDAT": {
        "label": "artnetDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Art-Net",
        "long": "The Art-Net DAT polls and lists all devices on the network.\t\n\n'''Tip''': If you are having trouble inspecting the Art-Net packets that are or aren\u2019t being read by a device, use the [https://www.wireshark.org/ Wireshark] utility to capture a network stream for comparison.\n\nSee [[Art-Net]], [[DMX In CHOP]], [[DMX Out CHOP]].",
        "opType": "artnet",
        "opClass": "artnetDAT_Class",
        "opFilter": "False",
        "short": "The Art-Net DAT polls and lists all devices on the network.",
        "opCategories": ""
    },
    "chopexecuteDAT": {
        "label": "chopexecuteDAT",
        "members": [
            {
                "text": "Menu : ([[Operator Language|Tscript]] only) Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            },
            {
                "text": "Menu : Enabled when using the <span class=\"tipTextDAT\">While On</span> or <span class=\"tipTextDAT\">While Off</span> options above.  Determines if the DAT executes <span class=\"tipTextDAT\">For Every Sample</span> or <span class=\"tipTextDAT\">Once Per Frame</span>.",
                "type": "Par",
                "name": "freq"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "CHOP Execute",
        "long": "The CHOP Execute DAT will run its script when the channel values of a specified CHOP change. You can specify which channels to look at, and trigger based on their values changing in various ways.  The script gets called for every sample that changes, so when rendering one frame, it may get called 2 or more times per channel, depending on how many frames forward TouchDesigner has stepped (see [[Time Slicing]]).\t\t\n\t\t\t\nCHOP Execute DATs are created with [[chopexecuteDAT_Class|default python method placeholders]]. For each monitored condition in the parameters, there is a matching python method in the DAT. When a condition is turned on in the parameters, each time that condition is satisfied the corresponding python method will be executed.",
        "opType": "chopexec",
        "opClass": "chopexecuteDAT_Class",
        "opFilter": "False",
        "short": "The CHOP Execute DAT will run its script when the channel values of a specified CHOP change.",
        "opCategories": ""
    },
    "choptoDAT": {
        "label": "choptoDAT",
        "members": [
            {
                "text": "Menu : Create a row per channel or column per channel.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "CHOP to",
        "long": "The CHOP to DAT allows you to get CHOP channel values into a DAT in table format.",
        "opType": "chopto",
        "opClass": "choptoDAT_Class",
        "opFilter": "False",
        "short": "The CHOP to DAT allows you to get CHOP channel values into a DAT in table format.",
        "opCategories": ""
    },
    "clipDAT": {
        "label": "clipDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Pro",
        "opLabel": "Clip",
        "long": "The Clip DAT contains information about motion clips that are manipulated by a [[Clip CHOP]] and [[Clip Blender CHOP]].\t\t\nThe Clip DAT can hold any command or script text, which can be triggered based on the settings on the <span class=\"tipTextDAT\">Execute</span> parameter page (This is where the Clip DAT and the Text DAT are different). The Clip DAT's script is triggered by specified clips being played through a [[Clip Blender CHOP]].",
        "opType": "clip",
        "opClass": "clipDAT_Class",
        "opFilter": "False",
        "short": "The Clip DAT contains information about motion clips that are manipulated by a [[Clip CHOP]] and [[Clip Blender CHOP]].",
        "opCategories": ""
    },
    "convertDAT": {
        "label": "convertDAT",
        "members": [
            {
                "text": "Menu : Convert text format.",
                "type": "Par",
                "name": "how"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Convert",
        "long": "The Convert DAT changes the text format from simple text to table form and vice-versa.",
        "opType": "convert",
        "opClass": "convertDAT_Class",
        "opFilter": "True",
        "short": "The Convert DAT changes the text format from simple text to table form and vice-versa.",
        "opCategories": ""
    },
    "cplusplusDAT": {
        "label": "cplusplusDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opType": "cplusplusDAT",
        "opLabel": "CPlusPlus",
        "opClass": "cplusplusDAT_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The CPlusPlus DAT allows you to make custom DAT operators by writing your own plugin using C++.",
        "long": "The CPlusPlus DAT allows you to make custom DAT operators by writing your own plugin using C++.\n \nUsing the CPlusPlus DAT, you can create either a Table or Text DAT output depending what type you specify at the time of creation.\nSee [[Write a CPlusPlus Plugin]] and the other articles in the [[:Category:C++|C++ category]] for more detailed information on how to make .dll for use with this DAT. Note that regardless of the type of DAT node (i.e. Table or Text), all the names for searching the cells and assigned texts have to be a encoded as a valid UTF-8.\n\nExample for CPlusPlus DAT as a Visual Studio project in Windows are available in <code>C:/Program Files/Derivative/TouchDesigner/Samples/CPlusPlus/DAT</code> or your custom TouchDesigner installation folder. (NOTE: On macOS it is here: <code>TouchDesigner.app/Contents/Resources/tfs/Samples/CPlusPlus/DAT</code>\n\n'''Custom Parameters''' - Custom Parameters can be automatically created by the C++ DAT <code>.dll</code>. This custom parameter page can be removed, edited, or appended to from within the <code>setupParameters()</code> function in CPlusPlusDATExample.cpp. The defined custom parameters can be enabled or disabled depending on whether they are valid for a specific task or not.)",
        "opCategories": ""
    },
    "datexecuteDAT": {
        "label": "datexecuteDAT",
        "members": [
            {
                "text": "Menu : ([[Operator Language|Tscript]] only) Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            },
            {
                "text": "Menu : Determines if the methods are executed at the start of the frame or end of the frame.",
                "type": "Par",
                "name": "execute"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "DAT Execute",
        "long": "The DAT Execute DAT monitors another DAT's contents and runs a script when those contents change. The other DAT is usually a table.\t\t\n\t\t\t\nDAT Execute DATs are created with [[datexecuteDAT_Class#Callbacks|default python method placeholders]]. For each monitored condition in the parameters, there is a matching python method in the DAT. When a condition is turned on in the parameters, each time that condition is satisfied the corresponding python method will be executed.",
        "opType": "datexec",
        "opClass": "datexecuteDAT_Class",
        "opFilter": "False",
        "short": "The DAT Execute DAT monitors another DAT's contents and runs a script when those contents change. The other DAT is usually a table.",
        "opCategories": ""
    },
    "errorDAT": {
        "label": "errorDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Error",
        "long": "The Error DAT lists the most recent TouchDesigner errors in its FIFO (first in/first out) table. \t\t\n\t\t\t\nYou can filter our messages using pattern matching on some of the columns like Severity, Type and path of the node containing the error. One column contains the absolute frame (<code>absTime.frame</code>) in which the error occurred.",
        "opType": "error",
        "opClass": "errorDAT_Class",
        "opFilter": "False",
        "short": "The Error DAT lists the most recent TouchDesigner errors in its FIFO (first in/first out) table.",
        "opCategories": ""
    },
    "etherdreamDAT": {
        "label": "etherdreamDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "EtherDream",
        "long": "The EtherDream DAT polls and lists all EtherDream devices connected.",
        "opType": "etherdream",
        "opClass": "etherdreamDAT_Class",
        "opFilter": "False",
        "short": "The EtherDream DAT polls and lists all EtherDream devices connected.",
        "opCategories": ""
    },
    "evaluateDAT": {
        "label": "evaluateDAT",
        "members": [
            {
                "text": "StrMenu : Determines what format will be used for output from the DAT.",
                "type": "Par",
                "name": "output"
            },
            {
                "text": "Menu : If the Output Table Size parameter is Strings, Expressions, or Commands, and there is a second input, you can choose the output table size to be either Input DAT or the Formula DAT.  If the Formula DAT is chosen and its table size is greater than the input data table, then the last cell in each row or column will be used when evaluating the remaining formulas.",
                "type": "Par",
                "name": "outputsize"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Evaluate",
        "long": "The Evaluate DAT changes the cells of the incoming DAT using string-editing and math expressions. \t\t\n\t\t\t\nIn its simplest form, without an input DAT attached, you can put any python expression in the Expression parameter of an Evaluate DAT. To evaluate the expression every frame you may need to put the parameter into Expression [[Parameter Mode]].\t\t\t\n\t\t\t\nWith a DAT attached, it outputs a table with the same number of rows and columns as the input. \t\t\t\n\t\t\t\nThe Scope page can be used to restrict which rows and columns of cells are affected.\t\t\t\n\t\t\t\n* When the <span class=\"tipTextDAT\">Output</span> menu is set to Expressions, it causes the input cells to be evaluated as Pythong expressions. <code>me.inputCell.val</code> is the value of the input cell. \t\t\t\n\t\t\t\n* The optional second input DAT is an array of expressions which are matched to the cells of the input, then evaluated and output. If there are fewer rows in the second DAT than the first, the expressions in the last row of the second input are repeated. If there are fewer columns in the second DAT than the first, the last column is repeated.\t\t\t\n\t\t\t\n* '''Expressions are optimized by storing a compiled internal version, which runs much faster.'''  Use this where possible.  If you are reusing expressions by repeating them in a table, having an input table with the few expressions you will cycle through separate from the data will also improve performance.\t\t\t\n\t\t\t\nIf the second DAT is one cell, like the Expression parameter, it applies its expression to all the input cells. A one-cell second DAT with <code>me.inputCell.val+1</code> adds 1 to all the first input's cells.\t\t\t\n\t\t\t\nIf the second DAT is\n{{{!}} class=\"wikitable\"\n{{!}}<syntaxhighlight lang=python inline>me.inputCell.val</syntaxhighlight> {{!}}{{!}} <syntaxhighlight lang=python inline>me.inputCell.val</syntaxhighlight>\n{{!}}-\n{{!}}<syntaxhighlight lang=python inline>me.inputCell.val</syntaxhighlight> {{!}}{{!}} <syntaxhighlight lang=python inline>math.sin(math.radians(float(me.inputCell.val)))</syntaxhighlight>\n{{!}}}\nthen the first row and first column are left intact and the rest of the cells get their <code>sin()</code> computed.\t\t\t\n\t\t\t\n[[File:EvaluateDAT_ex.png]]\t\t\t\n\t\t\t\nThe Evaluate DAT maintains the format of the first input DAT (table or text) unless the Output Table Size parameter is used.\t\t\t\n\t\t\t\nSee also the [[Substitute DAT]], [[Expression CHOP]].",
        "opType": "eval",
        "opClass": "evaluateDAT_Class",
        "opFilter": "False",
        "short": "The Evaluate DAT changes the cells of the incoming DAT using string-editing and math expressions.",
        "opCategories": ""
    },
    "examineDAT": {
        "label": "examineDAT",
        "members": [
            {
                "text": "Menu : Specifies what part of the operator to examine.",
                "type": "Par",
                "name": "source"
            },
            {
                "text": "Menu : Determines whether the output is raw text or in table format.",
                "type": "Par",
                "name": "format"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Examine",
        "long": "The Examine DAT lets you inspect an operator's python storage, locals, globals, expressions, and extensions.",
        "opType": "examine",
        "opClass": "examineDAT_Class",
        "opFilter": "False",
        "short": "The Examine DAT lets you inspect an operator's python storage, locals, globals, expressions, and extensions.",
        "opCategories": ""
    },
    "executeDAT": {
        "label": "executeDAT",
        "members": [
            {
                "text": "Menu : ([[Operator Language|Tscript]] only) Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Execute",
        "long": "The Execute DAT lets you edit scripts and run them based on conditions. It can be executed at the start or end of every frame, or at the start or end of the TouchDesigner process. \n\t\t\t\nExecute DATs are created with [[executeDAT_Class|default python method placeholders]].  For each monitored condition in the parameters, there is a matching python method in the DAT.  When a condition is turned on in the parameters, each time that condition is satisfied the corresponding python method will be executed.\t\n\nText can also can be passed into the Text DAT through the node's input, however this text will not be editable. Text can be created in the DAT via the [[Node Viewer]] or an external text editor.  \t\n\nSee also [[OP Execute DAT]].",
        "opType": "execute",
        "opClass": "executeDAT_Class",
        "opFilter": "False",
        "short": "The Execute DAT lets you edit scripts and run them based on conditions.",
        "opCategories": ""
    },
    "fifoDAT": {
        "label": "fifoDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "FIFO",
        "long": "The FIFO DAT maintains a user-set maximum number of rows in a table. You add rows using the <code>appendRow()</code> method found in [[DAT Class]]. When its capacity is reached, the first row is removed. After the maximum number of rows is reached, the oldest row is discarded when a new row is added.\t\t\n\t\t\t\nExample:\n<syntaxhighlight lang=python>op('fifo1').appendRow(['a','b','c'])</syntaxhighlight>",
        "opType": "fifo",
        "opClass": "fifoDAT_Class",
        "opFilter": "False",
        "short": "The FIFO DAT maintains a user-set maximum number of rows in a table.",
        "opCategories": ""
    },
    "fileinDAT": {
        "label": "fileinDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "File In",
        "long": "The File In DAT reads in <code>.txt</code> text files and <code>.dat</code> table files. It will attempt to read any other file as raw text. The file can be located on disk or on the web. Use <code>http://</code> when specifying a URL.\n    \nSee also [[Table DAT]], [[Text DAT]].",
        "opType": "filein",
        "opClass": "fileinDAT_Class",
        "opFilter": "False",
        "short": "The File In DAT reads in <code>.txt</code> text files and <code>.dat</code> table files.",
        "opCategories": ""
    },
    "fileoutDAT": {
        "label": "fileoutDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "File Out",
        "long": "The File Out DAT allows you to write out DAT contents to a <code>.dat</code> file or a <code>.txt</code> file. A <code>.dat</code> file is one of the [[File Types]] of TouchDesigner that is used to hold the arrays of the [[Table DAT]].\t\n\t\t\nWhen the File Out DAT has 0 inputs, it can be triggered to send text by using the <code>send</code> command.\t\t\n\t\t\nIf 'Append' is off, a new file is written every time, if 'Append' is on, the file is appended to, and the file handle remains open.",
        "opType": "fileout",
        "opClass": "fileoutDAT_Class",
        "opFilter": "True",
        "short": "The File Out DAT allows you to write out DAT contents to a <code>.dat</code> file or a <code>.txt</code> file.",
        "opCategories": ""
    },
    "folderDAT": {
        "label": "folderDAT",
        "members": [
            {
                "text": "Menu : Select whether to include the filename extension or not.",
                "type": "Par",
                "name": "nameformat"
            },
            {
                "text": "Menu : The format used to display the item's dates in the table.",
                "type": "Par",
                "name": "dateformat"
            },
            {
                "text": "Menu : The types of contents to display.",
                "type": "Par",
                "name": "type"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Folder",
        "long": "The Folder DAT lists the files and subfolders found in a file system folder and monitors any changes.\t\t\n\t\t\t\nFor each item found, a row is created in the table with optional columns for the following information: \t\t\t\n* Name\t\t\t\n* Base Name\t\t\t\n* Extension\t\t\t\n* Type\t\t\t\n* Size\t\t\t\n* Depth\t\t\t\n* Folder\t\t\t\n* Path\t\t\t\n* Relative Path\t\t\t\n* Date Created\t\t\t\n* Date Modified\t\t\t\n* Date Accessed",
        "opType": "folder",
        "opClass": "folderDAT_Class",
        "opFilter": "False",
        "short": "The Folder DAT lists the files and subfolders found in a file system folder and monitors any changes.",
        "opCategories": ""
    },
    "inDAT": {
        "label": "inDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "In",
        "long": "The In DAT is used to create a DAT input in a Component. Component inputs are positioned alphanumerically on the left side of the Component. Disconnecting an input to an In DAT will still keep the contents instanced to the original input.",
        "opType": "in",
        "opClass": "inDAT_Class",
        "opFilter": "True",
        "short": "The In DAT is used to create a DAT input in a Component.",
        "opCategories": ""
    },
    "indicesDAT": {
        "label": "indicesDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Indices",
        "long": "The Indices DAT creates a series of numbers in a table, ranging between the start and end values.  These values are suitable for display along a graph horizontal or vertical axis.  They are carefully picked to make them all round, nicely spaced, etc.",
        "opType": "indices",
        "opClass": "indicesDAT_Class",
        "opFilter": "False",
        "short": "The Indices DAT creates a series of numbers in a table, ranging between the start and end values."
    },
    "infoDAT": {
        "label": "infoDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Info",
        "long": "The Info DAT gives you string information about a node. Only some nodes contain additional string information which can be accessed by the Info DAT.",
        "opType": "info",
        "opClass": "infoDAT_Class",
        "opFilter": "False",
        "short": "The Info DAT gives you string information about a node.",
        "opCategories": ""
    },
    "insertDAT": {
        "label": "insertDAT",
        "members": [
            {
                "text": "Menu : Specify what to insert.",
                "type": "Par",
                "name": "insert"
            },
            {
                "text": "Menu : Specify where to insert.",
                "type": "Par",
                "name": "at"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Insert",
        "long": "The Insert DAT allows you to insert a row or column into an existing table.  \t\t\n\t\t\t\nYou can add strings that will be put in the new cells, space separated. If you want a cell to include spaces, in the Contents parameter put the cell contents in quotes:  <code>cell1 'cell 2' cell3</code>. Or a list in the parameter expression: <code>['cell1', 'cell 2']</code>\t\t\t\n\t\t\t\nIf the input DAT is not a table, it will be converted to a table.",
        "opType": "insert",
        "opClass": "insertDAT_Class",
        "opFilter": "True",
        "short": "The Insert DAT allows you to insert a row or column into an exiting table.",
        "opCategories": ""
    },
    "jsonDAT": {
        "label": "jsonDAT",
        "members": [
            {
                "text": "Menu : Select the output of the JSON DAT.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opType": "jsonDAT",
        "opLabel": "JSON",
        "opClass": "jsonDAT_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The JSON DAT converts and filters JSON text using [[JSONPath]] syntax and outputs the filtered results. It eliminates having to code scripts to parse and manipulate JSON, and keeps the data flow procedural.",
        "long": "The JSON DAT converts and filters JSON text using [[JSONPath]] syntax and outputs the filtered results. It eliminates having to code scripts to parse and manipulate JSON, and keeps the data flow procedural.\n    \nIt expects JSON text as input and converts the input to a Python object in the <code>DAT.source</code> member.\n\nIt then filters the JSON down using the [[JSONPath|JSONPath Filter parameter]], and it outputs the resulting data from the DAT as JSON text. \n\nIt also puts the filtered results as <code>DAT.results</code> (a Python list of results) and <code>DAT.result</code> (the first result).\n\nYou can test expressions on <code>DAT.source</code>, <code>DAT.result</code> and <code>DAT.results</code> by setting the Output menu to Expression and using expressions like <code>me.result['city']</code>, which outputs the evaluated expression from the DAT. You can then use that expression as <code>op('json1').result['city']</code> in an expression elsewhere.  <code>DAT.expr</code> is also a member of the JSON DAT, for example, <code>op('json1').expr</code> returns the evaluated expression parameter.\n\n'''Output tables''': The JSON DAT can output a table by setting the Output Format menu to Table. It will do its best to take the result of the JSON Filter and form rows and columns of values and headings in a DAT table. Any cell than can't be expressed as a simple string, integer, float or boolean will be left as the JSON string of the remainder. A cell or range of cells can be further reduced with a [[Select DAT]] and then passed to another JSON DAT which can convert the JSON strings to a table.\n\n'''See also:''' [[JSONPath]], [[OP Snippets]], and the [[TDJSON]] functions for converting and manipulating JSON data.",
        "opCategories": ""
    },
    "keyboardinDAT": {
        "label": "keyboardinDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Keyboard In",
        "long": "The Keyboard In DAT lists the most recent key events in its FIFO (first in/first out) table. There is one row for every key press down and every key-up, including Shift, Ctrl and Alt, with distinction between left and right side. For convenience, with each key press, a column indicates if the  Shift, Ctrl and Alt were being held down at the time.\t\t\n\t\t\t\nYou get key presses even of the cursor is outside the TouchDesigner windows, whether they are control panels, Perform Mode or the network editor window. Exceptions: while entering text in the editor window.\t\t\t\n\t\t\t\nYou can set a filter to watch only certain keys. Custom shortcuts can be defined and handled by a [[keyboardinDAT_Class|python callback in the attached script]].",
        "opType": "keyboardin",
        "opClass": "keyboardinDAT_Class",
        "opFilter": "False",
        "short": "The Keyboard In DAT lists the most recent key events in its FIFO (first in/first out) table.",
        "opCategories": ""
    },
    "lookupDAT": {
        "label": "lookupDAT",
        "members": [
            {
                "text": "dropmenu : Select how the index values are interpreted: as values/indices contained in a column or contained in a row.",
                "type": "Par",
                "name": "index"
            },
            {
                "text": "dropmenu : When 'Row Values' or 'Col Values' is selected in the Index Parameter, this parameter lets you select how the lookup row or column where the index value searches will be specified.",
                "type": "Par",
                "name": "valueloction"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opType": "lookupDAT",
        "opLabel": "Lookup",
        "opClass": "lookupDAT_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "short": "The Lookup DAT  outputs values from a lookup Table. The first input is an index into the second input.",
        "long": "The Lookup DAT  outputs values from a lookup Table. The first input is an index into the second input. \n    \nThe Lookup DAT allows you to select rows from its second input by referencing data either via row/column indices or row/column names. The advantage of the Lookup DAT is such that the order the data is selected is independent from the order in the Lookup Table, rather the Index Table dictates the order therefore allowing for reordering of data and selecting rows/columns multiple times.",
        "opCategories": ""
    },
    "mergeDAT": {
        "label": "mergeDAT",
        "members": [
            {
                "text": "Menu : Sets how tables are merged together.",
                "type": "Par",
                "name": "how"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Merge",
        "long": "The Merged DAT is a multi-input DAT which merges the text or tables from the input DATs together.",
        "opType": "merge",
        "opClass": "mergeDAT_Class",
        "opFilter": "True",
        "short": "The Merged DAT is a multi-input DAT which merges the text or tables from the input DATs together.",
        "opCategories": ""
    },
    "midieventDAT": {
        "label": "midieventDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "MIDI Event",
        "long": "The MIDI Event DAT logs all [[MIDI]] messages coming into or out of TouchDesigner from all MIDI In/Out operators. Note: no messages will be logged if there are no active MIDI In or Out operators set to receive them. It outputs columns in a table format: message, type, channel, index, value.\t\t\n\t\t\t\nThe table is FIFO \"first-in first-out\" and limited to parameter-set number of lines. An optional script may be run for each packet received.\t\t\t\n\t\t\t\nSee also the [[MIDI In DAT]], [[MIDI In Map CHOP]], [[MIDI In CHOP]], [[MIDI Out CHOP]], Tscript <code>midi()</code> Command.",
        "opType": "midievent",
        "opClass": "midieventDAT_Class",
        "opFilter": "False",
        "short": "The MIDI Event DAT logs all MIDI messages coming into TouchDesigner from all MIDI devices.",
        "opCategories": ""
    },
    "midiinDAT": {
        "label": "midiinDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "MIDI In",
        "long": "The MIDI In DAT logs all [[MIDI]] messages coming into TouchDesigner from a specified MIDI device. It outputs columns in a table format - message, type, channel, index, value. \t\t\n\t\t\t\nHowever general setup is simpler. Once you have MIDI set up via the Dialogs -> MIDI Device Mapper, TouchDesigner is ready to receive MIDI via Select CHOPs that point to <code>/local/maps/map1</code> for device 1, etc.\t\t\t\n\t\t\t\nSee also the [[MIDI Event DAT]], [[MIDI In Map CHOP]], [[MIDI In CHOP]], [[MIDI Out CHOP]], Tscript <code>midi()</code> Command, [[MIDI Device Mapper Dialog]].",
        "opType": "midiin",
        "opClass": "midiinDAT_Class",
        "opFilter": "False",
        "short": "The MIDI In DAT logs all MIDI messages coming into TouchDesigner from a specified MIDI device.",
        "opCategories": ""
    },
    "monitorsDAT": {
        "label": "monitorsDAT",
        "members": [
            {
                "text": "Menu : Specify which monitors to report information about.",
                "type": "Par",
                "name": "monitors"
            },
            {
                "text": "Menu : Specify if the numbers are reported in Native Pixel units or DPI Scaled units.",
                "type": "Par",
                "name": "units"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Monitors",
        "long": "The Monitors DAT is a table of data about all currently detected monitors with information on the resolution, screen positioning, monitor name and description, GPU, and a flag indicating whether it is a primary monitor or not.\t\t\n\t\t\t\nYou can also set it to display the overall bounds of all the detected monitors.\t\t\t\n\t\t\t\nIt runs a callback script when a change in the monitors has been detected. These changes can be that a monitor was plugged in, a monitor was unplugged, the resolution of a monitor has changed, or the primary monitor has changed.\t\t\t\n\t\t\t\nThe Monitor DAT returns top/bottom values in lower-left origin coordinates, (0,0) is the lower-left corner of the monitor.",
        "opType": "monitors",
        "opClass": "monitorsDAT_Class",
        "opFilter": "False",
        "short": "The Monitors DAT is a table of data about all currently detected monitors with information on the resolution, screen positioning, monitor name and description, GPU, and a flag indicating whether it is a primary monitor or not.",
        "opCategories": ""
    },
    "mqttclientDAT": {
        "label": "mqttclientDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "MQTT Client",
        "long": "The MQTT Client DAT receives and sends data from/to [[MQTT]] devices via MQTT servers (broker). TouchDesigner can act as a client and another computer needs to act as a MQTT Server.  Once a client establishes a connection with a server, it can do two things: \t\t\n# Send a message to the server to express interest in any data that has a specific \"topic\" string. This is called \"subscribing\". Then the MQTT Client DAT will receive all messages that the server gets with that topic. \t\t\t\n# Inform the server that it will send messages to the server with a certain topic string, and then send messages with that topic. The messages then get forward to any client that has expressed interest in that topic.\t\t\t\n\t\t\t\nSee also [[MQTT]], [[TCP/IP DAT]].",
        "opType": "mqttclient",
        "opClass": "mqttclientDAT_Class",
        "opFilter": "False",
        "short": "The MQTT Client DAT receives and sends data from/to [[MQTT]] devices via MQTT servers (broker).",
        "opCategories": ""
    },
    "multitouchinDAT": {
        "label": "multitouchinDAT",
        "members": [
            {
                "text": "Menu : Sets how the output is displayed in the table.",
                "type": "Par",
                "name": "outputtype"
            },
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Multi Touch In",
        "long": "The Multi Touch In DAT is used for receiving messages and events from the Windows 7+ standard multi-touch API. It captures all the messages, where each new message changes the table it outputs. When a messages is added to the DAT, any script can be called pointing to the new message. The Multi Touch In DAT is most frequently sent to the [[Render Pick DAT]].\t\t\n\t\t\t\nIt can output either of two table formats: (1) Raw Events as a FIFO (first in - first out) list, or (2) ID Table, which is the events processed into a more usable one-row-per-finger table.\t\t\t\n\t\t\t\nThe Raw Events format creates a FIFO-type DAT (see also [[FIFO DAT]]) which, for each multi-touch event, has a row added to the bottom of the table while at the same time a row at the top is deleted.\t\t\t\n\t\t\t\nNote: To operate panel gadgets with multi-touch screens that send events through the Windows 7, 8 or 10 event stream, multi-touch works without requiring DATs. You need to use the DAT when using multiple fingers on one panel, like in a container displaying a 3D render whose objects you want to pick.\t\t\t\n\t\t\t\nThe ID table format includes the columns:\t\t\t\n* <code>id</code> - every finger press increases the id by 1\t\t\t\n* <code>sn</code> - an ongoing count of each finger press.\t\t\t\n* <code>select</code> - when 1, this row represents a finger is down.\t\t\t\n* <code>downf</code> - the absolute frame number when the finger press occurred.\t\t\t\n* <code>upf</code> - the absolute frame number that the finger press ended\t\t\t\n* <code>x</code>, <code>y</code> - the position, in pixels in the horizontal and vertical directions. <code>NOTE</code>: The <code>x</code> and <code>y</code> values are expressed in screen pixels, not panel width/height pixels. For example, the top-right corner of a panel will be different if the panel is scaled within another panel, window or network viewer. It is better to use <code>u</code> and <code>v</code>, and scale them by the panel Width and Height.\t\t\t\n* <code>u</code>, <code>v</code> - the position, 0 to 1 in the horizontal and vertical directions\t\t\t\n* <code>downu</code>, <code>downv</code> - the position, 0 to 1 in the horizontal and vertical directions when the touch first occured (ie. initial touch down location).\t\t\t\n<code>contactx</code>, <code>contacty</code> - the width of the contact area.\t\t\t\n<code>contactu</code>, <code>contactv</code> - the height of the contact area.\t\t\t\n** <code>monitor</code> - monitor number, starting with 0\t\t\t\n* <code>clicktime</code> - like <code>downf</code>, in seconds\t\t\t\n* <code>elapsedtime</code> - the number of seconds that finger has been down.\t\t\t\n* <code>changedtime</code> - the time since the finger press that the most recent u or v value changed.\t\t\t\n* <code>dclick</code> - double-tap occurred\t\t\t\n* <code>aux</code> - user supplied data via the [[PanelCOMP_Class]] method <code>interactTouch()</code>.  When the event is triggered by the mouse via the Include Mouse option, <code>aux</code> will include the mouse buttons used (<code>1</code> for left, <code>2</code> for middle, <code>4</code> for right, can be tested bitwise).\t\t\n\t\t\t\nYou can use the attached callback DAT (named <code>mtouchin1_callbacks</code>) to react to multi-touch events. This is suitable for 2D interfaces that do not require a [[Render Pick DAT]].\t\t\t\n\t\t\t\nSee the [[Palette:multiTouch]] example in the [[Palette]] under Tools.\t\t\t\n\t\t\t\nSee also the [[MultiTouch]] page.",
        "opType": "mtouchin",
        "opClass": "multitouchinDAT_Class",
        "opFilter": "False",
        "short": "The Multi Touch In DAT is used for receiving messages and events from the Windows 7+ standard multi-touch API.",
        "opCategories": ""
    },
    "ndiDAT": {
        "label": "ndiDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opType": "ndiDAT",
        "opLabel": "NDI",
        "opClass": "ndiDAT_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The NDI DAT lists in a table and monitors all NDI sources and streams found on the network. Callbacks are provided to trigger actions when sources are added/removed/changed and when streams start/stop.",
        "long": "The NDI DAT lists in a table and monitors all NDI sources and streams found on the network. Callbacks are provided to trigger actions when sources are added/removed/changed and when streams start/stop.\n    \nSee [[NDI]], [[NDI In TOP]] and [[NDI Out TOP]].",
        "opCategories": ""
    },
    "nullDAT": {
        "label": "nullDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Null",
        "long": "The Null DAT has no effect on the data. It is an instance of the DAT connected to its input. The Null DAT is often used when making reference to a DAT network, allowing new DATs to be added to the network (upstream) without the need to update the reference.",
        "opType": "null",
        "opClass": "nullDAT_Class",
        "opFilter": "True",
        "short": "The Null DAT has no effect on the data. It is an instance of the DAT connected to its input.",
        "opCategories": ""
    },
    "opexecuteDAT": {
        "label": "opexecuteDAT",
        "members": [
            {
                "text": "Menu : ([[Operator Language|Tscript]] only) Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "OP Execute",
        "long": "The OP Execute DAT runs a script when the state of an [[Operator|operator]] changes. \t\t\n\t\t\t\nOP Execute DATs are created with default python method placeholders. For each monitored condition in the parameters, there is a [[opexecuteDAT_Class|matching python method]] in the DAT. When a condition is turned on in the parameters, each time that condition is satisfied the corresponding python method will be executed.",
        "opType": "opexec",
        "opClass": "opexecuteDAT_Class",
        "opFilter": "False",
        "short": "The OP Execute DAT runs a script when the state of an [[Operator|operator]] changes.",
        "opCategories": ""
    },
    "opfindDAT": {
        "label": "opfindDAT",
        "members": [
            {
                "text": "Menu : Determines when to cook the DAT.",
                "type": "Par",
                "name": "activecook"
            },
            {
                "text": "Menu : Combine 'All', 'Any' or 'Custom' of the filters below to get a match. 'Custom' allows for specifying a subselection of filters with 'or' and 'and' keywords.",
                "type": "Par",
                "name": "combinefilters"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "OP Find",
        "long": "The OP Find DAT traverses the component hierarchy starting at one component and looking at all nodes within that component, and outputs a table with one row per node that matches criteria the user chooses. For example, the criteria could be all Ramp TOPs, or all nodes whose name starts with \u201c<code>wave</code>\u201d, or all nodes with the Clone parameter set to \u201c<code>master1</code>\u201d, or all Geometry components with a tag called \u201c<code>emitter</code>\u201d.\t\t\n\t\t\t\nThe criteria can limited to include only nodes of certain families, or certain operator types. It can filter on matching its path, certain parameters containing certain values (both constant and expressions), comments, tags, or the content of a DAT containing certain strings.\t\t\t\n\t\t\t\nYou can also cause the DAT to only look to some depth of the hierarchy from the specified component, such as 2 levels down, or limitless.\t\t\t\n\t\t\t\nCriteria can be case-sensitive or not, but case-sensitive On or Off applies to all criteria in the OP Find DAT.\t\t\t\n\t\t\t\nFurthermore you can exclude some nodes using more specialized criteria by returning a True of False in a callback contained in the attached callback DAT.\t\t\t\n\t\t\t\nWith the Combine Filters Menu (Any or All, Default is All), you can do an \"or\" or \"and\" on the pattern matching criterea.  \t\t\t\n\t\t\t\nIt also takes an optional DAT containing a list of operators (eg, another OP Find DAT) which can be used to chain filters.\t\t\t\n\t\t\t\n=== Output Columns ===\t\t\t\nThere is a variety of columns that you can select from including <code>name</code>, <code>id</code>, <code>paths</code>, <code>type</code> and <code>tags</code>.  (<code>id</code> is a member of the operator, which is an integer unique to the node, and doesn't change during the running of the TouchDesigner process.)\t\t\t\n\t\t\t\nYou can also output custom columns by defining the column names in the callback DAT, and filling in the column cells via another function in the callback DAT. For example, you can output a custom column which is the <code>tx</code> parameter value of the node.\t\t\t\n\t\t\t\nYou can control when the OP Find DAT cooks. Normally it cooks whenever any of the nodes in the specified hierarchy changes. Using the Active Cook menu parameter, you can also force-cook it every frame, or turn off cooking entirely.  You can also click the Pulse parameter on Active Cook in order to force-cook it once, or do the equivalent using the node.cookpulse.pulse() python call.\t\t\t\n\t\t\t\nInstead of being give the path to a component to start at, the OP Find DAT can take an input DAT containing a pre-generated list of paths to nodes to start from, and merge the results of each input line together in the output. To use this, the input DAT should contain the node \u201cid\u201d as the first column, which can be generated with another OP Find DAT with the Column called \u201cID\u201d turned on.\t\t\t\n\t\t\t\nFor example, say you first list all components that are panels, then you separate into groups based on type or Clone parameter. The first OP Find DAT pre-filters a huge hierarchy to a small fraction of the nodes, the subsequent OP Find DATs are operating on simpler sets to eliminate a lot of checking and cooking.\t\t\t\n\t\t\t\nRefer to Help -> [[OP Snippets|Operator Snippets]].\t\t\t\n\t\t\t\nSee also: [[Script DAT]]",
        "opType": "opfind",
        "opClass": "opfindDAT_Class",
        "opFilter": "False",
        "short": "The OP Find DAT traverses the component hierarchy starting at one component and looking at all nodes within that component, and outputs a table with one row per node that matches criteria the user chooses."
    },
    "oscinDAT": {
        "label": "oscinDAT",
        "members": [
            {
                "text": "Menu : Select which protocol to use, refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "OSC In",
        "long": "The OSC In DAT receives and parses full Open Sound Control packets using UDP by default.  Each packet is parsed and appended as a row in the DAT's table. The table is FIFO \"fisrt-in first-out\" and limited to parameter-set number of lines. An optional script may be run for each packet received. Each packet/row represents either one OSC message, or an entire OSC bundle.  Each argument is translated into readable ASCII text. \t\t\n\t\t\t\nSee also [[OSC]], [[OSC Out DAT]], [[Peer Class]], [[OSC_In_CHOP|OSC In CHOP]], [[OSC Out CHOP]], [[iOS and OSC]], [[Network Protocols]].\t\t\t\n\t\t\t\nThe supported argument tag types are:\t\t\t\n\t\t\t\n*i int32 \t\t\t\n*f float32 \t\t\t\n*s OSC-string \t\t\t\n*b OSC-blob \t\t\t\n*h 64 bit big-endian two's complement integer \t\t\t\n*t OSC-timetag \t\t\t\n*d 64 bit (\"double\") IEEE 754 floating point number \t\t\t\n*S alternate type represented as an OSC-string\t\t\t\n*c ASCII character\t\t\t\n*r 32 bit RGBA color \t\t\t\n*m 4 byte MIDI message\t\t\t\n*T True\t\t\t\n*F False\t\t\t\n*N Nil\t\t\t\n*I Infinitum\t\t\t\n*[ Beginning of an array\t\t\t\n*] End of an array\t\t\t\n\t\t\t\n\t\t\t\nIn the case of multi-vectored arguments (example \"blob\", \"midi\", \"rgb\", etc), the list of values is enclosed in double quotes.  In the case of unknown argument types, a quoted list of decimal values representing the bytes of that argument are included instead.\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opType": "oscin",
        "opClass": "oscinDAT_Class",
        "opFilter": "False",
        "short": "The OSC In DAT receives and parses full Open Sound Control packets using UDP by default.",
        "opCategories": ""
    },
    "oscoutDAT": {
        "label": "oscoutDAT",
        "members": [
            {
                "text": "Menu : Selects the network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "OSC Out",
        "long": "The OSC Out DAT is used for sending information over a OSC connection between remotely located computers. Use the [[OscoutDAT_Class|<code>.sendOSC()</code>]] python method to output the OSC messages.\n    \nOSC bundles allows you to send a group of messages in a single command rather than as separate, individual messages. The OSC Out DAT <code>sendOSC()</code> function will accept a list of messages and send as a bundle when you set the kwarg <code>asBundle=True</code>.\nBundles were created as a performance optimization for real-time control of synthesizers with a large number of parameters. (thx Jesse Gilbert)\n\t\t\t\nSee also [[OSC]], [[OSC In DAT]], [[OSC In CHOP]], [[OSC Out CHOP]], [[iOS and OSC]], [[Network Protocols]], [[Sync]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opType": "oscout",
        "opClass": "oscoutDAT_Class",
        "opFilter": "False",
        "short": "The OSC Out DAT is used for sending information over a OSC connection between remotely located computers.",
        "opCategories": ""
    },
    "outDAT": {
        "label": "outDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Out",
        "long": "The Out DAT is used to create a DAT output in a Component. Component outputs are positioned alphanumerically on the right side of the Component.",
        "opType": "out",
        "opClass": "outDAT_Class",
        "opFilter": "True",
        "short": "The Out DAT is used to create a DAT output in a Component.",
        "opCategories": ""
    },
    "panelexecuteDAT": {
        "label": "panelexecuteDAT",
        "members": [
            {
                "text": "Menu : ([[Operator Language|Tscript]] only) Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Panel Execute",
        "long": "The Panel Execute DAT will run its script when the [[Panel Value]]s of a specified panel component changes. You can specify which panel values to monitor, and trigger scripts based on their values changing in various ways.\t\t\n\t\t\t\nPanel Execute DATs are created with [[panelexecuteDAT_Class|default python method]] placeholders. For each monitored condition in the parameters, there is a matching python method in the DAT. When a condition is turned on in the parameters, each time that condition is satisfied the corresponding python method will be executed.\t\t\t\n\t\t\t\nIn the template Python script, <code>panelValue</code> is passed to each method, and you can query each call by printing <code>panelValue.name</code> and <code>panelValue.val</code>. See [[PanelValue Class]].",
        "opType": "panelexec",
        "opClass": "panelexecuteDAT_Class",
        "opFilter": "False",
        "short": "The Panel Execute DAT will run its script when the [[Panel Value]]s of a specified panel component changes.",
        "opCategories": ""
    },
    "parameterDAT": {
        "label": "parameterDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opType": "parameterDAT",
        "opLabel": "Parameter",
        "opClass": "parameterDAT_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Parameter DAT outputs a table of parameter names and values of an operator, including custom parameters, from any OP type. It outputs pre-evaluated expressions, and the parameter mode.",
        "long": "The Parameter DAT outputs a table of parameter names and values of an operator, including custom parameters, from any OP type. \n    \nIt can output pre-evaluated expressions, the [[Parameter Mode]] plus all attributes that define parameters - their type, label, ranges, menu items, limits, etc. in up to 24 columns of information."
    },
    "parameterexecuteDAT": {
        "label": "parameterexecuteDAT",
        "members": [
            {
                "text": "Menu : ([[Operator Language|Tscript]] only) Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Parameter Execute",
        "long": "The Parameter Execute DAT runs a script when a [[parameter]] of any operator changes state. There are 4 ways a parameter can trigger the script: if its value, expression, export, or enable state changes.  \t\t\n\t\t\t\nParameter Execute DATs are created with [[parameterexecuteDAT_Class#Callbacks|default python method placeholders]]. Unlike other execute DATs, the Parameter Execute DAT does not cook the node that it is watching, to avoid issues with recursive updates.",
        "opType": "parexec",
        "opClass": "parameterexecuteDAT_Class",
        "opFilter": "False",
        "short": "The Parameter Execute DAT runs a  script when a [[parameter]] of any operator changes state.",
        "opCategories": ""
    },
    "pargroupexecuteDAT": {
        "label": "pargroupexecuteDAT",
        "members": [
            {
                "text": "Menu : This controls the format of the 'curr' and 'prev' arguments to the callbacks.",
                "type": "Par",
                "name": "callbackmode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opType": "pargroupexecuteDAT",
        "opLabel": "ParGroup Execute",
        "opClass": "pargroupexecuteDAT_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "",
        "long": ""
    },
    "performDAT": {
        "label": "performDAT",
        "members": [
            {
                "text": "Menu : Offers two options for when to trigger a refresh of the logs.",
                "type": "Par",
                "name": "triggermode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Perform",
        "long": "The Perform DAT logs various performance times in a [[Table DAT]] format. These benchmarks are similar to those reported by the [[Performance Monitor Dialog|Performance Monitor]].",
        "opType": "perform",
        "opClass": "performDAT_Class",
        "opFilter": "False",
        "short": "The Perform DAT logs various performance times in a [[Table DAT]] format.",
        "opCategories": ""
    },
    "renderpickDAT": {
        "label": "renderpickDAT",
        "members": [
            {
                "text": "Menu : Decides when to update values based on pick interactions.",
                "type": "Par",
                "name": "strategy"
            },
            {
                "text": "Menu : Determines when the values are updated.",
                "type": "Par",
                "name": "responsetime"
            },
            {
                "text": "Menu : Returns the position of the point picked on the geometry. Columns ''tx, ty, tz''.",
                "type": "Par",
                "name": "position"
            },
            {
                "text": "Menu : Returns the normals of the point picked on the geometry. Columns ''nx, ny, nz''.",
                "type": "Par",
                "name": "normal"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Render Pick",
        "long": "The Render Pick DAT lets you get information about the 3D surface at any pixel of any 3D render, allowing you to implement multi-touch on a 3D rendered scene. It samples a rendering (from a [[Render TOP]] or a [[Render Pass TOP]]) and returns 3D information from the geometry at the specified pick locations.\t\t\n\t\t\t\nYou feed it a DAT with minimum three columns: <code>select</code>, <code>u</code> and <code>v</code>. A [[Multi Touch In DAT]] is usually connected to the Render Pick DAT, where the Multi Touch In DAT points to a container that is displaying the output of the Render TOP.\t\t\t\n\t\t\t\n\t\t\t\nYou can pick from multiple cameras simultaneously. You can specify a <code>camera</code> which allows the pick to occur from the point of a view other than the first camera listed in the [[Render TOP]]. The value in the column can either be a path (relative to the Render Pick DAT, or absolute) to a Camera COMP, or it can be an integer index, started at 0. If it's an index it will select the camera to use if there are multiple cameras listed in the [[Render TOP]], or if there are cameras listed in the 'Custom Pick Camera(s)' parameter. This is useful for various [[Multi-Camera Rendering]] setups, and cases such as VR where your picking isn't coming from the point of view of your eye cameras, but instead hand controllers.\t\t\t\n\t\t\t\nThe pick location is a u,v (horizontal, vertical) coordinate placed in the table that you connect to the Render Pick DAT input.  Each row of the input table represents one pick point to be sampled, except for the first row which contains column headings <code>select</code>, <code>u</code> and <code>v</code> (plus any other unused columns you want).  The <code>select</code>, <code>u</code> and <code>v</code> columns are what you would get from a [[Panel CHOP]]. The u and v values goes 0 to 1 left to right and bottom to top, no matter what the aspect ratio of the render is.\t\t\t\n\t\t\t\nWhen Strategy is Always, that u,v location is always sampled and the results are displayed in the corresponding row in the Render Pick DAT output. \t\t\t\n\t\t\t\nThe output table will show the path of the geometry that was picked, its position (in a choice of reference frames), surface normal (excluding bump mapping), distance from camera, texture UV coordinate, color, alpha and instance id. It properly picks surfaces with deforming vertices.\t\t\t\n\t\t\t\nThere are some examples here:\t\t\t\n\t\t\t\n* [[Palette:geoPanel|geoPanel]] in the palette.\t\t\t\n* [[Palette:multiTouch|multiTouch]] in the palette under Techniques.\t\t\t\n* [http://www.derivative.ca/Forum/viewtopic.php?f=22&t=166&p=13447 Render Pick DAT Example].\t\t\t\n\t\t\t\nSee also the single-sample [[Render Pick CHOP]].",
        "opType": "renderpick",
        "opClass": "renderpickDAT_Class",
        "opFilter": "False",
        "short": "The Render Pick DAT lets you get information about the 3D surface at any pixel of any 3D render, allowing you to implement multi-touch on a 3D rendered scene.",
        "opCategories": ""
    },
    "reorderDAT": {
        "label": "reorderDAT",
        "members": [
            {
                "text": "Menu : This parameter allows you to reorder either rows or columns.",
                "type": "Par",
                "name": "reorder"
            },
            {
                "text": "Menu : Specify how to reorder the table.",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Reorder",
        "long": "The Reorder DAT allows you to reorder the rows and columns of the input table. You can also use In Specified Order option to get duplicate copies of rows and columns.",
        "opType": "reorder",
        "opClass": "reorderDAT_Class",
        "opFilter": "True",
        "short": "The Reorder DAT allows you to reorder the rows and columns of the input table.",
        "opCategories": ""
    },
    "scriptDAT": {
        "label": "scriptDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Script",
        "long": "The Script DAT runs a script each time the DAT cooks and can build/modify the output table based in the optional input tables. The Script DAT is created with a [[Docking|dock]]ed (attached) DAT that contains three Python methods: <code>cook</code>, <code>onPulse</code>, and <code>setupParameters</code>. The <code>cook</code> method is run each time the Script DAT cooks. The <code>setupParameters</code> method is run whenever the Setup Parameter button on the Script page is pressed. The <code>onPulse</code> method is run whenever a custom pulse parameter is pushed.\t\t\n\t\t\t\nRefer to Help -> Python Examples, and Help -> [[OP Snippets|Operator Snippets]].\t\t\t\n\t\t\t\nNote: Because the Script DAT can get data from anywhere, it's difficult to determine what it procedurally depends on. So every time that any Script OP runs it will add to a list of operators, parameters, nodes etc that it depends upon, and when they change, the Script OP will re-cook. The list is reset when a <code>.toe</code> restarts.\t\n\t\t\t\nSee also: [[Script CHOP]], [[Script SOP]], [[Script TOP]]",
        "opType": "script",
        "opClass": "scriptDAT_Class",
        "opFilter": "False",
        "short": "The Script DAT runs a script each time the DAT cooks and can build/modify the output table based in the optional input tables.",
        "opCategories": ""
    },
    "selectDAT": {
        "label": "selectDAT",
        "members": [
            {
                "text": "Menu : This parameter allows you to pick different ways of specifying the rows selected.",
                "type": "Par",
                "name": "extractrows"
            },
            {
                "text": "Menu : This parameter allows you to pick different ways of specifying the columns selected.",
                "type": "Par",
                "name": "extractcols"
            },
            {
                "text": "Menu : Determines what format will be used for output from the DAT.",
                "type": "Par",
                "name": "output"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Select",
        "long": "The Select DAT allows you to fetch a DAT from any other location in the project, and to select any subset of rows and columns if it is a table.",
        "opType": "select",
        "opClass": "selectDAT_Class",
        "opFilter": "True",
        "short": "The Select DAT allows you to fetch a DAT from any other location in the project, and to select any subset of rows and columns if it is a table.",
        "opCategories": ""
    },
    "serialDAT": {
        "label": "serialDAT",
        "members": [
            {
                "text": "Menu : Interpret the incoming data as binary or ASCII data. If the format is Per Byte, one row is appended for each binary byte received. If the format is Per Line, one row is appended for each null or newline delimited message received.",
                "type": "Par",
                "name": "format"
            },
            {
                "text": "Int : The maximum number of bits of information, including \"control\" bits, that are transmitted per second. Check your input device's default baud rate and set accordingly.",
                "type": "Par",
                "name": "baudrate"
            },
            {
                "text": "Menu : This parameter sets the number of data bits sent in each. Data bits are transmitted \"backwards\". Backwards refers to the order of transmission, which is from least significant bit (LSB) to most significant bit (MSB). To interpret the data bits, you must read from right to left.",
                "type": "Par",
                "name": "databits"
            },
            {
                "text": "Menu : This parameter can be set to none, even, or odd. The optional parity bit follows the data bits and is included as a simple means of error checking. Parity bits work by specifying ahead of time whether the parity of the transmission is to be even or odd. If the parity is set to be odd, the transmitter will then set the parity bit in such a way as to make an odd number of 1's among the data bits and the parity bit.",
                "type": "Par",
                "name": "parity"
            },
            {
                "text": "Menu : The last part of transmission packet consists of 1 or 2 Stop bits. The connection will now wait for the next Start bit.",
                "type": "Par",
                "name": "stopbits"
            },
            {
                "text": "Menu : The DTR (data-terminal-ready) flow control. (Windows Only).",
                "type": "Par",
                "name": "dtr"
            },
            {
                "text": "Menu : The RTS (request-to-send) flow control. (Windows Only).",
                "type": "Par",
                "name": "rts"
            },
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "Serial",
        "long": "The Serial DAT is used for serial communication through an external port, using the RS-232 protocol. These ports are usually a 9 pin connector, or a USB port on new machines.  (Using a USB port requires a USB-to-serial adapter and driver.) \t\t\nAll of a computer's available serial ports can be found in the Device Manager in the Windows operating system under Computer \u2013> Manage -> Devices -> Serial\u2026 -> COM ports. Their names begin with 'COM'. Example: COM1, COM2, COM3.\t\t\t\n\t\t\t\nTo send bytes out this connection, see the send methods in the [[serialDAT_Class]], or in Tscript the <code>send</code> Command.\t\t\t\n\t\t\t\nSee also [[Arduino]] and [[Serial CHOP]].",
        "opType": "serial",
        "opClass": "serialDAT_Class",
        "opFilter": "False",
        "short": "The Serial DAT is used for serial communication through an external port, using the RS-232 protocol.",
        "opCategories": ""
    },
    "socketioDAT": {
        "label": "socketioDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "SocketIO",
        "opFilter": "False",
        "opType": "socketio",
        "long": "The SocketIO DAT connects to a [[Socket.IO]] server at the specified URL.\n    \nAdditional headers can be specified via the first input of the SocketIO DAT. This input should be in a table format with two columns, structured as name/value pairs.\n    \nThe SocketIO DAT listens to specific events that the server emits. These events are added as listeners via the second input, structured as a single column of event names. Then, when the server emits these events the <code>onReceiveEvent</code> callback will be triggered.\n\nThe SocketIO DAT can also emit events to the server. This is done using the python <code>emit</code> method. Acknowledgement callbacks are not supported.\n\nThe SocketIO DAT is built with [https://github.com/socketio/socket.io-client-cpp socket.io's C++ Client API] v2.0.0. Works with with socket.io v2.x servers; socket.io v3 currently not supported.\n\nThe SocketIO DAT prints socket.io status messages to the TouchDesigner text console. The text console can be enabled by setting the environment variable <code>TOUCH_TEXT_CONSOLE=1</code> (see: https://docs.derivative.ca/Variables#System_Environment_Variables). The text console will open the next time TouchDesigner is launched.\n\nSee also: [[WebSocket DAT]], [[Web Client DAT]]",
        "opClass": "socketioDAT_Class",
        "short": "The SocketIO DAT connects to a [[Socket.IO]] server at the specified URL.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "soptoDAT": {
        "label": "soptoDAT",
        "members": [
            {
                "text": "Menu : Specify whether to pull point data or primitive data.",
                "type": "Par",
                "name": "extract"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opLabel": "SOP to",
        "long": "The SOP to DAT allows you to extract point, vertex and primitive (e.g. polygon) data and attributes from a SOP.\t\t\n\t\t\t\nData is output in columns, with the first column being index. The index refers to the Point or Primitive number.  [[Attribute|Attributes]] are output with column name <code>''attrib''</code> if it is a single value attribute, or with multiple columns named <code>''attrib''(0)</code>, <code>''attrib''(1)</code>, <code>''attrib''(2)</code> etc. if it is a multiple value attribute.\t\t\t\n\t\t\t\nSee also: [[Geometry Detail]], [[Point]], [[Point List]], [[Point Class]], [[Primitive]], [[Prims Class]], [[Polygon]], [[Vertex]], [[SOP]], [[SOP Class]], [[Script SOP]], [[Point Group]]s, [[Primitive Group]]s, [[Attributes]].\n\t\t\n\t\t\t\n'''Example File :''' [[File:SOPtoDATtoSOP.tox]]",
        "opType": "sopto",
        "opClass": "soptoDAT_Class",
        "opFilter": "False",
        "short": "The SOP to DAT allows you to extract point, vertex and primitive (e.g. polygon) data and attributes from a SOP.",
        "opCategories": ""
    },
    "sortDAT": {
        "label": "sortDAT",
        "members": [
            {
                "text": "Menu : Determines how the table will be sorted.",
                "type": "Par",
                "name": "sortmethod"
            },
            {
                "text": "Menu : Determines the type of sorting.",
                "type": "Par",
                "name": "order"
            },
            {
                "text": "Menu : Remove duplicate rows/column entries in the sorted row/column.",
                "type": "Par",
                "name": "unique"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "Sort",
        "opFilter": "True",
        "long": "The Sort DAT will sort table DAT data by row or column.",
        "opClass": "sortDAT_Class",
        "opType": "sort",
        "short": "The Sort DAT will sort table DAT data by row or column.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "substituteDAT": {
        "label": "substituteDAT",
        "members": [
            {
                "text": "Menu : Specify where to match:",
                "type": "Par",
                "name": "match"
            },
            {
                "text": "Menu : This parameter allows you to pick different ways of specifying the rows scoped.",
                "type": "Par",
                "name": "extractrows"
            },
            {
                "text": "Menu : This parameter allows you to pick different ways of specifying the columns scoped.",
                "type": "Par",
                "name": "extractcols"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "substituteDAT_Class",
        "opType": "substitute",
        "short": "The Substitute DAT changes the cells of the incoming DAT using pattern matching and substitution strings.",
        "opFilter": "True",
        "opLabel": "Substitute",
        "long": "The Substitute DAT changes the cells of the incoming DAT using pattern matching and substitution strings. It outputs a table with the same number of rows and columns. \t\t\n\t\t\t\nSee examples below. Also you can use the second input to provide a table of strings to substitute, the first column being the \"before\" strings and the second column being the \"after\" strings.\t\n\n'''See also''': the Python <code>.replace()</code>  [https://www.w3schools.com/python/ref_string_replace.asp], which is a method you can apply to any string. You can do that in an [[Evaluate DAT]] or [[Script DAT]].",
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "switchDAT": {
        "label": "switchDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "Switch",
        "opFilter": "True",
        "long": "The Switch DAT is a multi-input operator which lets you choose which input is output by using the <span class=\"tipTextDAT\">Input</span> parameter.",
        "opClass": "switchDAT_Class",
        "opType": "switch",
        "short": "The Switch DAT is a multi-input operator which lets you choose which input is output by using the <span class=\"tipTextDAT\">Input</span> parameter.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "tableDAT": {
        "label": "tableDAT",
        "members": [
            {
                "text": "Menu : Sets the expected file encoding format, or auto-detects the format.  UTF8, UTF16-LE, UTF16-BE, CP1252",
                "type": "Par",
                "name": "defaultreadencoding"
            },
            {
                "text": "Menu : You can create and fill rows and columns of a table. Fill Type menu gives 5 options: Manual, Set Size, Set Size and Contents, Fill by Column, and Fill by Row. When a Fill option is chosen, you can generate multiple rows/columns with specific headings using space-separated names or an expression, plus expressions to fill the cells.",
                "type": "Par",
                "name": "fill"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "Table",
        "opFilter": "False",
        "long": "The Table DAT lets you hand-edit or create a table of rows and columns of cells, each cell containing a text string. A \"table\" is one of the two forms of DATs (the other being simply lines of \"free-form\" text via the [[Text DAT]]). \t\n\t\t\n'''Manually editing cells''' - When a Table DAT has its [[Viewer Active]] on, you can add rows and columns by right-clicking on row 0 or column 0 to add rows/columns, and typing text into any cell of its [[Node Viewer|node viewer]]. Use the Tab key to jump to the next cell, and the up/down arrow keys to navigate to adjacent cells.\n\n'''Procedurally filling cells''' - You can conveniently create and fill rows and columns of a table. On the Fill page, the Fill Type menu gives 5 options: Manual, Set Size, Set Size and Contents, Fill by Column, and Fill by Row. When a Fill option is chosen, you can generate multiple rows/columns with specific headings using space-separated names or an expression, plus expressions to fill the cells. \n\nYou can use <code>me.subRow</code> and <code>me.subCol</code> (for sub-section being filled) in your expressions. See the popup menu on the Cell Expression parameter for suggestions.\n\t\t\nClick the + below the parameters to you generate multiple sets of new cols or rows.\n\n'''Filling cells externally with python ''' - If you are not auto-filling, you can put strings into table cells using something like <code>op('table1')[2,'select'] = 'yes'</code> in a python script elsewhere, or append rows using <code>.appendRow()</code> in python. See also the [[Script DAT]] and its Snippets.\t\n\t\t\n'''Loading from external files''' - The Table DAT can also can load a table from a <code>.csv</code>, <code>.txt</code> or <code>.dat</code> file on disk or on the web. Either drag-drop the file into a network, or use the File parameter.\n\nUse <code>http://</code> when specifying a table on the internet. \n\nIf you drag the Table DAT to a desktop or folder, The DAT text will be converted into tab-delimited tables in a <code>.txt</code> file.\t\n\nSee also [[Script DAT]], [[Text DAT]].",
        "opClass": "tableDAT_Class",
        "opType": "table",
        "short": "The Table DAT lets you hand-edit or create a table of rows and columns of cells, each cell containing a text string.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "tcpipDAT": {
        "label": "tcpipDAT",
        "members": [
            {
                "text": "Menu : Specify if this operator is communicating as a '''client''' or a '''server'''.",
                "type": "Par",
                "name": "mode"
            },
            {
                "text": "Menu : Determines how the incoming data is parsed into the table.",
                "type": "Par",
                "name": "format"
            },
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "tcpipDAT_Class",
        "opType": "tcpip",
        "short": "The TCP/IP DAT is used for sending and receiving information over a TCP/IP connection between two remotely located computers.",
        "opFilter": "False",
        "opLabel": "TCP/IP",
        "long": "The TCP/IP DAT is used for sending and receiving information over a TCP/IP connection between two remotely located computers. It captures all the messages without any queuing or buffering, and allows you to send it any messages you want.\t\t\n\t\t\t\nSend messages using the [[tcpipDAT_Class]]. Handle received messages using the callback DAT attached to the TCP/IP DAT. See [[Network Protocols]].\t\t\t\n\t\t\t\nThis DAT can be used to intercept all the raw information being sent from a Pipe Out CHOP for example. The [[Pipe In CHOP]] and [[Pipe Out CHOP]] also communicate through a TCP/IP connection, though they use a specific syntax. \t\t\t\n\t\t\t\nSee also [[Peer Class]], [[UDP In DAT]], [[UDP Out DAT]].\t\t\t\n\t\t\t\nFor Tscript. see Tscript <code>send</code> Command.\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "textDAT": {
        "label": "textDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "Text",
        "opFilter": "False",
        "long": "The Text DAT lets you edit free-form, multi-line ASCII text. It is used for scripts, GLSL shaders, notes, XML and other purposes. \"Free-form text\" is one of the two forms of DATs (the other being tables of rows and columns of cells, each cell containing a text string as in a [[Table DAT]]). \t\n\t\t\nText can be typed into the DAT when its [[Viewer Active]] is on, or in an external text editor. The Text DAT can get its data from a file on disk or from a file on the web. Use <code>http://</code> when specifying a remote text file. \t\t\n\t\t\nSee also the Execute DATs which are specialized to run their text as a script: [[CHOP Execute DAT]] runs its script when a CHOP channel changes, [[DAT Execute DAT]] when a DAT changes, [[Execute DAT]] when you start or end your TouchDesigner process or want to run a script every frame, [[Panel Execute DAT]] when a control panel changes, [[Parameter Execute DAT]] when a parameter of a node changes, and [[OP Execute DAT]] when anything else about an operator changes, including creation and deletion of nodes in a component's network.\t\t\n\t\t\nUse the [[Web DAT]] to fetch via a URL query.",
        "opClass": "textDAT_Class",
        "opType": "text",
        "short": "The Text DAT lets you edit free-form, multi-line ASCII text.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "touchinDAT": {
        "label": "touchinDAT",
        "members": [
            {
                "text": "Menu : Select which protocol to use, refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "Touch In",
        "opFilter": "False",
        "long": "The Touch In DAT receives full tables across the network from the [[Touch Out DAT]], as opposed to messages with the other network based DATs.\t\t\n\t\t\t\nSee also [[UDP Out DAT]].",
        "opClass": "touchinDAT_Class",
        "opType": "touchin",
        "short": "The Touch In DAT receives full tables across the network from the [[Touch Out DAT]], as opposed to messages with the other network based DATs.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "touchoutDAT": {
        "label": "touchoutDAT",
        "members": [
            {
                "text": "Menu : Select which protocol to use, refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "Touch Out",
        "opFilter": "True",
        "long": "The Touch Out DAT sends full DAT tables across the network to the [[Touch In DAT]] in another TouchDesigner process, as opposed to messages with the other network based DATs. It is an extremely powerful mechanism to sync data between TouchDesigner processes.\t\t\n\t\t\t\nSee also [[UDP Out DAT]].",
        "opClass": "touchoutDAT_Class",
        "opType": "touchout",
        "short": "The Touch Out DAT sends full DAT tables across the network to the [[Touch In DAT]] in another TouchDesigner process, as opposed to messages with the other network based DATs.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "transposeDAT": {
        "label": "transposeDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "Transpose",
        "opFilter": "True",
        "long": "The Transpose DAT converts rows into columns. The number of rows becomes the number of columns, and vice versa.",
        "opClass": "transposeDAT_Class",
        "opType": "transpose",
        "short": "The Transpose DAT converts rows into columns.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "tuioinDAT": {
        "label": "tuioinDAT",
        "members": [
            {
                "text": "Menu : Select which protocol to use, refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opClass": "tuioinDAT_Class",
        "opType": "tuioin",
        "short": "The TUIO In DAT receives and parses TUIO messages (received over network) into columns in the table.",
        "opFilter": "False",
        "opLabel": "TUIO In",
        "long": "The TUIO In DAT receives and parses TUIO messages (received over network) into columns in the table. TUIO packets OSC bundles, so TUIO data can also be viewed in its more raw form in an [[OSC In DAT]].\tIt currently uses the TUIO 1.1 protocol. The TUIO 2.0 protocol is not yet supported.",
        "opFamily": "DAT",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "udpinDAT": {
        "label": "udpinDAT",
        "members": [
            {
                "text": "Menu : Select which protocol to use, refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Determines how the incoming data is parsed.",
                "type": "Par",
                "name": "format"
            },
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "UDP In",
        "opFilter": "False",
        "long": "The UDP In DAT is used for receiving information over a UDP connection between two remotely located computers. It captures all the messages without any queuing or buffering, and allows you to send it any messages you want. Once this DAT has received a message it can reply to the sender using the 'send' command. Using the send command before it has received a message will not work because it doesn't know where to send data yet. When in multicast mode it doesn't send out a multicast message, it sends a reply directly to the originator for the last multicast message it got.\t\t\n\t\t\t\nSee also [[Peer Class]], [[UDP Out DAT]], [[Touch In DAT]] and [[TCP/IP DAT]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opClass": "udpinDAT_Class",
        "opType": "udpin",
        "short": "The UDP In DAT is used for receiving information over a UDP connection between two remotely located computers.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "udpoutDAT": {
        "label": "udpoutDAT",
        "members": [
            {
                "text": "Menu : Selects the network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": "Menu : Determines how the incoming data is parsed.",
                "type": "Par",
                "name": "format"
            },
            {
                "text": "Menu : Choose between automatically or manually selecting local port to use.",
                "type": "Par",
                "name": "localportmode"
            },
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "UDP Out",
        "opFilter": "False",
        "long": "The UDP Out DAT is used to send information over a UDP connection to/from a remotely-located computer. Use the <code>sendBytes()</code> or <code>send()</code> methods of the [[udpoutDAT_Class]] to send messages. \t\t\n\t\t\t\nAlthough is it an 'Out' node, it can receive reply messages from the machine(s) it sends to. The messages will appear in the DAT's contents (just like the [[UDP In DAT]]).\t\t\t\n\t\t\t\nSee also [[UDP In DAT]], [[Touch Out DAT]] and [[TCP/IP DAT]].\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opClass": "udpoutDAT_Class",
        "opType": "udpout",
        "short": "The UDP Out DAT is used to send information over a UDP connection to/from a remotely-located computer.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "udtinDAT": {
        "label": "udtinDAT",
        "members": [
            {
                "text": " : Select which protocol to use, refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": " : Determines how the incoming data is parsed into the table.",
                "type": "Par",
                "name": "format"
            },
            {
                "text": " : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "UDT In",
        "opFilter": "False",
        "long": "'''NOTE This DAT has been removed from TouchDesigner 2021 Official builds and later.'''\n\nThe UDT In DAT is used for receiving information over a [[UDT]] connection between two remotely located computers. It captures all the messages without any queuing or buffering, and allows you to send it any messages you want. UDT Streaming is a reliable, streaming, connection orientated protocol. A single server can send to multiple clients at the same time.\t\t\n\t\t\t\nHandle received messages using the callback DAT attached to the UDT In DAT. Send replies using the [[udtinDAT_Class]].\t\t\t\n\t\t\t\nSee also [[Peer Class]], [[UDT Out DAT]], [[Network Protocols]]. \n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opClass": "udtinDAT_Class",
        "opType": "udtin",
        "short": "The UDT In DAT is used for receiving information over a [[UDT]] connection between two remotely located computers.",
        "opLicense": "Non-Commercial"
    },
    "udtoutDAT": {
        "label": "udtoutDAT",
        "members": [
            {
                "text": " : Selects the network protocol to use. Refer to the [[Network Protocols]] article for more information.",
                "type": "Par",
                "name": "protocol"
            },
            {
                "text": " : Determines how the incoming data is parsed.",
                "type": "Par",
                "name": "format"
            },
            {
                "text": " : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "UDT Out",
        "opFilter": "False",
        "long": "'''NOTE This DAT has been removed from TouchDesigner 2021 Official builds and later.'''\n    \nThe UDT Out DAT is used for sending information over a [[UDT]] connection between remotely located computers.  \t\t\n\t\t\t\nSend messages using the [[udtoutDAT_Class]]. Handle received messages using the callback DAT attached to the [[UDT In DAT]]. See [[Network Protocols]]. \t\t\t\n\t\t\t\nAlthough it is an 'Out' node, it can receive reply messages from the machine(s) it sends to. The messages will appear in the DAT's contents (just like the [[UDT In DAT]]).\t\t\t\n\t\t\t\n[[Tscript]] uses the <code>send</code> Command to initiate the data output.\t\t\t\n\t\t\t\nSee also: [[UDT In DAT]]\n\n'''NOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.'''",
        "opClass": "udtoutDAT_Class",
        "opType": "udtout",
        "short": "The UDT Out DAT is used for sending information over a [[UDT]] connection between remotely located computers.",
        "opLicense": "Non-Commercial"
    },
    "webclientDAT": {
        "label": "webclientDAT",
        "members": [
            {
                "text": "Menu : Selects the [https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods HTTP request method].",
                "type": "Par",
                "name": "reqmethod"
            },
            {
                "text": "Menu : The type of authentication.",
                "type": "Par",
                "name": "authtype"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opType": "webclientDAT",
        "opLabel": "Web Client",
        "opClass": "webclientDAT_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Web Client DAT allows you to send HTTP requests to web servers from TouchDesigner. It supports GET, POST, PUT, DELETE, HEAD, OPTIONS and PATCH http methods.",
        "long": "The Web Client DAT allows you to send HTTP requests to web servers from TouchDesigner. It supports GET, POST, PUT, DELETE, HEAD, OPTIONS and PATCH http methods.\n\nThe Web Client DAT supports various authentication types such as: basic, oauth1, oauth2.\n\nThe Web Client DAT allows for streaming from web servers.\n\nThe Web Client DAT sends HTTP requests to web servers and then outputs the response in the DAT. With streaming enabled it can stream data from a web server. \n    \nWhen streaming is enabled, Clamp Output as Rows should be enabled. This turns the output of the DAT into a FIFO table instead of raw text. Only the last N lines will be displayed, where N is the value of the Maximum Lines parameter. This will prevent the text in the DAT from getting too larger and will keep cook-times down as a result.\n    \nThe Web Client DAT supports sending of GET, POST, PUT, DELETE, HEAD, OPTIONS, and PATCH request methods. The Web Client DAT also supports 4 authentication methods: Basic, Digest, OAuth1, and OAuth2.\n\nThe first input is the extra headers to send in the request. It should be a table with 2 columns, structured as name/value pairs. For example:\n\n{{{!}} border=\"1\"\t\t\t\n{{!}}Content-Type\t\t\t\n{{!}}application/json\t\t\t\n{{!}}-\t\t\t\n{{!}}Connection\t\t\n{{!}}Close\n{{!}}}\t\n\nThe second input is the data/parameters to send in the request. This can be a table with two columns, structured as name/value pairs. It can also just be text, in which case it will be sent as is. If the request method doesn't have a request body (eg. GET, OPTIONS) then it will append the input to the URL as query parameters if a table, otherwise it will be sent as the request data.\n\n{{{!}} border=\"1\"\t\t\t\n{{!}}name\t\t\t\n{{!}}joe\t\t\t\n{{!}}-\t\t\t\n{{!}}month\t\t\t\n{{!}}May\t\t\t\n{{!}}}\n\nThe Web Client DAT is the successor to the [[Web DAT]]. \n\nSee also: [[Web Server DAT]], [[SocketIO DAT]], [[XML DAT]], [[TCP/IP DAT]], [[WebSocket DAT]], [[Web DAT]].",
        "opCategories": ""
    },
    "webDAT": {
        "label": "webDAT",
        "members": [
            {
                "text": " : Currently only POST is implemented, though this will be expanded with other techniques such as GET.",
                "type": "Par",
                "name": "method"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "long": "'''Note''': Web DAT deprecated build 2019.15230, use [[Web Client DAT]]. \n    \n    The Web DAT fetches pages of data from a web connection. The data should be ASCII-readable. The Web DAT will automatically uncompress any gzip compressed page transfers. XML content is formatted into a readable indented structure, versus one long line normally sent by the server. An Info DAT can be used to obtain properties of the last page retrieved.\t\t\n\t\t\t\nThere are two main methods of retrieving a page from a web site using the Web DAT:\t\t\t\n* Fetch\t\t\t\n* Submit and Fetch\t\t\t\n\t\t\t\nThe Fetch method simply fetches the page from the internet using the simple protocol \"GET\", while the Submit and Fetch method can be used for submitting form data to a server.  By default the latter method uses the \"POST\" protocol.\t\t\t\n\t\t\t\n\t\t\t\nBoth methods allow a DAT table input to specify options while fetching.  This table should consist of rows of name/value pairs.  The first column consists of the names, while the second column consists of the values.  The Fetch method simply concatenates the pairs into the specified URL, while the Update and Fetch method posts the pairs to a webserver, before fetching the resulting page.\t\t\t\n\t\t\t\nFor example, assume a table with the following contents is connected to the Web DAT:\t\t\t\n\n{{{!}} border=\"1\"\t\t\t\n{{!}}name\t\t\t\n{{!}}joe\t\t\t\n{{!}}-\t\t\t\n{{!}}month\t\t\t\n{{!}}May\t\t\t\n{{!}}}\n\t\t\t\nIf the specified URL is:\t\t\t\n''http://www.example.com''\t\t\t\n\t\t\t\nThen the Fetch method will actually fetch:\t\t\t\n''http://www.example.com?name=joe&month=May''\t\t\t\n\t\t\t\nSimilarly, the Submit and Fetch method will post the pairs to the specified webserver, before fetching the page.\t\t\t\n\t\t\t\nNote that spaces and other special characters in the table will be properly encoded. For example, each space in a name or value would be encoded as: %20\t\t\t\n\t\t\t\nThe first input can also be text data, in which case the data is sent to the webserver during a POST as-is, without any formatting or encoding. If the first input is text it will be ignored during a GET operation.\t\t\t\n\t\t\t\nThe 2nd input of the Web DAT can be used for custom HTTP request headers to be specified as part of the request. Like the 1st input this should be a table of name/value pairs for header field name and the value. E.g\t\t\t\n\t\t\t\n{{{!}} border=\"1\"\t\t\t\n{{!}}Content-Type\t\t\t\n{{!}}application/json\t\t\t\n{{!}}-\t\t\t\n{{!}}Date\t\t\t\n{{!}}Tue, 12 Nov 2013 08:12:31 GMT\t\t\t\n{{!}}}\t\t\t\n\t\t\t\nEach row will automatically be merged into a single line of text separated by a colon. If the 2nd column is empty then the entry in the first column will have a semi-color append to it when it's turned into the request header.\t\t\t\n\t\t\t\nSee also [[XML DAT]], [[TCP/IP DAT]], [[WebSocket DAT]].",
        "opLabel": "Web",
        "opLicense": "Non-Commercial",
        "opFamily": "DAT",
        "short": "The Web DAT fetches pages of data from a web connection.",
        "opType": "web",
        "opFilter": "False",
        "opClass": "webDAT_Class"
    },
    "webserverDAT": {
        "label": "webserverDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "Web Server",
        "opFilter": "False",
        "long": "The Web Server DAT allows you to connect to TouchDesigner as a web client, through a web browser for example. The Web Server DAT supports HTTP, WebSockets, as well as the sending/receiving of binary data, such as images (uploading/downloading). How client requests are handled is left up to the user via callbacks.\n    \nThe Web Server DAT can be secure, and also supports basic authentication via the authenticateBasic in the [[webserverDAT_Class]]. Currently only Basic authentication (ie. encoded username and password) is supported via a python method. Authentication will be in the HTTP request dictionary under the key 'Authorization'. \n\nUltimately, security is the complete responsibility of the user. It is up to the user to ensure that HTTP requests are properly authenticated, and any data storing usernames/passwords are encrypted or saved privately.\n\nHTTPS is supported via the Secure (TLS) parameter.\n\nThe Web Server DAT is built with [https://github.com/pocoproject/poco POCO] v1.9.1.\n\nSee also: [[Web Client DAT]]",
        "opClass": "webserverDAT_Class",
        "opType": "webserverDAT",
        "short": "The Text DAT lets you edit free-form, multi-line ASCII text.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "webrtcDAT": {
        "label": "webrtcDAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opType": "webrtcDAT",
        "opLabel": "WebRTC",
        "opClass": "webrtcDAT_Class",
        "opFilter": "True",
        "opLicense": "Non-Commercial",
        "opCategories": "",
        "short": "",
        "long": "A WebRTC DAT represents a peer on one end of any number of [[WebRTC]] peer-to-peer connections.\n\nEach connection is represented in TouchDesigner by a generated UUID. The UUID must be passed to [[WebrtcDAT Class]] connection-level python methods.\n\nThe WebRTC DAT output is a table formatted with a row per connection, with columns: id (ie. UUID), [https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/connectionState connection_state], [https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/signalingState signaling_state], [https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/iceConnectionState ice_connection_state], and [https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/iceGatheringState ice_gathering_state]. \n\nThe columns altogether describe the state of a connection and can also be useful for debugging. For example, if ice_connection_state failed then that means there's an issue pairing local and remote ICE candidates for streaming over the network. It could be that NAT traversal failed, and if using a STUN server that might indicate a need for a TURN server (see https://en.wikipedia.org/wiki/STUN#Limitations).\n\nWebRTC video and audio input/output is done via the [[Video Stream In TOP]], [[Video Stream Out TOP]], [[Audio Stream In CHOP]], and [[Audio Stream Out CHOP]].\n\nSee also [[WebRTC]]."
    },
    "websocketDAT": {
        "label": "websocketDAT",
        "members": [
            {
                "text": "Menu : Determines the location the script is run from.",
                "type": "Par",
                "name": "executeloc"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "WebSocket",
        "opFilter": "False",
        "opType": "websocket",
        "long": "The WebSocket DAT receives and parses [http://en.wikipedia.org/wiki/WebSocket WebSocket] messages. WebSockets are fast an efficient two way communication protocol used by web servers and clients. Each message is parsed and appended as a row in the DAT's table. The table is FIFO \"first-in first-out\" and limited to parameter-set number of lines. An optional script may be run for each packet received. Secure (tls) websocket servers are also supported.\t\t\nConnections to different WebSocket sites are supported without requiring manual header setup.\t\t\t\n\nThe WebSocket DAT prints status and error messages to the TouchDesigner text console. The text console can be enabled by setting the environment variable TOUCH_TEXT_CONSOLE=1 (see: https://docs.derivative.ca/Variables#System_Environment_Variables). The text console will open the next time TouchDesigner is launched.\n\nFor SocketIO support see the [[SocketIO DAT]].\n\t\t\t\nSee also: [[TCP/IP DAT]]\n\t\t\t\nExample project: [http://www.derivative.ca/Forum/viewtopic.php?p=30301 chat with WebSockets]",
        "opClass": "websocketDAT_Class",
        "short": "The WebSocket DAT receives and parses [http://en.wikipedia.org/wiki/WebSocket WebSocket] messages.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "xmlDAT": {
        "label": "xmlDAT",
        "members": [
            {
                "text": "Menu : Merge and label can be used to combine two inputs of data. The second input must be XML formatted, and not SGML/HTML. These two parameters control where and how the second input is merged.",
                "type": "Par",
                "name": "merge"
            },
            {
                "text": "Menu : This controls how the selected elements are presented.",
                "type": "Par",
                "name": "show"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "DAT",
        "opLabel": "XML",
        "opFilter": "True",
        "opType": "xml",
        "long": "The XML DAT can be used to parse arbitrary XML and SGML/HTML formatted data. Once formatted, selected sections of the text can be output for further processing.\t\t\n\t\t\t\nOne approach to parsing with the XML DAT is to read the XML with a Text DAT or a Web DAT, and pass that to a default XML DAT. Then you start to refine your selection by changing the match-all pattern (the \"*\"), to strings that reduce the elements that are in the output.\t\t\t\n\t\t\t\n===<div class=\"subSectionLineDAT\">XML and HTML Background</div>===\t\t\t\n\t\t\t\nXML and HTML data consists of a tree like structure consisting of elements. Each element can be either tagged or contain arbitrary text. Elements may be nested. Tagged elements begin with an opening section and usually are terminated with a closing section.\t\t\t\n\t\t\t\nExample:\t\t\t\n  <nowiki><greeting a=\"1\" b=\"2\" c=\"3\"> Hello there. </greeting></nowiki>\t\t\t\n\t\t\t\nIn the example above are two elements. The first is a '''tag''' element named ''greeting'' with attributes ''a, b'' and ''c''. The second element is a '''text''' element consisting of \"''Hello there.''\"\t\t\t\n\t\t\t\n===<div class=\"subSectionLineDAT\">XML DAT Operation</div>===\t\t\t\n\t\t\t\nThe XML DAT begins by parsing its input, creating an internal tree of elements.\t\t\t\n\t\t\t\nThe '''Element Scope''' parameters are then used to filter out unwanted elements. The remaining elements are then used to create the output. The format of the output is determined by the '''Format''' parameters. The '''Output''' parameters can then be used to futher limit the information displayed for each scoped element.\t\t\t\n\t\t\t\nEach parsed element contains a number of details:\t\t\t\n\t\t\t\n'''Label''' - Each element is given an arbitrary label named n0, n1, n2 etc. All elements are children of the reserved element labelled 'root'.\t\t\t\n\t\t\t\n'''Type''' - Elements are mainly of type 'tag' or 'text', though tag types can be further classified into 'doctype', 'declaration', 'comment' or 'entity'.\t\t\t\n\t\t\t\n'''Text''' - The text of an element refers to the tag attribute of an element, or the arbitrary text contents. In the above example, the first element would be of type 'tag' and contain text of 'greeting'. The second element would be of type 'text' and contain text of 'Hello there.'\t\t\t\n\t\t\t\n'''Level''' - This describes how deeply nested an element is. For example the single root element always has a level of 0.\t\t\t\n\t\t\t\n'''Parent''' - Each element contains one parent. The root element does not have a parent.\t\t\t\n\t\t\t\n'''Children''' - Each element can have an arbitrary number of children elements.\t\t\t\n\t\t\t\n'''Attributes''' - Each tagged element can have an arbitrary number of attributes. Each attribute consists of a name and a value. In the above example, the greeting tag would contain 3 attributes (with names a, b and c and values 1, 2, and 3 respectively).",
        "opClass": "xmlDAT_Class",
        "short": "The XML DAT can be used to parse arbitrary XML and SGML/HTML formatted data.",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "constantMAT": {
        "label": "constantMAT",
        "members": [
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorr"
            },
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorg"
            },
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorb"
            },
            {
                "text": "TOP : Provides a TOP texture to use as a color map.",
                "type": "Par",
                "name": "colormapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapcoordinterp"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Constant MAT renders a constant color on a material.",
        "opLicense": "Non-Commercial",
        "opFamily": "MAT",
        "opFilter": "False",
        "opLabel": "Constant",
        "opClass": "constantMAT_Class",
        "opType": "constant",
        "long": "The Constant MAT renders a constant color on a material.",
        "opCategories": ""
    },
    "depthMAT": {
        "label": "depthMAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Depth Only MAT can be used to prevent objects from being drawn by making an invisible barrier in Z.",
        "opLicense": "Non-Commercial",
        "opFamily": "MAT",
        "opFilter": "False",
        "opLabel": "Depth",
        "opClass": "depthMAT_Class",
        "opType": "depth",
        "long": "The Depth Only MAT can be used to prevent objects from being drawn by making an invisible barrier in Z.",
        "opCategories": ""
    },
    "glslMAT": {
        "label": "glslMAT",
        "members": [
            {
                "text": "Menu : Pick what version of GLSL to compile the shader with.",
                "type": "Par",
                "name": "glslversion"
            },
            {
                "text": "Menu : The type of geometry that will be inputed into the Geometry Shader.",
                "type": "Par",
                "name": "inprim"
            },
            {
                "text": "Menu : The type of geometry that the Geometry Shader will output.",
                "type": "Par",
                "name": "outprim"
            },
            {
                "text": "Menu : Allows lighting space switch from the current default World Space to legacy Camera Space which was used for TouchDesigner 088.",
                "type": "Par",
                "name": "lightingspace"
            },
            {
                "text": "TOP : This is the TOP that will be referenced by the above sampler name above it.\t\n\t\t\t\t\n'''Exposed by the + Button, texture sampling parameters''':\t\t\t\t\n\t\t\t\t\nRefer to the [[Texture Sampling Parameters]] article for more information on the parameters exposed by pressing the + button. The ''parameter'' prefix for each of the parameters is ''top[digit]''.",
                "type": "Par",
                "name": "top0extendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0extendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0filter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "top0anisotropy"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0x"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0y"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0z"
            },
            {
                "text": "The value to assign to the uniform. If the uniform is a float the first entry of the four is used, if the uniform is a vec2 the first two entries are used, etc.",
                "type": "Par",
                "name": "value0w"
            },
            {
                "text": "Menu : The type of the uniform. You can send up to 4 channels into the GLSL shader in a single uniform. For a CHOP with a single channel declare your uniform as a float, for one with two channels declare your uniform as a vec2, etc. The data is interleaved in the uniform. I.e., the .x component is the 1st channel, .y is the 2nd channel, etc.",
                "type": "Par",
                "name": "chopunitype0"
            },
            {
                "text": "Menu : GPUs can send array data into a GLSL shader using Uniform Arrays or Texture Buffers. A Uniform Array uses very limited memory to store its data, and can be access like any other regular uniform value (but in an array). Texture Buffers use texture memory and texture fetches to access the data, which allows them to store many more values.\t\t\n\t\t\t\t\nIn both cases the index is the 0-based index (an integer) into the array/buffer that you want to get a value for.",
                "type": "Par",
                "name": "choparraytype0"
            },
            {
                "text": "StrMenu : You can select which channels from the CHOP will be used to fill the array. Up to the first 4 channels scoped will be used (depending on the type of the uniform array).",
                "type": "Par",
                "name": "chanscope0"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The GLSL MAT allows you to write or import custom materials into TouchDesigner.",
        "opLicense": "Non-Commercial",
        "opFamily": "MAT",
        "opFilter": "False\t\t\ttexe",
        "opLabel": "GLSL",
        "opClass": "glslMAT_Class",
        "opType": "glsl",
        "long": "The GLSL MAT allows you to write or import custom materials into TouchDesigner. When there are compile errors in a GLSL [[shader]], a blue/red checkerboard ''error'' shader will be displayed.\t\t\t\n\t\t\t\t\nFor more information on writing a shader, see [[Write a GLSL Material]], and the [[:Category:GLSL|GLSL Category]].",
        "opCategories": ""
    },
    "inMAT": {
        "label": "inMAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The In MAT is used to create a  MAT input in a Component.",
        "opLicense": "Non-Commercial",
        "opFamily": "MAT",
        "opFilter": "True",
        "opLabel": "In",
        "opClass": "inMAT_Class",
        "opType": "in",
        "long": "The In MAT is used to create a  MAT input in a Component. Component inputs are positioned alphanumerically on the left side of the Component.",
        "opCategories": ""
    },
    "lineMAT": {
        "label": "lineMAT",
        "members": [
            {
                "text": "dropmenu : Depth Interpolation Model depthmodel \u2013 a menu to select how the width of line items changes by their distance from the camera.",
                "type": "Par",
                "name": "depthinterpolationmodel"
            },
            {
                "text": "dropmenu : If a line is being drawn on a polygon or its edge (the polygon being in another Geometry COMP + shader), and you need to lift it off the surface to be fully visible, this specifies whether to displace the line points toward the camera or along the line's normal (which can be the direction of the polygon's normal).",
                "type": "Par",
                "name": "liftdirection"
            },
            {
                "text": "dropmenu : A menu to select the joint type where two lines segments meet.",
                "type": "Par",
                "name": "linejointtype"
            },
            {
                "text": "dropmenu : A menu to Specify the end cap type at the Line start. You can control the size of each end cap type in the Cap page.",
                "type": "Par",
                "name": "linestartcaptype"
            },
            {
                "text": "dropmenu : A menu to Specify the end cap type at the Line end.",
                "type": "Par",
                "name": "lineendcaptype"
            },
            {
                "text": "Specifies the color value for the Line at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "linenearcolorr"
            },
            {
                "text": "Specifies the color value for the Line at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "linenearcolorg"
            },
            {
                "text": "Specifies the color value for the Line at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "linenearcolorb"
            },
            {
                "text": "Specifies the color value for the Line at the Distance Far plane and beyond (farther from camera).",
                "type": "Par",
                "name": "linefarcolorr"
            },
            {
                "text": "Specifies the color value for the Line at the Distance Far plane and beyond (farther from camera).",
                "type": "Par",
                "name": "linefarcolorg"
            },
            {
                "text": "Specifies the color value for the Line at the Distance Far plane and beyond (farther from camera).",
                "type": "Par",
                "name": "linefarcolorb"
            },
            {
                "text": "dropmenu : A menu to select the Point type.",
                "type": "Par",
                "name": "pointtype"
            },
            {
                "text": "Specifies the color value for the Point at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "pointnearcolorr"
            },
            {
                "text": "Specifies the color value for the Point at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "pointnearcolorg"
            },
            {
                "text": "Specifies the color value for the Point at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "pointnearcolorb"
            },
            {
                "text": "Specifies the color value for the Point at the Distance Far plane and beyond (farther from camera).",
                "type": "Par",
                "name": "pointfarcolorr"
            },
            {
                "text": "Specifies the color value for the Point at the Distance Far plane and beyond (farther from camera).",
                "type": "Par",
                "name": "pointfarcolorg"
            },
            {
                "text": "Specifies the color value for the Point at the Distance Far plane and beyond (farther from camera).",
                "type": "Par",
                "name": "pointfarcolorb"
            },
            {
                "text": "dropmenu : A menu to select the the dirction to lift points.  See parameter Lift Direction.",
                "type": "Par",
                "name": "pointliftdirection"
            },
            {
                "text": "dropmenu : When drawing a vector at each point, this determines where to get the XYZ of the vector. By default it gets it from an attribute of the SOP, the point normal by default. But when instancing is used, you can get it from an instance attribute from an Instance OP. The vector can be represented in world space or in the reference frame of the Geometry COMP.",
                "type": "Par",
                "name": "attributetype"
            },
            {
                "text": "dropmenu : A menu to Specify the end cap type at the Vector start. You can control the size of each end cap type in the Cap page.",
                "type": "Par",
                "name": "vectorstartcaptype"
            },
            {
                "text": "dropmenu : A menu to Specify the end cap type at the Vector end. You can control the size of each end cap type in the Cap page.",
                "type": "Par",
                "name": "vectorendcaptype"
            },
            {
                "text": "Specifies the color value for the Vector at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "vectornearcolorr"
            },
            {
                "text": "Specifies the color value for the Vector at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "vectornearcolorg"
            },
            {
                "text": "Specifies the color value for the Vector at the Distance Near plane and any location closer to camera.",
                "type": "Par",
                "name": "vectornearcolorb"
            },
            {
                "text": "rgb : Specifies the color value for the Vector at the Distance Far plane and beyond (farther from camera).",
                "type": "Par",
                "name": "vectorcolorfar"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFamily": "MAT",
        "opType": "lineMAT",
        "opLabel": "Line",
        "opClass": "lineMAT_Class",
        "opFilter": "False",
        "opLicense": "Non-Commercial",
        "short": "The Line MAT renders 3D line segments, dots and vectors. The line width and color can be varied based on distance to the camera, using two models: a 1/z dropoff (z = distance from camera), or a near-far distance rolloff model, where you set the width and color at the near and far distances, and you vary three rolloff controls.",
        "long": "The Line MAT renders 3D line segments, dots and vectors. The line width and color can be varied based on distance to the camera, using two models: a 1/z dropoff (z = distance from camera), or a near-far distance rolloff model, where you set the width and color at the near and far distances, and you vary three rolloff controls.\n    \nFor lines it renders different types of end caps and hinge/joints (round, box, arrow).\nThe light model is flat-shaded (no affect from scene lighting). It draws edges (like polygon edges), points and vectors from points. There are different parameters to control the desired shape, as explained in the Parameter sections.\nIt renders several primitive types: polygons, meshes, NURBS, quads, etc. It also manages closed polygons / open polygons.\n\nYou can render a dot at each point. You can render a vector at each point which uses any attribute, like Normal (N). The points or vectors can have their own colors and alpha.\n\nLine Width is a resolution-independent quantity. A line width of 1 will draw a line that is 1/1000 the width of the image. This is true when used with orthographic cameras and perspective cameras. \n\nTo make the width of a line and its points vary per-point of a SOP, the width can be set by adding a point attribute <code>width</code> on the SOP being rendered. A value of 2 scales the width at that point by 2 times its normal width. New point attributes can be created with the [[Point SOP]] Custom page. To affect per-point width and not affect the line width, use the point attribute <code>pscale</code>.\n\nWhen you are animating Ortho Width or Field of View, you may want line widths to adjust more realistically. When the parameter \"Width Affected by FOV/Ortho Width\" is on, the behavior is different: For Ortho cameras, the drawn line width increases when Ortho Width drops below 1, (as if you are zooming into it), and decreases when Ortho Width increases above 1. For Perspective cameras, the drawn line width increases when Field of View drops below 90 degrees, and decreases when Field of View increases above 90 degrees. Note that when the parameter \"Width Affected by FOV/Ortho Width\" is on, lines are still resolution-independent.\n\nIntro article here from Interactive Immersive HQ: [https://interactiveimmersive.io/blog/3d/new-superpowers-touchdesigners-line-mat/ new-superpowers-touchdesigners-line-mat/]",
        "opCategories": ""
    },
    "MAT": {
        "label": "NotSet",
        "members": [
            {
                "text": "Menu : This value is multiplied by the color value of the pixel that is being written to the Color-Buffer (also know as the Source Color).",
                "type": "Par",
                "name": ""
            },
            {
                "text": "Menu : This value is multiplied by the color value of the pixel currently in the Color-Buffer (also known as the Destination Color).",
                "type": "Par",
                "name": ""
            },
            {
                "text": "Menu : This value is multiplied by the alpha value of the pixel that is being written to the Color-Buffer (also know as the Source Alpha).",
                "type": "Par",
                "name": ""
            },
            {
                "text": "Menu : This value is multiplied by the alpha value of the pixel currently in the Color-Buffer (also known as the Destination Alpha).",
                "type": "Par",
                "name": ""
            },
            {
                "text": "Menu : The depth value of the pixel being drawn is compared to the depth value currently in the depth-buffer using this function. If the test passes then the pixel is drawn to the Frame-Buffer. If the test fails the pixel is discarded and no changes are made to the Frame-Buffer.",
                "type": "Par",
                "name": ""
            },
            {
                "text": "Menu : This menu works in conjunction with the Alpha Threshold parameter below in determining which pixels to keep based on their alpha value.",
                "type": "Par",
                "name": ""
            },
            {
                "text": "Menu : Enables and disables wire-frame rendering with the option of OpenGL Tesselated or Topology based wireframes.",
                "type": "Par",
                "name": ""
            },
            {
                "text": "Menu : Selects which faces to render.",
                "type": "Par",
                "name": ""
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": []
    },
    "nullMAT": {
        "label": "nullMAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Null MAT has no effect on the data. It is an instance of the MAT connected to its input.",
        "opLicense": "Non-Commercial",
        "opFamily": "MAT",
        "opFilter": "True",
        "opLabel": "Null",
        "opClass": "nullMAT_Class",
        "opType": "null",
        "long": "The Null MAT has no effect on the data. It is an instance of the MAT connected to its input. It doesn't do much but comes in handy when building networks.",
        "opCategories": ""
    },
    "outMAT": {
        "label": "outMAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The Out MAT is used to create a  MAT output in a Component.",
        "opLicense": "Non-Commercial",
        "opFamily": "MAT",
        "opFilter": "False",
        "opLabel": "Out",
        "opClass": "outMAT_Class",
        "opType": "out",
        "long": "The Out MAT is used to create a  MAT output in a Component. Component outputs are positioned alphanumerically on the right side of the Component.",
        "opCategories": ""
    },
    "pbrMAT": {
        "label": "pbrMAT",
        "members": [
            {
                "text": "Base color of the texture, used to calculate diffuse and specular contributions.",
                "type": "Par",
                "name": "basecolorr"
            },
            {
                "text": "Base color of the texture, used to calculate diffuse and specular contributions.",
                "type": "Par",
                "name": "basecolorg"
            },
            {
                "text": "Base color of the texture, used to calculate diffuse and specular contributions.",
                "type": "Par",
                "name": "basecolorb"
            },
            {
                "text": "This is the color that the material will emit even if there is no light.",
                "type": "Par",
                "name": "emitr"
            },
            {
                "text": "This is the color that the material will emit even if there is no light.",
                "type": "Par",
                "name": "emitg"
            },
            {
                "text": "This is the color that the material will emit even if there is no light.",
                "type": "Par",
                "name": "emitb"
            },
            {
                "text": "Adds to the final color. Where there are point colors, finalcolor += Point Color * Constant Color. This behaves like there is ambient illumination of 1 1 1. It is not affected by textures or transparency.",
                "type": "Par",
                "name": "constantr"
            },
            {
                "text": "Adds to the final color. Where there are point colors, finalcolor += Point Color * Constant Color. This behaves like there is ambient illumination of 1 1 1. It is not affected by textures or transparency.",
                "type": "Par",
                "name": "constantg"
            },
            {
                "text": "Adds to the final color. Where there are point colors, finalcolor += Point Color * Constant Color. This behaves like there is ambient illumination of 1 1 1. It is not affected by textures or transparency.",
                "type": "Par",
                "name": "constantb"
            },
            {
                "text": "Menu : Controls how the polygon's normal is used to light the front face of the polygon. For more information refer to the [[Two-Sided Lighting]] article.",
                "type": "Par",
                "name": "frontfacelit"
            },
            {
                "text": "Menu : Back Face's</span> <code>backfacelit</code> - Controls how the polygon's normal is used to light the back face of the polygon. For more information refer to the [[Two-Sided Lighting]] article.",
                "type": "Par",
                "name": "backfacelit"
            },
            {
                "text": "TOP : Clicking on the arrows to the right of the map field will open the [[Texture Sampling Parameters]] for Color Map.  The other Map parameters below will have their own Texture Sampling Parameters as well.",
                "type": "Par",
                "name": "basecolormapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "basecolormapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "basecolormapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "basecolormapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "basecolormapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "basecolormapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "basecolormapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "basecolormapcoordinterp"
            },
            {
                "text": "TOP : Specifies a specular level map.",
                "type": "Par",
                "name": "specularlevelmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specularlevelmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specularlevelmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specularlevelmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specularlevelmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specularlevelmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specularlevelmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specularlevelmapcoordinterp"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specularlevelmapchannelsource"
            },
            {
                "text": "TOP : Specifies a metallic texture map. This is equivalent to the Metallic map in Substance Designer.",
                "type": "Par",
                "name": "metalnessmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "metalnessmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "metalnessmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "metalnessmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "metalnessmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "metalnessmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "metallicmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "metallicmapcoordinterp"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "metallicmapchannelsource"
            },
            {
                "text": "TOP : Specifies a roughness texture map. This is equivalent to the Roughness map in Substance Designer.",
                "type": "Par",
                "name": "roughnessmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "roughnessmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "roughnessmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "roughnessmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "roughnessmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "roughnessmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "roughnessmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "roughnessmapcoordinterp"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "roughnessmapchannelsource"
            },
            {
                "text": "TOP : Specifies a ambient occlusion texture map. This is equivalent to the Ambient Occlusion map in Substance Designer. Ambient Occlusion affects the contribution from the Environement Light COMP.",
                "type": "Par",
                "name": "ambientocclusionmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "ambientocclusionmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "ambientocclusionmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "ambientocclusionmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "ambientocclusionmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "ambientocclusionmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "ambientocclusionmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "ambientocclusionmapcoordinterp"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "ambientocclusionmapchannelsource"
            },
            {
                "text": "TOP : Uses a [[Normal Map TOP|Normal Map]] from TOPs to create a 'bump map' effect. Bump-mapping simulates bumps or wrinkles in a surface to give it a 3D depth effect. Your geometry must have tangent attributes created for this feature to work (T[4]). Create these using the [[Attribute Create SOP]].",
                "type": "Par",
                "name": "normalmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapcoordinterp"
            },
            {
                "text": "TOP : Specifies a height texture map. This is equivalent to the Height map in Substance Designer. The height map is used in conjunction with the normal map to perform parallax mapping.",
                "type": "Par",
                "name": "heightmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapcoordinterp"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapchannelsource"
            },
            {
                "text": "TOP : Specifies a TOP texture that is multiplied with the Emit color parameter of the material. The object must have texture coordinates. The alpha of this map is ignored.",
                "type": "Par",
                "name": "emitmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapcoordinterp"
            },
            {
                "text": "TOP : This map multiplies the alpha of the object. It uses the red channel of the map, other channels are ignored.",
                "type": "Par",
                "name": "alphamapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapcoordinterp"
            },
            {
                "text": "TOP : This map will multiple the calculated rim light color.",
                "type": "Par",
                "name": "rim1mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapcoordinterp"
            },
            {
                "text": "The color of the rim light.",
                "type": "Par",
                "name": "rim1colorr"
            },
            {
                "text": "The color of the rim light.",
                "type": "Par",
                "name": "rim1colorg"
            },
            {
                "text": "The color of the rim light.",
                "type": "Par",
                "name": "rim1colorb"
            },
            {
                "text": "The color that will be used in shadowed areas.",
                "type": "Par",
                "name": "shadowcolorr"
            },
            {
                "text": "The color that will be used in shadowed areas.",
                "type": "Par",
                "name": "shadowcolorg"
            },
            {
                "text": "The color that will be used in shadowed areas.",
                "type": "Par",
                "name": "shadowcolorb"
            },
            {
                "text": "The color that is used for areas that are in darkness.",
                "type": "Par",
                "name": "darknessemitcolorr"
            },
            {
                "text": "The color that is used for areas that are in darkness.",
                "type": "Par",
                "name": "darknessemitcolorg"
            },
            {
                "text": "The color that is used for areas that are in darkness.",
                "type": "Par",
                "name": "darknessemitcolorb"
            },
            {
                "text": "TOP : This map multiplies the <span class=\"tipTextMAT\">Darkness Emit Color</span>. This maps alpha is not used.",
                "type": "Par",
                "name": "darknessemitmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapcoordinterp"
            },
            {
                "text": "StrMenu : When provider per-instance textures in the [[Geometry COMP]], this parameter selects which map the instance texture will be applied as.",
                "type": "Par",
                "name": "instancetexture"
            },
            {
                "text": "StrMenu : Allows sending things like normals or emit color to different Render TOP color buffers in a single pass.",
                "type": "Par",
                "name": "colorbuffer1rgb"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "short": "The PBR MAT creates a material using a Physically Based Rendering (PBR) lighting model.",
        "opLicense": "Non-Commercial",
        "opFamily": "MAT",
        "opFilter": "False",
        "opLabel": "PBR",
        "opClass": "pbrMAT_Class",
        "opType": "pbr",
        "long": "The PBR MAT creates a material using a Physically Based Rendering (PBR) lighting model. It has support for textures, reflections, bumps, cone lights, rim lights, alpha maps and more. \t\t\t\n\t\t\t\t\nIt also supports most [https://substance3d.adobe.com/community-assets Adobe Substance 3D Designer] PBR materials loaded in the [[Substance TOP]]. \t\t\t\t\n\t\t\t\t\nYou can output its [[:Category:GLSL|GLSL shader]] into two [[DAT]]s for further adaptation in a [[GLSL MAT]] by using the Output Shader parameter.\t\t\t\t\n\t\t\t\t\nThis OP creates physically based materials from texture maps you assign to it and works with any content pipeline whether you use Maya, Houdini, Unreal, Photoshop etc.\n\nYou can get more PBR materials from PBR texture libraries such as [http://quixel.se/ Quixel] and [http://www.poliigon.com/ Poliigon] and [https://gametextures.com/freebies Game Textures].\nSee also: [[Substance TOP]].",
        "opCategories": ""
    },
    "phongMAT": {
        "label": "phongMAT",
        "members": [
            {
                "text": "The color of the diffuse light reflected from the material.",
                "type": "Par",
                "name": "diffr"
            },
            {
                "text": "The color of the diffuse light reflected from the material.",
                "type": "Par",
                "name": "diffg"
            },
            {
                "text": "The color of the diffuse light reflected from the material.",
                "type": "Par",
                "name": "diffb"
            },
            {
                "text": "The color of the ambient light reflected from the material.",
                "type": "Par",
                "name": "ambr"
            },
            {
                "text": "The color of the ambient light reflected from the material.",
                "type": "Par",
                "name": "ambg"
            },
            {
                "text": "The color of the ambient light reflected from the material.",
                "type": "Par",
                "name": "ambb"
            },
            {
                "text": "The color of the specular light reflected from the material. This changes the color of the highlights on shiney objects.",
                "type": "Par",
                "name": "specr"
            },
            {
                "text": "The color of the specular light reflected from the material. This changes the color of the highlights on shiney objects.",
                "type": "Par",
                "name": "specg"
            },
            {
                "text": "The color of the specular light reflected from the material. This changes the color of the highlights on shiney objects.",
                "type": "Par",
                "name": "specb"
            },
            {
                "text": "This is the color that the material will emit even if there is no light.",
                "type": "Par",
                "name": "emitr"
            },
            {
                "text": "This is the color that the material will emit even if there is no light.",
                "type": "Par",
                "name": "emitg"
            },
            {
                "text": "This is the color that the material will emit even if there is no light.",
                "type": "Par",
                "name": "emitb"
            },
            {
                "text": "Adds to the final color. Where there are point colors, finalcolor += Point Color * Constant Color. This behaves like there is ambient illumination of 1 1 1. It is not affected by textures or transparency.",
                "type": "Par",
                "name": "constantr"
            },
            {
                "text": "Adds to the final color. Where there are point colors, finalcolor += Point Color * Constant Color. This behaves like there is ambient illumination of 1 1 1. It is not affected by textures or transparency.",
                "type": "Par",
                "name": "constantg"
            },
            {
                "text": "Adds to the final color. Where there are point colors, finalcolor += Point Color * Constant Color. This behaves like there is ambient illumination of 1 1 1. It is not affected by textures or transparency.",
                "type": "Par",
                "name": "constantb"
            },
            {
                "text": "TOP : Specifies a TOP texture that is multiplied by the results of all of the lighting calculations. The alpha of this map is used as a part of calculating the objects alpha.  Clicking on the arrows to the right of the map field will open the [[Texture Sampling Parameters]] for Color Map.  The other Map parameters below will have their own Texture Sampling Parameters as well.",
                "type": "Par",
                "name": "colormapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapcoordinterp"
            },
            {
                "text": "TOP : Uses a [[Normal Map TOP|Normal Map]] from TOPs to create a 'bump map' effect. Bump-mapping simulates bumps or wrinkles in a surface to give it a 3D depth effect. '''Your geometry must have tangent attributes created for this feature to work (T[4]). Create these using the [[Attribute Create SOP]].'''",
                "type": "Par",
                "name": "normalmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "normalmapcoordinterp"
            },
            {
                "text": "TOP : Specifies a height texture map. The height map is used in conjunction with the normal map to perform parallax mapping.",
                "type": "Par",
                "name": "heightmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapcoordinterp"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "heightmapchannelsource"
            },
            {
                "text": "TOP : Specifies a TOP that multiples the Diffuse Color. The object must have texture coordinates. The alpha of this map is ignored.",
                "type": "Par",
                "name": "diffusemapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "diffusemapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "diffusemapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "diffusemapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "diffusemapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "diffusemapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "diffusemapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "diffusemapcoordinterp"
            },
            {
                "text": "TOP : Specifies a TOP texture that is multiplied with the Specular color parameter of the material. The object must have texture coordinates. The alpha of this map is ignored.",
                "type": "Par",
                "name": "specmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "specmapcoordinterp"
            },
            {
                "text": "TOP : Specifies a TOP texture that is multiplied with the Emit color parameter of the material. The object must have texture coordinates. The alpha of this map is ignored.",
                "type": "Par",
                "name": "emitmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "emitmapcoordinterp"
            },
            {
                "text": "TOP : Uses a TOP texture to define an environment map for the material. Environment mapping simulates an object reflecting its surroundings. The TOP defined in this parameter is the texture that will be reflected. The Env Map is added to whatever the normal lighting will be, so to make an object purely reflective turn the Diffuse and Specular parameters to 0. This input expects a sphere map. An example of a sphere map can be found [http://debevec.org/Probes/campus_probe.jpg here]. This input will also accept a cube map, created with the [[Cube Map TOP]] or the [[Render TOP]]'s Render Cube Map parameter.",
                "type": "Par",
                "name": "envmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "envmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "envmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "envmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "envmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "envmapanisotropy"
            },
            {
                "text": "This color is multiplied with the texture specified by the <span class=\"tipTextMAT\">Environment Map</span> parameter above.",
                "type": "Par",
                "name": "envmapcolorr"
            },
            {
                "text": "This color is multiplied with the texture specified by the <span class=\"tipTextMAT\">Environment Map</span> parameter above.",
                "type": "Par",
                "name": "envmapcolorg"
            },
            {
                "text": "This color is multiplied with the texture specified by the <span class=\"tipTextMAT\">Environment Map</span> parameter above.",
                "type": "Par",
                "name": "envmapcolorb"
            },
            {
                "text": "Rotate the texture specified by the <span class=\"tipTextMAT\">Environment Map</span> parameter above.",
                "type": "Par",
                "name": "envmaprotatex"
            },
            {
                "text": "Rotate the texture specified by the <span class=\"tipTextMAT\">Environment Map</span> parameter above.",
                "type": "Par",
                "name": "envmaprotatey"
            },
            {
                "text": "Rotate the texture specified by the <span class=\"tipTextMAT\">Environment Map</span> parameter above.",
                "type": "Par",
                "name": "envmaprotatez"
            },
            {
                "text": "Menu : Select between using a sphere map or an equirectangular map as the Environment Map type.",
                "type": "Par",
                "name": "envmaptype2d"
            },
            {
                "text": "Menu : Controls how the polygon's normal is used to light the front face of the polygon. For more information refer to the [[Two-Sided Lighting]] article.",
                "type": "Par",
                "name": "frontfacelit"
            },
            {
                "text": "Menu : Controls how the polygon's normal is used to light the back face of the polygon. For more information refer to the [[Two-Sided Lighting]] article.",
                "type": "Par",
                "name": "backfacelit"
            },
            {
                "text": "TOP : This map multiplies the alpha of the object. It uses the red channel of the map, other channels are ignored.",
                "type": "Par",
                "name": "alphamapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "alphamapcoordinterp"
            },
            {
                "text": "TOP : You can specify up to 4 textures for multi-texturing.",
                "type": "Par",
                "name": "texture1mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture1mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture1mapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture1mapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture1mapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture1mapanisotropy"
            },
            {
                "text": "Menu : Specifies which texture coordinate to use for the map.",
                "type": "Par",
                "name": "texture1coord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture1coordinterp"
            },
            {
                "text": "TOP : You can specify up to 4 textures for multi-texturing.",
                "type": "Par",
                "name": "texture2mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture2mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture2mapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture2mapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture2mapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture2mapanisotropy"
            },
            {
                "text": "Menu : Specifies which texture coordinate to use for the map.",
                "type": "Par",
                "name": "texture2coord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture2coordinterp"
            },
            {
                "text": "TOP : You can specify up to 4 textures for multi-texturing.",
                "type": "Par",
                "name": "texture3mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture3mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture3mapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture3mapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture3mapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture3mapanisotropy"
            },
            {
                "text": "Menu : Specifies which texture coordinate to use for the map.",
                "type": "Par",
                "name": "texture3coord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture3coordinterp"
            },
            {
                "text": "TOP : You can specify up to 4 textures for multi-texturing.",
                "type": "Par",
                "name": "texture4mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture4mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture4mapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture4mapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture4mapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture4mapanisotropy"
            },
            {
                "text": "Menu : Specifies which texture coordinate to use for the map.",
                "type": "Par",
                "name": "texture4coord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "texture4coordnterp"
            },
            {
                "text": "TOP : This map will multiple the calculated rim light color.",
                "type": "Par",
                "name": "rim1mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "rim1mapcoordinterp"
            },
            {
                "text": "The color of the rim light.",
                "type": "Par",
                "name": "rim1colorr"
            },
            {
                "text": "The color of the rim light.",
                "type": "Par",
                "name": "rim1colorg"
            },
            {
                "text": "The color of the rim light.",
                "type": "Par",
                "name": "rim1colorb"
            },
            {
                "text": "The color that will be used in shadowed areas.",
                "type": "Par",
                "name": "shadowcolorr"
            },
            {
                "text": "The color that will be used in shadowed areas.",
                "type": "Par",
                "name": "shadowcolorg"
            },
            {
                "text": "The color that will be used in shadowed areas.",
                "type": "Par",
                "name": "shadowcolorb"
            },
            {
                "text": "The color that is used for areas that are in darkness.",
                "type": "Par",
                "name": "darknessemitcolorr"
            },
            {
                "text": "The color that is used for areas that are in darkness.",
                "type": "Par",
                "name": "darknessemitcolorg"
            },
            {
                "text": "The color that is used for areas that are in darkness.",
                "type": "Par",
                "name": "darknessemitcolorb"
            },
            {
                "text": "TOP : This map multiplies the <span class=\"tipTextMAT\">Darkness Emit Color</span>. This maps alpha is not used.",
                "type": "Par",
                "name": "darknessemitmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapanisotropy"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapcoord"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "darknessemitmapcoordinterp"
            },
            {
                "text": "Adds a secondary specular highlight color.",
                "type": "Par",
                "name": "spec2r"
            },
            {
                "text": "Adds a secondary specular highlight color.",
                "type": "Par",
                "name": "spec2g"
            },
            {
                "text": "Adds a secondary specular highlight color.",
                "type": "Par",
                "name": "spec2b"
            },
            {
                "text": "StrMenu : When provider per-instance textures in the [[Geometry COMP]], this parameter selects which map the instance texture will be applied as.",
                "type": "Par",
                "name": "instancetexture"
            },
            {
                "text": "StrMenu : Allows sending things like normals or diffuse color to different Render TOP color buffers in a single pass.",
                "type": "Par",
                "name": "colorbuffer1rgb"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Phong",
        "opFamily": "MAT",
        "long": "The Phong MAT creates a material using the Phong Shading model. It has support for textures, reflections, bumps, cone lights, rim lights, alpha maps and more. You can output its [[:Category:GLSL|GLSL shader]] into two [[DAT]]s for further adaptation in a [[GLSL MAT]] by using the Output Shader parameter.\t\t\t\n\t\t\t\t\nPhong Shading models three types of reflected light:\t\t\t\t\n\t\t\t\t\n* Ambient - Ambient is considered light that does not come from any particular direction and is therefore constant across the surface. In the physical world, ambient light is created from the reflection of light off surfaces in the environment.\t\t\t\t\n* Diffuse - Diffuse models the light reflected by matte surfaces. This light is reflected equally in all directions, therefore the position of the observer does not effect the percieved illumination.\t\t\t\t\n* Specular - Specular models the light reflected by glossy surfaces. This light is reflected mainly in the direction of the reflected ray and is attenuated by the 'shiny-ness' of an object. Since the light reflected from the surface is mainly in the direction of the reflected ray, the position of the observer determines the specular highlight on the surface.\t\t\t\t\n\t\t\t\t\n<blockquote>\t\t\t\t\n'''NOTE:''' We see the color of an object because of the color of light that the material reflects.\t\n</blockquote>\t\t\t\t\n\t\t\t\t\nPhong Shading produces very nice specular highlights, although it is still an approximation and not physically accurate.  Contrasting with the Gouraud shading model that calculates the lighting at each vertex and interpolates the value across the polygon, Phong calculates the lighting at each pixel.\n\nTo see how all of the different parts are summed together by looking at the [[Phong Lighting Equation]] article.",
        "opClass": "phongMAT_Class",
        "short": "The Phong MAT creates a material using the Phong Shading model.",
        "opType": "phong",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "pointspriteMAT": {
        "label": "pointspriteMAT",
        "members": [
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorr"
            },
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorg"
            },
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorb"
            },
            {
                "text": "TOP : The color map to apply to the sprites. The Color Map will be multiplied by the color of the sprites. The Color Map parameter can also take 3D / 2D Texture Arrays (from the [[Texture 3D TOP]] for example), and the w texture coordinate will select the correct map from the array.\t\t\n\t\t\t\t\nThe final size of the point sprite is controlled by the pscale point attribute (if present) getting multiplied of the result of the next 6 parameters. There are two types of scale this MAT can apply, and they are blended using the Attenuate Point Scale parameter to create one final point scale (which is multiplied by pscale).",
                "type": "Par",
                "name": "colormapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendu"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendv"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapextendw"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapfilter"
            },
            {
                "text": "Menu : ",
                "type": "Par",
                "name": "colormapanisotropy"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Point Sprite",
        "opFamily": "MAT",
        "long": "The Point Sprite MAT allows you to control some attributes of Point Sprites (creatable using the [[Particle SOP]], [[DAT to SOP]], or [[Convert SOP]]). You can apply color, a color map, change the size of the created point sprite from a square to a rectangle, and scale the size of the point sprite.\t\t\t\n\t\t\t\t\nA point sprite's final size controls the number of pixels wide/high it is, regardless of how far it is from the camera (unless you are using attenuation).",
        "opClass": "pointspriteMAT_Class",
        "short": "The Point Sprite MAT allows you to control some attributes of Point Sprites (creatable using the [[Particle SOP]] or [[DAT to SOP]]).",
        "opType": "pointsprite",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "selectMAT": {
        "label": "selectMAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Select",
        "opFamily": "MAT",
        "long": "The Select MAT gets another material from any location in the project.",
        "opClass": "selectMAT_Class",
        "short": "The Select MAT gets another material from any location in the project.",
        "opType": "select",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "switchMAT": {
        "label": "switchMAT",
        "members": [],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "True",
        "opLabel": "Switch",
        "opFamily": "MAT",
        "long": "The Switch MAT allows you to switch between multiple materials.",
        "opClass": "switchMAT_Class",
        "short": "The Switch MAT allows you to switch between multiple materials.",
        "opType": "switch",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    },
    "wireframeMAT": {
        "label": "wireframeMAT",
        "members": [
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorr"
            },
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorg"
            },
            {
                "text": "The color of the light reflected from the material.",
                "type": "Par",
                "name": "colorb"
            },
            {
                "text": "Menu : Controls what wireframes are rendered.",
                "type": "Par",
                "name": "wireframemode"
            }
        ],
        "methods": [],
        "subclasses": {},
        "inherits": [],
        "opFilter": "False",
        "opLabel": "Wireframe",
        "opFamily": "MAT",
        "long": "The Wireframe MAT renders the edges of polygons and curves as lines.",
        "opClass": "wireframeMAT_Class",
        "short": "The Wireframe MAT renders the edges of polygons and curves as lines.",
        "opType": "wireframe",
        "opLicense": "Non-Commercial",
        "opCategories": ""
    }
}